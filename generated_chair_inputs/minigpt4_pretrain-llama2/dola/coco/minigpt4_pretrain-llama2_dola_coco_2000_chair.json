{"overall": {"Bleu_1": 0.2983679532853717, "Bleu_2": 0.19940220319955987, "Bleu_3": 0.12816848072728643, "Bleu_4": 0.08289696632684411, "METEOR": 0.2272973682653733, "ROUGE_L": 0.303607523812116, "CIDEr": 0.09885726818607715, "SPICE": 0.19071427869548513}, "imgToEval": {"281533": {"image_id": 281533, "Bleu_1": 0.4411764705752596, "Bleu_2": 0.32703497007409993, "Bleu_3": 0.27168347305382384, "Bleu_4": 0.23847864361324922, "METEOR": 0.3880826973824259, "ROUGE_L": 0.46763202725724023, "CIDEr": 0.0009243237095051215, "SPICE": {"All": {"pr": 0.25, "re": 0.36363636363636365, "f": 0.2962962962962963, "fn": 14.0, "numImages": 1.0, "fp": 24.0, "tp": 8.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.09090909090909091, "f": 0.09090909090909091, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.5, "f": 0.2, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.6666666666666666, "f": 0.5454545454545455, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "A small dog is sitting in front of a television, watching a show. The dog is wearing a collar and looking up at the screen. The room is decorated with plants and a couch."}, "397773": {"image_id": 397773, "Bleu_1": 0.12499999999857957, "Bleu_2": 0.07580980435702393, "Bleu_3": 0.04058050371253319, "Bleu_4": 5.2952118952188235e-06, "METEOR": 0.14758895611545755, "ROUGE_L": 0.16917591125198098, "CIDEr": 1.64844466200136e-36, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.19230769230769232, "f": 0.23255813953488372, "fn": 21.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "This image shows a bowl of pasta with meatballs, broccoli, and cheese. The pasta is cooked and has a golden brown color, while the meatballs are cooked through and have a crispy exterior. The broccoli is steamed and has a green color, and the cheese is melted and has a yellow color. The bowl is made of white ceramic and has a red and white checkered pattern on the side. There is a fork on the side of the bowl, and the overall presentation is simple and elegant."}, "371250": {"image_id": 371250, "Bleu_1": 0.26315789472991696, "Bleu_2": 0.14607233344869358, "Bleu_3": 8.399971471326652e-07, "Bleu_4": 2.0285762996808684e-09, "METEOR": 0.1641189248793914, "ROUGE_L": 0.26483357452966716, "CIDEr": 3.3604833776928066e-05, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.12, "f": 0.11764705882352941, "fn": 22.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This is an image of a couch with two pillows on it. The couch is brown in color and has a pattern of palm trees on it. There are two lamps on the table next to the couch."}, "573877": {"image_id": 573877, "Bleu_1": 0.5882352940830451, "Bleu_2": 0.3321055820573897, "Bleu_3": 0.24499865249946995, "Bleu_4": 0.1800282927025759, "METEOR": 0.2618980775388274, "ROUGE_L": 0.44248704663212435, "CIDEr": 0.7832270319338417, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.13636363636363635, "f": 0.15384615384615383, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "A white cat sitting on a laptop with its paws on the keyboard, looking at the screen."}, "181859": {"image_id": 181859, "Bleu_1": 0.24999999999652778, "Bleu_2": 0.20555661294538444, "Bleu_3": 0.12188830570609638, "Bleu_4": 1.2727973355219968e-05, "METEOR": 0.2472335556460401, "ROUGE_L": 0.2459677419354839, "CIDEr": 1.9918191069084015e-22, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.10526315789473684, "f": 0.11764705882352941, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "This is an image of a cat laying on top of a sink in a bathroom. The cat is looking up at the camera with its eyes closed. The sink is made of white marble and has a faucet on the right side. There is a towel hanging on the left side of the sink. The walls are painted white and there is a window on the right side of the image."}, "119939": {"image_id": 119939, "Bleu_1": 0.27272727271487607, "Bleu_2": 0.11396057645433466, "Bleu_3": 8.65950551279142e-07, "Bleu_4": 2.4178614975561836e-09, "METEOR": 0.11995668833535127, "ROUGE_L": 0.20938215102974828, "CIDEr": 0.019484114297337686, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.3076923076923077, "f": 0.21621621621621623, "fn": 9.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A group of people skateboarding on the sidewalk in front of a building\""}, "385320": {"image_id": 385320, "Bleu_1": 0.29999999999250004, "Bleu_2": 0.23204774044025303, "Bleu_3": 0.17829685970436746, "Bleu_4": 0.1464157017197837, "METEOR": 0.30594638918459593, "ROUGE_L": 0.34078212290502796, "CIDEr": 1.3245147694689096e-05, "SPICE": {"All": {"pr": 0.2571428571428571, "re": 0.42857142857142855, "f": 0.3214285714285714, "fn": 12.0, "numImages": 1.0, "fp": 26.0, "tp": 9.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}}, "caption": "The image shows a young girl sitting on the floor, holding a toothbrush in her mouth. She is wearing a striped shirt and white shorts. The room appears to be a bedroom, with a bed and dresser in the background."}, "490415": {"image_id": 490415, "Bleu_1": 0.35483870966597303, "Bleu_2": 0.26639771382432886, "Bleu_3": 0.16978435204742748, "Bleu_4": 2.044719497965893e-05, "METEOR": 0.30570858369428827, "ROUGE_L": 0.3885350318471337, "CIDEr": 0.00278306108462014, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.13793103448275862, "f": 0.13793103448275862, "fn": 25.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 17.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a man standing in a park, holding a kite and flying it in the air. The sky is clear and there are trees and buildings in the background."}, "432293": {"image_id": 432293, "Bleu_1": 0.3333333333247864, "Bleu_2": 0.2477973138852387, "Bleu_3": 0.11839421659860744, "Bleu_4": 1.465285462748969e-05, "METEOR": 0.2526423889823177, "ROUGE_L": 0.3559445660102115, "CIDEr": 7.4956089700297546e-06, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.12, "f": 0.1276595744680851, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "This image shows a pizza on a wooden cutting board with various toppings such as shrimp, tomatoes, and cheese. There is also a knife and a spatula on the board. The pizza appears to be ready to be served."}, "256301": {"image_id": 256301, "Bleu_1": 0.45454545453168055, "Bleu_2": 0.315328111933741, "Bleu_3": 0.21269713851710706, "Bleu_4": 0.13382613079577468, "METEOR": 0.24794655013816444, "ROUGE_L": 0.30886075949367087, "CIDEr": 0.005766150541359117, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.13793103448275862, "f": 0.1509433962264151, "fn": 25.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a large neon sign with the words \"Public Market\" written in red letters on a black background. The sign is surrounded by people standing on the sidewalk, looking at it."}, "361103": {"image_id": 361103, "Bleu_1": 0.39999999999200003, "Bleu_2": 0.27105237086609907, "Bleu_3": 0.18293988070876474, "Bleu_4": 0.1068333456439781, "METEOR": 0.23501114314437918, "ROUGE_L": 0.326397146254459, "CIDEr": 9.75646589163526e-07, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.13043478260869565, "f": 0.1333333333333333, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a street scene with people walking on the sidewalk. There are several buildings on the left and right sides of the street, including a bank and a restaurant. The street is lined with red traffic lights and there are cars parked on the side of the road."}, "567562": {"image_id": 567562, "Bleu_1": 0.16666666666468255, "Bleu_2": 0.10020060200582526, "Bleu_3": 0.06256319725020774, "Bleu_4": 7.415115950320124e-06, "METEOR": 0.209688790480784, "ROUGE_L": 0.19117976270427578, "CIDEr": 1.0829888375300742e-30, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.19047619047619047, "f": 0.18604651162790697, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of people sitting around a table with plates of food in front of them. There are two adults and two children at the table, all of whom are smiling and enjoying their meal. The table is covered with a red and white checkered tablecloth, and there are several chairs around it. The walls of the room are painted a light blue color, and there are several windows on the opposite side of the room that let in natural light."}, "448320": {"image_id": 448320, "Bleu_1": 0.27536231883658896, "Bleu_2": 0.20123234991383482, "Bleu_3": 0.13421269446231296, "Bleu_4": 0.0777963484108558, "METEOR": 0.2180680175638774, "ROUGE_L": 0.25884016973125884, "CIDEr": 1.296745853174725e-18, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.10714285714285714, "f": 0.11111111111111112, "fn": 25.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.25, "f": 0.2608695652173913, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is a bathroom with a sink, toilet, and mirror. The sink is made of wood and has a large bowl for washing hands. The toilet is a standard white porcelain toilet with a seat and lid. The mirror is mounted on the wall above the sink and has a light fixture above it. There is a window on the wall opposite the sink that lets in natural light."}, "14874": {"image_id": 14874, "Bleu_1": 0.3255813953412656, "Bleu_2": 0.23294541396842086, "Bleu_3": 0.17428559286486234, "Bleu_4": 0.14115992921770773, "METEOR": 0.27773942528483964, "ROUGE_L": 0.30521801286633315, "CIDEr": 4.176957159806204e-07, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.21052631578947367, "f": 0.21621621621621623, "fn": 15.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.6, "f": 0.4615384615384615, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a man standing in the snow with skis and poles. He is wearing a blue jacket and black pants, and has a pair of goggles on his face. The background is a mountain range with snow covered peaks and trees."}, "373713": {"image_id": 373713, "Bleu_1": 0.4090909090723141, "Bleu_2": 0.2791452631065508, "Bleu_3": 0.2269432455075259, "Bleu_4": 0.18728674626942446, "METEOR": 0.2771714886600897, "ROUGE_L": 0.3489702517162472, "CIDEr": 0.05455539730409441, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.13636363636363635, "f": 0.1714285714285714, "fn": 19.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A group of people sitting around a table, discussing something on their laptops.\""}, "539326": {"image_id": 539326, "Bleu_1": 0.4999999999687501, "Bleu_2": 0.4472135954710755, "Bleu_3": 0.3851713570850814, "Bleu_4": 0.30620490880240453, "METEOR": 0.5211394711237674, "ROUGE_L": 0.6740331491712707, "CIDEr": 0.8830568600606457, "SPICE": {"All": {"pr": 0.07894736842105263, "re": 0.21428571428571427, "f": 0.11538461538461539, "fn": 11.0, "numImages": 1.0, "fp": 35.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.1875, "re": 0.5, "f": 0.2727272727272727, "fn": 3.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}}, "caption": "A herd of cows grazes in a green field with a blue sky in the background."}, "20059": {"image_id": 20059, "Bleu_1": 0.18421052631094187, "Bleu_2": 0.1222128823790783, "Bleu_3": 0.09396955198772322, "Bleu_4": 0.06977877744333115, "METEOR": 0.20671638502472842, "ROUGE_L": 0.23940345368916802, "CIDEr": 8.346872288052286e-06, "SPICE": {"All": {"pr": 0.045454545454545456, "re": 0.06451612903225806, "f": 0.05333333333333334, "fn": 29.0, "numImages": 1.0, "fp": 42.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.043478260869565216, "re": 0.08333333333333333, "f": 0.057142857142857134, "fn": 11.0, "numImages": 1.0, "fp": 22.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.1, "f": 0.0909090909090909, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "Sure! Here is a short caption for the image:\n\nThe zebras are grazing in the grassy area. They are standing next to each other and looking at something in the distance. The zookeeper is standing nearby, watching them."}, "530520": {"image_id": 530520, "Bleu_1": 0.4999999999750001, "Bleu_2": 0.42919753761745155, "Bleu_3": 0.3446412921079625, "Bleu_4": 0.2215201577642272, "METEOR": 0.2734202029537304, "ROUGE_L": 0.42558139534883715, "CIDEr": 0.13219254409364406, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.041666666666666664, "f": 0.05405405405405406, "fn": 23.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image shows a group of people sitting on the grass outside a building, using laptops and working on something."}, "117337": {"image_id": 117337, "Bleu_1": 0.15492957746260663, "Bleu_2": 0.11523748551592801, "Bleu_3": 0.0727427112430955, "Bleu_4": 8.673909463338955e-06, "METEOR": 0.16570265352685642, "ROUGE_L": 0.19668355596499307, "CIDEr": 9.462120411221069e-23, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.14285714285714285, "f": 0.1395348837209302, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "Here is a short caption for the image:\n\n\"A colorful and vibrant image of an orange and blue themed room with a variety of objects and decorations. The image includes a vase with orange flowers, a blue vase with blue flowers, a blue and orange striped rug, and a blue and orange striped wall. The image also includes a blue and orange striped curtain and a blue and orange striped table.\""}, "256504": {"image_id": 256504, "Bleu_1": 0.4399999999824001, "Bleu_2": 0.33166247902199714, "Bleu_3": 0.26744939109643207, "Bleu_4": 0.22599865451185372, "METEOR": 0.2878800128205944, "ROUGE_L": 0.433502538071066, "CIDEr": 0.04224567911971843, "SPICE": {"All": {"pr": 0.3125, "re": 0.1724137931034483, "f": 0.22222222222222224, "fn": 24.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows two people sitting on a bed, both of them holding laptops. The room is decorated with a colorful tapestry on the wall."}, "265472": {"image_id": 265472, "Bleu_1": 0.18867924527945892, "Bleu_2": 0.14754891442234067, "Bleu_3": 0.09486600651870754, "Bleu_4": 1.1431164199464497e-05, "METEOR": 0.17433570853110766, "ROUGE_L": 0.21908296420447745, "CIDEr": 3.4999681984245136e-12, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.2777777777777778, "f": 0.2272727272727273, "fn": 13.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.6666666666666666, "f": 0.4705882352941177, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This image shows a plate of food with bacon, eggs, and bananas. The bacon is cooked and crispy, while the eggs are fried and fluffy. The bananas are sliced and placed on top of the eggs. The plate is on a white tablecloth, and there is a fork and knife on the side."}, "441083": {"image_id": 441083, "Bleu_1": 0.2857142857061225, "Bleu_2": 0.24253562502930154, "Bleu_3": 0.12124924590343557, "Bleu_4": 1.5362849996056047e-05, "METEOR": 0.23634737458232594, "ROUGE_L": 0.3096446700507614, "CIDEr": 0.0019453345384892093, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.20833333333333334, "f": 0.1851851851851852, "fn": 19.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.3333333333333333, "f": 0.2, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The dog is sitting in the back seat of the car, looking out the window. The car is parked on the side of the road, and there are trees and houses visible in the background."}, "126958": {"image_id": 126958, "Bleu_1": 0.41463414633135043, "Bleu_2": 0.2276604231967495, "Bleu_3": 0.10994365150211913, "Bleu_4": 1.3675138027356721e-05, "METEOR": 0.20429965843489178, "ROUGE_L": 0.32685867381111855, "CIDEr": 2.1291583426207245e-05, "SPICE": {"All": {"pr": 0.17073170731707318, "re": 0.30434782608695654, "f": 0.21875, "fn": 16.0, "numImages": 1.0, "fp": 34.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 6.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.23529411764705882, "re": 0.4444444444444444, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}}, "caption": "This is a bedroom with a blue wall and a white ceiling. There is a mirror on the wall opposite the bed, and a window on the left side of the room. The floor is covered in a light blue carpet."}, "484075": {"image_id": 484075, "Bleu_1": 0.37209302324716065, "Bleu_2": 0.16302782918400804, "Bleu_3": 8.654590923115623e-07, "Bleu_4": 2.006411049352811e-09, "METEOR": 0.2587157054997703, "ROUGE_L": 0.31946132984195263, "CIDEr": 1.7463689423426796e-06, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.3157894736842105, "f": 0.33333333333333337, "fn": 13.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 1.0, "f": 0.5714285714285715, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is a cluttered room with a desk, chair, and computer in the center. There are various items on the desk, including a keyboard, mouse, and monitor. The walls are painted white and there is a window on one side of the room."}, "274528": {"image_id": 274528, "Bleu_1": 0.3571428571301021, "Bleu_2": 0.25717224992746507, "Bleu_3": 0.1719893752106008, "Bleu_4": 2.1239349525504125e-05, "METEOR": 0.17987071945698688, "ROUGE_L": 0.2782846715328467, "CIDEr": 0.015505085376403892, "SPICE": {"All": {"pr": 0.0967741935483871, "re": 0.10714285714285714, "f": 0.10169491525423728, "fn": 25.0, "numImages": 1.0, "fp": 28.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.2727272727272727, "f": 0.24999999999999994, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A group of bicyclists ride down the street, passing by a truck with a banner promoting a cycling event.\""}, "286820": {"image_id": 286820, "Bleu_1": 0.3030303030211204, "Bleu_2": 0.2383656473040621, "Bleu_3": 0.12237946382258257, "Bleu_4": 1.5721757596698785e-05, "METEOR": 0.18079060871927258, "ROUGE_L": 0.25738396624472576, "CIDEr": 0.00017556919838530443, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.26666666666666666, "f": 0.18604651162790697, "fn": 11.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.8, "f": 0.4444444444444444, "fn": 1.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows two iPhones on a green carpet. One iPhone is white and the other is black. The white iPhone has a cracked screen, while the black iPhone has a clean screen."}, "69236": {"image_id": 69236, "Bleu_1": 0.19230769230399414, "Bleu_2": 0.06140634384744192, "Bleu_3": 4.224923263061475e-07, "Bleu_4": 1.1138202232666472e-09, "METEOR": 0.15335604702898692, "ROUGE_L": 0.15024630541871922, "CIDEr": 6.0127809260288066e-12, "SPICE": {"All": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 24.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "This is a nighttime image of a park with a bench and trees. The sky is clear and there are no clouds in sight. The grass is green and the trees are tall and lush. The bench is made of metal and has a backrest. There are no people in the image."}, "333237": {"image_id": 333237, "Bleu_1": 0.5555555555349795, "Bleu_2": 0.38674623406228154, "Bleu_3": 0.2618250193562784, "Bleu_4": 0.16536955121564323, "METEOR": 0.308105272411202, "ROUGE_L": 0.41391009329940626, "CIDEr": 0.04346423723604782, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.2, "f": 0.12903225806451613, "fn": 16.0, "numImages": 1.0, "fp": 38.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.21052631578947367, "re": 0.5, "f": 0.2962962962962963, "fn": 4.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}}, "caption": "This is a bedroom with a white bed and red curtains. There is a dresser in the corner of the room and a window with red curtains."}, "285258": {"image_id": 285258, "Bleu_1": 0.3454545454482645, "Bleu_2": 0.22622654834606154, "Bleu_3": 0.0988409906791752, "Bleu_4": 1.1673524021794383e-05, "METEOR": 0.19724703167707705, "ROUGE_L": 0.21095100864553315, "CIDEr": 5.203406410319138e-13, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.17857142857142858, "f": 0.21739130434782608, "fn": 23.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.23076923076923078, "f": 0.2857142857142857, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a group of dogs playing in a grassy area. One dog is standing on its hind legs and appears to be trying to catch another dog that is running away. The other dogs are standing around, watching the two dogs play. The background is a green field with trees in the distance."}, "574454": {"image_id": 574454, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.1624659147420524, "Bleu_3": 0.10182666119201575, "Bleu_4": 0.06813136779964551, "METEOR": 0.13023332821234695, "ROUGE_L": 0.1920654911838791, "CIDEr": 4.017457859757816e-12, "SPICE": {"All": {"pr": 0.15151515151515152, "re": 0.2631578947368421, "f": 0.19230769230769232, "fn": 14.0, "numImages": 1.0, "fp": 28.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.23529411764705882, "re": 0.5714285714285714, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}}, "caption": "The image shows a group of people on the beach, with kite surfers in the foreground and Table Mountain in the background. The sky is clear and blue, with a few clouds scattered across it. The waves are crashing against the shore, and there are some rocks and driftwood on the beach."}, "57703": {"image_id": 57703, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.2544697557892895, "Bleu_3": 0.19305302549200576, "Bleu_4": 0.14882455879058204, "METEOR": 0.294519922127194, "ROUGE_L": 0.36624416277518346, "CIDEr": 3.5501575220823795e-08, "SPICE": {"All": {"pr": 0.0975609756097561, "re": 0.26666666666666666, "f": 0.14285714285714285, "fn": 11.0, "numImages": 1.0, "fp": 37.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.6666666666666666, "f": 0.36363636363636365, "fn": 2.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}}, "caption": "Here is a short caption for the image:\n\nA group of people hiking in the woods with their dogs. One person is holding a leash and another is petting a dog. The dogs are wearing collars and tags. The trees in the background are tall and green."}, "70294": {"image_id": 70294, "Bleu_1": 0.27906976743537054, "Bleu_2": 0.2156655464018017, "Bleu_3": 0.1314021767661405, "Bleu_4": 1.5432522609842e-05, "METEOR": 0.2530864270901824, "ROUGE_L": 0.31774970699309807, "CIDEr": 1.720395534787588e-06, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.12, "f": 0.15789473684210525, "fn": 22.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.3333333333333333, "f": 0.42857142857142855, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows a blue bus parked on the side of a road in front of a building. The bus has the words \"Wheelchair Accessible\" written on the side in white letters. There are people standing on the sidewalk looking at the bus."}, "279769": {"image_id": 279769, "Bleu_1": 0.39999999998400004, "Bleu_2": 0.3162277660039253, "Bleu_3": 0.23539531025786062, "Bleu_4": 0.1560424226798813, "METEOR": 0.23497621785224818, "ROUGE_L": 0.35847208619000986, "CIDEr": 0.056634966180748446, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 12.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.6, "f": 0.35294117647058826, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a banana on a table with a piece of paper on top of it. The paper has a number written on it."}, "541474": {"image_id": 541474, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.11459194182328535, "Bleu_3": 6.280739235613542e-07, "Bleu_4": 1.4774310979864886e-09, "METEOR": 0.20716688110833015, "ROUGE_L": 0.21095100864553315, "CIDEr": 1.7909428437788533e-13, "SPICE": {"All": {"pr": 0.5, "re": 0.30434782608695654, "f": 0.3783783783783784, "fn": 16.0, "numImages": 1.0, "fp": 7.0, "tp": 7.0}, "Relation": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.6666666666666666, "f": 0.7058823529411765, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 6.0}}, "caption": "This is an image of a person skiing down a snowy slope. The person is wearing a blue jacket and black pants, and has a helmet on their head. They are holding onto a snowboard and are in the process of turning. The sky is clear and blue, with a few clouds in the distance."}, "217561": {"image_id": 217561, "Bleu_1": 0.4090909090723141, "Bleu_2": 0.19738550847874506, "Bleu_3": 1.2489168104898057e-06, "Bleu_4": 3.182084683852089e-09, "METEOR": 0.10061604799796474, "ROUGE_L": 0.21837708830548927, "CIDEr": 0.05776725359610814, "SPICE": {"All": {"pr": 0.3, "re": 0.21428571428571427, "f": 0.25, "fn": 22.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2727272727272727, "f": 0.3529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a table set with white plates, silverware, and glasses. There are also several glasses of wine on the table."}, "303778": {"image_id": 303778, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.24867513640166544, "Bleu_3": 0.16407619071671853, "Bleu_4": 1.8117080302616905e-05, "METEOR": 0.31951147961359566, "ROUGE_L": 0.37602739726027395, "CIDEr": 1.5014768317710375e-07, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 14.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.6, "f": 0.4615384615384615, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is an image of a baseball player in a uniform, holding a bat and standing on a baseball field. The player is wearing a white jersey with blue pants and white cleats. The field is green and there are spectators in the stands."}, "40426": {"image_id": 40426, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.1956151991049542, "Bleu_3": 0.11764652669092619, "Bleu_4": 1.3716549481276805e-05, "METEOR": 0.22392188464463259, "ROUGE_L": 0.2663755458515284, "CIDEr": 5.082460350600423e-09, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.17857142857142858, "f": 0.20408163265306123, "fn": 23.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a kitchen countertop with a blender, a bowl of strawberries, and a spoon. The blender is turned on and has a cup of frozen strawberries in it. There are also several other ingredients on the counter, including a jar of jam and a container of yogurt."}, "324291": {"image_id": 324291, "Bleu_1": 0.29268292682212976, "Bleu_2": 0.20952908872569917, "Bleu_3": 0.1500312630234139, "Bleu_4": 0.0970935599504286, "METEOR": 0.2576221943815638, "ROUGE_L": 0.31182108626198085, "CIDEr": 2.2847905482867868e-05, "SPICE": {"All": {"pr": 0.11864406779661017, "re": 0.3181818181818182, "f": 0.1728395061728395, "fn": 15.0, "numImages": 1.0, "fp": 52.0, "tp": 7.0}, "Relation": {"pr": 0.047619047619047616, "re": 0.14285714285714285, "f": 0.07142857142857142, "fn": 6.0, "numImages": 1.0, "fp": 20.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.07692307692307693, "re": 0.14285714285714285, "f": 0.1, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.625, "f": 0.30303030303030304, "fn": 3.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}}, "caption": "A woman is riding a pony in a green field. The pony is wearing a red halter and lead rope. The woman is wearing a white shirt and black pants. The sky is blue and there are trees in the background."}, "96241": {"image_id": 96241, "Bleu_1": 0.3947368420948754, "Bleu_2": 0.20657747505062754, "Bleu_3": 0.10583300875240854, "Bleu_4": 1.356590733316526e-05, "METEOR": 0.2459098822888197, "ROUGE_L": 0.23282442748091606, "CIDEr": 2.9695034635712307e-05, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.1, "f": 0.12765957446808512, "fn": 27.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "This is an image of a train traveling down a track in the countryside. There are people standing on the platform and watching the train go by. The train is black and has a number on the side."}, "326911": {"image_id": 326911, "Bleu_1": 0.16981132075151303, "Bleu_2": 0.11429089766174176, "Bleu_3": 0.0915921222537406, "Bleu_4": 0.07445752386401949, "METEOR": 0.24085499866501955, "ROUGE_L": 0.24811156304474144, "CIDEr": 6.1154259529188764e-12, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.22727272727272727, "f": 0.2777777777777778, "fn": 17.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5714285714285714, "f": 0.5714285714285714, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a small dog standing on the sidewalk next to a bicycle. The dog is looking up at the bicycle with its tail wagging. The bicycle has a basket on the front and a bell on the handlebars. The background is a cobblestone street with trees and buildings in the distance."}, "209222": {"image_id": 209222, "Bleu_1": 0.22535211267288235, "Bleu_2": 0.16048217085473143, "Bleu_3": 0.12311892972156699, "Bleu_4": 0.10236026304798825, "METEOR": 0.2238706868227662, "ROUGE_L": 0.23249166269652216, "CIDEr": 4.2160841846988636e-23, "SPICE": {"All": {"pr": 0.4166666666666667, "re": 0.2631578947368421, "f": 0.3225806451612903, "fn": 14.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}, "Relation": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a man sitting on a bench in the middle of a city street. The bench is made of wood and has a backrest. The man is wearing a black hoodie and sunglasses, and he is looking down at his phone. There are people walking by on the sidewalk, and there are trees and buildings in the background. The sky is cloudy and there is a light breeze blowing."}, "362293": {"image_id": 362293, "Bleu_1": 0.45238095237018144, "Bleu_2": 0.3321698626434563, "Bleu_3": 0.20226802739876257, "Bleu_4": 0.1206922205024378, "METEOR": 0.28736606867263104, "ROUGE_L": 0.2952973720608575, "CIDEr": 2.9759012944252564e-05, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.3333333333333333, "f": 0.25641025641025644, "fn": 10.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "A horse and carriage are driving down the street in front of a group of people. The horse is pulling a carriage with two people inside. The people are wearing hats and coats. There are buildings on either side of the street."}, "144481": {"image_id": 144481, "Bleu_1": 0.2343749999963379, "Bleu_2": 0.12198750911664548, "Bleu_3": 0.06214597592719474, "Bleu_4": 7.920038643416778e-06, "METEOR": 0.1676703012464868, "ROUGE_L": 0.21785714285714283, "CIDEr": 1.2173820525154397e-18, "SPICE": {"All": {"pr": 0.1875, "re": 0.13636363636363635, "f": 0.15789473684210525, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image shows two large vases on display in a museum. One vase is black and has a red handle, while the other is red and has a black handle. Both vases are made of ceramic and have intricate designs on them. The vases are placed on a blue carpet in front of a white wall with a few other objects on display nearby."}, "433804": {"image_id": 433804, "Bleu_1": 0.3030303030211204, "Bleu_2": 0.13762047063655966, "Bleu_3": 8.485318099037327e-07, "Bleu_4": 2.124324129849806e-09, "METEOR": 0.18097639444904065, "ROUGE_L": 0.2911694510739857, "CIDEr": 0.0006002209816769799, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.2, "f": 0.17391304347826086, "fn": 16.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.23076923076923078, "re": 0.5, "f": 0.3157894736842105, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a small boat traveling down a river surrounded by tall palm trees and lush green foliage. The water is calm and peaceful, with the sun shining down on the scene."}, "142815": {"image_id": 142815, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.20516007603198386, "Bleu_3": 0.12321617651106383, "Bleu_4": 1.4359444090526792e-05, "METEOR": 0.27975117159865126, "ROUGE_L": 0.27056139906222276, "CIDEr": 7.705030039085704e-08, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.20833333333333334, "f": 0.2380952380952381, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a man sitting on a bed, holding a camera in his hand. He is wearing a red shirt and has a serious expression on his face. The background of the image is a bedroom with a white wall and a window in the background."}, "85292": {"image_id": 85292, "Bleu_1": 0.39999999998666674, "Bleu_2": 0.23488808779791684, "Bleu_3": 0.1253683714769749, "Bleu_4": 1.6436148153953708e-05, "METEOR": 0.26469191334542014, "ROUGE_L": 0.321390937829294, "CIDEr": 0.004272393417869744, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.2, "f": 0.1904761904761905, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a train traveling along the tracks, with several cars loaded with cargo. The train is traveling through a rural area with fields and trees in the background."}, "500423": {"image_id": 500423, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.07754322001996182, "Bleu_3": 5.112402630440968e-07, "Bleu_4": 1.3200963130423504e-09, "METEOR": 0.14842300556586271, "ROUGE_L": 0.20847573479152426, "CIDEr": 2.1853136091067495e-09, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.08, "f": 0.08163265306122448, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a red and orange train on the tracks in a large, modern train station. The train is parked in front of a large window with a reflection of the train in it. There are people standing in front of the train, looking at it."}, "196280": {"image_id": 196280, "Bleu_1": 0.2205882352908737, "Bleu_2": 0.16229261771775497, "Bleu_3": 0.09276009759866431, "Bleu_4": 1.0526707571008397e-05, "METEOR": 0.1692429062831971, "ROUGE_L": 0.22889305816135083, "CIDEr": 9.419553611966626e-20, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.07692307692307693, "f": 0.1, "fn": 24.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a young boy standing in front of a kitchen counter with several pots and pans on it. The boy is wearing a white shirt and black pants, and has a spoon in one hand and a bowl in the other. The background is a dark kitchen with a stove and refrigerator in the background. The caption reads, \"Growing up always had to leave something behind.\""}, "84752": {"image_id": 84752, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.15639188177115004, "Bleu_3": 0.11216278231474784, "Bleu_4": 0.08624849693567765, "METEOR": 0.203263685966947, "ROUGE_L": 0.2853801169590643, "CIDEr": 9.87591322020074e-12, "SPICE": {"All": {"pr": 0.25, "re": 0.18518518518518517, "f": 0.2127659574468085, "fn": 22.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a large, white jet plane sitting on the ground in front of a building. The plane has a black nose and tail, and its wings are folded back. There are several people standing around the plane, looking at it. The sky is cloudy and there are some trees in the background."}, "222317": {"image_id": 222317, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.18663625434394557, "Bleu_3": 0.1505903985438184, "Bleu_4": 0.1285643204879068, "METEOR": 0.27930383740239767, "ROUGE_L": 0.3258160237388724, "CIDEr": 8.135191414717623e-12, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.16666666666666666, "f": 0.16216216216216214, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "A small dog is sitting on a couch in a living room. The dog is wearing a collar and looking up at the camera. There are two lamps on the coffee table in front of the couch. The walls are made of wood and there are windows on one side of the room."}, "544421": {"image_id": 544421, "Bleu_1": 0.7499999999375001, "Bleu_2": 0.36927447290582666, "Bleu_3": 2.389091911370125e-06, "Bleu_4": 6.238986071516447e-09, "METEOR": 0.24096385542168677, "ROUGE_L": 0.46212121212121204, "CIDEr": 0.6664098582835156, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.15789473684210525, "f": 0.14285714285714288, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 1.0, "f": 0.33333333333333337, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This is a chocolate cake with a waterfall and trees on it."}, "526827": {"image_id": 526827, "Bleu_1": 0.6923076922011837, "Bleu_2": 0.41602514710358474, "Bleu_3": 2.5058139740241378e-06, "Bleu_4": 6.29812999135685e-09, "METEOR": 0.2188102421987333, "ROUGE_L": 0.4834874504623514, "CIDEr": 0.7507080976224378, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.23529411764705882, "f": 0.17391304347826086, "fn": 13.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.6, "f": 0.33333333333333337, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "A pair of scissors and a ruler are sitting on a green table."}, "527529": {"image_id": 527529, "Bleu_1": 0.2340425531865098, "Bleu_2": 0.10087498788996685, "Bleu_3": 0.06092349727774221, "Bleu_4": 8.466919880732135e-06, "METEOR": 0.17412742730386646, "ROUGE_L": 0.20847573479152426, "CIDEr": 1.6297743517477048e-09, "SPICE": {"All": {"pr": 0.4, "re": 0.125, "f": 0.19047619047619047, "fn": 14.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.3333333333333333, "f": 0.4444444444444444, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "The image shows a white cat sitting on top of a black bag that is hanging from a hook on the wall. The cat is looking up at the camera with its eyes closed. There are several other bags and boxes on the shelf behind the cat."}, "152785": {"image_id": 152785, "Bleu_1": 0.17721518987117452, "Bleu_2": 0.15073120492133932, "Bleu_3": 0.12097314061631544, "Bleu_4": 0.09824904021370334, "METEOR": 0.21218000280481347, "ROUGE_L": 0.21179242358484715, "CIDEr": 4.745694454995553e-29, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.21739130434782608, "f": 0.26315789473684204, "fn": 18.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.36363636363636365, "f": 0.4444444444444444, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a herd of elephants walking across a dry, dusty field at sunset. The sky is orange and pink, with clouds in the distance. The elephants are walking in a line, with their trunks held high and their ears flapping in the wind. They are all facing forward, with their eyes fixed on something in the distance. The image is taken from a bird's eye view, with the elephants looking like tiny dots on the horizon."}, "516212": {"image_id": 516212, "Bleu_1": 0.7122777526922006, "Bleu_2": 0.46887861829052635, "Bleu_3": 0.33326034014641265, "Bleu_4": 0.24195572800734544, "METEOR": 0.42160638319548127, "ROUGE_L": 0.7018697349496609, "CIDEr": 2.116203148399291, "SPICE": {"All": {"pr": 0.5555555555555556, "re": 0.29411764705882354, "f": 0.3846153846153846, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.6666666666666666, "f": 0.7272727272727272, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The cat is sitting on top of the microwave oven in the kitchen."}, "403378": {"image_id": 403378, "Bleu_1": 0.2903225806357961, "Bleu_2": 0.21997067252481586, "Bleu_3": 0.18827696382144854, "Bleu_4": 0.1635267085857025, "METEOR": 0.3243996487326926, "ROUGE_L": 0.3885350318471337, "CIDEr": 0.0023568262887801415, "SPICE": {"All": {"pr": 0.4, "re": 0.18181818181818182, "f": 0.25000000000000006, "fn": 18.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The woman in the image is looking at herself in a mirror. She is wearing a white dress and has long blonde hair. There are candles on the table behind her."}, "216051": {"image_id": 216051, "Bleu_1": 0.24657534246237567, "Bleu_2": 0.18505830254684866, "Bleu_3": 0.13410437138081685, "Bleu_4": 0.10082959080721547, "METEOR": 0.24551221511275423, "ROUGE_L": 0.2270823638901815, "CIDEr": 2.8159990974144396e-24, "SPICE": {"All": {"pr": 0.25, "re": 0.2413793103448276, "f": 0.24561403508771928, "fn": 22.0, "numImages": 1.0, "fp": 21.0, "tp": 7.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.4166666666666667, "f": 0.4, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a woman sitting on a bench in a park, holding a small dog in her lap. The woman is wearing purple scrubs and has a blanket wrapped around her legs. The dog is a small black and white terrier with a collar and tag. The bench is made of wood and has a wooden slat design. The trees in the background are tall and green, with leaves on the ground."}, "543043": {"image_id": 543043, "Bleu_1": 0.16883116882897622, "Bleu_2": 0.11545032042537927, "Bleu_3": 0.08924755717349157, "Bleu_4": 0.07326889419525183, "METEOR": 0.21594651173034274, "ROUGE_L": 0.2135667396061269, "CIDEr": 2.3226468874794995e-26, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.23076923076923078, "f": 0.25531914893617025, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 1.0, "re": 0.2, "f": 0.33333333333333337, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4166666666666667, "f": 0.45454545454545453, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a red sports car parked in front of a small, rusty old school bus. The car has a flat tire and is covered in dust and dirt. The bus has a faded paint job and is covered in graffiti. There are several other old cars and trucks parked around the bus, some of which are also in disrepair. The scene is set in a rural area with trees and fields visible in the background."}, "392493": {"image_id": 392493, "Bleu_1": 0.22222222221869492, "Bleu_2": 0.15839698776796265, "Bleu_3": 0.09369821824227359, "Bleu_4": 1.082083280580907e-05, "METEOR": 0.2570822580793716, "ROUGE_L": 0.2785388127853881, "CIDEr": 2.5598253510034345e-17, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.1724137931034483, "f": 0.2173913043478261, "fn": 24.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1111111111111111, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a colorful kite flying in the sky with a sunset in the background. The kite is made of brightly colored streamers and has a long tail that trails behind it. The sky is a deep blue and there are clouds in the distance. The grass is green and there are people walking on the sidewalk in front of the kite."}, "524681": {"image_id": 524681, "Bleu_1": 0.29824561402985533, "Bleu_2": 0.1930821114268906, "Bleu_3": 0.11067523724715086, "Bleu_4": 0.07078470170866812, "METEOR": 0.276080577413818, "ROUGE_L": 0.26798462383305877, "CIDEr": 4.916418330718234e-14, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 18.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a group of people standing on a beach with a kite flying in the sky. The people are wearing casual clothing and are looking up at the kite. The sky is clear and blue, with a few clouds scattered about. The beach is covered in sand and there are some rocks in the distance."}, "265816": {"image_id": 265816, "Bleu_1": 0.20430107526662042, "Bleu_2": 0.14137176080860728, "Bleu_3": 0.09577407756531399, "Bleu_4": 0.06647109833947891, "METEOR": 0.199349564800568, "ROUGE_L": 0.19815917704385488, "CIDEr": 3.098025768798873e-39, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.14285714285714285, "f": 0.18604651162790697, "fn": 24.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.23076923076923078, "f": 0.3, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a horse and carriage parked on the side of a cobblestone street in front of a building with white walls and red roof tiles. The carriage has a black canopy and is pulled by a white horse wearing a pink ribbon around its neck. The driver is sitting on the seat, wearing a straw hat and holding the reins. The building has a large window on the second floor with shutters and a balcony with white railings. There are palm trees and other plants growing in pots on the sidewalk."}, "528984": {"image_id": 528984, "Bleu_1": 0.3913043478175804, "Bleu_2": 0.2467175818921615, "Bleu_3": 0.1607026084013227, "Bleu_4": 0.0991174409108344, "METEOR": 0.25776440446398674, "ROUGE_L": 0.29249580436346195, "CIDEr": 1.087383604367191e-06, "SPICE": {"All": {"pr": 0.25, "re": 0.15384615384615385, "f": 0.1904761904761905, "fn": 22.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "This is an image of a ski slope with people skiing down it. There are several people in the image, including some in brightly colored clothing and others in black. The snow is covered in a layer of fog, making it difficult to see very far."}, "565776": {"image_id": 565776, "Bleu_1": 0.3599999999928, "Bleu_2": 0.24243661068763242, "Bleu_3": 0.1347912565777208, "Bleu_4": 1.510851663234064e-05, "METEOR": 0.25343722557241616, "ROUGE_L": 0.28405122235157165, "CIDEr": 1.2665616051492166e-09, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.13636363636363635, "f": 0.12499999999999997, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This is a kitchen with white cabinets and black countertops. There is a large island in the center of the room with a sink and stove on it. The walls are painted a light color and there are windows on one side of the room that let in natural light."}, "208132": {"image_id": 208132, "Bleu_1": 0.3793103448145066, "Bleu_2": 0.28509785718527286, "Bleu_3": 0.24690585127674183, "Bleu_4": 0.21936644510644115, "METEOR": 0.2712478362329535, "ROUGE_L": 0.4353256021409455, "CIDEr": 0.01802882026986888, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.18518518518518517, "f": 0.17857142857142858, "fn": 22.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.3333333333333333, "f": 0.2608695652173913, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a table with a plate of food on it, including a hamburger, fries, and a drink. There are also two glasses of water on the table."}, "37017": {"image_id": 37017, "Bleu_1": 0.34883720929421314, "Bleu_2": 0.2734059812097495, "Bleu_3": 0.1939236242118044, "Bleu_4": 0.11620051194706985, "METEOR": 0.2602222936170194, "ROUGE_L": 0.30262225372076546, "CIDEr": 3.237506095983832e-07, "SPICE": {"All": {"pr": 0.07894736842105263, "re": 0.10714285714285714, "f": 0.09090909090909091, "fn": 25.0, "numImages": 1.0, "fp": 35.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a black dog sitting on the floor in front of a kitchen counter. The dog is looking up at the camera with its tongue hanging out of its mouth. The kitchen has white cabinets and a stove in the background."}, "20536": {"image_id": 20536, "Bleu_1": 0.32499999999187507, "Bleu_2": 0.15811388300441548, "Bleu_3": 8.697320427224378e-07, "Bleu_4": 2.0534714635906755e-09, "METEOR": 0.1784061365495973, "ROUGE_L": 0.18944099378881987, "CIDEr": 7.75238991775342e-06, "SPICE": {"All": {"pr": 0.5, "re": 0.13636363636363635, "f": 0.21428571428571427, "fn": 19.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.42857142857142855, "f": 0.6, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}}, "caption": "This is a bathroom with a toilet and a sink. The toilet is on the left side of the room and the sink is on the right side. There is trash on the floor and the walls are painted white."}, "289264": {"image_id": 289264, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.17733172552966228, "Bleu_3": 0.10654502541910188, "Bleu_4": 1.2409587310674509e-05, "METEOR": 0.23609691629072738, "ROUGE_L": 0.25507765830346474, "CIDEr": 5.621016789808148e-12, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.17647058823529413, "f": 0.17647058823529413, "fn": 14.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a brown dog sitting on a windowsill looking out at the rain. The dog is wearing a collar and has its head tilted to the side as if it is looking at something outside. The background of the image is a rainy day with trees and buildings visible through the window."}, "18014": {"image_id": 18014, "Bleu_1": 0.5161290322414152, "Bleu_2": 0.3212877315504627, "Bleu_3": 0.19237121770506102, "Bleu_4": 2.24551294330736e-05, "METEOR": 0.2660897420066169, "ROUGE_L": 0.3843384338433843, "CIDEr": 0.0014846017041164896, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.17391304347826086, "f": 0.2162162162162162, "fn": 19.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a pizza with various toppings such as vegetables, meat, and cheese. The pizza is cut into slices and is sitting in a box with a lid on top."}, "381123": {"image_id": 381123, "Bleu_1": 0.370370370356653, "Bleu_2": 0.2668802563317374, "Bleu_3": 0.17861076327216507, "Bleu_4": 2.2073840969171684e-05, "METEOR": 0.1801755815991933, "ROUGE_L": 0.3960304210721573, "CIDEr": 0.029261370371835092, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.20833333333333334, "f": 0.12658227848101267, "fn": 19.0, "numImages": 1.0, "fp": 50.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 22.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.21739130434782608, "re": 0.5, "f": 0.30303030303030304, "fn": 5.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}}, "caption": "The image shows a group of people standing on a beach with kayaks in the water. The sky is cloudy and there are mountains in the background."}, "19608": {"image_id": 19608, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.14953924108841646, "Bleu_3": 7.54806561769252e-07, "Bleu_4": 1.7040573474649363e-09, "METEOR": 0.16430361617278874, "ROUGE_L": 0.2533748701973001, "CIDEr": 1.6266189542232177e-10, "SPICE": {"All": {"pr": 0.3, "re": 0.14285714285714285, "f": 0.19354838709677416, "fn": 18.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA heron stands on the edge of a pond, looking out at the water. The pond is surrounded by trees and grass, and there are people walking their bikes on the path nearby. The sky is clear and blue, with a few clouds scattered about."}, "497348": {"image_id": 497348, "Bleu_1": 0.40624999998730477, "Bleu_2": 0.1982788847218369, "Bleu_3": 0.10943188833092986, "Bleu_4": 1.4580030099308147e-05, "METEOR": 0.2097305562884111, "ROUGE_L": 0.25501672240802675, "CIDEr": 0.0015982421762597222, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.2777777777777778, "f": 0.27027027027027023, "fn": 13.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5714285714285714, "f": 0.5333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a road with no traffic on it. There are trees on both sides of the road and a few houses in the distance. The sky is clear and blue."}, "437594": {"image_id": 437594, "Bleu_1": 0.4594594594470417, "Bleu_2": 0.3195341955041846, "Bleu_3": 0.22681696947578164, "Bleu_4": 0.17912955294697497, "METEOR": 0.2939919802329883, "ROUGE_L": 0.3890857547838412, "CIDEr": 0.0005029726177641284, "SPICE": {"All": {"pr": 0.2, "re": 0.21052631578947367, "f": 0.20512820512820512, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "A woman is sitting at a desk in front of a brick wall. She is wearing a blue shirt and has a laptop open in front of her. There are several photos on the wall behind her."}, "413404": {"image_id": 413404, "Bleu_1": 0.43478260867674867, "Bleu_2": 0.344350221559779, "Bleu_3": 0.2243557191518718, "Bleu_4": 2.7412292652641044e-05, "METEOR": 0.2858870795146088, "ROUGE_L": 0.4241019698725377, "CIDEr": 0.1310458580138555, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.17391304347826086, "f": 0.1951219512195122, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a park with several benches and trees. People are walking on the sidewalk and there are buildings in the background."}, "332775": {"image_id": 332775, "Bleu_1": 0.24999999997916675, "Bleu_2": 4.767312945812628e-09, "Bleu_3": 1.3147679470444613e-11, "Bleu_4": 7.08885680157797e-13, "METEOR": 0.208812158625653, "ROUGE_L": 0.2932692307692307, "CIDEr": 0.8171605111991675, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.06896551724137931, "f": 0.09302325581395349, "fn": 27.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The cat is sitting in the suitcase, looking out at the camera."}, "530624": {"image_id": 530624, "Bleu_1": 0.17910447760926712, "Bleu_2": 0.10418645221255786, "Bleu_3": 0.05506847470461123, "Bleu_4": 7.147140047139338e-06, "METEOR": 0.2057409445116468, "ROUGE_L": 0.20982800982800984, "CIDEr": 1.5221215746064853e-20, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.14285714285714285, "f": 0.12244897959183672, "fn": 18.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a brown and white dog lying under a floral quilt on a bed. The dog is curled up and appears to be sleeping. The quilt has a floral pattern with pink, purple, and blue flowers. The bed is covered with a white sheet and has a pillow on it. The room is dimly lit by a window on the left side of the image."}, "139113": {"image_id": 139113, "Bleu_1": 0.4999999999772728, "Bleu_2": 0.3086066999098223, "Bleu_3": 0.2426427503086868, "Bleu_4": 0.19692215901893703, "METEOR": 0.2839803828554559, "ROUGE_L": 0.40219780219780216, "CIDEr": 0.13179814188422032, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.06896551724137931, "f": 0.09302325581395349, "fn": 27.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.18181818181818182, "f": 0.2222222222222222, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "Sure, here is a short caption for the image:\n\nA group of young men playing soccer on a dusty field at night."}, "192858": {"image_id": 192858, "Bleu_1": 0.46428571426913273, "Bleu_2": 0.3469443332317352, "Bleu_3": 0.2645668419848922, "Bleu_4": 0.1961887304180976, "METEOR": 0.20303345370936524, "ROUGE_L": 0.3546511627906977, "CIDEr": 0.01851557717980648, "SPICE": {"All": {"pr": 0.2, "re": 0.21428571428571427, "f": 0.20689655172413796, "fn": 22.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.1, "re": 0.08333333333333333, "f": 0.0909090909090909, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5, "f": 0.45454545454545453, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a group of people sitting at a table with pizzas in front of them. They are all smiling and laughing as they enjoy their meals."}, "482742": {"image_id": 482742, "Bleu_1": 0.41999999999160004, "Bleu_2": 0.3070597894252916, "Bleu_3": 0.1988023664903713, "Bleu_4": 0.11370817726560954, "METEOR": 0.25256935333824904, "ROUGE_L": 0.27341123739394907, "CIDEr": 3.1804684884304337e-06, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.18181818181818182, "f": 0.19999999999999998, "fn": 27.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.46153846153846156, "f": 0.42857142857142855, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}}, "caption": "The image shows a person riding a bicycle on the sidewalk next to a building with a red roof. There are trees and bushes on either side of the street, and a stop sign is visible in the distance. The sky is blue and there are clouds in the background."}, "398818": {"image_id": 398818, "Bleu_1": 0.5714285713877553, "Bleu_2": 0.29649972664244745, "Bleu_3": 1.9421783838169644e-06, "Bleu_4": 5.080057942628497e-09, "METEOR": 0.20367632405846198, "ROUGE_L": 0.3620178041543027, "CIDEr": 0.5013519287073454, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.16, "f": 0.17391304347826086, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "There are three bananas on the counter, each with a different sticker on them."}, "305871": {"image_id": 305871, "Bleu_1": 0.3437499999892579, "Bleu_2": 0.21060588478687045, "Bleu_3": 0.11392173307167976, "Bleu_4": 1.5026417037436177e-05, "METEOR": 0.26379694055954406, "ROUGE_L": 0.3060200668896321, "CIDEr": 0.0008330665371262945, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.12, "f": 0.15384615384615383, "fn": 22.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is an image of a street with a sign on the sidewalk that reads, \"San Carlos Street.\" The street is lined with buildings and has a blue sky in the background."}, "443818": {"image_id": 443818, "Bleu_1": 0.18032786884950286, "Bleu_2": 0.05482211671191619, "Bleu_3": 3.7069767545950536e-07, "Bleu_4": 9.680725341515885e-10, "METEOR": 0.1662847886579697, "ROUGE_L": 0.19565914679781887, "CIDEr": 3.4531185263600854e-17, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.08695652173913043, "f": 0.0975609756097561, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "This is an image of a brown and white dog lying in a small, furry bed. The dog is wearing a collar and tag on its neck. The bed is made of soft, fluffy material and has a small opening on the top for the dog to stick its head through. The dog appears to be sleeping peacefully in the bed."}, "421109": {"image_id": 421109, "Bleu_1": 0.5384615384201185, "Bleu_2": 0.36689969282327245, "Bleu_3": 0.23044502516602136, "Bleu_4": 3.3260249502635095e-05, "METEOR": 0.2381786129196738, "ROUGE_L": 0.5343065693430658, "CIDEr": 0.8986201797075721, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.15789473684210525, "f": 0.15, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.4, "f": 0.3076923076923077, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "A brown horse grazes in a green field with mountains in the background."}, "416660": {"image_id": 416660, "Bleu_1": 0.1313868613129096, "Bleu_2": 0.09324547583282732, "Bleu_3": 0.06362980426466273, "Bleu_4": 0.03723653323526111, "METEOR": 0.11007577082333131, "ROUGE_L": 0.11389703921045612, "CIDEr": 5.1866650230524436e-96, "SPICE": {"All": {"pr": 0.7142857142857143, "re": 0.38461538461538464, "f": 0.5, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.5714285714285714, "f": 0.7272727272727273, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 4.0}}, "caption": "This is an image of a group of people standing in front of a storefront. The storefront has a large window with display cases filled with various items. There are people walking down the sidewalk in front of the store.\n\nThe image is in black and white and has a vintage feel to it. The people in the image are dressed in clothing from the 1940s or 1950s. The storefront has a sign that reads \"johnson's jewelers\" in white letters.\n\nThe image is taken from a low angle, looking up at the storefront. The people in the image are looking at the display cases in the store. The image is well lit, with natural light coming from the sky.\n\nOverall, this image has a nostalgic feel to it, capturing a moment in time from the past."}, "322845": {"image_id": 322845, "Bleu_1": 0.2749999999931251, "Bleu_2": 0.1877669040449484, "Bleu_3": 0.12288385580936055, "Bleu_4": 0.08415321094031712, "METEOR": 0.20420047934152125, "ROUGE_L": 0.263536866359447, "CIDEr": 1.3484667245969985e-05, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.17647058823529413, "f": 0.16666666666666669, "fn": 14.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.75, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is an image of a stop sign on the side of a building. The sign is made of metal and has the words stop written on it in white letters. The background is a blue sky with some clouds."}, "304361": {"image_id": 304361, "Bleu_1": 0.11764705882122263, "Bleu_2": 1.5339299776643633e-09, "Bleu_3": 3.634725880340672e-12, "Bleu_4": 1.778457282414307e-13, "METEOR": 0.09822133240209788, "ROUGE_L": 0.14923547400611623, "CIDEr": 3.506811212120071e-11, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.13636363636363635, "f": 0.14634146341463414, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a young child sitting on the floor, playing with a tablet computer. The child is wearing a white onesie and has a look of concentration on their face as they play with the device. The room is dimly lit and there are suitcases and bags on the floor."}, "446917": {"image_id": 446917, "Bleu_1": 0.3846153846005918, "Bleu_2": 0.17541160385452437, "Bleu_3": 0.10863467408031745, "Bleu_4": 1.536541839019132e-05, "METEOR": 0.15667323418197873, "ROUGE_L": 0.32527550657660864, "CIDEr": 0.0610333902642162, "SPICE": {"All": {"pr": 0.25, "re": 0.3157894736842105, "f": 0.27906976744186046, "fn": 13.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A cyclist wearing a yellow jersey and carrying a banana on their handlebars rides down a street.\""}, "234676": {"image_id": 234676, "Bleu_1": 0.5555555555349795, "Bleu_2": 0.32686022521796804, "Bleu_3": 0.2044582845909689, "Bleu_4": 0.13737279170537006, "METEOR": 0.28821629232965373, "ROUGE_L": 0.4491781722550953, "CIDEr": 0.037190087576526, "SPICE": {"All": {"pr": 0.375, "re": 0.13043478260869565, "f": 0.19354838709677416, "fn": 20.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.09090909090909091, "f": 0.15384615384615385, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image shows a group of people standing on a beach next to a surfboard. The sky is blue and there are waves crashing against the shore."}, "343692": {"image_id": 343692, "Bleu_1": 0.6315789473351802, "Bleu_2": 0.4588314677163038, "Bleu_3": 0.3336769761698013, "Bleu_4": 0.2610490903179286, "METEOR": 0.3137833376316078, "ROUGE_L": 0.4707828004410144, "CIDEr": 0.3148635152956298, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.14285714285714285, "f": 0.13636363636363635, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a yellow scooter parked in front of a building with a sign that reads \"traffic ahead.\""}, "293011": {"image_id": 293011, "Bleu_1": 0.4324324324207451, "Bleu_2": 0.3287979746017048, "Bleu_3": 0.24903099802112144, "Bleu_4": 0.17361123498626596, "METEOR": 0.314689237961315, "ROUGE_L": 0.3520197856553999, "CIDEr": 0.001372646290167447, "SPICE": {"All": {"pr": 0.05714285714285714, "re": 0.07407407407407407, "f": 0.06451612903225806, "fn": 25.0, "numImages": 1.0, "fp": 33.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.25, "f": 0.1904761904761905, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a birthday cake with an airplane on it. The cake is decorated with blue frosting and has a candle on top. The airplane is made of fondant and has a red nose and wings."}, "104625": {"image_id": 104625, "Bleu_1": 0.17948717948487838, "Bleu_2": 0.13655774839802168, "Bleu_3": 0.09937863591849791, "Bleu_4": 0.07152567360310166, "METEOR": 0.24519635667843448, "ROUGE_L": 0.2600170502983802, "CIDEr": 2.2544458948124756e-28, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.22580645161290322, "f": 0.2641509433962264, "fn": 24.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.4166666666666667, "f": 0.4761904761904762, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a cat sitting on a couch in front of a television. The cat is looking at the television with interest, as if it is watching a soccer match. The television has a blue screen with white text that reads \"Image Content\" in the center. The room is dimly lit, with only a few light sources coming from the windows. The cat's fur is fluffy and white, and it appears to be a small breed."}, "175612": {"image_id": 175612, "Bleu_1": 0.17647058823183395, "Bleu_2": 0.11881770515484788, "Bleu_3": 0.0832144496600632, "Bleu_4": 1.0467398290586188e-05, "METEOR": 0.15397828647770256, "ROUGE_L": 0.18654434250764526, "CIDEr": 3.359250095288934e-11, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.16, "f": 0.2222222222222222, "fn": 21.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a cartoon character holding a skateboard in front of a pile of leaves on the ground. The character is wearing a red and blue striped shirt and has a yellow hat on its head. The sun is shining behind the character, casting a warm glow on the scene."}, "43448": {"image_id": 43448, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.1630820182599269, "Bleu_3": 0.08330762903217113, "Bleu_4": 1.0646588104484678e-05, "METEOR": 0.18127333373153967, "ROUGE_L": 0.1828537170263789, "CIDEr": 1.9887133954205585e-05, "SPICE": {"All": {"pr": 0.09375, "re": 0.21428571428571427, "f": 0.13043478260869562, "fn": 11.0, "numImages": 1.0, "fp": 29.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.08333333333333333, "re": 1.0, "f": 0.15384615384615385, "fn": 0.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 1.0, "f": 0.33333333333333337, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2857142857142857, "f": 0.2105263157894737, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows two elephants standing on a rocky beach with trees in the background. The elephants are brown and have large ears. One of the elephants is standing on its hind legs while the other is standing on all fours. They are both looking at each other."}, "528705": {"image_id": 528705, "Bleu_1": 0.21621621621329437, "Bleu_2": 0.1333086488300892, "Bleu_3": 6.272799201720742e-07, "Bleu_4": 1.3654677647627198e-09, "METEOR": 0.18136671288161454, "ROUGE_L": 0.16835326586936522, "CIDEr": 4.660029150403825e-24, "SPICE": {"All": {"pr": 0.45454545454545453, "re": 0.23809523809523808, "f": 0.31249999999999994, "fn": 16.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.6, "re": 0.42857142857142855, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows a young girl sitting on the back of a man's jacket, holding a stuffed teddy bear. The girl is wearing a red coat and has a red scarf around her neck. The man is wearing a black jacket and has a red scarf around his neck as well. They are standing in front of a large stone building with a clock tower. There are people standing around them, looking on."}, "319221": {"image_id": 319221, "Bleu_1": 0.3863636363548554, "Bleu_2": 0.23218786590068996, "Bleu_3": 0.1369262081775037, "Bleu_4": 0.08895471488927703, "METEOR": 0.2187959872082807, "ROUGE_L": 0.25702247191011235, "CIDEr": 3.384673772892904e-07, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.26666666666666666, "f": 0.19047619047619047, "fn": 11.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "This is an image of a tray filled with various dishes, including meat, vegetables, and sauces. There are several servers standing around the table, preparing to serve the food to guests. The atmosphere is dimly lit and there are several candles on the table."}, "338903": {"image_id": 338903, "Bleu_1": 0.7272727272066117, "Bleu_2": 0.5393598899191094, "Bleu_3": 0.40134229189878995, "Bleu_4": 0.2998221389022263, "METEOR": 0.3586416176643412, "ROUGE_L": 0.6110183639398998, "CIDEr": 2.086379925992914, "SPICE": {"All": {"pr": 0.14705882352941177, "re": 0.23809523809523808, "f": 0.18181818181818185, "fn": 16.0, "numImages": 1.0, "fp": 29.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.13333333333333333, "re": 0.2857142857142857, "f": 0.18181818181818182, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.42857142857142855, "f": 0.27272727272727276, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "The image shows a bowl of cereal with bananas and milk."}, "364993": {"image_id": 364993, "Bleu_1": 0.41176470587024233, "Bleu_2": 0.2736170867397671, "Bleu_3": 0.16725873794533458, "Bleu_4": 0.11084119214220596, "METEOR": 0.21112471249605547, "ROUGE_L": 0.3477198697068403, "CIDEr": 0.0007059203870550817, "SPICE": {"All": {"pr": 0.5, "re": 0.10344827586206896, "f": 0.17142857142857143, "fn": 26.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.125, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.15384615384615385, "f": 0.25, "fn": 11.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "This is an image of a person holding a sandwich in their hand. The sandwich appears to be made with meat, cheese, and lettuce. There is also a side of fries on the plate."}, "37616": {"image_id": 37616, "Bleu_1": 0.253731343279795, "Bleu_2": 0.17537193143852542, "Bleu_3": 0.1415965552335955, "Bleu_4": 0.11541427300594326, "METEOR": 0.23684216853550347, "ROUGE_L": 0.28110599078341014, "CIDEr": 1.2069046300233664e-18, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.27586206896551724, "f": 0.29090909090909095, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 8.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.46153846153846156, "re": 0.46153846153846156, "f": 0.46153846153846156, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "This is a man standing in a living room with a box of books on the floor. He is wearing glasses and has a serious expression on his face. There are two chairs in the room, one of which he is sitting in. The walls are painted white and there are several pieces of furniture in the room, including a couch, a coffee table, and a bookshelf."}, "157756": {"image_id": 157756, "Bleu_1": 0.3157894736759004, "Bleu_2": 0.26130213377863615, "Bleu_3": 0.19649332466112915, "Bleu_4": 0.15968868820583185, "METEOR": 0.24655882537735752, "ROUGE_L": 0.3531114327062228, "CIDEr": 7.755608755145778e-05, "SPICE": {"All": {"pr": 0.1, "re": 0.19047619047619047, "f": 0.1311475409836066, "fn": 17.0, "numImages": 1.0, "fp": 36.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.08333333333333333, "re": 0.14285714285714285, "f": 0.10526315789473685, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.375, "f": 0.23076923076923078, "fn": 5.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}}, "caption": "The image shows a large clock tower in the middle of a city square. The clock face is illuminated and there are people walking around the square. The sky is clear and there are streetlights on the sidewalk."}, "516508": {"image_id": 516508, "Bleu_1": 0.25641025640368187, "Bleu_2": 0.14227759830242195, "Bleu_3": 0.08178816083045058, "Bleu_4": 1.1103047724285478e-05, "METEOR": 0.17788319769503125, "ROUGE_L": 0.24148851939825808, "CIDEr": 3.3513456740291022e-06, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.15, "f": 0.19354838709677416, "fn": 17.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.3333333333333333, "f": 0.42857142857142855, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This image shows a large, ornate clock hanging on the wall of a church. The clock has two hands and is surrounded by intricate carvings. The walls of the church are made of stone and have stained glass windows."}, "520528": {"image_id": 520528, "Bleu_1": 0.45161290321123837, "Bleu_2": 0.30053715350890803, "Bleu_3": 0.14603807954737016, "Bleu_4": 1.8262493612863805e-05, "METEOR": 0.29782642252924046, "ROUGE_L": 0.3330300272975432, "CIDEr": 0.001293644542209661, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 12.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3333333333333333, "f": 0.27272727272727276, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a young boy in a baseball uniform holding a baseball bat and about to throw a pitch. The background is a green field with trees in the distance."}, "37675": {"image_id": 37675, "Bleu_1": 0.2142857142806123, "Bleu_2": 0.12521758066643465, "Bleu_3": 0.07318524682825046, "Bleu_4": 1.0012706930582776e-05, "METEOR": 0.23463805588992892, "ROUGE_L": 0.21631205673758863, "CIDEr": 2.2210197480773345e-07, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2608695652173913, "f": 0.24, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.1, "f": 0.09523809523809525, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a white church with a red roof and a bell tower in the background. In front of the church, there are two horses grazing on the grass. The sky is clear and blue, with some clouds in the distance."}, "232383": {"image_id": 232383, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.22131333406452386, "Bleu_3": 0.15981270600836578, "Bleu_4": 0.09653482517624169, "METEOR": 0.2643762243817187, "ROUGE_L": 0.2765544041450777, "CIDEr": 1.5685400204654685e-10, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.16, "f": 0.19047619047619052, "fn": 21.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.2, "f": 0.33333333333333337, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a cat sitting on top of a computer monitor, looking at the screen. The cat is wearing a collar and has its paws on the edge of the monitor. The background of the image is a messy room with a desk, chair, and other objects scattered around."}, "137658": {"image_id": 137658, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.14819171472405493, "Bleu_3": 0.07652745233046604, "Bleu_4": 9.829979956142771e-06, "METEOR": 0.2291115737712953, "ROUGE_L": 0.25553560742070613, "CIDEr": 1.2497519080159981e-10, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.3125, "f": 0.30303030303030304, "fn": 11.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.2857142857142857, "f": 0.4, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This image shows a person holding a small flashlight in their hand. The flashlight is attached to a harness that is worn around the person's wrist. The person is wearing a backpack with various items inside, including a laptop and a cell phone. The background is a dark, cloudy sky."}, "209322": {"image_id": 209322, "Bleu_1": 0.45161290321123837, "Bleu_2": 0.3470304129597038, "Bleu_3": 0.25515202680037635, "Bleu_4": 0.15606652450341843, "METEOR": 0.33287084461486094, "ROUGE_L": 0.41673783091374894, "CIDEr": 0.005682744174815719, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.2727272727272727, "f": 0.2926829268292683, "fn": 16.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5, "f": 0.5263157894736842, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "This is a bathroom with a toilet, sink, and shower. The walls are painted blue and white tiles line the floor. There is a mirror on the wall above the sink."}, "128644": {"image_id": 128644, "Bleu_1": 0.27941176470177337, "Bleu_2": 0.1937341570712195, "Bleu_3": 0.11948954426178365, "Bleu_4": 1.2728261503983665e-05, "METEOR": 0.16988316436605516, "ROUGE_L": 0.2575046904315197, "CIDEr": 4.674767691425065e-16, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.25, "f": 0.20512820512820512, "fn": 12.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is an image of a small airplane parked on the runway of an airport. The plane is painted in a red and white color scheme with the words \"Southern Airways\" written on the side. The plane is parked on the runway next to a small building with a sign that reads \"Southern Airways.\" There are several other planes parked nearby, and the runway is covered in snow."}, "342675": {"image_id": 342675, "Bleu_1": 0.19999999999636367, "Bleu_2": 0.13608276348545723, "Bleu_3": 0.07043309782608961, "Bleu_4": 9.053817930686393e-06, "METEOR": 0.2601243245962571, "ROUGE_L": 0.2513243084167157, "CIDEr": 2.563794508599409e-13, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 14.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a man standing on the platform of a train station, looking at a sign on the side of the train. The train is red and has the words \"train\" written on the side in white letters. There are people standing on the platform and in the background, there are buildings and trees."}, "200234": {"image_id": 200234, "Bleu_1": 0.2142857142818878, "Bleu_2": 0.12483755678422238, "Bleu_3": 0.06608439529502602, "Bleu_4": 8.590238521223447e-06, "METEOR": 0.1310942744087003, "ROUGE_L": 0.23775055679287305, "CIDEr": 2.135074371962179e-11, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.21052631578947367, "f": 0.21621621621621623, "fn": 15.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA young boy is playing with a soccer ball in a park surrounded by trees. There are picnic tables and benches nearby, and a small stream runs through the area. The boy is wearing a soccer jersey and soccer cleats, and he is concentrating on his game."}, "545390": {"image_id": 545390, "Bleu_1": 0.4999999999772728, "Bleu_2": 0.4364357804516745, "Bleu_3": 0.3364781731319479, "Bleu_4": 0.21160663099152388, "METEOR": 0.3020835807255814, "ROUGE_L": 0.5362637362637362, "CIDEr": 0.19668991280639359, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.13043478260869565, "f": 0.13043478260869565, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A woman is holding a pizza in her hands at a restaurant table\""}, "43073": {"image_id": 43073, "Bleu_1": 0.24999999999609374, "Bleu_2": 0.18898223650163734, "Bleu_3": 0.13207990771849945, "Bleu_4": 0.07839621745129201, "METEOR": 0.2549287194805877, "ROUGE_L": 0.2401574803149606, "CIDEr": 1.6123653061709643e-17, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.21428571428571427, "f": 0.26666666666666666, "fn": 22.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.36363636363636365, "f": 0.4444444444444444, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a young boy sitting on a bed, looking at a woman who is holding a hair dryer. The woman is wearing a pink shirt and has a smiling expression on her face. The boy is wearing a blue shirt and has a curious expression on his face. The background of the image is a pink wall with white flowers on it."}, "188651": {"image_id": 188651, "Bleu_1": 0.26190476189852613, "Bleu_2": 0.17871654962201275, "Bleu_3": 0.0927733381723083, "Bleu_4": 1.1961929431463712e-05, "METEOR": 0.20840122076474188, "ROUGE_L": 0.2663755458515284, "CIDEr": 1.9561157744900803e-07, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.20833333333333334, "f": 0.1851851851851852, "fn": 19.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.18181818181818182, "f": 0.19999999999999998, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a cat lying on the ground next to a car. The cat is white with black spots and has a pink nose. The car is a silver sedan with tinted windows. There are no other objects in the image."}, "484551": {"image_id": 484551, "Bleu_1": 0.39999999999, "Bleu_2": 0.267945650816049, "Bleu_3": 0.19624108648339775, "Bleu_4": 0.14216723686741756, "METEOR": 0.289286029913773, "ROUGE_L": 0.3359559402045633, "CIDEr": 1.959569539237413e-05, "SPICE": {"All": {"pr": 0.15625, "re": 0.14285714285714285, "f": 0.14925373134328357, "fn": 30.0, "numImages": 1.0, "fp": 27.0, "tp": 5.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.1, "f": 0.0909090909090909, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.3076923076923077, "f": 0.3076923076923077, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The woman is sitting in the front of a small boat on the water. She is wearing an orange shirt and has her hands on the steering wheel. The water is calm and there are some trees in the background."}, "396224": {"image_id": 396224, "Bleu_1": 0.4090909090723141, "Bleu_2": 0.19738550847874506, "Bleu_3": 1.2489168104898057e-06, "Bleu_4": 3.182084683852089e-09, "METEOR": 0.13364796171197912, "ROUGE_L": 0.2791762013729977, "CIDEr": 0.043937998806853645, "SPICE": {"All": {"pr": 0.25, "re": 0.08695652173913043, "f": 0.12903225806451613, "fn": 21.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.18181818181818182, "f": 0.26666666666666666, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image shows a table set with a turkey, mashed potatoes, and vegetables. There are also glasses of wine on the table."}, "255067": {"image_id": 255067, "Bleu_1": 0.2444444444390124, "Bleu_2": 0.14907119849663567, "Bleu_3": 0.08024900879514213, "Bleu_4": 1.0532159683631698e-05, "METEOR": 0.20938944088649886, "ROUGE_L": 0.21048999309868874, "CIDEr": 9.61715690620439e-08, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.03225806451612903, "f": 0.046511627906976744, "fn": 30.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.07692307692307693, "f": 0.1111111111111111, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}}, "caption": "The image shows a polar bear standing on the edge of a small pond, looking out at the water. The bear is wearing a blue collar and has a tag on its neck. The background is a rocky terrain with some trees in the distance."}, "479129": {"image_id": 479129, "Bleu_1": 0.3793103448145066, "Bleu_2": 0.28509785718527286, "Bleu_3": 0.14439141776034822, "Bleu_4": 1.8446445731695713e-05, "METEOR": 0.24897904816040942, "ROUGE_L": 0.3373271889400921, "CIDEr": 0.008470964957650184, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.18518518518518517, "f": 0.17857142857142858, "fn": 22.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.3333333333333333, "f": 0.16666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4, "f": 0.34782608695652173, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a plate with a banana split on it. The banana is topped with whipped cream and chocolate sauce. There are also some sprinkles on the plate."}, "363887": {"image_id": 363887, "Bleu_1": 0.17142857142612247, "Bleu_2": 0.09968895725441093, "Bleu_3": 0.05267385023875527, "Bleu_4": 6.834041280576724e-06, "METEOR": 0.19432916895902813, "ROUGE_L": 0.1764705882352941, "CIDEr": 1.387885751020068e-20, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.19230769230769232, "f": 0.2272727272727273, "fn": 21.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3333333333333333, "f": 0.34782608695652173, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This is an old fire truck parked on the side of a dirt road in the mountains. The truck is red and has a large ladder on the back. There are several other vehicles parked nearby, including a pickup truck and a motorcycle. The sky is clear and blue, with a few clouds scattered across it. The mountains in the background are rugged and rocky, with trees growing on them."}, "441969": {"image_id": 441969, "Bleu_1": 0.26785714285235973, "Bleu_2": 0.19738550848437394, "Bleu_3": 0.15336829563872276, "Bleu_4": 0.11953994172638398, "METEOR": 0.2340136888084681, "ROUGE_L": 0.2426136363636364, "CIDEr": 7.026693950981311e-13, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.2608695652173913, "f": 0.1764705882352941, "fn": 17.0, "numImages": 1.0, "fp": 39.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.16666666666666666, "f": 0.11764705882352942, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}}, "caption": "This image shows a small balcony with a table and chairs on it. There is a large window on the wall behind the table, which allows natural light to enter the room. The balcony is surrounded by brick walls and has a wooden floor. There are plants on the table and in pots on the balcony."}, "410225": {"image_id": 410225, "Bleu_1": 0.4583333333142362, "Bleu_2": 0.2823298512746205, "Bleu_3": 1.535902471682881e-06, "Bleu_4": 3.6242479821540745e-09, "METEOR": 0.2571891908950349, "ROUGE_L": 0.38677536231884063, "CIDEr": 0.04996724827871868, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.14285714285714285, "f": 0.17857142857142855, "fn": 30.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.08333333333333333, "f": 0.1111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "A table with a cup of coffee and a spoon sitting on it. There are several laptops and cups of coffee on the table."}, "277073": {"image_id": 277073, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.13726099121497223, "Bleu_3": 0.07537266335317148, "Bleu_4": 9.989489215549929e-06, "METEOR": 0.17038735009297976, "ROUGE_L": 0.19728331177231562, "CIDEr": 5.165248919907456e-09, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.14814814814814814, "f": 0.1509433962264151, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.25, "f": 0.2608695652173913, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a man riding a motorcycle on the street. The man is wearing a helmet and has a backpack on his back. There are other vehicles on the road, including cars and buses. The sky is blue and there are buildings in the background."}, "41011": {"image_id": 41011, "Bleu_1": 0.4999999999791667, "Bleu_2": 0.39009474878613976, "Bleu_3": 0.2747975949286121, "Bleu_4": 0.1772984226390508, "METEOR": 0.3270915987085849, "ROUGE_L": 0.5029446407538279, "CIDEr": 0.10059290936829776, "SPICE": {"All": {"pr": 0.08571428571428572, "re": 0.3333333333333333, "f": 0.13636363636363638, "fn": 12.0, "numImages": 1.0, "fp": 64.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.42857142857142855, "f": 0.21428571428571427, "fn": 4.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 18.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.0967741935483871, "re": 0.5, "f": 0.16216216216216214, "fn": 3.0, "numImages": 1.0, "fp": 28.0, "tp": 3.0}}, "caption": "The image shows a man in a black suit and top hat riding a horse through a field with other horses in the background."}, "343821": {"image_id": 343821, "Bleu_1": 0.22499999999437506, "Bleu_2": 0.07595545252935183, "Bleu_3": 5.334717645470252e-07, "Bleu_4": 1.4232564071963268e-09, "METEOR": 0.19684233360950465, "ROUGE_L": 0.22426470588235295, "CIDEr": 8.633312135843897e-07, "SPICE": {"All": {"pr": 0.2, "re": 0.17391304347826086, "f": 0.18604651162790697, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "A white swan is standing in the water with its babies. The swan is looking down at the water and the babies are looking up at it. The sky is cloudy and there are some birds flying in the distance."}, "530620": {"image_id": 530620, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.1628822035823003, "Bleu_3": 0.08206702275709715, "Bleu_4": 1.041362763232212e-05, "METEOR": 0.18179525596617024, "ROUGE_L": 0.23252858958068615, "CIDEr": 3.9680677283507054e-10, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.13793103448275862, "f": 0.1904761904761905, "fn": 25.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "A group of people are standing next to a truck that is parked on the side of a road. They are all wearing yellow vests and helmets, and one person is holding a large balloon. The sky is clear and there are no buildings or other structures in the background."}, "22113": {"image_id": 22113, "Bleu_1": 0.45454545453168055, "Bleu_2": 0.315328111933741, "Bleu_3": 0.18580806511385534, "Bleu_4": 0.12092555992241515, "METEOR": 0.2965137315302783, "ROUGE_L": 0.36033755274261603, "CIDEr": 0.0006780976328946315, "SPICE": {"All": {"pr": 0.16, "re": 0.16666666666666666, "f": 0.16326530612244897, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.3333333333333333, "f": 0.2, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This is an image of a red fire hydrant on the side of a street. The hydrant has a green handle and is surrounded by concrete. There is a fence in the background."}, "82836": {"image_id": 82836, "Bleu_1": 0.3499999999912501, "Bleu_2": 0.28419928002220657, "Bleu_3": 0.21985893410905843, "Bleu_4": 0.15481575551498444, "METEOR": 0.24354938760720207, "ROUGE_L": 0.31961077844311375, "CIDEr": 4.72631974561176e-06, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.18181818181818182, "f": 0.17391304347826086, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of seagulls standing on the beach, looking out at the ocean. The sky is cloudy and there are waves crashing against the shore. The sand is brown and there are some rocks in the distance."}, "538925": {"image_id": 538925, "Bleu_1": 0.49999999998684214, "Bleu_2": 0.3676073110370993, "Bleu_3": 0.22414497723305324, "Bleu_4": 0.13393057934008426, "METEOR": 0.27661925947974303, "ROUGE_L": 0.39725036179450074, "CIDEr": 0.0013222607337571848, "SPICE": {"All": {"pr": 0.11428571428571428, "re": 0.25, "f": 0.1568627450980392, "fn": 12.0, "numImages": 1.0, "fp": 31.0, "tp": 4.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.125, "f": 0.09523809523809525, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1875, "re": 0.5, "f": 0.2727272727272727, "fn": 3.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}}, "caption": "The image shows a bedroom with a white wall and a wooden floor. There is a bed with a white sheet and a brown blanket on it. The room has a window with a view of the outside."}, "440189": {"image_id": 440189, "Bleu_1": 0.7499999999531252, "Bleu_2": 0.5916079782717537, "Bleu_3": 0.3684031498394055, "Bleu_4": 4.428500142384227e-05, "METEOR": 0.2690688369212308, "ROUGE_L": 0.5897790055248618, "CIDEr": 0.4991894623215585, "SPICE": {"All": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 12.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "A young boy is playing with a frisbee on the beach in front of a castle."}, "32777": {"image_id": 32777, "Bleu_1": 0.38461538460552275, "Bleu_2": 0.22496063532707972, "Bleu_3": 0.16009491213292282, "Bleu_4": 0.10332550163062576, "METEOR": 0.26567556823769933, "ROUGE_L": 0.2741573033707865, "CIDEr": 3.727831887473839e-06, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.2727272727272727, "f": 0.2666666666666666, "fn": 16.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a train station with a train on the tracks. There are people standing on the platform and others walking around the station. The train has a blue and yellow livery and is pulling into the station."}, "50679": {"image_id": 50679, "Bleu_1": 0.6923076922011837, "Bleu_2": 0.5883484053221515, "Bleu_3": 0.45533661740057985, "Bleu_4": 0.37068663811774644, "METEOR": 0.32212936405287224, "ROUGE_L": 0.657935285053929, "CIDEr": 0.8250343792287953, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.15, "f": 0.13953488372093023, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "An orange lies on the ground in the middle of a parking lot."}, "86250": {"image_id": 86250, "Bleu_1": 0.1481481481467764, "Bleu_2": 0.09114479026910724, "Bleu_3": 0.053917441618449524, "Bleu_4": 0.03495422140533509, "METEOR": 0.13002030560641312, "ROUGE_L": 0.13791989664082688, "CIDEr": 6.768940832237717e-57, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.15789473684210525, "f": 0.125, "fn": 16.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.3333333333333333, "f": 0.2608695652173913, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a young woman sitting on the floor in a living room, wearing a black shirt and jeans. She is holding a book in her hand and looking up at the ceiling. There are two windows on the wall behind her, one of which is open, allowing natural light to enter the room. The floor is made of hardwood and there is a rug in the center of the room. The walls are painted white and there are two couches in the room, one of which is covered in a throw blanket. The room is well lit and there are no other objects in the room."}, "482432": {"image_id": 482432, "Bleu_1": 0.692307692254438, "Bleu_2": 0.48038446137676916, "Bleu_3": 0.39777317387085076, "Bleu_4": 0.33495318894035875, "METEOR": 0.25133343486244786, "ROUGE_L": 0.5922330097087377, "CIDEr": 1.3957419039877124, "SPICE": {"All": {"pr": 0.5714285714285714, "re": 0.18181818181818182, "f": 0.27586206896551724, "fn": 18.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.4, "f": 0.5714285714285715, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 4.0}}, "caption": "The image shows a sink with a toothbrush and toothpaste on the counter."}, "330880": {"image_id": 330880, "Bleu_1": 0.20289855072169713, "Bleu_2": 0.18116794523581797, "Bleu_3": 0.14324508243582404, "Bleu_4": 0.10751130192709912, "METEOR": 0.22160547478688764, "ROUGE_L": 0.2503419972640219, "CIDEr": 2.713556446935802e-20, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.11764705882352941, "f": 0.11428571428571428, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5, "f": 0.36363636363636365, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "This is a photo of a man sitting at a table in a restaurant, holding a large pizza in his hands. The pizza has various toppings on it, including pepperoni, mushrooms, and olives. The man is wearing glasses and has a serious expression on his face. There are other people sitting at tables nearby, enjoying their meals. The atmosphere is cozy and intimate, with dim lighting and comfortable seating."}, "201934": {"image_id": 201934, "Bleu_1": 0.5757575757401286, "Bleu_2": 0.444878260487613, "Bleu_3": 0.2944829952668866, "Bleu_4": 0.20312919694591627, "METEOR": 0.29449765076720663, "ROUGE_L": 0.39967239967239965, "CIDEr": 0.0013387316494315098, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.35714285714285715, "f": 0.22727272727272724, "fn": 9.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6666666666666666, "f": 0.4444444444444444, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "This is an image of a white school bus parked on the side of a road next to a fence. There are no people in the image, just the bus and the fence."}, "579462": {"image_id": 579462, "Bleu_1": 0.06730769230736873, "Bleu_2": 0.047708547839492715, "Bleu_3": 0.022272812359215643, "Bleu_4": 2.7095229161041962e-06, "METEOR": 0.10382637980994337, "ROUGE_L": 0.07729905865314989, "CIDEr": 8.686613169210557e-234, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.125, "f": 0.13043478260869565, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The woman is standing in front of a bed with a suitcase on it. She is wearing a dress and has her hair tied back. There is a lamp on the nightstand next to the bed.\n\nThe image is taken in a bedroom with a large window on the wall opposite the bed. The curtains are open, allowing natural light to enter the room. The floor is covered in a red carpet, and there is a rug on top of it. The walls are painted a light color, and there are two paintings on the wall. One is a landscape, and the other is a still life.\n\nThe woman is standing in front of the bed, looking at the suitcase. She is wearing a dress and has her hair tied back. She is holding the handle of the suitcase with one hand and looking at it with the other. The suitcase is open, revealing its contents.\n\nThe image is taken in a warm, inviting room with a comfortable bed and a well-lit space. The woman is standing in front of the bed, looking at the suitcase with a sense of purpose. The image is taken in a warm, inviting room with a comfortable bed and a well-lit space."}, "183657": {"image_id": 183657, "Bleu_1": 0.21951219511659734, "Bleu_2": 0.07407971974688987, "Bleu_3": 5.201293386117482e-07, "Bleu_4": 1.3871953183286941e-09, "METEOR": 0.153546265063178, "ROUGE_L": 0.22021660649819497, "CIDEr": 4.568823162969218e-07, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.3333333333333333, "f": 0.27027027027027023, "fn": 10.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.5, "f": 0.22222222222222224, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a cup of coffee floating in the water. The cup is made of ceramic and has a white handle. The cup is surrounded by ice and snow. The background is a frozen lake with trees in the distance."}, "352652": {"image_id": 352652, "Bleu_1": 0.29629629628532245, "Bleu_2": 0.18490006540142992, "Bleu_3": 1.1099703391050027e-06, "Bleu_4": 2.7474558341074007e-09, "METEOR": 0.1797882322104056, "ROUGE_L": 0.2278244631185808, "CIDEr": 0.018244716294271976, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.23076923076923078, "f": 0.21818181818181817, "fn": 20.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.3333333333333333, "f": 0.16666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "This is an image of a car parked in the snow. The car has snow on the hood and windshield, and there are other cars parked nearby."}, "339823": {"image_id": 339823, "Bleu_1": 0.3571428571343538, "Bleu_2": 0.22861497842409673, "Bleu_3": 0.13773990809586936, "Bleu_4": 1.6088986597188548e-05, "METEOR": 0.27848842706053256, "ROUGE_L": 0.2622527944969905, "CIDEr": 9.590122694061356e-07, "SPICE": {"All": {"pr": 0.5384615384615384, "re": 0.2916666666666667, "f": 0.3783783783783784, "fn": 17.0, "numImages": 1.0, "fp": 6.0, "tp": 7.0}, "Relation": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The woman in the image is wearing a yellow and black dress with an orange scarf around her neck. She is holding an umbrella in her hand and smiling at the camera. The background is a blue sky with fluffy white clouds."}, "203690": {"image_id": 203690, "Bleu_1": 0.30434782607372407, "Bleu_2": 0.16633695977521876, "Bleu_3": 0.10962747416686626, "Bleu_4": 1.6020720993317762e-05, "METEOR": 0.25434156493021653, "ROUGE_L": 0.3262032085561497, "CIDEr": 0.0459603348443305, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.16666666666666666, "f": 0.16, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "A group of people are walking on the beach with surfboards. The sky is cloudy and there are palm trees in the background."}, "344614": {"image_id": 344614, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.23145502493836512, "Bleu_3": 0.1786220727645711, "Bleu_4": 0.1388488219206855, "METEOR": 0.20362472270933948, "ROUGE_L": 0.3078864353312303, "CIDEr": 6.543526299774247e-10, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.1, "f": 0.13953488372093023, "fn": 27.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.375, "f": 0.42857142857142855, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a clock tower in the middle of a city. The clock tower is made of stone and has a large clock face on it. There are buildings in the background, including a tall skyscraper with windows on the upper floors. The sky is clear and blue."}, "573549": {"image_id": 573549, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.1010152544531381, "Bleu_3": 6.010242872773113e-07, "Bleu_4": 1.4739391640949855e-09, "METEOR": 0.1720867566745868, "ROUGE_L": 0.19690122659780504, "CIDEr": 7.53948719829263e-11, "SPICE": {"All": {"pr": 0.11428571428571428, "re": 0.19047619047619047, "f": 0.14285714285714285, "fn": 17.0, "numImages": 1.0, "fp": 31.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}}, "caption": "The image shows a street with a few people walking on it. There are buildings on either side of the street, with signs on them that read \"dance hall\" and \"theater\". There is a large tree in the middle of the street, with people sitting on benches under it."}, "522941": {"image_id": 522941, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.15041420939612582, "Bleu_3": 0.09672659665842727, "Bleu_4": 1.1657633846364334e-05, "METEOR": 0.22960790613266416, "ROUGE_L": 0.22048192771084338, "CIDEr": 1.1966282412381701e-11, "SPICE": {"All": {"pr": 0.16, "re": 0.2222222222222222, "f": 0.18604651162790697, "fn": 14.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a large elephant standing in the middle of a dirt road with people gathered around it. The elephant has a large tusk and is wearing a decorative headdress on its head. The people in the background are dressed in various clothing and are looking at the elephant with curiosity."}, "511662": {"image_id": 511662, "Bleu_1": 0.19999999999692308, "Bleu_2": 0.12499999999806191, "Bleu_3": 0.079159520964846, "Bleu_4": 0.05318380992999435, "METEOR": 0.18575874954826818, "ROUGE_L": 0.2474087426768815, "CIDEr": 1.4331721009370563e-15, "SPICE": {"All": {"pr": 0.1875, "re": 0.15789473684210525, "f": 0.17142857142857143, "fn": 16.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a beach with palm trees and a large cruise ship in the background. The ship has several colorful sails and is docked at the shore. There are several beach chairs and umbrellas on the sand, and a few people are standing on the shore, looking out at the water. The sky is clear and blue, with a few clouds in the distance."}, "377371": {"image_id": 377371, "Bleu_1": 0.45454545452479345, "Bleu_2": 0.36037498506145293, "Bleu_3": 0.2690709701483211, "Bleu_4": 0.1789417717985297, "METEOR": 0.3081325017228779, "ROUGE_L": 0.35952848722986247, "CIDEr": 0.239251570520479, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.16, "f": 0.15384615384615383, "fn": 21.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a wooden cutting board with sliced nuts on it. There are also bananas and other fruits on the table."}, "170813": {"image_id": 170813, "Bleu_1": 0.18518518518175586, "Bleu_2": 0.1182211503531082, "Bleu_3": 6.453505325095797e-07, "Bleu_4": 1.5151450472612192e-09, "METEOR": 0.20348646859323777, "ROUGE_L": 0.17468499427262313, "CIDEr": 6.646308546026124e-13, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.13636363636363635, "f": 0.12244897959183673, "fn": 19.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a person sitting on a bench in a park, looking at their phone. The bench is made of wood and has a backrest. The person is wearing a black jacket and jeans, and has a black hat on their head. The grass is green and there are trees in the background."}, "347210": {"image_id": 347210, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.20966962740242623, "Bleu_3": 0.12595520584707845, "Bleu_4": 1.4682329883681743e-05, "METEOR": 0.2508313324304731, "ROUGE_L": 0.24238410596026488, "CIDEr": 8.527967707350812e-09, "SPICE": {"All": {"pr": 0.0625, "re": 0.05263157894736842, "f": 0.05714285714285714, "fn": 18.0, "numImages": 1.0, "fp": 15.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image shows a park with a bench in the middle of the grass. The bench is made of wood and has a green seat and backrest. The trees are green and have leaves on them. The sky is blue and there are clouds in it."}, "175494": {"image_id": 175494, "Bleu_1": 0.22727272726756204, "Bleu_2": 0.17807996398101744, "Bleu_3": 0.11472822500028991, "Bleu_4": 0.07790345908043068, "METEOR": 0.2035783414482347, "ROUGE_L": 0.25318206972883234, "CIDEr": 9.505398439435087e-08, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.21739130434782608, "f": 0.23809523809523808, "fn": 18.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.625, "f": 0.5555555555555556, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "This is a picture of a dog lying on a bed with a cartoon character on the wall. The dog is wearing a collar and appears to be sleeping. The cartoon character on the wall is a character from the cartoon show \"Scooby Doo\"."}, "265879": {"image_id": 265879, "Bleu_1": 0.340909090901343, "Bleu_2": 0.21810252258335, "Bleu_3": 0.17824363503564447, "Bleu_4": 0.15331320282613667, "METEOR": 0.3204725683927055, "ROUGE_L": 0.35835509138381205, "CIDEr": 8.208914727085685e-07, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.08888888888888889, "f": 0.12698412698412698, "fn": 41.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 16.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.07692307692307693, "f": 0.11764705882352941, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.1875, "f": 0.25, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is a picture of a man sitting at a table with other people. They are all wearing sunglasses and smiling. There are several bottles of wine on the table, as well as plates of food. The atmosphere appears to be festive and social."}, "433998": {"image_id": 433998, "Bleu_1": 0.4523809523594105, "Bleu_2": 0.2779132460864775, "Bleu_3": 0.21293293268812977, "Bleu_4": 0.1650806950002169, "METEOR": 0.2230247585037262, "ROUGE_L": 0.3881176665014048, "CIDEr": 0.14245080617906708, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.2, "f": 0.1923076923076923, "fn": 20.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.5, "f": 0.41666666666666663, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a baseball game in progress, with a pitcher standing on the mound and a catcher behind him. The crowd is seated in the stands, watching the game. The field is green and there are white lines marking the bases."}, "286711": {"image_id": 286711, "Bleu_1": 0.34482758619500603, "Bleu_2": 0.22194838080144763, "Bleu_3": 0.12219311400302733, "Bleu_4": 1.6275776313020367e-05, "METEOR": 0.2039228056469627, "ROUGE_L": 0.26361279170267937, "CIDEr": 0.01063647114512796, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.1875, "f": 0.16216216216216214, "fn": 13.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a baseball player in the middle of a game, holding a bat and running towards home plate. The crowd is cheering and watching from the stands."}, "552744": {"image_id": 552744, "Bleu_1": 0.29629629628532245, "Bleu_2": 0.10675210253269501, "Bleu_3": 7.69610448813251e-07, "Bleu_4": 2.0876149875064654e-09, "METEOR": 0.15326709003579042, "ROUGE_L": 0.2606837606837607, "CIDEr": 0.011007235749125498, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.17391304347826086, "f": 0.15094339622641512, "fn": 19.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The woman is wearing a black shirt and has her hair tied back. She is holding a stuffed animal in her arms and looking at the camera."}, "447279": {"image_id": 447279, "Bleu_1": 0.25714285713918367, "Bleu_2": 0.22010725787113397, "Bleu_3": 0.1527249316435895, "Bleu_4": 0.11238130413195728, "METEOR": 0.24707051483913386, "ROUGE_L": 0.2890995260663507, "CIDEr": 3.0989546123986625e-22, "SPICE": {"All": {"pr": 0.25, "re": 0.17391304347826086, "f": 0.20512820512820512, "fn": 19.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This image shows a group of people standing on the side of a street at night. They are wearing yellow vests and helmets, and they are holding onto the reins of horses that are pulling a cart. The horses are wearing blankets and saddles, and they are standing in the middle of the street. There are streetlights on either side of the street, and there are buildings in the background."}, "409217": {"image_id": 409217, "Bleu_1": 0.19047619047316708, "Bleu_2": 0.14664711501900682, "Bleu_3": 0.10188560350198984, "Bleu_4": 0.07705561713121692, "METEOR": 0.1900994707323242, "ROUGE_L": 0.24314897857498752, "CIDEr": 3.4066030394784983e-15, "SPICE": {"All": {"pr": 0.05263157894736842, "re": 0.034482758620689655, "f": 0.041666666666666664, "fn": 28.0, "numImages": 1.0, "fp": 18.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "This image shows a plate of food with steak, broccoli, and beans. The steak is cooked and has a nice char on it, while the broccoli is tender and slightly wilted. The beans are cooked through and have a nice crunch to them. The plate is on a green surface, and there are no utensils or other food items visible in the image."}, "28114": {"image_id": 28114, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.18971331171167066, "Bleu_3": 0.09574966238312985, "Bleu_4": 1.2171327283748823e-05, "METEOR": 0.23032505459255626, "ROUGE_L": 0.21254355400696864, "CIDEr": 1.4195483219870702e-07, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.14285714285714285, "f": 0.13636363636363635, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This is an image of a bus driving down the street. It is a large, orange bus with the words \"Van\" written on the side. There are people walking on the sidewalk and biking on the road. The sky is clear and blue."}, "33994": {"image_id": 33994, "Bleu_1": 0.4054054053944486, "Bleu_2": 0.18380365551841535, "Bleu_3": 9.882801705785478e-07, "Bleu_4": 2.3082897967275263e-09, "METEOR": 0.20414342492605864, "ROUGE_L": 0.27858121479677267, "CIDEr": 9.001547418310908e-05, "SPICE": {"All": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a large, yellow flower sitting on a table with several other flowers around it. The table has a green cloth covering it and there are several people standing around it, looking at the flowers."}, "278509": {"image_id": 278509, "Bleu_1": 0.36585365852766216, "Bleu_2": 0.30242918944709846, "Bleu_3": 0.22718741467371711, "Bleu_4": 0.18743785288733245, "METEOR": 0.3062761879226263, "ROUGE_L": 0.3434201266713582, "CIDEr": 5.946890355469604e-06, "SPICE": {"All": {"pr": 0.4444444444444444, "re": 0.2962962962962963, "f": 0.3555555555555555, "fn": 19.0, "numImages": 1.0, "fp": 10.0, "tp": 8.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.5, "f": 0.5555555555555556, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "This is an image of a motorcycle parked on the side of a road. The motorcycle is black and has a white license plate on the front. There is a reflection of the motorcycle in the window of a nearby building."}, "544975": {"image_id": 544975, "Bleu_1": 0.23076923076568048, "Bleu_2": 0.15887222732309736, "Bleu_3": 0.07371996827596482, "Bleu_4": 8.965838925947828e-06, "METEOR": 0.2372056711816187, "ROUGE_L": 0.22171740118128122, "CIDEr": 4.211270427652146e-16, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.11764705882352941, "f": 0.11428571428571428, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a giraffe standing next to a zebra in a zoo enclosure. The giraffe is looking down at the zebra, while the zebra is looking up at the giraffe. The giraffe has a long neck and legs, while the zebra has a black and white striped body. The background of the image is a rocky terrain with trees and bushes growing in it."}, "158806": {"image_id": 158806, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.18210783976741574, "Bleu_3": 0.11216649288903491, "Bleu_4": 1.323451095652116e-05, "METEOR": 0.22869915603954905, "ROUGE_L": 0.22578655151141266, "CIDEr": 5.275721199734693e-10, "SPICE": {"All": {"pr": 0.15, "re": 0.35294117647058826, "f": 0.21052631578947367, "fn": 11.0, "numImages": 1.0, "fp": 34.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 16.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.3333333333333333, "f": 0.18181818181818182, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3125, "re": 0.7142857142857143, "f": 0.43478260869565216, "fn": 2.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}}, "caption": "A dog is sitting on the ground next to a person who is holding a plate with a piece of toast on it. The dog is looking up at the person with its mouth open, as if it is waiting for them to give it some of the toast."}, "267321": {"image_id": 267321, "Bleu_1": 0.34146341462581803, "Bleu_2": 0.2771809306010938, "Bleu_3": 0.2143601397219743, "Bleu_4": 0.1508931842274024, "METEOR": 0.24437039797271012, "ROUGE_L": 0.3808344068972352, "CIDEr": 0.002460137144758688, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.125, "f": 0.19354838709677416, "fn": 21.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Relation": {"pr": 1.0, "re": 0.125, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "This is a living room with a couch, chair, and coffee table. There are plants on the coffee table and a red chair in the corner. The walls are painted white and there are windows on one side of the room."}, "137188": {"image_id": 137188, "Bleu_1": 0.4583333333142362, "Bleu_2": 0.3457820373893416, "Bleu_3": 0.1758169434508259, "Bleu_4": 2.2554890371657057e-05, "METEOR": 0.28885300014289067, "ROUGE_L": 0.428714859437751, "CIDEr": 0.08017017365253795, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.25, "f": 0.2941176470588235, "fn": 15.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.6666666666666666, "re": 0.2857142857142857, "f": 0.4, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.5, "f": 0.5454545454545454, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A cat sits on a shelf next to a stuffed animal in a store window.\""}, "132702": {"image_id": 132702, "Bleu_1": 0.24999999999431824, "Bleu_2": 0.1704985848636984, "Bleu_3": 0.11144846405416943, "Bleu_4": 1.3555314602468014e-05, "METEOR": 0.2123961045842725, "ROUGE_L": 0.25702247191011235, "CIDEr": 4.635112754308359e-08, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.21052631578947367, "f": 0.1702127659574468, "fn": 15.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.1, "re": 0.2, "f": 0.13333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a plate of steamed broccoli on a white surface. The broccoli is arranged in a neat row, with each piece of the vegetable visible. The plate is covered with a white cloth, and there are no other objects in the image."}, "151075": {"image_id": 151075, "Bleu_1": 0.3090909090852893, "Bleu_2": 0.22696949467552002, "Bleu_3": 0.1428653103202315, "Bleu_4": 0.08653548971325163, "METEOR": 0.23336533106434224, "ROUGE_L": 0.24610951008645532, "CIDEr": 2.8272439003565365e-13, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.16, "f": 0.15384615384615383, "fn": 21.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a surfer riding a wave on a surfboard. The surfer is wearing a black wetsuit and a helmet, and is standing on the board as it rides the wave. The wave is large and white, with foam on top. The sky is cloudy and there are some birds flying in the distance."}, "516372": {"image_id": 516372, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.1628822035823003, "Bleu_3": 0.13027327825651416, "Bleu_4": 0.10899268608532943, "METEOR": 0.2982487623967818, "ROUGE_L": 0.23252858958068615, "CIDEr": 1.984977790180968e-10, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.20833333333333334, "f": 0.25641025641025644, "fn": 19.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4444444444444444, "f": 0.5333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image shows a parked car in front of a house with a red fire hydrant next to it. The car is a silver truck with a black hood and a white roof. The house has a brown roof and white siding. There are trees and bushes in the background."}, "397958": {"image_id": 397958, "Bleu_1": 0.15789473684002772, "Bleu_2": 0.13764944032051382, "Bleu_3": 0.11538680376481274, "Bleu_4": 0.09578585725811953, "METEOR": 0.17182184784570587, "ROUGE_L": 0.20926243567753, "CIDEr": 5.69235214205341e-26, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.2608695652173913, "f": 0.23529411764705882, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a black and white cow standing in a field with tall grass and wildflowers growing around it. The cow is looking directly at the camera with its eyes and mouth open, as if it is about to speak. The sky in the background is a bright blue with fluffy white clouds.\n\nCaption: A curious black and white cow stands in a field, looking directly at the camera with its eyes and mouth open."}, "154004": {"image_id": 154004, "Bleu_1": 0.23076923076568048, "Bleu_2": 0.199156876700835, "Bleu_3": 0.136051505473477, "Bleu_4": 0.07983247459997697, "METEOR": 0.197594438876003, "ROUGE_L": 0.24457650175413476, "CIDEr": 6.337563900090996e-19, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.18181818181818182, "f": 0.17391304347826086, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a group of people sitting on the beach, looking out at the ocean. They are wearing swimsuits and sunglasses, and some of them are holding surfboards. The sky is clear and blue, with a few clouds in the distance. The beach is sandy and has some rocks and shells scattered along it. There are palm trees and other vegetation in the background."}, "179599": {"image_id": 179599, "Bleu_1": 0.3636363636280992, "Bleu_2": 0.22525531672830443, "Bleu_3": 0.1341869459898098, "Bleu_4": 1.5580691816086134e-05, "METEOR": 0.23026155007759344, "ROUGE_L": 0.29985955056179775, "CIDEr": 2.638813623780403e-07, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.1111111111111111, "f": 0.13793103448275862, "fn": 16.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a baseball player standing on a mound, holding a baseball in his hand. He is wearing a blue jersey with the number 27 on the back and white pants. The background is a blue and green field with a dirt infield."}, "282553": {"image_id": 282553, "Bleu_1": 0.3265306122382341, "Bleu_2": 0.14285714285419707, "Bleu_3": 7.572431510387479e-07, "Bleu_4": 1.75281894102292e-09, "METEOR": 0.19147342501216658, "ROUGE_L": 0.19242902208201892, "CIDEr": 8.654200059749148e-10, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.14285714285714285, "f": 0.12903225806451615, "fn": 24.0, "numImages": 1.0, "fp": 30.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.23076923076923078, "re": 0.21428571428571427, "f": 0.22222222222222224, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.08333333333333333, "re": 0.1, "f": 0.0909090909090909, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The image shows two people walking on a dirt path in the middle of a field at sunset. The sky is a deep blue and there are tall, thin trees in the background. The people are walking towards the camera, one with their arms around the other's shoulders."}, "53529": {"image_id": 53529, "Bleu_1": 0.29032258064047867, "Bleu_2": 0.18252590494116375, "Bleu_3": 0.10355615621127776, "Bleu_4": 1.1713021448556377e-05, "METEOR": 0.25469404320343003, "ROUGE_L": 0.3281173594132029, "CIDEr": 6.026564171942465e-12, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.13636363636363635, "f": 0.11999999999999998, "fn": 19.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.42857142857142855, "f": 0.2857142857142857, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA woman is sitting in the driver's seat of a green truck, wearing a green shamrock hat and holding a leash with her dog sitting in the passenger seat. The truck is decorated with green and white streamers and balloons, and there is a large shamrock on the back of the truck."}, "13168": {"image_id": 13168, "Bleu_1": 0.2972972972892623, "Bleu_2": 0.1817499189304432, "Bleu_3": 9.809046705543318e-07, "Bleu_4": 2.2953576924413835e-09, "METEOR": 0.22983240604595892, "ROUGE_L": 0.2848249027237354, "CIDEr": 2.3305912553928664e-05, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.29411764705882354, "f": 0.3225806451612903, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.75, "re": 0.6, "f": 0.6666666666666665, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a train at a station with people standing on the platform. The train is silver and has windows on the sides. There are streetlights on the platform and a sign that reads \"train station\"."}, "528738": {"image_id": 528738, "Bleu_1": 0.30769230768047345, "Bleu_2": 0.11094003924069364, "Bleu_3": 8.004271223128442e-07, "Bleu_4": 2.172998307894553e-09, "METEOR": 0.20137970107941608, "ROUGE_L": 0.18118811881188118, "CIDEr": 0.016035411466404054, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.1724137931034483, "f": 0.22727272727272724, "fn": 24.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.3333333333333333, "f": 0.4210526315789474, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "This is a kitchen countertop with various vegetables and fruits arranged on it. There are carrots, beets, potatoes, onions, garlic, lemons, and other vegetables and fruits."}, "368193": {"image_id": 368193, "Bleu_1": 0.21999999999560005, "Bleu_2": 0.06700593942469525, "Bleu_3": 4.5393651709319995e-07, "Bleu_4": 1.187741350296707e-09, "METEOR": 0.1635561090876926, "ROUGE_L": 0.18944099378881987, "CIDEr": 6.0378461399831e-11, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.09090909090909091, "f": 0.13043478260869568, "fn": 30.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.21428571428571427, "f": 0.2857142857142857, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a group of horses standing on the side of the road in front of a white building with a red roof. The horses are wearing saddles and bridles and appear to be waiting for something. The sky is clear and blue with some clouds in the distance."}, "538064": {"image_id": 538064, "Bleu_1": 0.27586206896076104, "Bleu_2": 0.20870354281255962, "Bleu_3": 0.14598577364278748, "Bleu_4": 0.10313349331598666, "METEOR": 0.28831172074719413, "ROUGE_L": 0.2643553629469122, "CIDEr": 4.704145598699269e-14, "SPICE": {"All": {"pr": 0.15151515151515152, "re": 0.25, "f": 0.18867924528301888, "fn": 15.0, "numImages": 1.0, "fp": 28.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This is a statue of a man standing on a pedestal in front of a building. The man is wearing a hat and has a cigar in his mouth. There are several other statues nearby, including one of a woman holding a baby. In the background, there is a large clock tower with a flag flying from it."}, "265636": {"image_id": 265636, "Bleu_1": 0.23809523808956923, "Bleu_2": 0.15240998561606448, "Bleu_3": 8.343000781860357e-07, "Bleu_4": 1.9643802608337804e-09, "METEOR": 0.21007084895259234, "ROUGE_L": 0.2663755458515284, "CIDEr": 1.874918644175677e-07, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.1935483870967742, "f": 0.20338983050847456, "fn": 25.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a stuffed animal sitting on top of a pile of presents. The stuffed animal is wearing a birthday hat and holding a sign that says \"happy birthday\". There is a small pile of presents next to the stuffed animal."}, "577796": {"image_id": 577796, "Bleu_1": 0.32608695651465036, "Bleu_2": 0.24077170616624616, "Bleu_3": 0.13812196235285776, "Bleu_4": 1.573366652415358e-05, "METEOR": 0.20655985384749212, "ROUGE_L": 0.25452016689847007, "CIDEr": 6.205692881646769e-09, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.18181818181818182, "f": 0.1568627450980392, "fn": 18.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is a bathroom with three urinals on the wall. The urinals are made of white porcelain and have a round shape with a hole in the center. The walls are made of white tiles and there are no other fixtures or decorations in the room."}, "554046": {"image_id": 554046, "Bleu_1": 0.4814814814636489, "Bleu_2": 0.38490017944522087, "Bleu_3": 0.2872579586598586, "Bleu_4": 0.17727652989120093, "METEOR": 0.2455919231424428, "ROUGE_L": 0.41256038647342996, "CIDEr": 0.011261822222573048, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.12, "f": 0.15789473684210525, "fn": 22.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.2727272727272727, "f": 0.37499999999999994, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This is an image of a group of sheep standing in a snowy field. They are wearing coats and hats to keep warm in the cold weather."}, "316534": {"image_id": 316534, "Bleu_1": 0.423076923060651, "Bleu_2": 0.2253202848508038, "Bleu_3": 0.12836987367391073, "Bleu_4": 1.741467509925889e-05, "METEOR": 0.2817752319630288, "ROUGE_L": 0.3382624768946396, "CIDEr": 0.02685700729379345, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.16666666666666666, "f": 0.21874999999999997, "fn": 35.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.18181818181818182, "f": 0.26666666666666666, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.29411764705882354, "f": 0.37037037037037035, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "Here is a short caption for the image:\n\nA herd of cows grazes on the grass next to a beach with palm trees in the background."}, "158950": {"image_id": 158950, "Bleu_1": 0.31914893616342244, "Bleu_2": 0.22037727300834692, "Bleu_3": 0.1479383543866371, "Bleu_4": 0.11014249684706096, "METEOR": 0.2616126199457199, "ROUGE_L": 0.2848565710473649, "CIDEr": 5.3513912707826325e-09, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.0967741935483871, "f": 0.15000000000000002, "fn": 28.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.14285714285714285, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.16666666666666666, "f": 0.23529411764705882, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a blue and yellow train traveling along a track through a rural area. The train is pulling a large cargo car with the words \"Sydney to Melbourne\" written on the side. The sky is cloudy and there are trees and fields in the background."}, "524822": {"image_id": 524822, "Bleu_1": 0.26190476189852613, "Bleu_2": 0.17871654962201275, "Bleu_3": 0.1338023071149955, "Bleu_4": 0.08852818280776471, "METEOR": 0.2101587137400264, "ROUGE_L": 0.2543786488740617, "CIDEr": 1.0230040043893737e-06, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.25, "f": 0.23076923076923075, "fn": 18.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.1111111111111111, "f": 0.09523809523809525, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This is a living room with white couches and a white coffee table. There is a large window on one wall with black shutters. The floor is made of white tiles and there is a fireplace in the corner of the room."}, "248111": {"image_id": 248111, "Bleu_1": 0.3399999999932, "Bleu_2": 0.23560603574482045, "Bleu_3": 0.1322474157068083, "Bleu_4": 1.4894157124520858e-05, "METEOR": 0.20334290232548705, "ROUGE_L": 0.2594167679222357, "CIDEr": 3.3058355444156073e-10, "SPICE": {"All": {"pr": 0.1935483870967742, "re": 0.2222222222222222, "f": 0.20689655172413793, "fn": 21.0, "numImages": 1.0, "fp": 25.0, "tp": 6.0}, "Relation": {"pr": 0.07142857142857142, "re": 0.09090909090909091, "f": 0.08, "fn": 10.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3125, "re": 0.5, "f": 0.38461538461538464, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}}, "caption": "This is a kitchen with white cabinets, a white refrigerator, and a white stove. There is a white sink in the corner of the room and a white microwave on the counter. The floor is made of hardwood and there is a white rug in the center of the room."}, "409964": {"image_id": 409964, "Bleu_1": 0.34146341462581803, "Bleu_2": 0.2065984676302324, "Bleu_3": 0.12983940805705807, "Bleu_4": 0.08711822053257058, "METEOR": 0.32502800531884785, "ROUGE_L": 0.3165307635285397, "CIDEr": 1.1886401154123783e-06, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.2222222222222222, "f": 0.19672131147540983, "fn": 21.0, "numImages": 1.0, "fp": 28.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3076923076923077, "re": 0.3333333333333333, "f": 0.32, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a man playing tennis on a court. He is wearing a white shirt and blue shorts, and is holding a tennis racket in his right hand. The background is a green grassy field with trees in the distance."}, "337987": {"image_id": 337987, "Bleu_1": 0.41666666665509267, "Bleu_2": 0.345032779661456, "Bleu_3": 0.2759292130984703, "Bleu_4": 0.22463880215974344, "METEOR": 0.36004438174969305, "ROUGE_L": 0.3841655420602789, "CIDEr": 0.000260817437117598, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.16, "f": 0.1818181818181818, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is a small bird perched on a branch of a tree. It has a brown and white striped body with a black head and beak. The bird is looking down and appears to be sleeping."}, "544104": {"image_id": 544104, "Bleu_1": 0.1969696969667126, "Bleu_2": 0.0953462589231035, "Bleu_3": 5.2176600559778e-07, "Bleu_4": 1.2253825679269957e-09, "METEOR": 0.15747447242313262, "ROUGE_L": 0.17888563049853376, "CIDEr": 6.933487117064151e-19, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.13043478260869565, "f": 0.16666666666666669, "fn": 20.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a harbor with several boats docked at the pier. The boats are painted in various colors and have different shapes, some are small and some are large. The water is calm and there are no waves. The sky is orange and the sun is setting behind the buildings on the horizon. There are buildings on the left and right sides of the harbor."}, "121210": {"image_id": 121210, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.21470745394187096, "Bleu_3": 0.12608269096038197, "Bleu_4": 1.4527419364666047e-05, "METEOR": 0.31735019791570396, "ROUGE_L": 0.27371794871794874, "CIDEr": 5.2139598410909844e-08, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 27.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.25, "f": 0.35294117647058826, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This is a plate of food with a stew and vegetables on it. The stew is made with beef and potatoes, and there are carrots and green beans on the side. The plate is on a white tablecloth, and there is a fork and knife on the table."}, "46551": {"image_id": 46551, "Bleu_1": 0.2027027026999635, "Bleu_2": 0.15808461078848351, "Bleu_3": 0.11155838740505554, "Bleu_4": 0.07908053205938495, "METEOR": 0.19070844763048447, "ROUGE_L": 0.1916517055655296, "CIDEr": 3.706126326385832e-21, "SPICE": {"All": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a group of people standing in a room with a large wooden table in the center. One person is holding a camera and taking a photo of another person who is sitting at the table. There are several other people in the room, including one who is standing behind the person taking the photo. The walls of the room are made of brick and there are several windows on the sides."}, "535588": {"image_id": 535588, "Bleu_1": 0.37209302324716065, "Bleu_2": 0.2976467318172675, "Bleu_3": 0.12928241614120298, "Bleu_4": 1.5245427153839246e-05, "METEOR": 0.2534573716853156, "ROUGE_L": 0.2620596538603167, "CIDEr": 3.1648323668887705e-05, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.18181818181818182, "f": 0.14285714285714285, "fn": 18.0, "numImages": 1.0, "fp": 30.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.1, "f": 0.09523809523809525, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.42857142857142855, "f": 0.27272727272727276, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "This is an image of a bus parked on the side of the road. The bus has a bike rack on the back and a person is standing next to it, looking at their phone. There are trees and buildings in the background."}, "173997": {"image_id": 173997, "Bleu_1": 0.8571428570816327, "Bleu_2": 0.6289709019864966, "Bleu_3": 0.4039893837658757, "Bleu_4": 4.947995468177741e-05, "METEOR": 0.25362990903840293, "ROUGE_L": 0.4680306905370844, "CIDEr": 0.7799996707692338, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.25, "f": 0.1739130434782609, "fn": 12.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "A couple sitting on a bench in a park, looking out at the water."}, "320396": {"image_id": 320396, "Bleu_1": 0.33333333332222226, "Bleu_2": 0.21442250696028833, "Bleu_3": 0.11797615444197407, "Bleu_4": 1.570379928529818e-05, "METEOR": 0.21796330522437268, "ROUGE_L": 0.3726003490401396, "CIDEr": 0.0021175979443014037, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.14285714285714285, "f": 0.1379310344827586, "fn": 24.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA man in a black shirt and white pants is throwing a frisbee on a sandy beach with birds flying overhead."}, "221282": {"image_id": 221282, "Bleu_1": 0.18181818181542703, "Bleu_2": 0.1399300524541518, "Bleu_3": 0.0848966731474613, "Bleu_4": 9.927339321042859e-06, "METEOR": 0.24863105311432215, "ROUGE_L": 0.2415499929288644, "CIDEr": 8.812662996633305e-18, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.12121212121212122, "f": 0.14545454545454545, "fn": 29.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This is an image of a woman in a white apron and gloves kneeling on a wooden table, cutting a pizza with a knife. The woman is surrounded by other people in white aprons and gloves, working on various tasks in the kitchen. The walls are painted a light green color and there are several windows with blinds open, allowing natural light to enter the room."}, "25143": {"image_id": 25143, "Bleu_1": 0.35135135134185547, "Bleu_2": 0.3124061420526953, "Bleu_3": 0.255764802339961, "Bleu_4": 0.22271699341963652, "METEOR": 0.27240150643329614, "ROUGE_L": 0.3596168017686072, "CIDEr": 8.940026655161138e-05, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.1875, "f": 0.1818181818181818, "fn": 13.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a group of people playing frisbee in a park. One person is throwing the frisbee while the others are running and catching it. The grass is green and there are trees in the background."}, "52835": {"image_id": 52835, "Bleu_1": 0.47058823526643606, "Bleu_2": 0.2425356250216204, "Bleu_3": 1.5769573215394795e-06, "Bleu_4": 4.091032653614925e-09, "METEOR": 0.16857202583435246, "ROUGE_L": 0.3257676902536716, "CIDEr": 0.21472598982932095, "SPICE": {"All": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 30.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.23076923076923078, "f": 0.33333333333333337, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows a lunchbox filled with various food items such as carrots, celery, and an orange."}, "300962": {"image_id": 300962, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.2659080117331791, "Bleu_3": 0.2144775697802318, "Bleu_4": 0.1851256466469489, "METEOR": 0.32767328909457993, "ROUGE_L": 0.336783988957902, "CIDEr": 2.4695733598341383e-08, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.1724137931034483, "f": 0.18867924528301888, "fn": 24.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.4166666666666667, "f": 0.4, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a baseball player swinging a bat at a baseball on a field. The player is wearing a white jersey with the number 12 on the back and blue pants. The field is made of grass and there are trees in the background."}, "332532": {"image_id": 332532, "Bleu_1": 0.38095238093424044, "Bleu_2": 0.276026223723469, "Bleu_3": 0.15887260951182014, "Bleu_4": 2.1725443230337628e-05, "METEOR": 0.19704433497536944, "ROUGE_L": 0.3446327683615819, "CIDEr": 0.1528108371549063, "SPICE": {"All": {"pr": 0.15, "re": 0.16666666666666666, "f": 0.15789473684210525, "fn": 15.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is a bathroom with a toilet, sink, and mirror. The walls are painted orange and there is a wooden floor."}, "528261": {"image_id": 528261, "Bleu_1": 0.25806451612070763, "Bleu_2": 0.09274777914899197, "Bleu_3": 6.669137632818231e-07, "Bleu_4": 1.8041089137611838e-09, "METEOR": 0.2174722369781793, "ROUGE_L": 0.2775250227479527, "CIDEr": 0.0006193772406497243, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.14814814814814814, "f": 0.14285714285714285, "fn": 23.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.3076923076923077, "f": 0.3076923076923077, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The giraffe is standing in front of a wooden fence, looking out at the grass. It has long legs and a long neck, and its spots are visible on its fur."}, "297046": {"image_id": 297046, "Bleu_1": 0.18367346938400672, "Bleu_2": 0.10714285714064781, "Bleu_3": 0.06250904486134176, "Bleu_4": 8.53626107680773e-06, "METEOR": 0.17413741894207016, "ROUGE_L": 0.12095175148711168, "CIDEr": 2.700979403510559e-09, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 8.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a train traveling down the tracks, with buildings and trees visible in the background. The train is red and has the words \"CPR\" written on the side. There are cars parked on the side of the road, and people can be seen walking on the sidewalk."}, "130839": {"image_id": 130839, "Bleu_1": 0.09195402298797728, "Bleu_2": 0.06916455233661911, "Bleu_3": 0.04809495931622368, "Bleu_4": 0.0284004776132358, "METEOR": 0.11083024365198402, "ROUGE_L": 0.10338357242297681, "CIDEr": 2.437583328758324e-162, "SPICE": {"All": {"pr": 0.1, "re": 0.10714285714285714, "f": 0.10344827586206898, "fn": 25.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.2727272727272727, "f": 0.24999999999999994, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "A man in a black suit and tie is carrying two large suitcases down a staircase at night. The stairs are made of metal and have a railing on either side. There are windows on either side of the stairs that are open, allowing natural light to enter the building. The man is walking down the stairs with a confident and purposeful gait. He is wearing a black suit and tie and has a serious expression on his face. The image is well-lit and the shadows are minimal.\n\nThe image is well-composed and the subject is centered in the frame. The background is blurred, which helps to focus the viewer's attention on the subject. The lighting is good and the shadows are minimal, which helps to create a sense of depth and dimension in the image. The colors are muted and the overall mood of the image is serious and professional.\n\nOverall, the image is well-executed and effectively conveys the message that the man is carrying important luggage down a staircase at night."}, "451120": {"image_id": 451120, "Bleu_1": 0.3333333333274854, "Bleu_2": 0.23145502493904102, "Bleu_3": 0.16950408960780877, "Bleu_4": 0.12825284547876994, "METEOR": 0.26910966874497216, "ROUGE_L": 0.2492702860478692, "CIDEr": 6.051037363793604e-14, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.16129032258064516, "f": 0.1923076923076923, "fn": 26.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "This image shows a woman standing at a table with various ingredients and kitchen tools. She is wearing a blue sweater and has a friendly expression on her face. The background is a large room with a wooden floor and white walls. There are several other people in the room, some of whom are also preparing food."}, "378134": {"image_id": 378134, "Bleu_1": 0.5238095237845806, "Bleu_2": 0.4577377081947216, "Bleu_3": 0.38061268797915826, "Bleu_4": 0.3096168826464989, "METEOR": 0.3027877915202508, "ROUGE_L": 0.4135593220338983, "CIDEr": 0.2122533205239045, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.09375, "f": 0.09836065573770493, "fn": 29.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.23076923076923078, "f": 0.24999999999999994, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA group of people playing frisbee on a grassy field at sunset."}, "458953": {"image_id": 458953, "Bleu_1": 0.34285714284734703, "Bleu_2": 0.24597601850010517, "Bleu_3": 0.17652150300160172, "Bleu_4": 0.11450137919355967, "METEOR": 0.2024023991620023, "ROUGE_L": 0.28960278525083083, "CIDEr": 0.0006384980861820942, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.23529411764705882, "f": 0.2580645161290323, "fn": 13.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "This is an image of a field with a group of people flying kites in the background. The kites are colorful and have different shapes and sizes. There are also some trees in the background."}, "159451": {"image_id": 159451, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.24671758189216153, "Bleu_3": 0.1905340106122511, "Bleu_4": 0.14821514446378253, "METEOR": 0.25195501953841515, "ROUGE_L": 0.27619663648124193, "CIDEr": 9.432563282308485e-09, "SPICE": {"All": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 24.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1111111111111111, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "This is an image of a yellow tractor parked on a dirt road in front of a large building. The tractor has a front end loader and is parked next to a pile of dirt and gravel. There are trees and buildings visible in the background."}, "294258": {"image_id": 294258, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.18971331171167066, "Bleu_3": 9.574966238312988e-07, "Bleu_4": 2.1644020701535495e-09, "METEOR": 0.18997386244515882, "ROUGE_L": 0.2767336357744653, "CIDEr": 6.109534767638028e-06, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.14814814814814814, "f": 0.19047619047619047, "fn": 23.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.23076923076923078, "f": 0.3, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a man wearing a suit and tie standing outside a building. He is looking down at his phone and appears to be in a hurry. There are other people in the background, but they are not visible in the image."}, "544695": {"image_id": 544695, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.142442462319253, "Bleu_3": 7.725775597136251e-07, "Bleu_4": 1.8096286076349793e-09, "METEOR": 0.23079530650467683, "ROUGE_L": 0.2367399741267788, "CIDEr": 1.624158954718076e-07, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.13043478260869565, "f": 0.11764705882352941, "fn": 20.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "A man and a woman are playing tennis on a court. The man is holding a racket and hitting a ball with his other hand, while the woman is standing behind him, watching him play. The sky is blue and there are trees in the background."}, "623": {"image_id": 623, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.1842190315423256, "Bleu_3": 0.12674769789184412, "Bleu_4": 0.09548024812134782, "METEOR": 0.28973332932137086, "ROUGE_L": 0.24233825198637912, "CIDEr": 1.2082767248269932e-10, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.3181818181818182, "f": 0.3181818181818182, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.45454545454545453, "re": 0.625, "f": 0.5263157894736842, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The woman is sitting on the floor next to a large stuffed bear. She is wearing a black shirt and pants, and has her arms around the bear's neck. The bear is wearing a white apron with a red heart on it. The woman is smiling and looking at the camera."}, "236690": {"image_id": 236690, "Bleu_1": 0.370370370356653, "Bleu_2": 0.2387049580041334, "Bleu_3": 0.1658075448734274, "Bleu_4": 0.11739521785616198, "METEOR": 0.193729577635694, "ROUGE_L": 0.31671858774662515, "CIDEr": 0.00841374184181509, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.4166666666666667, "f": 0.12987012987012989, "fn": 7.0, "numImages": 1.0, "fp": 60.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 23.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.07142857142857142, "re": 0.3333333333333333, "f": 0.11764705882352941, "fn": 2.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.8, "f": 0.24242424242424243, "fn": 1.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}}, "caption": "The image shows a seagull flying over the ocean with its wings spread wide. The sky is blue and cloudy, and there are waves in the distance."}, "382088": {"image_id": 382088, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.14401064146758893, "Bleu_3": 0.10755901259843535, "Bleu_4": 0.08441965712987705, "METEOR": 0.2331625852410396, "ROUGE_L": 0.26293103448275856, "CIDEr": 1.0794913218744027e-11, "SPICE": {"All": {"pr": 0.25, "re": 0.13333333333333333, "f": 0.1739130434782609, "fn": 26.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.3076923076923077, "f": 0.42105263157894735, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA beautiful white horse standing in a field with a fence in the background. The horse has a flowing mane and tail, and its eyes are looking directly at the camera. The sky is clear and blue, with a few clouds scattered about."}, "504711": {"image_id": 504711, "Bleu_1": 0.6363636363347108, "Bleu_2": 0.5773502691627578, "Bleu_3": 0.5108729549046713, "Bleu_4": 0.4328015276059101, "METEOR": 0.49037203760017767, "ROUGE_L": 0.6832993890020366, "CIDEr": 0.7178718138195763, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.11538461538461539, "f": 0.11538461538461539, "fn": 23.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a piece of chocolate cake with frosting on top, sitting on a plate with a fork next to it."}, "495348": {"image_id": 495348, "Bleu_1": 0.37209302324716065, "Bleu_2": 0.23055616707626844, "Bleu_3": 0.1373830673570816, "Bleu_4": 1.595639977425073e-05, "METEOR": 0.22656136740951058, "ROUGE_L": 0.24286662242866625, "CIDEr": 7.542162817142722e-07, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.20833333333333334, "f": 0.20833333333333334, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5714285714285714, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a group of zebras grazing in a grassy field surrounded by trees. There are several other animals in the background, including a giraffe and a few antelopes. The sky is clear and blue, with a few clouds scattered across it."}, "326217": {"image_id": 326217, "Bleu_1": 0.6666666666296297, "Bleu_2": 0.3429971702654019, "Bleu_3": 0.1944555593549452, "Bleu_4": 2.646015952198224e-05, "METEOR": 0.23569765162038217, "ROUGE_L": 0.3940568475452197, "CIDEr": 0.43622862742613355, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.1875, "f": 0.20338983050847456, "fn": 26.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.2727272727272727, "f": 0.2608695652173913, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a group of people in a boat on a river, surrounded by fruit and vegetables."}, "59752": {"image_id": 59752, "Bleu_1": 0.24999999999375005, "Bleu_2": 0.11322770341159263, "Bleu_3": 6.961571161674678e-07, "Bleu_4": 1.737720878510907e-09, "METEOR": 0.2265937776256727, "ROUGE_L": 0.2691176470588235, "CIDEr": 7.177363826484288e-07, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.23529411764705882, "f": 0.1702127659574468, "fn": 13.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.6666666666666666, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "This is a photograph of a river with boats docked on both sides. There are trees and buildings on the banks of the river, and a bridge in the distance. The sky is blue and there are clouds in it."}, "437393": {"image_id": 437393, "Bleu_1": 0.39999999998666674, "Bleu_2": 0.3107277331223966, "Bleu_3": 0.21789189983999352, "Bleu_4": 0.13990713818737435, "METEOR": 0.26710009326551193, "ROUGE_L": 0.34078212290502796, "CIDEr": 0.002348120799016281, "SPICE": {"All": {"pr": 0.23333333333333334, "re": 0.3181818181818182, "f": 0.2692307692307693, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.5555555555555556, "f": 0.43478260869565216, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "This is a white horse with blue and pink accents on its mane and tail. It has a pink rose on its head and a blue ribbon around its neck."}, "279209": {"image_id": 279209, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.0792476702271991, "Bleu_3": 5.22604859137564e-07, "Bleu_4": 1.3497799374494264e-09, "METEOR": 0.19111668582287203, "ROUGE_L": 0.1927939317319848, "CIDEr": 2.1651642449548806e-08, "SPICE": {"All": {"pr": 0.2, "re": 0.17391304347826086, "f": 0.18604651162790697, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "A person is skiing down a snowy mountain trail with trees on either side. The person is wearing a black and red jacket, black pants, and black ski boots. The person is carrying a backpack on their back. The sign in the distance reads \"Skiers Only\"."}, "202228": {"image_id": 202228, "Bleu_1": 0.3888888888780865, "Bleu_2": 0.3333333333239419, "Bleu_3": 0.21402603671754716, "Bleu_4": 0.15612734375979692, "METEOR": 0.31631134059849125, "ROUGE_L": 0.360794254330376, "CIDEr": 0.00023106412474407096, "SPICE": {"All": {"pr": 0.4117647058823529, "re": 0.22580645161290322, "f": 0.29166666666666663, "fn": 24.0, "numImages": 1.0, "fp": 10.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5454545454545454, "f": 0.6, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image shows a man standing in front of a mirror, taking a selfie. He is wearing a red jacket and black pants, and has a hat on his head. The mirror is reflecting his image."}, "193661": {"image_id": 193661, "Bleu_1": 0.24999999999305564, "Bleu_2": 0.22360679774367898, "Bleu_3": 0.18051655059265087, "Bleu_4": 0.13740950767737403, "METEOR": 0.230513322009078, "ROUGE_L": 0.3663663663663663, "CIDEr": 0.0005896591853118105, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.2, "f": 0.2631578947368421, "fn": 20.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "This is a living room with a fireplace and hardwood floors. There is a couch and two chairs in the room. The walls are painted yellow and there are white trim and molding on the ceiling."}, "457060": {"image_id": 457060, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.21148042285421853, "Bleu_3": 0.17280756432599467, "Bleu_4": 0.14183862598959415, "METEOR": 0.24865795230213006, "ROUGE_L": 0.23961840628507297, "CIDEr": 7.011935787409647e-11, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.2631578947368421, "f": 0.23255813953488372, "fn": 14.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.7142857142857143, "f": 0.5555555555555556, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows two giraffes standing next to each other in a fenced enclosure. One of the giraffes is looking directly at the camera while the other is looking off to the side. The fence is made of metal and has a gate that is open. There are trees and bushes in the background."}, "390215": {"image_id": 390215, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.18898223650071672, "Bleu_3": 0.09125318612878565, "Bleu_4": 1.1336958836408244e-05, "METEOR": 0.28199235246206994, "ROUGE_L": 0.31504196255648803, "CIDEr": 2.243379193723927e-09, "SPICE": {"All": {"pr": 0.3, "re": 0.15, "f": 0.2, "fn": 17.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.375, "f": 0.4615384615384615, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows a plate with two roasted chicken breasts on it, next to a bowl of broccoli. The chicken breasts are seasoned with herbs and spices, and the broccoli is steamed. The plate is on a white tablecloth, and there is a fork and knife on the side."}, "579635": {"image_id": 579635, "Bleu_1": 0.33333333332679743, "Bleu_2": 0.27080128014916915, "Bleu_3": 0.181574606837354, "Bleu_4": 0.10567713362197485, "METEOR": 0.2738194694040372, "ROUGE_L": 0.2893689114781872, "CIDEr": 5.385605705217112e-10, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.08571428571428572, "f": 0.13043478260869562, "fn": 32.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.1875, "f": 0.2727272727272727, "fn": 13.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a surfer riding a wave on the ocean. The surfer is wearing a black wetsuit and standing on a surfboard, with the sun setting in the background. The water is blue and there are whitecaps on the waves. The sailboat is in the distance, sailing across the ocean."}, "251920": {"image_id": 251920, "Bleu_1": 0.2916666666545139, "Bleu_2": 0.15925551431087165, "Bleu_3": 0.10485490691139454, "Bleu_4": 1.5306882399014526e-05, "METEOR": 0.198775664090377, "ROUGE_L": 0.2675438596491228, "CIDEr": 0.1133060489138385, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.18518518518518517, "f": 0.17543859649122806, "fn": 22.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.45454545454545453, "f": 0.3846153846153846, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}}, "caption": "There are three pizzas on the stove top, one with pepperoni and mushrooms, one with cheese and pepperoni, and one with cheese and mushrooms."}, "271117": {"image_id": 271117, "Bleu_1": 0.24999999999375005, "Bleu_2": 0.16012815380103265, "Bleu_3": 8.771030046935032e-07, "Bleu_4": 2.0665100326139495e-09, "METEOR": 0.1559523356917478, "ROUGE_L": 0.25558659217877094, "CIDEr": 1.116646894866435e-05, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.18181818181818182, "f": 0.2222222222222222, "fn": 18.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.16666666666666666, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is a small room with a desk, chair, and bookshelf. There are several books on the bookshelf and a lamp on the desk. The walls are painted yellow and there is a window on one side of the room."}, "11051": {"image_id": 11051, "Bleu_1": 0.3142857142767348, "Bleu_2": 0.214984853867146, "Bleu_3": 0.1118838140362068, "Bleu_4": 1.4463984657639369e-05, "METEOR": 0.18944405859242372, "ROUGE_L": 0.3633655994043187, "CIDEr": 0.00023312186080109412, "SPICE": {"All": {"pr": 0.15217391304347827, "re": 0.35, "f": 0.21212121212121213, "fn": 13.0, "numImages": 1.0, "fp": 39.0, "tp": 7.0}, "Relation": {"pr": 0.058823529411764705, "re": 0.125, "f": 0.07999999999999999, "fn": 7.0, "numImages": 1.0, "fp": 16.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.5, "f": 0.1818181818181818, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}}, "caption": "The image shows a young woman in a black dress and a man in a tuxedo standing next to each other, both holding flowers. The woman is smiling and the man is looking at her."}, "170605": {"image_id": 170605, "Bleu_1": 0.23880597014568944, "Bleu_2": 0.14734189373453566, "Bleu_3": 0.06938193046594304, "Bleu_4": 8.499429795978983e-06, "METEOR": 0.13078355753335108, "ROUGE_L": 0.1922016541945648, "CIDEr": 4.708090092171463e-12, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.2, "f": 0.1904761904761905, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of people on snowmobiles in the middle of a snowy field. The sun is shining down on them, and there are no trees or buildings in sight. The snowmobiles are parked on the ground, and one of them has a person sitting on it. There is a small airplane flying overhead, and the people on the snowmobiles are looking up at it."}, "84123": {"image_id": 84123, "Bleu_1": 0.41666666665509267, "Bleu_2": 0.28867513458667965, "Bleu_3": 0.19445555936085132, "Bleu_4": 0.12217624912312978, "METEOR": 0.27007618259609106, "ROUGE_L": 0.3663663663663663, "CIDEr": 0.0008054102997586787, "SPICE": {"All": {"pr": 0.375, "re": 0.15384615384615385, "f": 0.2181818181818182, "fn": 33.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.3125, "f": 0.4166666666666667, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "This is an image of a street with a sign on the side of the road that reads \"No Left Turn.\" There are cars parked on the side of the road and trees in the background."}, "505899": {"image_id": 505899, "Bleu_1": 0.38461538460552275, "Bleu_2": 0.34850751766960786, "Bleu_3": 0.2972379025897574, "Bleu_4": 0.2572114682384513, "METEOR": 0.3519483680172093, "ROUGE_L": 0.4112359550561798, "CIDEr": 2.040981764891879e-05, "SPICE": {"All": {"pr": 0.12, "re": 0.07894736842105263, "f": 0.09523809523809523, "fn": 35.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.21428571428571427, "f": 0.22222222222222224, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "A plate of donuts and a cup of coffee on a wooden table\n\nThe plate has three donuts on it, each one topped with glaze and sprinkles. The cup of coffee has a small amount of crema on top."}, "256814": {"image_id": 256814, "Bleu_1": 0.3225806451508845, "Bleu_2": 0.20739033893928357, "Bleu_3": 1.1404064937195537e-06, "Bleu_4": 2.697772065383126e-09, "METEOR": 0.2085229318393668, "ROUGE_L": 0.2775250227479527, "CIDEr": 0.001788355504062996, "SPICE": {"All": {"pr": 0.15151515151515152, "re": 0.22727272727272727, "f": 0.18181818181818182, "fn": 17.0, "numImages": 1.0, "fp": 28.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.29411764705882354, "re": 0.4166666666666667, "f": 0.3448275862068966, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}}, "caption": "The image shows a man and two women holding up a donut. The man is smiling and the women are laughing. The background is a car with the windows rolled down."}, "419680": {"image_id": 419680, "Bleu_1": 0.22413793103061835, "Bleu_2": 0.14021847959482642, "Bleu_3": 7.054628688135095e-07, "Bleu_4": 1.5895161605149888e-09, "METEOR": 0.17380130933050486, "ROUGE_L": 0.16522210184182015, "CIDEr": 2.473823030711369e-14, "SPICE": {"All": {"pr": 0.3, "re": 0.20689655172413793, "f": 0.24489795918367346, "fn": 23.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.4166666666666667, "f": 0.4761904761904762, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "This is an image of a street in a city. There are buildings on either side of the street, and a sign on the corner of the street reads, \"No Parking\". The buildings are made of brick and have large windows on the upper floors. There are people walking on the sidewalk and cars parked along the street."}, "519555": {"image_id": 519555, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.18994132206127556, "Bleu_3": 0.14746720993983883, "Bleu_4": 0.10987931098352247, "METEOR": 0.25217809428780014, "ROUGE_L": 0.2781758957654723, "CIDEr": 1.23560422821554e-08, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.1111111111111111, "f": 0.09523809523809525, "fn": 16.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.5, "f": 0.23529411764705882, "fn": 2.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "This is an image of a stop sign in the middle of a field. The sign is made of metal and has the words \"stop\" written on it in white letters. There are no other objects in the image, just the sign and the grass around it."}, "354929": {"image_id": 354929, "Bleu_1": 0.45454545453168055, "Bleu_2": 0.3370999312212464, "Bleu_3": 0.22237824385177052, "Bleu_4": 0.13836903383875293, "METEOR": 0.2827313667765212, "ROUGE_L": 0.38822593476531425, "CIDEr": 0.00636726740229433, "SPICE": {"All": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is an image of a group of people riding bicycles down a street at night. They are wearing helmets and have their lights on. There are buildings and cars in the background."}, "17379": {"image_id": 17379, "Bleu_1": 0.2295081967175491, "Bleu_2": 0.12369537763223652, "Bleu_3": 0.06377027796019516, "Bleu_4": 8.177239806403723e-06, "METEOR": 0.22364964237038076, "ROUGE_L": 0.21044849679645147, "CIDEr": 6.636273491159801e-14, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.3333333333333333, "f": 0.3571428571428571, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "This is a bathroom with a large mirror on the wall. The mirror is framed in wood and has a television mounted on it. There are two sinks on the counter in front of the mirror, and a toilet and shower in the background. The floor is made of tiles and there are two windows on the wall opposite the mirror."}, "13965": {"image_id": 13965, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.14254579382569355, "Bleu_3": 0.09270920944879872, "Bleu_4": 1.1235687646097306e-05, "METEOR": 0.19347802760096067, "ROUGE_L": 0.2381483547127719, "CIDEr": 8.500373903180545e-11, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 14.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}, "Relation": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.18181818181818182, "f": 0.26666666666666666, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.6, "f": 0.4615384615384615, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is an image of a green and white trolley car parked at a train station. The trolley car has a number on the side and is surrounded by other cars and trucks parked on the street. There are people standing on the platform and in the background, there are buildings and trees."}, "422836": {"image_id": 422836, "Bleu_1": 0.19512195121475318, "Bleu_2": 0.06984302957523308, "Bleu_3": 5.001042100780469e-07, "Bleu_4": 1.3469438255990044e-09, "METEOR": 0.15771216332042085, "ROUGE_L": 0.2260934025203855, "CIDEr": 8.981729270619571e-08, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.09090909090909091, "f": 0.1016949152542373, "fn": 30.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.21428571428571427, "f": 0.23076923076923075, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a man standing on the sidewalk, looking at his phone. He is wearing a black jacket and jeans, and has a backpack on his back. There are several buildings in the background, including a caf\u00e9 with outdoor seating."}, "513292": {"image_id": 513292, "Bleu_1": 0.31818181817458685, "Bleu_2": 0.17204158993311794, "Bleu_3": 0.08898958910772611, "Bleu_4": 1.1450077782939158e-05, "METEOR": 0.26079440546228255, "ROUGE_L": 0.2889039242219215, "CIDEr": 4.695626376969761e-07, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.2777777777777778, "f": 0.24390243902439024, "fn": 13.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a young boy holding a skateboard in his hand while walking on the sidewalk. He is wearing a red shirt and blue shorts, and has a big smile on his face. The background is a residential area with houses and trees."}, "202444": {"image_id": 202444, "Bleu_1": 0.19999999999636367, "Bleu_2": 0.12171612388780342, "Bleu_3": 6.538429607726683e-07, "Bleu_4": 1.5226646084547981e-09, "METEOR": 0.1434443429496473, "ROUGE_L": 0.17579250720461098, "CIDEr": 1.2588802838097853e-12, "SPICE": {"All": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 21.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is an image of a skateboarder performing a trick on a half pipe. The skateboarder is wearing a black shirt and jeans, and has a helmet on his head. There are several other people watching the skateboarder from the sidelines. The half pipe is made of metal and has a green tarp covering it."}, "268541": {"image_id": 268541, "Bleu_1": 0.33333333332407417, "Bleu_2": 0.25819888973988653, "Bleu_3": 0.19868417242611314, "Bleu_4": 0.14765612529678226, "METEOR": 0.2948433729164149, "ROUGE_L": 0.3408365261813538, "CIDEr": 0.00017145765057780107, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 12.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The man is holding a cup of coffee in his hand and looking at the camera. He is wearing a suit and tie and has a beard. There is a painting on the wall behind him."}, "377999": {"image_id": 377999, "Bleu_1": 0.27142857142469384, "Bleu_2": 0.18815878057389634, "Bleu_3": 0.10135768611627727, "Bleu_4": 0.06278759018511645, "METEOR": 0.17013604242316555, "ROUGE_L": 0.22739981360671016, "CIDEr": 1.544208110560985e-20, "SPICE": {"All": {"pr": 0.06896551724137931, "re": 0.07407407407407407, "f": 0.07142857142857142, "fn": 25.0, "numImages": 1.0, "fp": 27.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.18181818181818182, "f": 0.17391304347826086, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a man standing on the shore of a body of water, looking out at a sailboat in the distance. The sky is clear and blue, with a few clouds scattered across it. The water is calm and reflects the blue of the sky. The shore is rocky and covered in small plants and trees. In the background, there is a small town with buildings and streets visible."}, "272694": {"image_id": 272694, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.21932534684462168, "Bleu_3": 0.18579704197246943, "Bleu_4": 0.15539281181710843, "METEOR": 0.26495368706058153, "ROUGE_L": 0.36858006042296065, "CIDEr": 5.505856193638903e-07, "SPICE": {"All": {"pr": 0.45454545454545453, "re": 0.15625, "f": 0.2325581395348837, "fn": 27.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.16666666666666666, "f": 0.26666666666666666, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.75, "re": 0.23076923076923078, "f": 0.3529411764705882, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "This image shows a cup of coffee and a banana on a table. The cup of coffee has a straw in it and the banana is peeled and sliced in half. There are also some other food items on the table, including a muffin and a bagel."}, "137844": {"image_id": 137844, "Bleu_1": 0.1728395061707057, "Bleu_2": 0.12297746456057593, "Bleu_3": 5.763345554884101e-07, "Bleu_4": 1.251648386799783e-09, "METEOR": 0.21246630105235367, "ROUGE_L": 0.20461215932914045, "CIDEr": 8.335103616690463e-32, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.05555555555555555, "f": 0.0625, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image shows a skateboarder performing a trick on a halfpipe in a park. The skateboarder is wearing a black and white striped shirt and black pants, and has a red helmet on their head. The halfpipe is made of concrete and has a steep slope leading up to the top. There are several people watching the skateboarder from the sidelines, including a man with a camera around his neck. The sky is blue and there are mountains in the background."}, "374829": {"image_id": 374829, "Bleu_1": 0.22727272726928377, "Bleu_2": 0.1322214713349675, "Bleu_3": 0.0817494170260068, "Bleu_4": 9.65002327559596e-06, "METEOR": 0.22076022235444495, "ROUGE_L": 0.2506849315068493, "CIDEr": 8.758478934454539e-16, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.07692307692307693, "f": 0.0930232558139535, "fn": 24.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.16666666666666666, "f": 0.23529411764705882, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a baseball player in the middle of a swing, with his bat raised and ready to hit the ball. The crowd is watching from the stands, and there are several umpires standing behind home plate. The field is green and well maintained, with the bases and pitcher's mound clearly visible. The sky is cloudy and there are some trees in the background."}, "21465": {"image_id": 21465, "Bleu_1": 0.2295081967175491, "Bleu_2": 0.15149527936992757, "Bleu_3": 7.299874543262027e-07, "Bleu_4": 1.609272347846305e-09, "METEOR": 0.1370901164341688, "ROUGE_L": 0.18702095043433828, "CIDEr": 2.8962634671004253e-16, "SPICE": {"All": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 24.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3333333333333333, "f": 0.380952380952381, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "This is an image of a small, blue shelf with several items on it, including a vase, a lamp, and a book. The shelf is made of wood and has a distressed finish. The items on the shelf are arranged in a haphazard manner, with some of them leaning against each other. The overall effect is one of clutter and disorganization."}, "281929": {"image_id": 281929, "Bleu_1": 0.16666666666414143, "Bleu_2": 0.08770580192936384, "Bleu_3": 4.935057584295497e-07, "Bleu_4": 1.175260205329753e-09, "METEOR": 0.1707750952986023, "ROUGE_L": 0.21055226824457596, "CIDEr": 2.1008356368543468e-19, "SPICE": {"All": {"pr": 0.4444444444444444, "re": 0.2962962962962963, "f": 0.3555555555555555, "fn": 19.0, "numImages": 1.0, "fp": 10.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.7777777777777778, "re": 0.6363636363636364, "f": 0.7000000000000001, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 7.0}}, "caption": "The man is standing in front of a house wearing a brown suit and holding a black bicycle. The house has a white facade and a red door. There are plants and flowers in the garden.\n\nThe man is wearing a brown suit and holding a black bicycle. The house has a white facade and a red door. There are plants and flowers in the garden."}, "464814": {"image_id": 464814, "Bleu_1": 0.33333333332098775, "Bleu_2": 0.2531848417613592, "Bleu_3": 0.21726934816097013, "Bleu_4": 0.1892240568721587, "METEOR": 0.28868031002481914, "ROUGE_L": 0.41256038647342996, "CIDEr": 0.021345860150676178, "SPICE": {"All": {"pr": 0.4375, "re": 0.21875, "f": 0.2916666666666667, "fn": 25.0, "numImages": 1.0, "fp": 9.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.07142857142857142, "f": 0.1, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8571428571428571, "re": 0.4, "f": 0.5454545454545455, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 6.0}}, "caption": "This is a living room with a couch, coffee table, and TV. The walls are painted white and there are windows on one side of the room."}, "213538": {"image_id": 213538, "Bleu_1": 0.5217391304120984, "Bleu_2": 0.344350221559779, "Bleu_3": 0.2243557191518718, "Bleu_4": 2.7412292652641044e-05, "METEOR": 0.21890841577124623, "ROUGE_L": 0.36345580933465743, "CIDEr": 0.19274209955768493, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.030303030303030304, "f": 0.045454545454545456, "fn": 32.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}}, "caption": "This is a computer desk with a computer, keyboard, and mouse on it. There is also a red curtain hanging behind the desk."}, "461573": {"image_id": 461573, "Bleu_1": 0.2727272727190084, "Bleu_2": 0.09231861823165838, "Bleu_3": 6.502379296152039e-07, "Bleu_4": 1.7398984878177725e-09, "METEOR": 0.20221425247337046, "ROUGE_L": 0.2059071729957806, "CIDEr": 0.00019378297637561836, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.1724137931034483, "f": 0.22727272727272724, "fn": 24.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "This is an image of a park bench made of metal with a wooden seat and backrest. The bench is located on the sidewalk in front of a building with greenery around it."}, "360629": {"image_id": 360629, "Bleu_1": 0.624999999921875, "Bleu_2": 0.4999999999364584, "Bleu_3": 0.37697372051580974, "Bleu_4": 0.3013040488881211, "METEOR": 0.2675380970032834, "ROUGE_L": 0.505524861878453, "CIDEr": 0.7053910386781319, "SPICE": {"All": {"pr": 0.25, "re": 0.29411764705882354, "f": 0.27027027027027023, "fn": 12.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is a tray filled with various types of food, including sushi rolls, rice, and vegetables."}, "114745": {"image_id": 114745, "Bleu_1": 0.5499999999725, "Bleu_2": 0.24061325158054672, "Bleu_3": 1.476121796196066e-06, "Bleu_4": 3.708765841904931e-09, "METEOR": 0.20231255884724333, "ROUGE_L": 0.3546511627906977, "CIDEr": 0.12051627024871375, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.2, "f": 0.12500000000000003, "fn": 12.0, "numImages": 1.0, "fp": 30.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.25, "f": 0.14285714285714288, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2857142857142857, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A gorilla rides a skateboard down a ramp at an event.\""}, "548878": {"image_id": 548878, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.16658955971162087, "Bleu_3": 0.08511922922355492, "Bleu_4": 1.088071895098314e-05, "METEOR": 0.23020399809023415, "ROUGE_L": 0.2848565710473649, "CIDEr": 3.3767400773054104e-09, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.06666666666666667, "f": 0.0816326530612245, "fn": 28.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.16666666666666666, "f": 0.1904761904761905, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a person wearing a snowboarding helmet and goggles jumping off a ramp in the air. The person is wearing a black and red jacket with a white snowboard on their feet. The background is a city skyline with tall buildings and a blue sky."}, "385985": {"image_id": 385985, "Bleu_1": 0.3870967741873049, "Bleu_2": 0.23898250733805632, "Bleu_3": 0.14187332385618298, "Bleu_4": 1.4832438450012753e-05, "METEOR": 0.20886138449142566, "ROUGE_L": 0.21311639049710518, "CIDEr": 2.3594558491900074e-12, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.2631578947368421, "f": 0.25, "fn": 14.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.7142857142857143, "f": 0.588235294117647, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a young couple sitting on the ground, both holding cell phones in their hands. The woman is wearing black ripped jeans and a white t-shirt, while the man is wearing a black t-shirt and black pants. They are both looking at their phones intently, with their heads bent down towards the screens. The background is a dark, graffiti-covered wall."}, "289714": {"image_id": 289714, "Bleu_1": 0.1935483870936525, "Bleu_2": 0.14903177731519934, "Bleu_3": 0.10355615621127776, "Bleu_4": 0.06586716003364178, "METEOR": 0.17529161909076163, "ROUGE_L": 0.19307870858830975, "CIDEr": 6.620486157191918e-17, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.15625, "f": 0.16129032258064516, "fn": 27.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.45454545454545453, "f": 0.43478260869565216, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "This is an image of a kitchen with green walls and a yellow and white checkered floor. There is a woman standing in the kitchen, wearing a white apron and holding a mixing bowl. There are several appliances in the kitchen, including a stove, refrigerator, and sink. The walls are adorned with floral wallpaper and there are several vases on the countertops."}, "230226": {"image_id": 230226, "Bleu_1": 0.5555555555349795, "Bleu_2": 0.3580574370062001, "Bleu_3": 0.2172693481609701, "Bleu_4": 2.556795749388759e-05, "METEOR": 0.2263601001342632, "ROUGE_L": 0.31671858774662515, "CIDEr": 0.011203581619970232, "SPICE": {"All": {"pr": 0.2, "re": 0.26666666666666666, "f": 0.2285714285714286, "fn": 11.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is a clear plastic container filled with various toothbrushes, toothpaste, and other dental care items. It is hanging on a bathroom wall next to a sink."}, "319534": {"image_id": 319534, "Bleu_1": 0.16666666666435187, "Bleu_2": 0.11867816581772543, "Bleu_3": 0.05859778551003853, "Bleu_4": 7.348498842874634e-06, "METEOR": 0.1938987735902013, "ROUGE_L": 0.21863799283154117, "CIDEr": 8.348522064515412e-22, "SPICE": {"All": {"pr": 0.4444444444444444, "re": 0.13793103448275862, "f": 0.21052631578947367, "fn": 25.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}, "Relation": {"pr": 0.5, "re": 0.08333333333333333, "f": 0.14285714285714285, "fn": 11.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.25, "f": 0.35294117647058826, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\nThe woman in the image is standing in front of a bus with other passengers inside. She is wearing a white shirt and jeans, and has her hands on her hips. The bus is green and yellow, and has the words \"City Bus\" written on the side. The image is taken from a low angle, looking up at the woman and the bus."}, "427476": {"image_id": 427476, "Bleu_1": 0.32142857142283165, "Bleu_2": 0.22934123614279892, "Bleu_3": 0.12489168105266546, "Bleu_4": 1.3846218033148564e-05, "METEOR": 0.26695888611206964, "ROUGE_L": 0.26341764342998153, "CIDEr": 1.2591395721833706e-12, "SPICE": {"All": {"pr": 0.03125, "re": 0.043478260869565216, "f": 0.03636363636363636, "fn": 22.0, "numImages": 1.0, "fp": 31.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.07692307692307693, "re": 0.14285714285714285, "f": 0.1, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}}, "caption": "The little girl is standing in the bathroom, looking at the toilet. She is wearing a white shirt and jeans, and her hair is tied back in a ponytail. The bathroom has a white tile floor and a white bathtub. There is a sink in the corner of the room, and a window on the wall."}, "101223": {"image_id": 101223, "Bleu_1": 0.42857142856122454, "Bleu_2": 0.33909081142323877, "Bleu_3": 0.24313492762710862, "Bleu_4": 0.16476951417676958, "METEOR": 0.27948216960972583, "ROUGE_L": 0.4018445322793148, "CIDEr": 5.399871695388084e-06, "SPICE": {"All": {"pr": 0.15625, "re": 0.25, "f": 0.19230769230769232, "fn": 15.0, "numImages": 1.0, "fp": 27.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.29411764705882354, "re": 0.5555555555555556, "f": 0.3846153846153846, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}}, "caption": "The image shows a view of the mountains from an airplane window. The sky is clear and blue, with snow covered peaks in the distance. The plane is flying over the mountains, with its wings outstretched and the sun shining on it."}, "123570": {"image_id": 123570, "Bleu_1": 0.23809523809145886, "Bleu_2": 0.1639564589433648, "Bleu_3": 0.10975293929976046, "Bleu_4": 0.06851320868614279, "METEOR": 0.26151144151096317, "ROUGE_L": 0.2127553562531141, "CIDEr": 1.2392591823726383e-15, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.037037037037037035, "f": 0.05263157894736842, "fn": 26.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}}, "caption": "The image shows a woman standing in front of a store at night, holding an umbrella. The building is made of brick and has large windows on the sides. There are streetlights on either side of the building, casting a warm glow on the scene. The woman is dressed in a black coat and hat, and her face is obscured by the umbrella."}, "368581": {"image_id": 368581, "Bleu_1": 0.7272727271404961, "Bleu_2": 0.5393598898700768, "Bleu_3": 0.4013422918623043, "Bleu_4": 5.331675362351891e-05, "METEOR": 0.1862030900381086, "ROUGE_L": 0.4853375767219823, "CIDEr": 0.514963184872115, "SPICE": {"All": {"pr": 0.029411764705882353, "re": 0.041666666666666664, "f": 0.034482758620689655, "fn": 23.0, "numImages": 1.0, "fp": 33.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.1111111111111111, "f": 0.09523809523809525, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "This is a lunchbox with a sandwich, fruit, and vegetables inside."}, "446984": {"image_id": 446984, "Bleu_1": 0.37777777776938276, "Bleu_2": 0.2451550735724403, "Bleu_3": 0.1774834119198727, "Bleu_4": 0.10741279167487963, "METEOR": 0.32309752631754396, "ROUGE_L": 0.28754208754208754, "CIDEr": 5.512454354306577e-08, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.23076923076923078, "f": 0.24999999999999994, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "This image shows a group of people on bicycles standing in front of a park. They are wearing yellow vests and helmets, and one person is holding a pair of scissors. The background is a green field with trees and a river in the distance."}, "514668": {"image_id": 514668, "Bleu_1": 0.4583333333142362, "Bleu_2": 0.31565436976372857, "Bleu_3": 0.23862030429939607, "Bleu_4": 0.15948715930717874, "METEOR": 0.3332974610330624, "ROUGE_L": 0.428714859437751, "CIDEr": 0.06761991889212764, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.15625, "f": 0.22222222222222224, "fn": 27.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.08333333333333333, "f": 0.1111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.3076923076923077, "f": 0.4, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a cat sitting in the back seat of a car looking out the window at a mountain range in the distance."}, "532129": {"image_id": 532129, "Bleu_1": 0.2727272727223141, "Bleu_2": 0.2247332874836235, "Bleu_3": 0.15620909290310706, "Bleu_4": 0.09252921909857739, "METEOR": 0.2174798500206875, "ROUGE_L": 0.21542083578575633, "CIDEr": 2.5467172437986685e-12, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.06666666666666667, "f": 0.07692307692307691, "fn": 28.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.18181818181818182, "f": 0.1904761904761905, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This is a pizza that has been cut into slices and placed on a plate. The pizza has a crispy crust and cheese on top. There are also some toppings on the pizza, such as pepperoni and mushrooms. The plate is on a table in front of a window with a view of the outside."}, "200168": {"image_id": 200168, "Bleu_1": 0.29999999999000004, "Bleu_2": 0.14383899044073797, "Bleu_3": 9.040623994640335e-07, "Bleu_4": 2.2872196012666833e-09, "METEOR": 0.2126072244523022, "ROUGE_L": 0.29383429672447015, "CIDEr": 0.0018561146412321265, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.24, "f": 0.20338983050847456, "fn": 19.0, "numImages": 1.0, "fp": 28.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.5, "f": 0.41666666666666663, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "This is an image of a person skiing down a snowy slope. The person is wearing a helmet and holding skis. The trees in the background are covered in snow."}, "470801": {"image_id": 470801, "Bleu_1": 0.23333333332944448, "Bleu_2": 0.1886616557167528, "Bleu_3": 0.10706719584566136, "Bleu_4": 1.2113610558257804e-05, "METEOR": 0.22217193582433742, "ROUGE_L": 0.25738396624472576, "CIDEr": 1.276369777222569e-15, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.23809523809523808, "f": 0.22222222222222224, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "A woman is holding a kite in her hand and flying it in the sky. The kite has a red and white design with a smiley face on it. The woman is wearing a black shirt and jeans, and her hair is tied back in a ponytail. She is standing in front of a blue sky with fluffy white clouds."}, "138713": {"image_id": 138713, "Bleu_1": 0.23255813952947546, "Bleu_2": 0.14882336590863374, "Bleu_3": 0.08144281873878519, "Bleu_4": 1.0780144922565258e-05, "METEOR": 0.168844820073435, "ROUGE_L": 0.25505226480836235, "CIDEr": 1.8372151135683481e-06, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.2, "f": 0.25531914893617025, "fn": 24.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.06666666666666667, "f": 0.09523809523809522, "fn": 14.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.45454545454545453, "f": 0.45454545454545453, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "This image shows a group of people playing frisbee in a park. One person is throwing the frisbee while another person is catching it. They are both wearing purple shirts and shorts. The sky is blue and there are trees in the background."}, "195917": {"image_id": 195917, "Bleu_1": 0.36585365852766216, "Bleu_2": 0.191273013914278, "Bleu_3": 0.097892089462343, "Bleu_4": 1.2534724690400046e-05, "METEOR": 0.25938738910781295, "ROUGE_L": 0.26703633445206476, "CIDEr": 5.9757571234262575e-06, "SPICE": {"All": {"pr": 0.125, "re": 0.21052631578947367, "f": 0.1568627450980392, "fn": 15.0, "numImages": 1.0, "fp": 28.0, "tp": 4.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.125, "f": 0.1, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.25, "f": 0.15384615384615383, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The man in the image is holding a toothbrush in his hand and brushing his teeth. He has long hair and is wearing a black shirt. There are other people in the background of the image, but they are not visible."}, "145391": {"image_id": 145391, "Bleu_1": 0.4666666666511112, "Bleu_2": 0.2537081316938597, "Bleu_3": 0.1662826407225631, "Bleu_4": 0.11423369997737406, "METEOR": 0.2729543298030326, "ROUGE_L": 0.33406352683461116, "CIDEr": 0.10939107786987838, "SPICE": {"All": {"pr": 0.5, "re": 0.1935483870967742, "f": 0.27906976744186046, "fn": 25.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.08333333333333333, "f": 0.125, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.36363636363636365, "f": 0.5000000000000001, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The image shows a roll of tape with various colors and patterns on it. There are also scissors and a pair of scissors on the table next to the tape."}, "459303": {"image_id": 459303, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.13453455879664997, "Bleu_3": 7.126876576918604e-07, "Bleu_4": 1.6486383890708068e-09, "METEOR": 0.15092277554437805, "ROUGE_L": 0.22048192771084338, "CIDEr": 7.559619137845269e-11, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.16, "f": 0.1818181818181818, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.15384615384615385, "f": 0.2666666666666667, "fn": 11.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.4, "f": 0.5714285714285715, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a train traveling down the tracks in a station. The train is black and yellow and has a number 5 on the side. There are people standing on the platform watching the train go by. The train is surrounded by buildings and there are wires hanging from the ceiling."}, "497334": {"image_id": 497334, "Bleu_1": 0.21052631578670358, "Bleu_2": 0.14017532880823577, "Bleu_3": 0.06427426944847774, "Bleu_4": 7.765995718556258e-06, "METEOR": 0.1978151348769235, "ROUGE_L": 0.20926243567753, "CIDEr": 4.39885806118094e-26, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.02702702702702703, "f": 0.045454545454545456, "fn": 36.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.07142857142857142, "f": 0.11764705882352941, "fn": 13.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}}, "caption": "The image shows a book lying on a bed with a red cover. The book has a white page with black text on it. There is a blank space in the middle of the page where the text would go. The book is open and the pages are spread out. The bed is covered in a white sheet and there are pillows on it. The room is dimly lit and there are curtains on the windows."}, "173138": {"image_id": 173138, "Bleu_1": 0.18055555555304786, "Bleu_2": 0.11276160680100923, "Bleu_3": 5.663368537975733e-07, "Bleu_4": 1.2737782975876684e-09, "METEOR": 0.1368048467312798, "ROUGE_L": 0.1960514233241506, "CIDEr": 5.696800340312827e-24, "SPICE": {"All": {"pr": 0.27586206896551724, "re": 0.25, "f": 0.26229508196721313, "fn": 24.0, "numImages": 1.0, "fp": 21.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.46153846153846156, "f": 0.42857142857142855, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}}, "caption": "The image shows a person standing on the beach, looking out at the ocean. The waves are crashing against the shore and the person is holding onto a surfboard. The sky is clear and blue, with a few clouds scattered in the distance. The person is wearing a wetsuit and sunglasses, and their hair is blown back by the wind. The overall mood of the image is one of excitement and adventure."}, "404984": {"image_id": 404984, "Bleu_1": 0.34042553190765057, "Bleu_2": 0.22760466886504874, "Bleu_3": 0.16636805405423472, "Bleu_4": 0.12028093140521147, "METEOR": 0.3209999318453433, "ROUGE_L": 0.31063017186505404, "CIDEr": 8.779099987995327e-09, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.18181818181818182, "f": 0.14285714285714285, "fn": 18.0, "numImages": 1.0, "fp": 30.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.25, "f": 0.15384615384615383, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1875, "re": 0.375, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}}, "caption": "This is a living room with a couch, coffee table, and television. The walls are painted a light gray color and there are windows on one side of the room. There is a wooden bench in the corner of the room and a rug on the floor."}, "427965": {"image_id": 427965, "Bleu_1": 0.4999999999750001, "Bleu_2": 0.3973597070991224, "Bleu_3": 0.32737967506077853, "Bleu_4": 0.2805155031864108, "METEOR": 0.3471061696642509, "ROUGE_L": 0.4765625, "CIDEr": 0.28687030662387514, "SPICE": {"All": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 12.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5714285714285714, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "This is a living room with a couch, chair, and coffee table. There are also two dogs in the room."}, "445834": {"image_id": 445834, "Bleu_1": 0.26315789472991696, "Bleu_2": 0.08433490103776005, "Bleu_3": 5.824214923868025e-07, "Bleu_4": 1.5413846635645837e-09, "METEOR": 0.18604651162790697, "ROUGE_L": 0.23282442748091606, "CIDEr": 1.1495057484043483e-05, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.28, "f": 0.30434782608695654, "fn": 18.0, "numImages": 1.0, "fp": 14.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.6666666666666666, "f": 0.6, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "This is an image of a bus parked in front of a building. The bus is blue and white and has the words \"Bus\" written on the side. There are people standing around the bus, looking at it."}, "386958": {"image_id": 386958, "Bleu_1": 0.2051282051229455, "Bleu_2": 0.10390486669052698, "Bleu_3": 6.6326948668966e-07, "Bleu_4": 1.6872983760809617e-09, "METEOR": 0.2051460020286581, "ROUGE_L": 0.22846441947565538, "CIDEr": 3.210669477298976e-05, "SPICE": {"All": {"pr": 0.375, "re": 0.23076923076923078, "f": 0.2857142857142857, "fn": 20.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.16666666666666666, "f": 0.26666666666666666, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "This is an image of a fire hydrant on the side of a road. The hydrant is painted with yellow and green stripes, and there is a green curb in front of it. The sky is blue and cloudy."}, "306135": {"image_id": 306135, "Bleu_1": 0.3230769230719526, "Bleu_2": 0.15887222732309736, "Bleu_3": 0.07371996827596482, "Bleu_4": 8.965838925947828e-06, "METEOR": 0.24147851519511532, "ROUGE_L": 0.24584382871536525, "CIDEr": 3.0467127325785707e-17, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.25, "f": 0.22857142857142856, "fn": 24.0, "numImages": 1.0, "fp": 30.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.6666666666666666, "f": 0.26666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 1.0, "f": 0.33333333333333337, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.46153846153846156, "re": 0.5, "f": 0.48000000000000004, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image shows a man walking down a set of stairs in front of a building with columns and arches. The building appears to be made of stone and has a large statue of a person on top of it. There are people walking around the area and some are sitting on the steps. The sky is blue and there are trees in the background."}, "335839": {"image_id": 335839, "Bleu_1": 0.2586206896507135, "Bleu_2": 0.20207633640188252, "Bleu_3": 0.12981395520520816, "Bleu_4": 1.4122135180868542e-05, "METEOR": 0.22174438506364816, "ROUGE_L": 0.28357438016528924, "CIDEr": 1.2633300190945089e-12, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.07692307692307693, "f": 0.09090909090909093, "fn": 24.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image shows a man standing on the sidewalk in front of a brick building with graffiti on the walls. The man is wearing a black jacket and pants, and has a red hat on his head. He is looking down at something on the ground. There are other buildings in the background with similar graffiti on them."}, "190313": {"image_id": 190313, "Bleu_1": 0.5384615384408284, "Bleu_2": 0.3882901373424275, "Bleu_3": 0.2929007539136643, "Bleu_4": 0.23927026017243327, "METEOR": 0.37632048749036234, "ROUGE_L": 0.4782973956874825, "CIDEr": 0.09913765234036837, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.15, "f": 0.14285714285714282, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The woman is sitting on a bench outside a store, wearing a black jacket and carrying a bag. She is looking at something in her hand."}, "85328": {"image_id": 85328, "Bleu_1": 0.4761904761678005, "Bleu_2": 0.26726124189937955, "Bleu_3": 1.5549130951147036e-06, "Bleu_4": 3.801556631685876e-09, "METEOR": 0.20394411174117272, "ROUGE_L": 0.26492942453854507, "CIDEr": 0.10928800598329844, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.22727272727272727, "f": 0.22222222222222224, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This is an image of a train on the tracks, with people standing on the platform and buildings in the background."}, "104002": {"image_id": 104002, "Bleu_1": 0.4666666666355556, "Bleu_2": 0.2581988897293332, "Bleu_3": 1.7244679590986396e-06, "Bleu_4": 4.546697236652585e-09, "METEOR": 0.24677175136913426, "ROUGE_L": 0.46003016591251883, "CIDEr": 0.4032546939287879, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.15384615384615385, "f": 0.14814814814814817, "fn": 22.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5, "f": 0.36363636363636365, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "A herd of cows grazes in a green pasture with a fence in the background."}, "37389": {"image_id": 37389, "Bleu_1": 0.18840579709871877, "Bleu_2": 0.12893425037681305, "Bleu_3": 0.09062771225263064, "Bleu_4": 0.057950845799362175, "METEOR": 0.19747237424386643, "ROUGE_L": 0.1818181818181818, "CIDEr": 2.465696814750374e-22, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 20.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "This is an image of a clock tower in the middle of a city. The clock tower is made of stone and has a large clock face on the front. The clock face shows the time as 12:00. There are buildings around the clock tower, and there are people walking on the sidewalk in front of it. The sky is clear and blue, with some clouds in the distance."}, "383594": {"image_id": 383594, "Bleu_1": 0.32499999999187507, "Bleu_2": 0.18257418583043256, "Bleu_3": 0.12060770349712197, "Bleu_4": 1.4756414813339652e-05, "METEOR": 0.2376226365583253, "ROUGE_L": 0.3043044469783352, "CIDEr": 1.5383577395240796e-05, "SPICE": {"All": {"pr": 0.03571428571428571, "re": 0.045454545454545456, "f": 0.04, "fn": 21.0, "numImages": 1.0, "fp": 27.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.125, "f": 0.1, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "This is an image of a plate with two chicken sandwiches, fries, and pickles on the side. The sandwiches are made with bread and filled with chicken. There are also some condiments on the plate, such as ketchup and mustard."}, "319696": {"image_id": 319696, "Bleu_1": 0.5199999999792001, "Bleu_2": 0.41633319987622636, "Bleu_3": 0.3562611792168968, "Bleu_4": 0.25320845569844685, "METEOR": 0.3755840599383525, "ROUGE_L": 0.46768893756845564, "CIDEr": 0.04351847166624835, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.24, "f": 0.22222222222222224, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5555555555555556, "f": 0.4545454545454546, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "This is a red microwave sitting on a counter in a kitchen. The counter has a tile pattern and there are some dishes on it."}, "318911": {"image_id": 318911, "Bleu_1": 0.388888888867284, "Bleu_2": 0.21389631596101674, "Bleu_3": 1.4193697400876474e-06, "Bleu_4": 3.7157701522892835e-09, "METEOR": 0.23355176859414223, "ROUGE_L": 0.3940568475452197, "CIDEr": 0.3109470094709965, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.2222222222222222, "f": 0.27586206896551724, "fn": 14.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.5, "f": 0.6, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A flock of sheep grazing in a green pasture\""}, "455506": {"image_id": 455506, "Bleu_1": 0.9999999998000004, "Bleu_2": 0.9428090413882642, "Bleu_3": 0.9196413919320425, "Bleu_4": 0.9036020034112857, "METEOR": 0.5792878359573337, "ROUGE_L": 0.9, "CIDEr": 2.710780072536463, "SPICE": {"All": {"pr": 0.45454545454545453, "re": 0.20833333333333334, "f": 0.28571428571428575, "fn": 19.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}, "Relation": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.3333333333333333, "f": 0.42857142857142855, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The dog is running with a frisbee in its mouth."}, "444631": {"image_id": 444631, "Bleu_1": 0.2749999999931251, "Bleu_2": 0.20568833779665252, "Bleu_3": 0.13058358239001738, "Bleu_4": 0.08807770766281207, "METEOR": 0.2943735469443672, "ROUGE_L": 0.2764350453172206, "CIDEr": 9.87643303389347e-07, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.13793103448275862, "f": 0.16666666666666666, "fn": 25.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "A person is walking on the beach with a surfboard under their arm. The person is wearing a black and red wetsuit and has a surfboard under their arm. The sky is cloudy and there are waves in the distance."}, "497014": {"image_id": 497014, "Bleu_1": 0.6363636363057852, "Bleu_2": 0.5045249790613539, "Bleu_3": 0.3838700925692668, "Bleu_4": 0.28997844144056417, "METEOR": 0.2689082197032768, "ROUGE_L": 0.5417406749555951, "CIDEr": 0.690811058084721, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.14285714285714285, "f": 0.15, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The dog is playing fetch with a stick in the grass."}, "502749": {"image_id": 502749, "Bleu_1": 0.2909090909038017, "Bleu_2": 0.1797866299868988, "Bleu_3": 0.10684551660659944, "Bleu_4": 1.237560363984256e-05, "METEOR": 0.2449838484802057, "ROUGE_L": 0.24610951008645532, "CIDEr": 2.0084298686594467e-13, "SPICE": {"All": {"pr": 0.2, "re": 0.13636363636363635, "f": 0.16216216216216214, "fn": 19.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "This is a kitchen with white cabinets and countertops. There is a large island in the center of the room with a sink and stove on it. The walls are painted red and there are wreaths hanging from the ceiling. The floor is made of gray marble and there are two chairs at the table."}, "230593": {"image_id": 230593, "Bleu_1": 0.35999999998560006, "Bleu_2": 0.21213203434730224, "Bleu_3": 0.12507242179545755, "Bleu_4": 1.7268932788606005e-05, "METEOR": 0.20601432160231611, "ROUGE_L": 0.3096446700507614, "CIDEr": 0.029020511363219897, "SPICE": {"All": {"pr": 0.3103448275862069, "re": 0.34615384615384615, "f": 0.32727272727272727, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 9.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.5454545454545454, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA group of geese walk along a path in a park, surrounded by trees and grass."}, "364636": {"image_id": 364636, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.22447181760045806, "Bleu_3": 0.10711408851603445, "Bleu_4": 1.3239450175851498e-05, "METEOR": 0.23768549346889742, "ROUGE_L": 0.29756097560975614, "CIDEr": 7.334209383169332e-07, "SPICE": {"All": {"pr": 1.0, "re": 0.24, "f": 0.3870967741935484, "fn": 19.0, "numImages": 1.0, "fp": 0.0, "tp": 6.0}, "Relation": {"pr": 1.0, "re": 0.375, "f": 0.5454545454545454, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.3, "f": 0.4615384615384615, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}}, "caption": "This is a dog walking on a leash in the dirt. The dog is brown and white with a collar around its neck. The dog is looking up at the camera with its mouth open. There are trees and buildings in the background."}, "288313": {"image_id": 288313, "Bleu_1": 0.5384615384408284, "Bleu_2": 0.35948681369506397, "Bleu_3": 0.27823060044492287, "Bleu_4": 0.17493298655958203, "METEOR": 0.37965533018634895, "ROUGE_L": 0.47339246119733924, "CIDEr": 0.024917008108437454, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.23809523809523808, "f": 0.23809523809523808, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.45454545454545453, "f": 0.41666666666666663, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "A plate of food is set on a table with a fork and knife. There are several other plates of food on the table as well."}, "384503": {"image_id": 384503, "Bleu_1": 0.423076923060651, "Bleu_2": 0.2253202848508038, "Bleu_3": 0.12836987367391073, "Bleu_4": 1.741467509925889e-05, "METEOR": 0.22970064814942065, "ROUGE_L": 0.36237623762376237, "CIDEr": 0.01828938387710487, "SPICE": {"All": {"pr": 0.25, "re": 0.2631578947368421, "f": 0.25641025641025644, "fn": 14.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a trolley car traveling down a rainy street with a yellow bow on the front. There are trees and buildings in the background."}, "190156": {"image_id": 190156, "Bleu_1": 0.39999999999, "Bleu_2": 0.3038218101174071, "Bleu_3": 0.1938765058105794, "Bleu_4": 0.1408805232033212, "METEOR": 0.3111251410264395, "ROUGE_L": 0.2981843575418994, "CIDEr": 4.90410282673548e-05, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.09523809523809523, "f": 0.10526315789473684, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "A black and white cat is sitting on a table with a cup of coffee in its paws. The cat is looking up at the camera with its eyes. There is a laptop on the table next to the cat."}, "174123": {"image_id": 174123, "Bleu_1": 0.41666666665509267, "Bleu_2": 0.28867513458667965, "Bleu_3": 0.19445555936085132, "Bleu_4": 2.1726350821144763e-05, "METEOR": 0.24056663382541962, "ROUGE_L": 0.413279132791328, "CIDEr": 0.005129130917990245, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.13793103448275862, "f": 0.1951219512195122, "fn": 25.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2727272727272727, "f": 0.3529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "This is an image of a pizza with various toppings on it. The pizza is on a plate with a fork and knife next to it. There are also two glasses of water on the table."}, "557239": {"image_id": 557239, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.20084043275925678, "Bleu_3": 0.13804538956739063, "Bleu_4": 0.10398502497799242, "METEOR": 0.2890587969877915, "ROUGE_L": 0.29901960784313725, "CIDEr": 5.1579796096336935e-09, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.2222222222222222, "f": 0.16326530612244897, "fn": 14.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a cat sitting in a toilet bowl, looking up at the camera with its eyes. The cat is wearing a collar and has its paws up on the sides of the bowl. The background is a white bathroom with a toilet seat and a sink."}, "184474": {"image_id": 184474, "Bleu_1": 0.11111111110905351, "Bleu_2": 0.04578685464870713, "Bleu_3": 3.4289363674893317e-07, "Bleu_4": 9.42924728285967e-10, "METEOR": 0.1388591923289544, "ROUGE_L": 0.11172161172161171, "CIDEr": 1.1607611797184294e-13, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.2413793103448276, "f": 0.25, "fn": 22.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.4166666666666667, "f": 0.43478260869565216, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "This is a bench sitting on top of a hill overlooking the ocean. The bench is made of wood and has a small table next to it. There are some plants growing on the hillside and a few rocks in the foreground. The sky is clear and blue with some clouds in the distance."}, "335099": {"image_id": 335099, "Bleu_1": 0.27272727272107444, "Bleu_2": 0.11262765836415223, "Bleu_3": 6.709347299490495e-07, "Bleu_4": 1.6474575790853053e-09, "METEOR": 0.18096765673618054, "ROUGE_L": 0.12381596752368064, "CIDEr": 4.957482296888067e-06, "SPICE": {"All": {"pr": 0.2, "re": 0.05263157894736842, "f": 0.08333333333333333, "fn": 18.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}}, "caption": "The image shows a dog looking out of a window with its tongue hanging out of its mouth. The dog is standing on a balcony with a railing and a gate in the background. The balcony has a white table and chairs on it."}, "431306": {"image_id": 431306, "Bleu_1": 0.4090909090723141, "Bleu_2": 0.3120938919516558, "Bleu_3": 0.24446720039491812, "Bleu_4": 0.1665240823320508, "METEOR": 0.3590005065233611, "ROUGE_L": 0.509546539379475, "CIDEr": 0.11600804277832298, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.29411764705882354, "f": 0.21276595744680848, "fn": 12.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5714285714285714, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "This is a bathroom with two sinks and a mirror on the wall. The mirror is reflecting the sink and the floor."}, "125815": {"image_id": 125815, "Bleu_1": 0.34482758619500603, "Bleu_2": 0.22194838080144763, "Bleu_3": 0.12219311400302733, "Bleu_4": 1.6275776313020367e-05, "METEOR": 0.22691536954608799, "ROUGE_L": 0.28110599078341014, "CIDEr": 0.028525492290179276, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.25, "f": 0.1935483870967742, "fn": 18.0, "numImages": 1.0, "fp": 32.0, "tp": 6.0}, "Relation": {"pr": 0.06666666666666667, "re": 0.1, "f": 0.08, "fn": 9.0, "numImages": 1.0, "fp": 14.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.29411764705882354, "re": 0.5, "f": 0.37037037037037035, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}}, "caption": "The image shows a train station with a train parked on the platform. There are people standing on the platform and in the background, there are buildings and trees."}, "521106": {"image_id": 521106, "Bleu_1": 0.20833333332899312, "Bleu_2": 0.06657795516001168, "Bleu_3": 4.584595505702186e-07, "Bleu_4": 1.2096859591117995e-09, "METEOR": 0.1795708910422205, "ROUGE_L": 0.15641025641025638, "CIDEr": 7.713846445944576e-08, "SPICE": {"All": {"pr": 0.16, "re": 0.21052631578947367, "f": 0.1818181818181818, "fn": 15.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.375, "f": 0.2727272727272727, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a man playing tennis on a court. He is wearing a yellow shirt and black shorts, and has a racket in his hand. The other players are also wearing tennis gear and are playing the game. The background is a blue sky with some clouds."}, "508672": {"image_id": 508672, "Bleu_1": 0.25641025640368187, "Bleu_2": 0.21733262130578967, "Bleu_3": 0.18549806009493156, "Bleu_4": 0.16319013503559496, "METEOR": 0.3430251167397176, "ROUGE_L": 0.33808392715756136, "CIDEr": 9.517160984580854e-06, "SPICE": {"All": {"pr": 0.5833333333333334, "re": 0.3684210526315789, "f": 0.4516129032258065, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 7.0}, "Relation": {"pr": 0.4, "re": 0.18181818181818182, "f": 0.25000000000000006, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.8, "f": 0.7272727272727272, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "This is an image of a bicycle parked next to a flooded road. The bicycle is covered in mud and the tires are submerged in the water. There is a fence in the background and trees in the distance."}, "221737": {"image_id": 221737, "Bleu_1": 0.2424242424168963, "Bleu_2": 0.1740776559503404, "Bleu_3": 0.12504071661134744, "Bleu_4": 0.08984797156546269, "METEOR": 0.168898016299041, "ROUGE_L": 0.2911694510739857, "CIDEr": 0.0012960561740429052, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.30434782608695654, "f": 0.2978723404255319, "fn": 16.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.09090909090909091, "f": 0.09090909090909091, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.625, "f": 0.5555555555555556, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a road with a sign that reads \"Stop\" in white letters on a green background. The road is lined with trees and there are no cars or people in sight."}, "345580": {"image_id": 345580, "Bleu_1": 0.21951219511659734, "Bleu_2": 0.1656472891081792, "Bleu_3": 0.11205846904084894, "Bleu_4": 0.07800772536068061, "METEOR": 0.21733776832934995, "ROUGE_L": 0.2713120830244626, "CIDEr": 1.7769500620184787e-06, "SPICE": {"All": {"pr": 0.2, "re": 0.17647058823529413, "f": 0.18750000000000003, "fn": 14.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a zebra standing in a field with tall trees in the background. The zebra is black and white with a long mane and tail. It is looking directly at the camera with its head tilted to the side."}, "46440": {"image_id": 46440, "Bleu_1": 0.24561403508341031, "Bleu_2": 0.19867985355623988, "Bleu_3": 0.1626917039538614, "Bleu_4": 0.14130844488229263, "METEOR": 0.3046122487906546, "ROUGE_L": 0.27901658090337333, "CIDEr": 4.075967241184029e-13, "SPICE": {"All": {"pr": 0.1, "re": 0.2, "f": 0.13333333333333333, "fn": 12.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.5, "f": 0.3157894736842105, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a group of young men playing basketball in a gym. One player is dribbling the ball while the others are trying to block him. The players are wearing orange and blue jerseys and black shorts. The walls of the gym are painted with different colors and there are some basketball hoops on the ceiling."}, "270066": {"image_id": 270066, "Bleu_1": 0.2105263157857803, "Bleu_2": 0.16222142112789117, "Bleu_3": 0.12415700710750358, "Bleu_4": 0.09175663647792374, "METEOR": 0.24284141771052595, "ROUGE_L": 0.24413950829045164, "CIDEr": 4.703524149094477e-13, "SPICE": {"All": {"pr": 0.5, "re": 0.35294117647058826, "f": 0.41379310344827586, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}, "Relation": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.8, "f": 0.7272727272727272, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image shows a white motorcycle parked in front of a building with a green and white striped awning. The motorcycle has a black seat and a black engine. There is a black trunk on the back of the motorcycle. The building has a large window on the side and a small sign that reads \"Adventure Riders\"."}, "419867": {"image_id": 419867, "Bleu_1": 0.3749999999882814, "Bleu_2": 0.2909938476144488, "Bleu_3": 0.2038242586060542, "Bleu_4": 0.13072010980250545, "METEOR": 0.25984742118995363, "ROUGE_L": 0.3758802816901408, "CIDEr": 0.0009953629967417415, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.30434782608695654, "f": 0.27999999999999997, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a grocery store with a display of bananas on the shelves. There are several people shopping in the store, and the bananas are arranged in rows on the shelves."}, "194724": {"image_id": 194724, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.16578342426777695, "Bleu_3": 0.08681823924888467, "Bleu_4": 1.1239895308238822e-05, "METEOR": 0.13198996114642098, "ROUGE_L": 0.23890339425587467, "CIDEr": 8.196890207993301e-06, "SPICE": {"All": {"pr": 0.3684210526315789, "re": 0.35, "f": 0.358974358974359, "fn": 13.0, "numImages": 1.0, "fp": 12.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.625, "f": 0.5882352941176471, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a table with two pizzas on it, one with pepperoni and the other with mushrooms. There are also two glasses of soda on the table and a couple of slices of bread. The background is a red and white striped tablecloth."}, "236426": {"image_id": 236426, "Bleu_1": 0.517241379292509, "Bleu_2": 0.2718301411002404, "Bleu_3": 0.13987619794120837, "Bleu_4": 1.8012107374706402e-05, "METEOR": 0.24957299806786276, "ROUGE_L": 0.34186437511675694, "CIDEr": 0.01501036863988376, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.16666666666666666, "f": 0.14545454545454548, "fn": 20.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a tennis player in mid air, jumping to hit the ball with his racket. The background is a green court with a crowd of people watching."}, "499826": {"image_id": 499826, "Bleu_1": 0.28169014084110294, "Bleu_2": 0.21974926263633632, "Bleu_3": 0.1613314377660033, "Bleu_4": 0.0886465881376154, "METEOR": 0.24391642316033643, "ROUGE_L": 0.3226497071972797, "CIDEr": 8.052062294702034e-18, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 14.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5714285714285714, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a woman standing on the sidewalk next to a group of elephants. The elephants are walking in a line, with their trunks curled up and their ears flapping in the wind. The woman is wearing a white shirt and jeans, and she is looking at the elephants with a smile on her face. There are trees and greenery in the background, and the sky is blue and cloudy."}, "514904": {"image_id": 514904, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.21470745394187096, "Bleu_3": 0.17112053874527608, "Bleu_4": 0.1351928705097216, "METEOR": 0.29386831605273583, "ROUGE_L": 0.27371794871794874, "CIDEr": 2.6448392360561444e-09, "SPICE": {"All": {"pr": 0.15625, "re": 0.2631578947368421, "f": 0.19607843137254902, "fn": 14.0, "numImages": 1.0, "fp": 27.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5, "f": 0.4347826086956522, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "Here is a short caption for the image:\n\nA woman is holding a hot dog in her hand while standing on the sidewalk. She is wearing a black and white striped shirt and has a red scarf around her neck. There are buildings and cars in the background."}, "359864": {"image_id": 359864, "Bleu_1": 0.17910447760926712, "Bleu_2": 0.12760182301581513, "Bleu_3": 0.09091604859111013, "Bleu_4": 0.06961341182139986, "METEOR": 0.24148037421417426, "ROUGE_L": 0.26056003796867583, "CIDEr": 2.1008974756237453e-19, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.35714285714285715, "f": 0.25, "fn": 9.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.25, "f": 0.14285714285714288, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.75, "f": 0.375, "fn": 1.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a man standing on the deck of a boat, wearing a red life jacket and sunglasses. He is looking out at the water in front of him, with the sun shining down on his face. The boat is white and has a blue stripe running along the side of it. There are other boats in the background, and the water is calm and clear."}, "247333": {"image_id": 247333, "Bleu_1": 0.5384615384408284, "Bleu_2": 0.32816506164407266, "Bleu_3": 0.23788381719511642, "Bleu_4": 0.18496911301593644, "METEOR": 0.35054868583848214, "ROUGE_L": 0.43306288032454365, "CIDEr": 0.05654209734263674, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.2608695652173913, "f": 0.2666666666666666, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5555555555555556, "f": 0.5263157894736842, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a plate of food with various vegetables, meats, and condiments. There is a glass of soda on the table next to the plate."}, "54277": {"image_id": 54277, "Bleu_1": 0.3599999999928, "Bleu_2": 0.2267786838009545, "Bleu_3": 0.10232641080729249, "Bleu_4": 1.2287579518093226e-05, "METEOR": 0.26962086757298154, "ROUGE_L": 0.2594167679222357, "CIDEr": 7.665525358815614e-10, "SPICE": {"All": {"pr": 0.12, "re": 0.17647058823529413, "f": 0.14285714285714282, "fn": 14.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a person standing on top of a snow covered slope, wearing a pair of skis and holding a snowboard. The person is looking down at the ground and appears to be enjoying the snow. The background is a large white building with a sign that reads \"Village\"."}, "80172": {"image_id": 80172, "Bleu_1": 0.3617021276518787, "Bleu_2": 0.2660221937781222, "Bleu_3": 0.18459831800739637, "Bleu_4": 0.14390899797272783, "METEOR": 0.325952528663389, "ROUGE_L": 0.34163036714374606, "CIDEr": 3.566614326902494e-08, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.06896551724137931, "f": 0.0975609756097561, "fn": 27.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.16666666666666666, "f": 0.2105263157894737, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a young boy sitting on the edge of a bathtub, brushing his teeth with a toothbrush. He is wearing a blue shirt and has a towel around his neck. The bathroom is clean and well lit, with a sink and toilet in the background."}, "376959": {"image_id": 376959, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.27439773622258, "Bleu_3": 0.2307907074427526, "Bleu_4": 0.16648830933698916, "METEOR": 0.2627129005558405, "ROUGE_L": 0.3190932868352223, "CIDEr": 3.636756759415631e-09, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.1724137931034483, "f": 0.19999999999999998, "fn": 24.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.25, "f": 0.3, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a young girl sitting at a table with a pencil and paper in front of her. She is wearing a pink dress and has long blonde hair. The background is a light brown color with a few objects on the table, such as a book and a pen."}, "47055": {"image_id": 47055, "Bleu_1": 0.2027027026999635, "Bleu_2": 0.11782931197321524, "Bleu_3": 0.07278938682550534, "Bleu_4": 8.584924072835393e-06, "METEOR": 0.17357418221477652, "ROUGE_L": 0.21118227453695693, "CIDEr": 2.533416522490872e-21, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.1, "f": 0.13636363636363638, "fn": 27.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.25, "f": 0.3157894736842105, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "This is an image of a bedroom with a white bed, gray walls, and black blinds. The bed has a white headboard and footboard, and the bedding is white and gray. There is a nightstand on one side of the bed with a lamp on it, and a dresser on the other side with a mirror above it. The floor is made of hardwood and there is a rug in front of the bed."}, "154816": {"image_id": 154816, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.14869042853022912, "Bleu_3": 7.777190244898269e-07, "Bleu_4": 1.7882473253246786e-09, "METEOR": 0.2147849966426163, "ROUGE_L": 0.22679390259015986, "CIDEr": 1.7832460739805584e-09, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 14.0, "numImages": 1.0, "fp": 35.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.2777777777777778, "re": 0.625, "f": 0.3846153846153846, "fn": 3.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}}, "caption": "The image shows a baseball player in the middle of a game, holding a bat and running towards home plate. There are several people in the stands watching the game, including a coach and several players. The field is made of grass and there are trees in the background."}, "155179": {"image_id": 155179, "Bleu_1": 0.22580645160561919, "Bleu_2": 0.12269377914088728, "Bleu_3": 0.08036785237228378, "Bleu_4": 1.1668694360280925e-05, "METEOR": 0.1435564070253247, "ROUGE_L": 0.3032311516155758, "CIDEr": 0.0008720942938626652, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.07692307692307693, "f": 0.10526315789473684, "fn": 36.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.1875, "f": 0.26086956521739124, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a loaf of bread on a plate. The bread appears to be freshly baked and has a golden brown color. There are no other objects in the image."}, "328374": {"image_id": 328374, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.1842190315423256, "Bleu_3": 0.08788194533129833, "Bleu_4": 1.0848650703059748e-05, "METEOR": 0.1632406527811072, "ROUGE_L": 0.2771467514766015, "CIDEr": 4.783304840298497e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.36363636363636365, "f": 0.2962962962962963, "fn": 14.0, "numImages": 1.0, "fp": 24.0, "tp": 8.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.625, "f": 0.45454545454545453, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A group of people are sitting on skis at the bottom of a snowy hill. They are all wearing ski gear and helmets, and some of them are holding poles. The hill is covered in snow and there are trees in the background.\""}, "264919": {"image_id": 264919, "Bleu_1": 0.19999999999777776, "Bleu_2": 0.1161169499561301, "Bleu_3": 5.351015254878484e-07, "Bleu_4": 1.1519863381539594e-09, "METEOR": 0.1710838687304273, "ROUGE_L": 0.17566594672426203, "CIDEr": 1.3730295450712192e-32, "SPICE": {"All": {"pr": 0.34782608695652173, "re": 0.36363636363636365, "f": 0.3555555555555555, "fn": 14.0, "numImages": 1.0, "fp": 15.0, "tp": 8.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.75, "f": 0.5714285714285714, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image shows a man wearing a colorful costume made of balloons. He is standing on the sidewalk, holding a phone to his ear and looking down at the ground. The costume is made of long, thin balloons that are tied together in the shape of a mohawk. The man's body is covered in the balloons, which are tied around his arms, legs, and torso. The balloons are brightly colored and create a psychedelic effect. The man's face is not visible due to the balloons covering his head."}, "48185": {"image_id": 48185, "Bleu_1": 0.32499999999187507, "Bleu_2": 0.2236067977443172, "Bleu_3": 0.17394640854448745, "Bleu_4": 0.14372803311998567, "METEOR": 0.28873158205319777, "ROUGE_L": 0.38337988826815644, "CIDEr": 8.335186083180946e-06, "SPICE": {"All": {"pr": 0.17142857142857143, "re": 0.21428571428571427, "f": 0.19047619047619047, "fn": 22.0, "numImages": 1.0, "fp": 29.0, "tp": 6.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.125, "f": 0.1, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4444444444444444, "f": 0.34782608695652173, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "This is a bathroom with a large mirror, sink, and shower. The walls are white and the floor is tiled in black and white. There is a large window with curtains on one side and a door on the other."}, "43376": {"image_id": 43376, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.2175844552512906, "Bleu_3": 0.147788770508639, "Bleu_4": 1.655251397468764e-05, "METEOR": 0.2695314707336006, "ROUGE_L": 0.32317880794701986, "CIDEr": 4.0557032064624234e-08, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.20689655172413793, "f": 0.23529411764705882, "fn": 23.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5555555555555556, "f": 0.5263157894736842, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a giraffe standing on a fence in a zoo. The giraffe is looking down and appears to be eating something from its mouth. The fence is made of metal and has a railing on top. There are trees and plants in the background."}, "204994": {"image_id": 204994, "Bleu_1": 0.21276595744228163, "Bleu_2": 0.1360198059227937, "Bleu_3": 7.435849582310868e-07, "Bleu_4": 1.7483757647538984e-09, "METEOR": 0.22453671015004728, "ROUGE_L": 0.26571250777846916, "CIDEr": 5.745279726639716e-09, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.16, "f": 0.1818181818181818, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a man standing on a bench next to a giraffe. The man is wearing a black shirt and pants, and has a hat on his head. The giraffe is standing on the ground, looking at the man. There are palm trees in the background."}, "309264": {"image_id": 309264, "Bleu_1": 0.26666666665777783, "Bleu_2": 0.13561270071956377, "Bleu_3": 0.0869255738105391, "Bleu_4": 1.2488771902030573e-05, "METEOR": 0.20067252011401562, "ROUGE_L": 0.2350674373795761, "CIDEr": 0.0019739193865151742, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.13636363636363635, "f": 0.11764705882352941, "fn": 19.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A colorful bird cage filled with various birds, including parakeets, cockatiels, and finches, sits on a shelf in a pet store.\""}, "356028": {"image_id": 356028, "Bleu_1": 0.41463414633135043, "Bleu_2": 0.36709140217978414, "Bleu_3": 0.314467264387792, "Bleu_4": 0.26471191840584474, "METEOR": 0.30586168310352074, "ROUGE_L": 0.4085733422638982, "CIDEr": 9.215061289084587e-06, "SPICE": {"All": {"pr": 0.25, "re": 0.2608695652173913, "f": 0.2553191489361702, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.5454545454545454, "f": 0.4999999999999999, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "This is a black and white photograph of a room with several beds in it. There are curtains on the windows and a wooden floor. The walls are made of brick and there are no furniture or decorations in the room."}, "544794": {"image_id": 544794, "Bleu_1": 0.5833333332361111, "Bleu_2": 0.398862017540745, "Bleu_3": 0.2515060603801396, "Bleu_4": 3.646285861281333e-05, "METEOR": 0.2415383940392113, "ROUGE_L": 0.4326241134751773, "CIDEr": 1.1477036733639547, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.12, "f": 0.12499999999999997, "fn": 22.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is a plate of pizza with mushrooms and cheese on it."}, "264619": {"image_id": 264619, "Bleu_1": 0.2499999999958334, "Bleu_2": 0.1841149235765701, "Bleu_3": 0.12058420238621656, "Bleu_4": 0.07447304260682251, "METEOR": 0.19537221736052796, "ROUGE_L": 0.22956989247311832, "CIDEr": 6.11705045823185e-13, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.125, "f": 0.15789473684210525, "fn": 21.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a group of people on the beach, with kite surfers in the background flying their kites in the sky. The sky is clear and blue, with a few clouds scattered about. The ocean is calm and there are waves crashing against the shore. The sand is dry and there are some rocks and driftwood on the beach."}, "322222": {"image_id": 322222, "Bleu_1": 0.5135135134996348, "Bleu_2": 0.2925501419943171, "Bleu_3": 0.19430528452575682, "Bleu_4": 0.12119751909567932, "METEOR": 0.34377094192050106, "ROUGE_L": 0.33862014274385416, "CIDEr": 0.0001841660132121138, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.21428571428571427, "f": 0.19672131147540986, "fn": 22.0, "numImages": 1.0, "fp": 27.0, "tp": 6.0}, "Relation": {"pr": 0.07142857142857142, "re": 0.07692307692307693, "f": 0.07407407407407408, "fn": 12.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.36363636363636365, "f": 0.32, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a man playing tennis on a court. He is wearing a white shirt and white shorts, and has a racket in his hand. There are two other people watching him play from the sidelines."}, "359791": {"image_id": 359791, "Bleu_1": 0.21951219511927422, "Bleu_2": 0.13773231175519954, "Bleu_3": 0.0779837103025032, "Bleu_4": 8.802299629085486e-06, "METEOR": 0.16552909079981576, "ROUGE_L": 0.15278009684421437, "CIDEr": 5.422931299897754e-29, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.18181818181818182, "f": 0.16666666666666669, "fn": 18.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA group of people are standing on a boat in the water, looking out at the horizon. The boat is orange and white, with several rows of chairs lined up along the deck. There is a person standing at the front of the boat, holding an umbrella over their head to protect themselves from the rain. In the background, there is a large body of water with a few clouds in the sky."}, "404635": {"image_id": 404635, "Bleu_1": 0.2903225806357961, "Bleu_2": 0.24096579866284706, "Bleu_3": 0.18177940993538677, "Bleu_4": 0.14392177550546975, "METEOR": 0.3199710823736472, "ROUGE_L": 0.41673783091374894, "CIDEr": 0.00969285523837624, "SPICE": {"All": {"pr": 0.3, "re": 0.20689655172413793, "f": 0.24489795918367346, "fn": 23.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.3333333333333333, "f": 0.3846153846153846, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a group of elephants standing in a grassy field with trees in the background. They are all facing each other and appear to be communicating with each other."}, "364343": {"image_id": 364343, "Bleu_1": 0.15151515151285586, "Bleu_2": 0.1182624791960109, "Bleu_3": 0.060233485463859565, "Bleu_4": 7.674381043002201e-06, "METEOR": 0.13969464273033763, "ROUGE_L": 0.18208955223880596, "CIDEr": 2.6210212628025286e-20, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.2, "f": 0.1851851851851852, "fn": 20.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This image appears to be a plate of food, possibly breakfast or brunch, with various fruits and pastries on it. There is a banana, strawberries, blueberries, and a crepe on the plate. The crepe is folded into a triangle shape and topped with whipped cream and a sprinkle of sugar. The plate is on a white tablecloth with a red and white checkered napkin on top."}, "1573": {"image_id": 1573, "Bleu_1": 0.5652173912797732, "Bleu_2": 0.32057261019905153, "Bleu_3": 1.6977660468584403e-06, "Bleu_4": 3.955040035595633e-09, "METEOR": 0.23790782351823148, "ROUGE_L": 0.379746835443038, "CIDEr": 0.06651110677899923, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.21739130434782608, "f": 0.22727272727272724, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This is an image of a kitchen with a stove, sink, and refrigerator. There are also some pots and pans on the countertop."}, "174898": {"image_id": 174898, "Bleu_1": 0.2153846153813018, "Bleu_2": 0.19240382212441318, "Bleu_3": 0.16751702151973252, "Bleu_4": 0.13953680853541478, "METEOR": 0.23889417865817952, "ROUGE_L": 0.28168291431503334, "CIDEr": 1.896561168555396e-17, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.08823529411764706, "f": 0.0967741935483871, "fn": 31.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.23076923076923078, "f": 0.22222222222222224, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "Sure, here is a short caption for the image:\n\nThe black motorcycle is parked on the side of the road in front of a row of trees. The sun is shining down on the bike, casting a warm glow on it. The trees are bare and their branches stretch up towards the sky. The road is empty and there are no other vehicles in sight."}, "527580": {"image_id": 527580, "Bleu_1": 0.32812499999487305, "Bleu_2": 0.22821773229022504, "Bleu_3": 0.14978064313054842, "Bleu_4": 0.1024511431064054, "METEOR": 0.17809255042110672, "ROUGE_L": 0.2293233082706767, "CIDEr": 3.61404127743082e-15, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.17857142857142858, "f": 0.17543859649122806, "fn": 23.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a group of people sitting on the beach in front of a hotel with a train passing by on the tracks. The train is an old fashioned one with wooden seats and a wooden roof. The people are wearing sun hats and sunglasses, and some of them are holding umbrellas. The sky is cloudy and there are mountains in the background."}, "522020": {"image_id": 522020, "Bleu_1": 0.47368421050138515, "Bleu_2": 0.3627381250353841, "Bleu_3": 0.31400205658385943, "Bleu_4": 0.24941747175577164, "METEOR": 0.30370921359602093, "ROUGE_L": 0.458072590738423, "CIDEr": 0.24446206437287846, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.18518518518518517, "f": 0.23809523809523808, "fn": 22.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.09090909090909091, "f": 0.15384615384615385, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is a white cat sitting in the grass, looking up at the camera with its big green eyes."}, "142890": {"image_id": 142890, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.20447945297237122, "Bleu_3": 0.14637049365650087, "Bleu_4": 0.09469433563006603, "METEOR": 0.28733437878784474, "ROUGE_L": 0.308080808080808, "CIDEr": 2.635986179971434e-06, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.3684210526315789, "f": 0.22950819672131145, "fn": 12.0, "numImages": 1.0, "fp": 35.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2631578947368421, "re": 0.5555555555555556, "f": 0.35714285714285715, "fn": 4.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}}, "caption": "The image shows a black cat sitting on top of a computer keyboard. The cat is looking directly at the camera with its eyes fixed on the screen. The background is a messy office with papers and other office supplies scattered around."}, "503238": {"image_id": 503238, "Bleu_1": 0.36585365852766216, "Bleu_2": 0.25303041366748835, "Bleu_3": 0.18726083047926023, "Bleu_4": 0.13634738359895024, "METEOR": 0.3167965319655202, "ROUGE_L": 0.2713120830244626, "CIDEr": 8.956425937213446e-06, "SPICE": {"All": {"pr": 0.1, "re": 0.11538461538461539, "f": 0.10714285714285714, "fn": 23.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.2727272727272727, "f": 0.24999999999999994, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This is an image of a bus driving down the street in a city. The bus is orange and has a number on the side. There are people walking on the sidewalk and cars parked on the side of the road."}, "522430": {"image_id": 522430, "Bleu_1": 0.36956521738327036, "Bleu_2": 0.23976639193762495, "Bleu_3": 0.13773721951769352, "Bleu_4": 1.5700785118695926e-05, "METEOR": 0.1974109888374136, "ROUGE_L": 0.24238410596026488, "CIDEr": 2.0825923642063513e-08, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.13043478260869565, "f": 0.18750000000000003, "fn": 20.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.5, "f": 0.5454545454545454, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows a group of cows standing in a field at sunset. The cows are brown and white, with long, curly hair. They are standing in a line, looking out at the camera. The sky is a deep orange color, with clouds scattered across it."}, "155897": {"image_id": 155897, "Bleu_1": 0.2444444444390124, "Bleu_2": 0.12909944487067912, "Bleu_3": 0.09186218331858677, "Bleu_4": 0.06554510293192194, "METEOR": 0.22186300238165602, "ROUGE_L": 0.21585279547062985, "CIDEr": 1.093457960333974e-08, "SPICE": {"All": {"pr": 0.12, "re": 0.13636363636363635, "f": 0.1276595744680851, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "This is an image of a woman sitting on a bench holding a sandwich in her hand. The sandwich appears to be made of bread, meat, and vegetables. There are several people in the background of the image, some of whom are also eating sandwiches."}, "214494": {"image_id": 214494, "Bleu_1": 0.4074074073923183, "Bleu_2": 0.35405666968249755, "Bleu_3": 0.24685519352919957, "Bleu_4": 0.1582263796105431, "METEOR": 0.3217560540142621, "ROUGE_L": 0.4434060228452752, "CIDEr": 0.017054111357788795, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.15384615384615385, "f": 0.186046511627907, "fn": 22.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a chocolate cake with a knife cutting into it. The cake is on a black plate and there is a hand holding the knife."}, "223093": {"image_id": 223093, "Bleu_1": 0.3863636363548554, "Bleu_2": 0.2997532459416044, "Bleu_3": 0.18583745582527877, "Bleu_4": 1.9890878941153608e-05, "METEOR": 0.27692652940595713, "ROUGE_L": 0.3981723237597911, "CIDEr": 1.8159373015638714e-07, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.16, "f": 0.15384615384615383, "fn": 21.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.25, "f": 0.24000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a brick building with a clock tower on top. The clock tower has a large clock face on it, and the sky is clear and blue. There are trees in the background, and the sun is shining down on the building."}, "422706": {"image_id": 422706, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.1824897193978171, "Bleu_3": 0.11396323345568955, "Bleu_4": 0.07615710086477687, "METEOR": 0.16217477684698703, "ROUGE_L": 0.28454810495626826, "CIDEr": 1.8608667022806165e-07, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.045454545454545456, "f": 0.05405405405405406, "fn": 21.0, "numImages": 1.0, "fp": 14.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "A group of people are standing on the deck of a cruise ship, looking out at the ocean. One person is holding a camera and taking pictures of the water and the sky. The ship is traveling through the ocean, with the sun shining down on it."}, "4011": {"image_id": 4011, "Bleu_1": 0.21333333333048887, "Bleu_2": 0.16107745324920364, "Bleu_3": 0.10216197995109837, "Bleu_4": 1.1031481773677e-05, "METEOR": 0.2559377083978026, "ROUGE_L": 0.21602478972996908, "CIDEr": 2.6094219768915284e-22, "SPICE": {"All": {"pr": 0.1, "re": 0.09523809523809523, "f": 0.0975609756097561, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a woman standing in front of a table with a cake on it. The cake appears to be a white dog with a pink nose and paws. The woman is wearing an apron and has a smile on her face. There are several utensils and ingredients on the table, including a mixing bowl, a measuring cup, and a pastry bag. The background is a white wall with a window in the background."}, "188824": {"image_id": 188824, "Bleu_1": 0.23809523809145886, "Bleu_2": 0.21466939536711102, "Bleu_3": 0.16549589548291546, "Bleu_4": 0.11086899395833859, "METEOR": 0.27563973376866896, "ROUGE_L": 0.2934102934102934, "CIDEr": 1.2578384308389017e-15, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.2222222222222222, "f": 0.2424242424242424, "fn": 14.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a gray and white cat sitting on top of a couch, looking at the camera with its green eyes. The cat is wearing a collar around its neck and has a tag on its ear. The background of the image is a messy living room with a television in the corner and a coffee table in front of the couch."}, "247206": {"image_id": 247206, "Bleu_1": 0.5312499999833985, "Bleu_2": 0.4139697666871967, "Bleu_3": 0.2837648915610377, "Bleu_4": 2.9793360867621898e-05, "METEOR": 0.3027851409540423, "ROUGE_L": 0.42068965517241375, "CIDEr": 0.0019712116652407874, "SPICE": {"All": {"pr": 0.14634146341463414, "re": 0.42857142857142855, "f": 0.2181818181818182, "fn": 8.0, "numImages": 1.0, "fp": 35.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.5714285714285714, "f": 0.36363636363636365, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image shows a man lying on the floor with a cat sitting next to him. The man is holding a toy in his hand and the cat is looking at him."}, "430047": {"image_id": 430047, "Bleu_1": 0.517241379292509, "Bleu_2": 0.3595974761014168, "Bleu_3": 0.26757354076938045, "Bleu_4": 0.1647551645544836, "METEOR": 0.2602173856267417, "ROUGE_L": 0.30678960603520533, "CIDEr": 0.029464649276077764, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.08333333333333333, "f": 0.09756097560975609, "fn": 22.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "This is a living room with a television on the wall and a couch in front of it. There are also some books and other items on the shelves."}, "244240": {"image_id": 244240, "Bleu_1": 0.34285714284734703, "Bleu_2": 0.22454435656302607, "Bleu_3": 0.14511315402717082, "Bleu_4": 1.7578936267302155e-05, "METEOR": 0.20954427831497874, "ROUGE_L": 0.33406352683461116, "CIDEr": 0.0005675695081490602, "SPICE": {"All": {"pr": 0.125, "re": 0.0967741935483871, "f": 0.10909090909090909, "fn": 28.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is a photo of a toilet in a bathroom. The toilet is white and has a seat on it. There is a sink next to the toilet and some plants growing outside the window."}, "49810": {"image_id": 49810, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.19411635536098795, "Bleu_3": 0.09496360514530064, "Bleu_4": 1.1879571650374926e-05, "METEOR": 0.24972738537895303, "ROUGE_L": 0.28968792401628224, "CIDEr": 6.160047083116599e-08, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.3125, "f": 0.21739130434782608, "fn": 11.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5, "f": 0.36363636363636365, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a cat sitting on a wooden deck, looking at its reflection in a mirror. The cat has a white coat with orange patches and is looking directly at the camera with its eyes. The background is a blurred image of trees and buildings."}, "85914": {"image_id": 85914, "Bleu_1": 0.49999999998437505, "Bleu_2": 0.2540002539923155, "Bleu_3": 0.16262688653272234, "Bleu_4": 1.9624326516524827e-05, "METEOR": 0.22439024390243906, "ROUGE_L": 0.40970149253731347, "CIDEr": 0.01588605959665255, "SPICE": {"All": {"pr": 0.5, "re": 0.2608695652173913, "f": 0.3428571428571428, "fn": 17.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.3333333333333333, "f": 0.4444444444444444, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.3333333333333333, "f": 0.42857142857142855, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This is an image of a plate with a variety of vegetables, including broccoli, carrots, and potatoes, topped with a piece of beef. The dish is served with a side of rice."}, "442942": {"image_id": 442942, "Bleu_1": 0.2051282051229455, "Bleu_2": 0.10390486669052698, "Bleu_3": 6.6326948668966e-07, "Bleu_4": 1.6872983760809617e-09, "METEOR": 0.18063896042472247, "ROUGE_L": 0.28175519630484985, "CIDEr": 2.198968316033824e-06, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.2, "f": 0.22580645161290322, "fn": 28.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.1, "re": 0.08333333333333333, "f": 0.0909090909090909, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}}, "caption": "This is an image of a train on a track in the middle of a field. There are people standing on the train and in the background, there is a red building with a sign that reads \"train station\"."}, "162543": {"image_id": 162543, "Bleu_1": 0.3124999999902345, "Bleu_2": 0.245934688411173, "Bleu_3": 0.1591656839177488, "Bleu_4": 1.9310235945030586e-05, "METEOR": 0.21880910356455352, "ROUGE_L": 0.273542600896861, "CIDEr": 0.0010141517046606562, "SPICE": {"All": {"pr": 0.07894736842105263, "re": 0.15789473684210525, "f": 0.10526315789473684, "fn": 16.0, "numImages": 1.0, "fp": 35.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.1875, "re": 0.42857142857142855, "f": 0.26086956521739124, "fn": 4.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}}, "caption": "The image shows a group of elephants standing in a field with a fence in the background. The elephants are wearing collars and appear to be in a zoo or wildlife sanctuary."}, "157352": {"image_id": 157352, "Bleu_1": 0.3235294117551904, "Bleu_2": 0.1714985851373884, "Bleu_3": 0.09722777968025705, "Bleu_4": 1.3122070075706762e-05, "METEOR": 0.18993760286329228, "ROUGE_L": 0.24478330658105937, "CIDEr": 0.0003336926573542209, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.09523809523809523, "f": 0.08333333333333333, "fn": 19.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a group of people skateboarding down a ramp. One person is jumping off the ramp while another person is riding on the board. There are trees and buildings in the background."}, "262810": {"image_id": 262810, "Bleu_1": 0.19148936169805347, "Bleu_2": 0.0645198590415134, "Bleu_3": 4.522633916831482e-07, "Bleu_4": 1.2041494936393691e-09, "METEOR": 0.15213946117274169, "ROUGE_L": 0.158957654723127, "CIDEr": 6.065566506444303e-08, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.14285714285714285, "f": 0.15, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This image shows a wedding reception with guests dancing and taking photos. The bride and groom are standing at the head table, surrounded by their friends and family. There are several tables set up with food and drinks, and the room is decorated with balloons and streamers."}, "498807": {"image_id": 498807, "Bleu_1": 0.3333333333247864, "Bleu_2": 0.264906471406127, "Bleu_3": 0.21166601750496777, "Bleu_4": 0.15150264942498534, "METEOR": 0.2927794663652461, "ROUGE_L": 0.3756735950731332, "CIDEr": 6.876309101458022e-06, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.09523809523809523, "f": 0.0909090909090909, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "A young girl is surfing on a pink surfboard in the ocean. She is wearing a black wetsuit and has her hair tied back. The waves are crashing against the shore and the sun is shining down on her."}, "563605": {"image_id": 563605, "Bleu_1": 0.38461538460552275, "Bleu_2": 0.2661770133303563, "Bleu_3": 0.19712110312662995, "Bleu_4": 0.12077421280261788, "METEOR": 0.22925293341723715, "ROUGE_L": 0.2959112959112959, "CIDEr": 0.00011267345768493491, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.08, "f": 0.08163265306122448, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.18181818181818182, "f": 0.1904761904761905, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a group of people standing under an umbrella on a street. They are all wearing different outfits, including leather jackets and skirts. The building in the background is a large, ornate structure with columns and arches."}, "162503": {"image_id": 162503, "Bleu_1": 0.1969696969667126, "Bleu_2": 0.14564381624866016, "Bleu_3": 0.12575303021010983, "Bleu_4": 0.1120846675078732, "METEOR": 0.22877267188483263, "ROUGE_L": 0.21631205673758866, "CIDEr": 4.2299461518430555e-19, "SPICE": {"All": {"pr": 0.25, "re": 0.21428571428571427, "f": 0.23076923076923075, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A barn owl perched on a branch in a forest of tall trees. The owl has a round, fluffy body and big, round eyes. Its feathers are a mottled brown and white color, with a distinctive white patch on its forehead. The tree behind it is covered in leaves and branches, creating a cozy and secluded atmosphere.\""}, "62089": {"image_id": 62089, "Bleu_1": 0.27906976743537054, "Bleu_2": 0.16302782918400804, "Bleu_3": 0.08654590923115621, "Bleu_4": 1.1282878483696187e-05, "METEOR": 0.2017905548963433, "ROUGE_L": 0.28561872909699, "CIDEr": 4.100755151389899e-06, "SPICE": {"All": {"pr": 0.0625, "re": 0.038461538461538464, "f": 0.04761904761904762, "fn": 25.0, "numImages": 1.0, "fp": 15.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image shows a young boy wearing a skateboard helmet and holding a skateboard. He is standing on the side of a basketball court with other kids playing basketball in the background. The sky is blue and there are trees in the background."}, "340737": {"image_id": 340737, "Bleu_1": 0.30769230768441824, "Bleu_2": 0.20121090914115636, "Bleu_3": 0.12983061254080153, "Bleu_4": 0.08829928855227857, "METEOR": 0.22183481649393752, "ROUGE_L": 0.28175519630484985, "CIDEr": 8.525272566269335e-06, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.4375, "f": 0.37837837837837834, "fn": 9.0, "numImages": 1.0, "fp": 14.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is a bathroom with a bathtub, sink, and toilet. The walls are yellow and the floor is made of tile. There is a window on the left side of the room and a door on the right side."}, "423744": {"image_id": 423744, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.06440351676097583, "Bleu_3": 4.3613042737873907e-07, "Bleu_4": 1.1406785378264665e-09, "METEOR": 0.12185554449195277, "ROUGE_L": 0.22241127856101123, "CIDEr": 2.4766964071060573e-11, "SPICE": {"All": {"pr": 0.3103448275862069, "re": 0.4090909090909091, "f": 0.35294117647058826, "fn": 13.0, "numImages": 1.0, "fp": 20.0, "tp": 9.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Size": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.75, "f": 0.5714285714285714, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "This image shows a workshop with various tools and equipment on the workbench. There are two laptops on the workbench, one with a screen open and the other closed. There is also a wrench, pliers, and other tools on the workbench. The image appears to be in a garage or workshop setting."}, "343903": {"image_id": 343903, "Bleu_1": 0.46428571426913273, "Bleu_2": 0.3708990934959662, "Bleu_3": 0.27660884444516043, "Bleu_4": 0.17057467190627254, "METEOR": 0.320631997697234, "ROUGE_L": 0.5350877192982456, "CIDEr": 0.1754249302591509, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.2, "f": 0.23728813559322035, "fn": 28.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a plate with a blueberry pancake on it, sitting on top of a colorful tablecloth. There is a glass of milk next to the plate."}, "117786": {"image_id": 117786, "Bleu_1": 0.20833333333043982, "Bleu_2": 0.132686223106713, "Bleu_3": 0.06312255093093734, "Bleu_4": 7.770091505881875e-06, "METEOR": 0.19632635369350904, "ROUGE_L": 0.1938090050835149, "CIDEr": 1.8571548676990915e-21, "SPICE": {"All": {"pr": 0.25, "re": 0.11538461538461539, "f": 0.15789473684210525, "fn": 23.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "The image shows a man standing in front of a large building with a fountain in the foreground. The building appears to be made of stone and has a large dome on top. The man is wearing a white shirt and pants and is holding a bird on his arm. There are several other people walking around the area, including some children playing on the ground. The sky is clear and blue."}, "3693": {"image_id": 3693, "Bleu_1": 0.6153846153609468, "Bleu_2": 0.3843075691171325, "Bleu_3": 0.26429521259190897, "Bleu_4": 0.16831972515625004, "METEOR": 0.25422242610889106, "ROUGE_L": 0.42277227722772265, "CIDEr": 0.021745846586503484, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "Sure, here is a short caption for the image:\n\n\"A group of people standing in front of a graffiti wall, smiling and looking at their phones.\""}, "187852": {"image_id": 187852, "Bleu_1": 0.2656249999958496, "Bleu_2": 0.18365772167022085, "Bleu_3": 0.11773781812950343, "Bleu_4": 0.07192080318269316, "METEOR": 0.17870136236283019, "ROUGE_L": 0.19022869022869024, "CIDEr": 2.6041714940472495e-14, "SPICE": {"All": {"pr": 0.15151515151515152, "re": 0.25, "f": 0.18867924528301888, "fn": 15.0, "numImages": 1.0, "fp": 28.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.1111111111111111, "f": 0.09999999999999999, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a group of people standing in front of a building, looking at a camera. One person is holding a camera, while the others are holding their phones and taking pictures. The building in the background appears to be made of brick and has a red roof. There are trees and flowers in the foreground, and people are walking in the background."}, "414078": {"image_id": 414078, "Bleu_1": 0.4102564102458909, "Bleu_2": 0.27490643727245323, "Bleu_3": 0.18299102222839972, "Bleu_4": 2.0311720520162125e-05, "METEOR": 0.21521138953099092, "ROUGE_L": 0.3155949741315595, "CIDEr": 2.413739822521651e-05, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.09090909090909091, "f": 0.08163265306122448, "fn": 20.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "The image shows a black and white cat lying on top of a blue blanket. The cat is looking up at the camera with its eyes. The background is a blue bedspread with white pillows and a blue comforter."}, "121716": {"image_id": 121716, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.14531393175596577, "Bleu_3": 7.502652544655378e-07, "Bleu_4": 1.7134131896259546e-09, "METEOR": 0.18771054430983444, "ROUGE_L": 0.18373493975903615, "CIDEr": 3.783038440294572e-11, "SPICE": {"All": {"pr": 0.22580645161290322, "re": 0.20588235294117646, "f": 0.2153846153846154, "fn": 27.0, "numImages": 1.0, "fp": 24.0, "tp": 7.0}, "Relation": {"pr": 0.1, "re": 0.08333333333333333, "f": 0.0909090909090909, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.375, "f": 0.38709677419354843, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}}, "caption": "This is an image of a person skiing down a snowy slope. The person is wearing a black and white jacket, black pants, and black ski boots. They are holding onto two skis and are in mid-air, jumping off a ramp. The background is a snowy mountain with trees in the distance."}, "327794": {"image_id": 327794, "Bleu_1": 0.3454545454482645, "Bleu_2": 0.2529289702084681, "Bleu_3": 0.18206666150945108, "Bleu_4": 0.123432488437285, "METEOR": 0.25691776499759617, "ROUGE_L": 0.33190827827438785, "CIDEr": 2.8276434474562046e-11, "SPICE": {"All": {"pr": 0.2, "re": 0.23333333333333334, "f": 0.2153846153846154, "fn": 23.0, "numImages": 1.0, "fp": 28.0, "tp": 7.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.125, "f": 0.10526315789473685, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.08333333333333333, "f": 0.1, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3125, "re": 0.5, "f": 0.38461538461538464, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}}, "caption": "This is a bowl of vegetables and meat being cooked in a pan. The vegetables are carrots, onions, and mushrooms, while the meat is chicken. The pan is made of stainless steel and has a wooden spoon in it. The vegetables are cooking in the pan and the meat is being added to the pan."}, "143370": {"image_id": 143370, "Bleu_1": 0.3499999999912501, "Bleu_2": 0.23204774044025306, "Bleu_3": 0.16199344770305452, "Bleu_4": 0.12312043871302324, "METEOR": 0.33237668927529984, "ROUGE_L": 0.4006463719766472, "CIDEr": 0.00037223618402492216, "SPICE": {"All": {"pr": 0.34615384615384615, "re": 0.23684210526315788, "f": 0.28125, "fn": 29.0, "numImages": 1.0, "fp": 17.0, "tp": 9.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4444444444444444, "re": 0.23529411764705882, "f": 0.30769230769230765, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is a bathroom with a white sink, toilet, and mirror on the wall. The mirror has a picture of a woman hanging on it. The floor is made of white tiles and there are no windows in the room."}, "354202": {"image_id": 354202, "Bleu_1": 0.4761904761678005, "Bleu_2": 0.30860669990912093, "Bleu_3": 0.17114033061407738, "Bleu_4": 2.297185935726835e-05, "METEOR": 0.28805006163297286, "ROUGE_L": 0.46362649294245384, "CIDEr": 0.17025372157639243, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.15384615384615385, "f": 0.21052631578947367, "fn": 22.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A giraffe peers over the fence at its enclosure in the zoo.\""}, "189193": {"image_id": 189193, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.16903085094228823, "Bleu_3": 8.411954328528159e-07, "Bleu_4": 1.8864626675179613e-09, "METEOR": 0.22342436386076356, "ROUGE_L": 0.22938079719227877, "CIDEr": 9.076029464937237e-11, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.15789473684210525, "f": 0.13043478260869565, "fn": 16.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "A woman in a green sweater and blue jeans is standing on a skateboard in the middle of a parking lot. She is wearing a black helmet and has her arms out to the side. There are cars parked on either side of her and a building in the background."}, "561967": {"image_id": 561967, "Bleu_1": 0.5666666666477778, "Bleu_2": 0.36983997780949307, "Bleu_3": 1.6967709721638485e-06, "Bleu_4": 3.6675536733081834e-09, "METEOR": 0.2722984434553056, "ROUGE_L": 0.4128595600676818, "CIDEr": 0.0034692830824603867, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.15789473684210525, "f": 0.16216216216216214, "fn": 16.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "A train traveling on a railroad track with a cargo car attached to the back. The train is traveling through a rural area with trees and buildings in the background."}, "404071": {"image_id": 404071, "Bleu_1": 0.3928571428431123, "Bleu_2": 0.2954684201318916, "Bleu_3": 0.14974405772212573, "Bleu_4": 1.9143758008581856e-05, "METEOR": 0.25362990903840293, "ROUGE_L": 0.4121621621621622, "CIDEr": 0.01041551244393011, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.2777777777777778, "f": 0.25641025641025644, "fn": 13.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA blue and white train traveling down a railroad track next to trees and a bridge in the background."}, "251572": {"image_id": 251572, "Bleu_1": 0.339622641503026, "Bleu_2": 0.2285817953234835, "Bleu_3": 0.1600261774492132, "Bleu_4": 0.09514824286433507, "METEOR": 0.26033026364011186, "ROUGE_L": 0.34718269778030736, "CIDEr": 1.0298997880112636e-10, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.2, "f": 0.16, "fn": 16.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.25, "f": 0.13333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "A woman is sitting on a couch with her dog in her lap. The dog is a small, fluffy white puppy with brown spots. The woman is wearing a gray sweatshirt and has her arms around the dog. The background is a beige colored couch with a pattern of brown and white stripes."}, "436791": {"image_id": 436791, "Bleu_1": 0.39999999999111113, "Bleu_2": 0.31622776600973085, "Bleu_3": 0.2649763888374642, "Bleu_4": 0.22705489693084108, "METEOR": 0.3482030633555363, "ROUGE_L": 0.3696969696969697, "CIDEr": 3.7286974379461293e-07, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.2, "f": 0.1568627450980392, "fn": 16.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.2, "f": 0.13333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The man in the image is holding a cell phone to his ear while walking down the street. He is wearing a black jacket and has a serious expression on his face. The background is a city street with buildings and cars in the distance."}, "319257": {"image_id": 319257, "Bleu_1": 0.22857142856816326, "Bleu_2": 0.15227739752318503, "Bleu_3": 0.06986408782005805, "Bleu_4": 8.446402906872447e-06, "METEOR": 0.16417649476202748, "ROUGE_L": 0.20236966824644548, "CIDEr": 3.1600978935232103e-22, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.24, "f": 0.30769230769230765, "fn": 19.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a cat sitting on top of a potted cactus plant. The cat is looking up at the sun through the window. The plant is in a pot with soil and water in it. The cat's fur is light brown and it has a white patch on its forehead. The sun is shining brightly through the window, casting a warm glow on the cat and the plant."}, "279437": {"image_id": 279437, "Bleu_1": 0.41666666664930563, "Bleu_2": 0.3009646327016102, "Bleu_3": 0.20193553397396088, "Bleu_4": 2.502388506469318e-05, "METEOR": 0.25706516131680657, "ROUGE_L": 0.4020715630885122, "CIDEr": 0.08122386735841551, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 16.0, "numImages": 1.0, "fp": 32.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5, "f": 0.36363636363636365, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "This is a bedroom with a bed, dresser, and chair. The walls are covered in floral wallpaper and there is a window with curtains."}, "175718": {"image_id": 175718, "Bleu_1": 0.8749999999453126, "Bleu_2": 0.6390096503814245, "Bleu_3": 0.44395200084161557, "Bleu_4": 0.28642846472173955, "METEOR": 0.3110467261093701, "ROUGE_L": 0.6014084507042253, "CIDEr": 0.9914776239106314, "SPICE": {"All": {"pr": 0.30434782608695654, "re": 0.2692307692307692, "f": 0.28571428571428575, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5, "f": 0.5263157894736842, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "A pizza with cheese and pepperoni on a wooden cutting board next to a beer bottle."}, "126671": {"image_id": 126671, "Bleu_1": 0.4444444444279836, "Bleu_2": 0.292352673091307, "Bleu_3": 0.2172693481609701, "Bleu_4": 0.17098323692086584, "METEOR": 0.3257201943101257, "ROUGE_L": 0.4714975845410628, "CIDEr": 0.04056990305798812, "SPICE": {"All": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "This is a bathroom with a toilet, shower, and sink. The walls are white and the floor is tiled. There is a curtain hanging in the shower."}, "281424": {"image_id": 281424, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.12635334149896824, "Bleu_3": 0.09792829216201589, "Bleu_4": 0.07828816852535843, "METEOR": 0.20898557450214789, "ROUGE_L": 0.22195269860521533, "CIDEr": 4.0746779136887286e-12, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.125, "f": 0.11538461538461538, "fn": 21.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a cat sleeping in a suitcase. The cat is lying on its side with its head resting on the handle of the suitcase. The suitcase appears to be black and has a zipper on the front. There is a small table next to the suitcase with a lamp on it."}, "136": {"image_id": 136, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.09701425001261196, "Bleu_3": 5.76976768606882e-07, "Bleu_4": 1.4143550190666944e-09, "METEOR": 0.1627578706464231, "ROUGE_L": 0.2238532110091743, "CIDEr": 2.342387255506004e-11, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.12, "f": 0.13636363636363635, "fn": 22.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a group of giraffes standing in a large enclosure. They are looking out of the window, their heads peeking over the ledge. The enclosure is made of metal bars and has a wooden floor. There are several people standing in front of the enclosure, looking at the giraffes."}, "71929": {"image_id": 71929, "Bleu_1": 0.2575757575718549, "Bleu_2": 0.17804952036066723, "Bleu_3": 0.11411453518982669, "Bleu_4": 0.06969001963160085, "METEOR": 0.21143749629482747, "ROUGE_L": 0.291866028708134, "CIDEr": 5.525285025266648e-15, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.125, "f": 0.17391304347826086, "fn": 28.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.07692307692307693, "f": 0.1111111111111111, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "A plate of food with shrimp, rice, and vegetables on a table\n\nThe image shows a plate of food with shrimp, rice, and vegetables on a table. The plate is white and has a red and green pattern on it. There is a fork and knife on the plate, and a glass of water next to it. The background is a blue sky with some clouds."}, "69293": {"image_id": 69293, "Bleu_1": 0.3235294117551904, "Bleu_2": 0.22140372137841335, "Bleu_3": 0.1452390111187727, "Bleu_4": 0.09970617113142893, "METEOR": 0.24631216457873134, "ROUGE_L": 0.3477198697068403, "CIDEr": 0.0005160795945715513, "SPICE": {"All": {"pr": 0.125, "re": 0.08695652173913043, "f": 0.10256410256410256, "fn": 21.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "This is a bathroom with a toilet, sink, and mirror. The walls are made of beige tiles and the floor is made of wood. There is a shower in the corner of the room."}, "90040": {"image_id": 90040, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.19711142525707728, "Bleu_3": 0.11997212723629987, "Bleu_4": 1.4074957768979279e-05, "METEOR": 0.23889585727859003, "ROUGE_L": 0.24069446271208733, "CIDEr": 9.396885745509665e-09, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.125, "f": 0.15789473684210525, "fn": 21.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.375, "f": 0.42857142857142855, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "This image shows a riverbank with several boats docked at the shore. There are buildings on the other side of the river, and a person is standing on the shore looking out at the boats. The sky is cloudy and there are some trees in the background."}, "409646": {"image_id": 409646, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.13231937691727144, "Bleu_3": 0.06912848008424652, "Bleu_4": 8.92774794149235e-06, "METEOR": 0.18520475438654943, "ROUGE_L": 0.2127164942461932, "CIDEr": 9.93966361750827e-13, "SPICE": {"All": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 14.0, "numImages": 1.0, "fp": 12.0, "tp": 8.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.75, "re": 0.42857142857142855, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a black bear standing in the middle of a dirt road. The bear is looking directly at the camera, and its fur is shiny and smooth. The background is a green field with trees and bushes. The car window is open, and there is a person sitting in the driver's seat."}, "296383": {"image_id": 296383, "Bleu_1": 0.339622641503026, "Bleu_2": 0.2555622163811263, "Bleu_3": 0.15662032595896783, "Bleu_4": 1.6649208479626035e-05, "METEOR": 0.18732429597710776, "ROUGE_L": 0.28103661044837513, "CIDEr": 2.0304050000989327e-09, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.24, "f": 0.17391304347826086, "fn": 19.0, "numImages": 1.0, "fp": 38.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 16.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5555555555555556, "f": 0.3448275862068966, "fn": 4.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}}, "caption": "This is an image of a cell phone with a glowing light on the screen. The light is shining bright green and blue, and it appears to be coming from the phone's screen. The phone is sitting on a wooden floor, and there is a reflection of the light on the floor."}, "566672": {"image_id": 566672, "Bleu_1": 0.4210526315678671, "Bleu_2": 0.2822385621600037, "Bleu_3": 0.20685374951645563, "Bleu_4": 0.14996435224002086, "METEOR": 0.3161716274777968, "ROUGE_L": 0.37251908396946565, "CIDEr": 5.201330889992531e-05, "SPICE": {"All": {"pr": 0.1388888888888889, "re": 0.1724137931034483, "f": 0.15384615384615385, "fn": 24.0, "numImages": 1.0, "fp": 31.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3125, "re": 0.5, "f": 0.38461538461538464, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}}, "caption": "The image shows a baseball player in the batter's box, ready to hit the ball. The umpire is standing behind him, holding a baseball bat and wearing a white uniform. The crowd is cheering in the background."}, "202865": {"image_id": 202865, "Bleu_1": 0.3902439024295063, "Bleu_2": 0.24194335155767877, "Bleu_3": 0.11449528240744468, "Bleu_4": 1.40975873865915e-05, "METEOR": 0.20817197909563784, "ROUGE_L": 0.30049261083743845, "CIDEr": 7.611092839886218e-07, "SPICE": {"All": {"pr": 0.15625, "re": 0.1724137931034483, "f": 0.1639344262295082, "fn": 24.0, "numImages": 1.0, "fp": 27.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "A hand is holding a doughnut with a bite taken out of it. The doughnut has a glaze on top and is sprinkled with sugar. There is a piece of paper in the background with the words \"Doughnut\" written on it."}, "226805": {"image_id": 226805, "Bleu_1": 0.31034482758085613, "Bleu_2": 0.1952242881526263, "Bleu_3": 0.1108246975736063, "Bleu_4": 0.07053208849722335, "METEOR": 0.25238561882730237, "ROUGE_L": 0.27508455467869225, "CIDEr": 8.494265780864726e-13, "SPICE": {"All": {"pr": 0.12, "re": 0.10714285714285714, "f": 0.1132075471698113, "fn": 25.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a large, open living room with high ceilings and large windows. There are several couches and chairs arranged around the room, and a fireplace in the corner. The walls are painted white and there are several paintings on the walls. The floor is made of hardwood and there are several rugs scattered throughout the room."}, "235221": {"image_id": 235221, "Bleu_1": 0.387755102032903, "Bleu_2": 0.3113499245321993, "Bleu_3": 0.24350015231718203, "Bleu_4": 0.17517224006420834, "METEOR": 0.25081666854652473, "ROUGE_L": 0.32086499123319695, "CIDEr": 1.398711050180016e-07, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.36363636363636365, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a lightning storm in the background, with a clock tower in the foreground. The clock tower is illuminated by the lightning, and there are people standing on the sidewalk in front of it. The sky is dark and stormy, with clouds and lightning in the distance."}, "499402": {"image_id": 499402, "Bleu_1": 0.46153846152662725, "Bleu_2": 0.3655177681857001, "Bleu_3": 0.2212647199619898, "Bleu_4": 2.3421165563756408e-05, "METEOR": 0.2887642320489117, "ROUGE_L": 0.3287143956889915, "CIDEr": 7.347283271285644e-06, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.15625, "f": 0.21739130434782608, "fn": 27.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.4, "re": 0.14285714285714285, "f": 0.21052631578947364, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2727272727272727, "f": 0.3529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a view of the wing of an airplane from the inside, with the windows open and the sky visible through them. The plane is flying over a mountain range, with snow covered peaks in the background."}, "539557": {"image_id": 539557, "Bleu_1": 0.25423728813128416, "Bleu_2": 0.17516794979677439, "Bleu_3": 0.10249156970769513, "Bleu_4": 1.177522194601263e-05, "METEOR": 0.19872132109431953, "ROUGE_L": 0.23735408560311286, "CIDEr": 5.999843897288267e-16, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.23529411764705882, "f": 0.16666666666666666, "fn": 13.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.25, "f": 0.15384615384615383, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.21428571428571427, "re": 0.42857142857142855, "f": 0.2857142857142857, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a large ship with a purple and white hull, a white mast, and a white light on top of the mast. There are several birds flying in the sky above the ship. The sky is a light purple color with some clouds. The background is a city with tall buildings and a lighthouse in the distance."}, "109976": {"image_id": 109976, "Bleu_1": 0.37142857141795926, "Bleu_2": 0.313559129551974, "Bleu_3": 0.22841694424328834, "Bleu_4": 0.16520235814636053, "METEOR": 0.31319349883414965, "ROUGE_L": 0.3951417004048583, "CIDEr": 0.00016387120884795526, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.2692307692307692, "f": 0.27999999999999997, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is a kitchen with white cabinets and a white refrigerator. There is a stove and an oven on the countertop. The floor is made of tile and there is a microwave on the countertop."}, "210448": {"image_id": 210448, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.14280110945625535, "Bleu_3": 0.07466017915299245, "Bleu_4": 9.649536682952496e-06, "METEOR": 0.18860444693761202, "ROUGE_L": 0.25553560742070613, "CIDEr": 6.117522742284648e-11, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.2777777777777778, "f": 0.27027027027027023, "fn": 13.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.2, "f": 0.33333333333333337, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a group of zebras standing in a enclosure made of wood and metal bars. They are all looking at each other and appear to be in good health. There is a small pond in the background with some plants growing around it. The sky is clear and sunny."}, "32724": {"image_id": 32724, "Bleu_1": 0.20689655172057078, "Bleu_2": 0.18074256993548984, "Bleu_3": 0.13263687777342026, "Bleu_4": 0.0807063200389711, "METEOR": 0.24440699137878702, "ROUGE_L": 0.23908174692049275, "CIDEr": 7.153665953574309e-15, "SPICE": {"All": {"pr": 0.038461538461538464, "re": 0.037037037037037035, "f": 0.03773584905660377, "fn": 26.0, "numImages": 1.0, "fp": 25.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.07692307692307693, "f": 0.08695652173913043, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a group of giraffes running across a grassy plain. They are running in a line, with their long necks and legs stretched out in front of them. The sky is clear and blue, with a few clouds scattered across it. The landscape is flat and open, with no trees or other obstacles in the way."}, "277689": {"image_id": 277689, "Bleu_1": 0.5294117646903115, "Bleu_2": 0.35824886040522297, "Bleu_3": 0.15888145887773167, "Bleu_4": 1.896550847016865e-05, "METEOR": 0.3284834352015992, "ROUGE_L": 0.3664886515353805, "CIDEr": 0.006227037182480865, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.16, "f": 0.19047619047619052, "fn": 21.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1111111111111111, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a white wedding cake with red strawberries on top, sitting on a glass table with clear glasses and silverware. The background is a blue sky with palm trees in the distance."}, "167818": {"image_id": 167818, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.126168012373563, "Bleu_3": 0.06921800773739777, "Bleu_4": 9.165155901802696e-06, "METEOR": 0.15329463285931763, "ROUGE_L": 0.18944099378881987, "CIDEr": 5.523771049828919e-10, "SPICE": {"All": {"pr": 0.34615384615384615, "re": 0.45, "f": 0.3913043478260869, "fn": 11.0, "numImages": 1.0, "fp": 17.0, "tp": 9.0}, "Relation": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.6666666666666666, "f": 0.4705882352941177, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This is a desk with a computer, keyboard, mouse, and other office supplies. The desk is made of wood and has a white surface. There are windows on either side of the desk, providing natural light. The room is tidy and organized, with a chair in front of the desk."}, "445135": {"image_id": 445135, "Bleu_1": 0.5135135134996348, "Bleu_2": 0.413728378482538, "Bleu_3": 0.30844041305916664, "Bleu_4": 0.24239503819135857, "METEOR": 0.38171892105149297, "ROUGE_L": 0.4395265054040145, "CIDEr": 0.003202088318228643, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.14285714285714285, "f": 0.12121212121212122, "fn": 12.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.4, "f": 0.26666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a man holding a tennis racket and standing on a tennis court. He is wearing a black shirt and white shorts. The background is a green grassy field with a fence in the distance."}, "3145": {"image_id": 3145, "Bleu_1": 0.34042553190765057, "Bleu_2": 0.22760466886504874, "Bleu_3": 0.16636805405423472, "Bleu_4": 0.10114380404202028, "METEOR": 0.222819667415662, "ROUGE_L": 0.2749517063747585, "CIDEr": 7.462418122142756e-08, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.24242424242424243, "f": 0.2807017543859649, "fn": 25.0, "numImages": 1.0, "fp": 16.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.5, "re": 0.4166666666666667, "f": 0.45454545454545453, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "This is a living room with a couch, coffee table, and chairs. There is a window on the left side of the room and a door on the right side. The walls are painted green and there is a ceiling fan in the center of the room."}, "319127": {"image_id": 319127, "Bleu_1": 0.3928571428431123, "Bleu_2": 0.3191423692405037, "Bleu_3": 0.22735557714145974, "Bleu_4": 2.618449527145847e-05, "METEOR": 0.29905099785222783, "ROUGE_L": 0.37044534412955465, "CIDEr": 0.005046358427495668, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.12, "f": 0.11764705882352941, "fn": 22.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is a snowy scene with a few trees and a park bench in the foreground. The sky is cloudy and there are no people in the image."}, "380906": {"image_id": 380906, "Bleu_1": 0.20689655172057078, "Bleu_2": 0.134717557601255, "Bleu_3": 6.868893635096677e-07, "Bleu_4": 1.5580249967419038e-09, "METEOR": 0.1729904312292191, "ROUGE_L": 0.22834224598930483, "CIDEr": 2.2086354723989308e-13, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.25, "f": 0.36363636363636365, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is a picture of a bench on the beach with purple flowers on it. The bench is made of wood and has a backrest. The flowers are arranged in a vase on the bench. The background is a clear blue sky with white clouds. The beach is covered in sand and there are rocks in the distance."}, "524850": {"image_id": 524850, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.16695677422191285, "Bleu_3": 0.11170159251877246, "Bleu_4": 1.3749229838123655e-05, "METEOR": 0.17209704774740164, "ROUGE_L": 0.17304964539007092, "CIDEr": 1.7942885954929183e-06, "SPICE": {"All": {"pr": 0.3, "re": 0.3157894736842105, "f": 0.3076923076923077, "fn": 13.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.75, "f": 0.7058823529411765, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image shows a large airplane with passengers boarding and deplaning. There are several people standing around the plane, some of them are carrying luggage. The plane's engines are visible on the wing, and there are other airplanes in the background."}, "85926": {"image_id": 85926, "Bleu_1": 0.26785714285235973, "Bleu_2": 0.13957263155725563, "Bleu_3": 0.07118725684669193, "Bleu_4": 9.08307135844184e-06, "METEOR": 0.18851619743979045, "ROUGE_L": 0.20378619153674835, "CIDEr": 1.1385035026267153e-12, "SPICE": {"All": {"pr": 0.25, "re": 0.22727272727272727, "f": 0.23809523809523808, "fn": 17.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.125, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a mother bear and her cubs standing in a field of tall grass. The mother bear is looking down at her cubs while they are eating something from the ground. The cubs are small and cute, with their fur still growing in. The background is a vast expanse of green grass and trees."}, "102355": {"image_id": 102355, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.10635890745081387, "Bleu_3": 6.093393760732184e-07, "Bleu_4": 1.465869850942177e-09, "METEOR": 0.14789915966386552, "ROUGE_L": 0.22048192771084338, "CIDEr": 1.938415438870096e-10, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.17391304347826086, "f": 0.22857142857142854, "fn": 19.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a group of people walking down a dirt road in front of a small house with a red roof. The people are walking behind a horse and cart, which is pulling a load of hay. The sky is cloudy and there are trees on either side of the road."}, "47112": {"image_id": 47112, "Bleu_1": 0.3809523809433107, "Bleu_2": 0.28917761562015887, "Bleu_3": 0.18441526604132946, "Bleu_4": 0.1126111776817302, "METEOR": 0.2504597469527088, "ROUGE_L": 0.2812911725955204, "CIDEr": 6.725944140453775e-06, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.10714285714285714, "f": 0.15384615384615383, "fn": 25.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.07142857142857142, "f": 0.11764705882352941, "fn": 13.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "There is a plate of pizza on the table with a glass of wine next to it. The pizza has various toppings such as mushrooms, pepperoni, and cheese. The table has a white tablecloth and there are two chairs at the table."}, "215709": {"image_id": 215709, "Bleu_1": 0.25641025640368187, "Bleu_2": 0.1836795895878896, "Bleu_3": 0.13985578774299565, "Bleu_4": 0.11103047724285477, "METEOR": 0.2201977516609954, "ROUGE_L": 0.24148851939825808, "CIDEr": 3.122523939422052e-06, "SPICE": {"All": {"pr": 0.2, "re": 0.20833333333333334, "f": 0.20408163265306126, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This is a bathroom with a sink, toilet, and shower. The walls are made of wood and there are tiles on the floor. There is a wooden bench in front of the sink and a mirror on the wall."}, "512982": {"image_id": 512982, "Bleu_1": 0.45161290321123837, "Bleu_2": 0.3470304129597038, "Bleu_3": 0.23182100110091095, "Bleu_4": 2.5827066150064015e-05, "METEOR": 0.2769136713104802, "ROUGE_L": 0.37621145374449333, "CIDEr": 0.0032013171442866776, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.14285714285714285, "f": 0.17391304347826086, "fn": 24.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.2727272727272727, "f": 0.3157894736842105, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is a bathroom with a sink, toilet, and shower. The walls are painted yellow and there is a window with curtains. There is a vase with flowers on the counter."}, "344633": {"image_id": 344633, "Bleu_1": 0.19148936169805347, "Bleu_2": 2.0402970888419055e-09, "Bleu_3": 4.522633916831483e-12, "Bleu_4": 2.1413142511476844e-13, "METEOR": 0.2190074767218837, "ROUGE_L": 0.15651058370750479, "CIDEr": 1.0673014676708368e-09, "SPICE": {"All": {"pr": 0.21875, "re": 0.2692307692307692, "f": 0.2413793103448276, "fn": 19.0, "numImages": 1.0, "fp": 25.0, "tp": 7.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.35294117647058826, "re": 0.5, "f": 0.41379310344827586, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}}, "caption": "The image shows two horses in a corral, one of which is being ridden by a person wearing a helmet and riding boots. The other horse is standing nearby, looking at the person riding. The corral is surrounded by trees and there are fences in the background."}, "555942": {"image_id": 555942, "Bleu_1": 0.21311475409486702, "Bleu_2": 0.14598450400344384, "Bleu_3": 0.10271351385205257, "Bleu_4": 0.07818459495876035, "METEOR": 0.26219531813196256, "ROUGE_L": 0.22652519893899206, "CIDEr": 4.998305816615751e-17, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.20833333333333334, "f": 0.1694915254237288, "fn": 19.0, "numImages": 1.0, "fp": 30.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.4, "f": 0.32, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A group of motorcycles parked on the side of a street. The bikes are green and have a vintage look to them. There are also other bikes parked nearby, some of which are also green. The scene is set in a city with tall buildings and cars passing by in the background.\""}, "471567": {"image_id": 471567, "Bleu_1": 0.30769230768441824, "Bleu_2": 0.22041550750546754, "Bleu_3": 0.10950337957304696, "Bleu_4": 1.3819585494461291e-05, "METEOR": 0.18806516645484778, "ROUGE_L": 0.3381843381843382, "CIDEr": 1.3576629591895789e-05, "SPICE": {"All": {"pr": 0.25, "re": 0.11764705882352941, "f": 0.15999999999999998, "fn": 15.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image shows a giraffe standing in a fenced enclosure with a wooden fence and trees in the background. The giraffe has a long neck and spotted fur, and is looking directly at the camera with its large eyes."}, "24260": {"image_id": 24260, "Bleu_1": 0.3142857142767348, "Bleu_2": 0.16652655174285833, "Bleu_3": 0.11889429373840883, "Bleu_4": 0.08513012360629148, "METEOR": 0.16507189051692442, "ROUGE_L": 0.21554770318021202, "CIDEr": 0.0046105438818191576, "SPICE": {"All": {"pr": 0.25, "re": 0.3684210526315789, "f": 0.2978723404255319, "fn": 12.0, "numImages": 1.0, "fp": 21.0, "tp": 7.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.4, "f": 0.2857142857142857, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows two horses standing in a field with people watching them. One of the horses is white and brown, while the other is brown and white. They are both wearing saddles and bridles."}, "106508": {"image_id": 106508, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.14531393175596577, "Bleu_3": 7.502652544655378e-07, "Bleu_4": 1.7134131896259546e-09, "METEOR": 0.22352745775579372, "ROUGE_L": 0.2771467514766015, "CIDEr": 1.582705645749188e-10, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.75, "f": 0.75, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 6.0}}, "caption": "The image shows a traffic police officer standing on the side of the road, directing traffic. There are several cars and buses passing by in the background. The officer is wearing a yellow vest and holding a stop sign. The sky is clear and there are trees and buildings in the background."}, "311082": {"image_id": 311082, "Bleu_1": 0.1999999999966667, "Bleu_2": 0.11644450194595923, "Bleu_3": 0.061603207790807316, "Bleu_4": 8.0026492316705e-06, "METEOR": 0.2520294953560997, "ROUGE_L": 0.22736954206602766, "CIDEr": 1.1191695812086007e-15, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.17857142857142858, "f": 0.18181818181818182, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.36363636363636365, "f": 0.34782608695652173, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows two elephants standing on the dirt path, looking at each other. One elephant is standing on the left side of the path, while the other is standing on the right side. They are both wearing green and brown robes, and their trunks are curled up. The background is a green and brown jungle with trees and plants."}, "312167": {"image_id": 312167, "Bleu_1": 0.17741935483584811, "Bleu_2": 0.12059257882752877, "Bleu_3": 0.07855490421664953, "Bleu_4": 9.520658216783467e-06, "METEOR": 0.16750086811966935, "ROUGE_L": 0.22147302904564312, "CIDEr": 1.3128525087196393e-16, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.35, "f": 0.3414634146341463, "fn": 13.0, "numImages": 1.0, "fp": 14.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5555555555555556, "f": 0.5263157894736842, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "This is a painting of a pink flower in a vase on a table. The flower has long, thin stems and delicate, pink petals. The vase is red and has a smooth, glossy finish. The table is made of wood and has a smooth, glossy finish. The background is a soft, blurred image of a room with a window and a door."}, "324937": {"image_id": 324937, "Bleu_1": 0.7499999999531252, "Bleu_2": 0.6708203932066132, "Bleu_3": 0.577757035627622, "Bleu_4": 0.4935578819637505, "METEOR": 0.41909558280567527, "ROUGE_L": 0.7223684210526317, "CIDEr": 1.433079006163337, "SPICE": {"All": {"pr": 0.1, "re": 0.15384615384615385, "f": 0.12121212121212123, "fn": 22.0, "numImages": 1.0, "fp": 36.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.36363636363636365, "f": 0.27586206896551724, "fn": 7.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}}, "caption": "A small white dog is laying on top of a couch, looking up at the camera."}, "65415": {"image_id": 65415, "Bleu_1": 0.35897435896515456, "Bleu_2": 0.21733262130578967, "Bleu_3": 1.0847992362433127e-06, "Bleu_4": 2.4402616953280328e-09, "METEOR": 0.23083341837094457, "ROUGE_L": 0.2347959969207082, "CIDEr": 2.273329620472656e-06, "SPICE": {"All": {"pr": 0.5, "re": 0.09523809523809523, "f": 0.16, "fn": 19.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}}, "caption": "This is a woman skiing down a snowy slope. She is wearing a red jacket and black pants, and has skis on her feet. The snow is covered in trees and there are several other skiers in the background."}, "201925": {"image_id": 201925, "Bleu_1": 0.4242424242295685, "Bleu_2": 0.282038037400203, "Bleu_3": 0.13690455291617346, "Bleu_4": 1.710145668798399e-05, "METEOR": 0.19770690282250764, "ROUGE_L": 0.32129420617005267, "CIDEr": 0.0021560758776237705, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.25, "f": 0.24000000000000002, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.2727272727272727, "f": 0.2608695652173913, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a cake baking in an oven. The cake is covered in flour and has a fork sticking out of it. There is a bowl of flour next to the oven."}, "273132": {"image_id": 273132, "Bleu_1": 0.4324324324207451, "Bleu_2": 0.28997255745928074, "Bleu_3": 0.19316228581877343, "Bleu_4": 0.14349260557576346, "METEOR": 0.349079646125722, "ROUGE_L": 0.36941710825132484, "CIDEr": 8.367363191782014e-05, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.14814814814814814, "f": 0.14035087719298248, "fn": 23.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.21428571428571427, "re": 0.25, "f": 0.23076923076923075, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "This is an image of an older woman sitting on a bench in a park. She is wearing a hat and sunglasses, and has a cigarette in her hand. The background is a fence and some trees."}, "475238": {"image_id": 475238, "Bleu_1": 0.19298245613696527, "Bleu_2": 0.15531518604659977, "Bleu_3": 7.597809220834375e-07, "Bleu_4": 1.6881764916028373e-09, "METEOR": 0.18682896779187994, "ROUGE_L": 0.2136602451838879, "CIDEr": 9.182100028881605e-14, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.24, "f": 0.23529411764705882, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "This is an image of a train traveling down the tracks. The train is made up of several cars, including a caboose and a locomotive. The train is traveling through a rural area with fields and trees on either side of the tracks. There are also several people standing on the platform, watching the train go by."}, "130527": {"image_id": 130527, "Bleu_1": 0.23809523808956923, "Bleu_2": 0.15240998561606448, "Bleu_3": 0.08343000781860355, "Bleu_4": 1.104652199055032e-05, "METEOR": 0.1722194721369903, "ROUGE_L": 0.22197962154294032, "CIDEr": 8.514739191993113e-07, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.4117647058823529, "f": 0.34146341463414637, "fn": 10.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.7142857142857143, "f": 0.5555555555555556, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a green field with cows grazing in it. In the background, there is a mountain range with blue sky and clouds. The image is taken from a car window, with the road running along the side of the field."}, "337563": {"image_id": 337563, "Bleu_1": 0.2352941176401385, "Bleu_2": 0.11941628680174102, "Bleu_3": 7.638223859874093e-07, "Bleu_4": 1.947169971344997e-09, "METEOR": 0.1888860681225535, "ROUGE_L": 0.20783645655877342, "CIDEr": 0.00010677224362664247, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.14285714285714285, "f": 0.18749999999999997, "fn": 18.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The woman is sitting on the bed holding a banana in her hand. The child is sitting on the bed next to her, also holding a banana. They are both smiling at each other."}, "135356": {"image_id": 135356, "Bleu_1": 0.2758620689560048, "Bleu_2": 0.19851666678721847, "Bleu_3": 0.113434038700165, "Bleu_4": 1.539267887805166e-05, "METEOR": 0.2512688262555853, "ROUGE_L": 0.34186437511675694, "CIDEr": 0.002152169493977593, "SPICE": {"All": {"pr": 0.4, "re": 0.35294117647058826, "f": 0.37500000000000006, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.6666666666666666, "f": 0.36363636363636365, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.125, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a man standing in a kitchen, holding a sink sponge and looking at something on the counter. There is a stove and refrigerator in the background."}, "290078": {"image_id": 290078, "Bleu_1": 0.4210526315678671, "Bleu_2": 0.3538047616718271, "Bleu_3": 0.2898061709193232, "Bleu_4": 0.21371943833955645, "METEOR": 0.3579780746557416, "ROUGE_L": 0.44138929088277856, "CIDEr": 4.17863655551082e-05, "SPICE": {"All": {"pr": 0.07317073170731707, "re": 0.12, "f": 0.0909090909090909, "fn": 22.0, "numImages": 1.0, "fp": 38.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 18.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.17647058823529413, "re": 0.375, "f": 0.24, "fn": 5.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}}, "caption": "This is an image of a toilet sitting on the side of a street. The toilet is white and has a small sink next to it. There is a building in the background with windows and a door."}, "578314": {"image_id": 578314, "Bleu_1": 0.28947368420290864, "Bleu_2": 0.15320195579385062, "Bleu_3": 8.671123520251266e-07, "Bleu_4": 2.0774927578554473e-09, "METEOR": 0.23575580786341366, "ROUGE_L": 0.19709208400646203, "CIDEr": 6.794159443454977e-06, "SPICE": {"All": {"pr": 0.25, "re": 0.17857142857142858, "f": 0.20833333333333331, "fn": 23.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4166666666666667, "f": 0.45454545454545453, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "This is a bathroom with a toilet and sink in it. The walls are white and the floor is made of tile. There is a window on the left side of the room that lets in natural light."}, "174893": {"image_id": 174893, "Bleu_1": 0.3214285714170919, "Bleu_2": 0.18898223649773932, "Bleu_3": 1.111619628811885e-06, "Bleu_4": 2.7225894229667797e-09, "METEOR": 0.24555093129624977, "ROUGE_L": 0.28773584905660377, "CIDEr": 0.010989384271898094, "SPICE": {"All": {"pr": 0.1935483870967742, "re": 0.3157894736842105, "f": 0.24000000000000002, "fn": 13.0, "numImages": 1.0, "fp": 25.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.35294117647058826, "re": 0.75, "f": 0.48, "fn": 2.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}}, "caption": "The little girl is sitting at a table with a pile of paper cut outs in front of her. She is using scissors to cut out the shapes."}, "539310": {"image_id": 539310, "Bleu_1": 0.5263157894459835, "Bleu_2": 0.34199278400988514, "Bleu_3": 0.23962841757505407, "Bleu_4": 0.17124730447964, "METEOR": 0.22390179685867584, "ROUGE_L": 0.40627973358706, "CIDEr": 0.4208871810086167, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.18181818181818182, "f": 0.19999999999999998, "fn": 18.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a street with cars parked on both sides. There are trees and buildings in the background."}, "49740": {"image_id": 49740, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.12399138853119372, "Bleu_3": 0.0839337382802947, "Bleu_4": 0.05835255555224193, "METEOR": 0.1981444523944461, "ROUGE_L": 0.21863799283154117, "CIDEr": 3.97289900185401e-12, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.24, "f": 0.24999999999999994, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "This is an image of a baseball player swinging a bat at a ball that is being thrown by a catcher. The player is wearing a white jersey with red and black stripes, and the catcher is wearing a black and white jersey. The background is a green field with trees in the distance."}, "274549": {"image_id": 274549, "Bleu_1": 0.46874999998535166, "Bleu_2": 0.2749633406563063, "Bleu_3": 0.17145603544752394, "Bleu_4": 0.11481934989105834, "METEOR": 0.26761018133166087, "ROUGE_L": 0.2713523131672598, "CIDEr": 0.000976856717474825, "SPICE": {"All": {"pr": 0.6666666666666666, "re": 0.2222222222222222, "f": 0.3333333333333333, "fn": 21.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 1.0, "re": 0.18181818181818182, "f": 0.3076923076923077, "fn": 9.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.4, "f": 0.5714285714285715, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 4.0}}, "caption": "This is an image of a person skiing down a snowy slope. The person is wearing a backpack and carrying skis. There are trees in the background and the sky is cloudy."}, "537211": {"image_id": 537211, "Bleu_1": 0.38095238093424044, "Bleu_2": 0.30860669990912093, "Bleu_3": 0.24682706829042084, "Bleu_4": 0.2021780303629901, "METEOR": 0.40467155819359824, "ROUGE_L": 0.5514124293785311, "CIDEr": 0.3889208487803641, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.21052631578947367, "f": 0.2, "fn": 15.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The man is sitting on the dock, eating a hot dog. The skyline of the city is visible in the background."}, "533743": {"image_id": 533743, "Bleu_1": 0.1935483870936525, "Bleu_2": 0.11265743434913567, "Bleu_3": 0.05958306238165251, "Bleu_4": 7.738006901000367e-06, "METEOR": 0.1889326142217684, "ROUGE_L": 0.18807810894141827, "CIDEr": 1.4672840327438064e-17, "SPICE": {"All": {"pr": 0.23333333333333334, "re": 0.3888888888888889, "f": 0.2916666666666667, "fn": 11.0, "numImages": 1.0, "fp": 23.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.2857142857142857, "f": 0.19047619047619047, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3125, "re": 0.625, "f": 0.4166666666666667, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}}, "caption": "The image shows a man standing in front of a television playing a video game with a controller in his hand. There are other people in the room, some of them sitting on the couch and others standing around the television. The room appears to be a living room with a large window on one side and a door on the other."}, "81812": {"image_id": 81812, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.20982172726164103, "Bleu_3": 0.16176672459792843, "Bleu_4": 0.13498619260852726, "METEOR": 0.26639362095259145, "ROUGE_L": 0.29151732377538825, "CIDEr": 6.159757975811184e-13, "SPICE": {"All": {"pr": 0.14705882352941177, "re": 0.23809523809523808, "f": 0.18181818181818185, "fn": 16.0, "numImages": 1.0, "fp": 29.0, "tp": 5.0}, "Relation": {"pr": 0.06666666666666667, "re": 0.14285714285714285, "f": 0.09090909090909091, "fn": 6.0, "numImages": 1.0, "fp": 14.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a group of people sitting around a table in a restaurant, with plates of food in front of them. One person is holding up a plate of pasta, while another person is pouring wine into glasses. There are candles on the table and a view of the city outside the window."}, "59743": {"image_id": 59743, "Bleu_1": 0.2972972972892623, "Bleu_2": 0.1817499189304432, "Bleu_3": 0.09809046705543314, "Bleu_4": 1.2907744865533497e-05, "METEOR": 0.20658277600506972, "ROUGE_L": 0.20115416323165708, "CIDEr": 1.3451524969211091e-05, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.16, "f": 0.1095890410958904, "fn": 21.0, "numImages": 1.0, "fp": 44.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 19.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.21052631578947367, "re": 0.36363636363636365, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}}, "caption": "The image shows a group of people surfing in the ocean. They are standing on their surfboards in the water, with the waves crashing against them. The sky is cloudy and there is a light rain falling."}, "356131": {"image_id": 356131, "Bleu_1": 0.35897435896515456, "Bleu_2": 0.19438820598718592, "Bleu_3": 0.1007038404331726, "Bleu_4": 1.2978033761735104e-05, "METEOR": 0.21304911179002547, "ROUGE_L": 0.2683677958644963, "CIDEr": 0.0025652992489695724, "SPICE": {"All": {"pr": 0.4444444444444444, "re": 0.14814814814814814, "f": 0.2222222222222222, "fn": 23.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.36363636363636365, "f": 0.4705882352941177, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "A small boat is sailing on the water with a person sitting in it. The person is wearing a hat and has their arms around the boat. The sky is cloudy and there are some trees in the background."}, "311310": {"image_id": 311310, "Bleu_1": 0.4705882352802769, "Bleu_2": 0.26702293490930384, "Bleu_3": 0.1306117907571673, "Bleu_4": 1.6373682487936863e-05, "METEOR": 0.2221602339795061, "ROUGE_L": 0.25979557069846676, "CIDEr": 0.0004122715015896009, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 18.0, "numImages": 1.0, "fp": 30.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "The image shows a group of people flying kites in a park. They are standing on a grassy field with trees in the background. The sky is clear and blue with a few clouds."}, "165257": {"image_id": 165257, "Bleu_1": 0.21999999999560005, "Bleu_2": 0.13401187884939042, "Bleu_3": 0.07205793047605258, "Bleu_4": 9.44575929237223e-06, "METEOR": 0.17773754865946997, "ROUGE_L": 0.29647630619684084, "CIDEr": 3.087065123079183e-10, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.037037037037037035, "f": 0.05128205128205128, "fn": 26.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}}, "caption": "This image shows a kitchen with wooden floors and cabinets. There is a sink and stove in the center of the room, and a refrigerator and microwave on the wall. The countertops are made of black granite, and there are several windows in the room that let in natural light."}, "202658": {"image_id": 202658, "Bleu_1": 0.28205128204405006, "Bleu_2": 0.14922200399597868, "Bleu_3": 8.442829210502149e-07, "Bleu_4": 2.0220429578334317e-09, "METEOR": 0.15246936966244484, "ROUGE_L": 0.2347959969207082, "CIDEr": 3.5696402904658757e-06, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.26666666666666666, "f": 0.2105263157894737, "fn": 11.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.75, "f": 0.4285714285714285, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is an image of a toilet in a bathroom. The toilet is pink and has a cartoon character on it. There is a sink next to the toilet and a trash can in the corner of the room."}, "50926": {"image_id": 50926, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.23008949664965453, "Bleu_3": 0.16288677812592836, "Bleu_4": 0.0974101171137652, "METEOR": 0.2321125762789453, "ROUGE_L": 0.26116207951070336, "CIDEr": 2.5732560574489526e-11, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.15384615384615385, "f": 0.16326530612244897, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of people standing in front of a large, empty field with mountains in the background. One person is holding a kite and another is holding a camera. There are several people standing in the background, looking on as the person in the foreground flies the kite."}, "514797": {"image_id": 514797, "Bleu_1": 0.31818181817458685, "Bleu_2": 0.1489923873895453, "Bleu_3": 8.085240745765992e-07, "Bleu_4": 1.8948452736055547e-09, "METEOR": 0.15823449209416193, "ROUGE_L": 0.20890410958904113, "CIDEr": 3.5948866821223135e-08, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.09375, "f": 0.11320754716981132, "fn": 29.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.08333333333333333, "f": 0.1111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "A group of people are standing on the beach, looking up at a kite flying in the sky. The kite has a blue and white design with a red tail. The people are wearing casual clothing and sunglasses. The sky is clear and sunny."}, "258021": {"image_id": 258021, "Bleu_1": 0.23076923076568048, "Bleu_2": 0.13427153888031182, "Bleu_3": 0.08302695801717525, "Bleu_4": 9.80203891484625e-06, "METEOR": 0.1726656796546068, "ROUGE_L": 0.1857302344463615, "CIDEr": 1.0449113809623927e-18, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.05263157894736842, "f": 0.06060606060606061, "fn": 18.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image shows a man standing on the sidewalk next to a parked motorcycle. The man is wearing a black jacket and pants, and has a backpack slung over his shoulder. The sidewalk is wet from rain, and there are puddles of water on the ground. The building in the background appears to be a large, modern structure with large windows and a flat roof."}, "203085": {"image_id": 203085, "Bleu_1": 0.24590163934023115, "Bleu_2": 0.16937687147073976, "Bleu_3": 0.09907454029581565, "Bleu_4": 0.0639903596428197, "METEOR": 0.22632184442060072, "ROUGE_L": 0.24574478799476282, "CIDEr": 3.0307068209057565e-14, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.045454545454545456, "f": 0.060606060606060615, "fn": 21.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "This is a man sitting at a desk in a room. He is wearing a white shirt and blue pants. There is a computer monitor on the desk in front of him. There are several other items on the desk, including a keyboard, a mouse, and a cup of coffee. The walls of the room are painted a light blue color."}, "441442": {"image_id": 441442, "Bleu_1": 0.27906976743537054, "Bleu_2": 0.14118624159718107, "Bleu_3": 7.863217694465758e-07, "Bleu_4": 1.867175871883868e-09, "METEOR": 0.19529409972063969, "ROUGE_L": 0.21801286633309508, "CIDEr": 1.9420100110734704e-07, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.125, "f": 0.16, "fn": 28.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3333333333333333, "f": 0.380952380952381, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a horse and rider in a field with a fence in the background. The horse is brown and has a saddle on its back. The rider is wearing a helmet and riding boots. The image is in black and white."}, "494759": {"image_id": 494759, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.19711142525707728, "Bleu_3": 0.15115540850568024, "Bleu_4": 0.11193401922301613, "METEOR": 0.2987527943677332, "ROUGE_L": 0.3552741055745586, "CIDEr": 6.274484533357171e-09, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.16666666666666666, "f": 0.1904761904761905, "fn": 20.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows two people standing on a beach with a kite flying in the sky. The person on the left is holding the kite and the person on the right is looking at it. The sky is cloudy and there are some clouds in the background."}, "336937": {"image_id": 336937, "Bleu_1": 0.23333333332944448, "Bleu_2": 0.10892385771382775, "Bleu_3": 0.05892134857092115, "Bleu_4": 7.739907933723665e-06, "METEOR": 0.15707496804910198, "ROUGE_L": 0.2046979865771812, "CIDEr": 2.6965584592219327e-16, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 21.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.42857142857142855, "f": 0.27272727272727276, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "This image shows a large group of white ceramic sinks arranged in rows, with some of them having water running out of them. The sinks are arranged in a row, with some of them having water running out of them. The image appears to be in a large public restroom or bathroom, with many sinks lined up in a row."}, "157155": {"image_id": 157155, "Bleu_1": 0.4705882352802769, "Bleu_2": 0.20683507599183215, "Bleu_3": 1.1016225079815204e-06, "Bleu_4": 2.5626197980885998e-09, "METEOR": 0.20398765817995526, "ROUGE_L": 0.27031019202363366, "CIDEr": 0.0021665030091422835, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.23809523809523808, "f": 0.19607843137254902, "fn": 16.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.625, "f": 0.4761904761904762, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "This is a photograph of a street scene at night. There are several people walking down the street, some of them on horseback. The buildings in the background are lit up with Christmas lights."}, "243600": {"image_id": 243600, "Bleu_1": 0.4666666666511112, "Bleu_2": 0.2537081316938597, "Bleu_3": 1.3197861940352348e-06, "Bleu_4": 3.0376430894125655e-09, "METEOR": 0.22240481020694827, "ROUGE_L": 0.3096446700507614, "CIDEr": 0.006830007075889088, "SPICE": {"All": {"pr": 0.4666666666666667, "re": 0.25925925925925924, "f": 0.33333333333333337, "fn": 20.0, "numImages": 1.0, "fp": 8.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.45454545454545453, "f": 0.5555555555555556, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "This is an image of a library with several people sitting at tables reading books. There are bookshelves on the walls and a fireplace in the corner of the room."}, "542147": {"image_id": 542147, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.1624659147420524, "Bleu_3": 8.081987454730765e-07, "Bleu_4": 1.8117138691105226e-09, "METEOR": 0.23742572892610642, "ROUGE_L": 0.21580188679245285, "CIDEr": 2.7542934209919385e-11, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.21052631578947367, "f": 0.23529411764705882, "fn": 15.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a large, open field with several cows grazing in it. In the background, there is a large building with windows and a roof. The building appears to be under construction, with scaffolding and construction equipment visible. The sky is clear and blue, with a few clouds scattered across it."}, "277227": {"image_id": 277227, "Bleu_1": 0.2666666666607408, "Bleu_2": 0.13483997248961796, "Bleu_3": 0.07505672632527667, "Bleu_4": 1.00168204947809e-05, "METEOR": 0.17517257554638763, "ROUGE_L": 0.2053872053872054, "CIDEr": 1.3007850840846879e-08, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.18181818181818182, "f": 0.14285714285714285, "fn": 18.0, "numImages": 1.0, "fp": 30.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.375, "f": 0.26086956521739135, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "This is a photograph of a small boat docked in a harbor. The boat is white and has a blue hull. There are several other boats docked nearby, some of which are also white and blue. The background is made up of buildings and streets."}, "323552": {"image_id": 323552, "Bleu_1": 0.5357142856951531, "Bleu_2": 0.34503277965862633, "Bleu_3": 0.2092148242246677, "Bleu_4": 2.4601372575997534e-05, "METEOR": 0.285378823165227, "ROUGE_L": 0.3824451410658307, "CIDEr": 0.04710841400107763, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 12.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A young woman sits on the floor next to a luggage carousel at an airport, looking at her phone.\""}, "319607": {"image_id": 319607, "Bleu_1": 0.4999999999833334, "Bleu_2": 0.3216337604404325, "Bleu_3": 0.15459249573783163, "Bleu_4": 1.923314763603185e-05, "METEOR": 0.23601557364280928, "ROUGE_L": 0.3523102310231023, "CIDEr": 0.025029531834834605, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.15789473684210525, "f": 0.16666666666666669, "fn": 16.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "This is an image of a street with a red light at the intersection. There are buildings on either side of the street, and people are walking on the sidewalk."}, "581702": {"image_id": 581702, "Bleu_1": 0.39393939392745647, "Bleu_2": 0.31382295722076564, "Bleu_3": 0.2120197545075465, "Bleu_4": 0.15876670465963394, "METEOR": 0.3153714053664483, "ROUGE_L": 0.3288409703504044, "CIDEr": 0.0011969937242422, "SPICE": {"All": {"pr": 0.15, "re": 0.13636363636363635, "f": 0.14285714285714282, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a small bird perched on a rock in a garden. The bird has a red head and black and white feathers. It is looking down at something on the ground."}, "328818": {"image_id": 328818, "Bleu_1": 0.1999999999966667, "Bleu_2": 0.1646773939157558, "Bleu_3": 0.13272008788175763, "Bleu_4": 0.10532078688575773, "METEOR": 0.24810997007955743, "ROUGE_L": 0.3043912175648702, "CIDEr": 3.832234571758405e-14, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA woman is sitting on a bench next to a bike rack in the woods. She is wearing pink pants and a white shirt, and has her bicycle next to her. The bench is made of wood and has a green metal railing. There are trees and bushes in the background."}, "55981": {"image_id": 55981, "Bleu_1": 0.16666666666468255, "Bleu_2": 0.08962214298857081, "Bleu_3": 4.609695786508341e-07, "Bleu_4": 1.048655754351178e-09, "METEOR": 0.17580069935994352, "ROUGE_L": 0.14454976303317535, "CIDEr": 4.6762020716701864e-32, "SPICE": {"All": {"pr": 0.125, "re": 0.08, "f": 0.09756097560975609, "fn": 23.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The little girl is standing in front of a staircase, holding a suitcase in her hand. She is wearing a pink sweater and blue jeans, and has a pink scarf around her neck. The staircase is made of wood and has a blue carpet on it. There are windows on either side of the staircase, and a door at the top of the stairs. The girl is looking up at the door, as if she is waiting for someone to come out of it."}, "385918": {"image_id": 385918, "Bleu_1": 0.36956521738327036, "Bleu_2": 0.23976639193762495, "Bleu_3": 0.1576697569115985, "Bleu_4": 0.09771116348684672, "METEOR": 0.2448412465237173, "ROUGE_L": 0.28968792401628224, "CIDEr": 5.810726330372326e-08, "SPICE": {"All": {"pr": 0.0625, "re": 0.1111111111111111, "f": 0.08, "fn": 16.0, "numImages": 1.0, "fp": 30.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.2857142857142857, "f": 0.19047619047619047, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "The image shows a group of people playing frisbee on a field. One person is throwing the frisbee while another person is catching it. There are several other people in the background watching the game. The sky is clear and there are trees in the background."}, "86625": {"image_id": 86625, "Bleu_1": 0.25423728813128416, "Bleu_2": 0.19862178549913379, "Bleu_3": 0.16073485125453693, "Bleu_4": 0.13123525835991323, "METEOR": 0.26599269758384414, "ROUGE_L": 0.2712618121178432, "CIDEr": 2.990568403054464e-15, "SPICE": {"All": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This is a man standing in front of a refrigerator with a container of food on the counter. He is wearing a black hoodie and has his hands in his pockets. The refrigerator has a shelf with various food items on it, including jars of sauce and condiments. The man is looking down at the food on the shelf."}, "87429": {"image_id": 87429, "Bleu_1": 0.056680161943090376, "Bleu_2": 0.02629109140199487, "Bleu_3": 0.014130267445860338, "Bleu_4": 1.8440187380291822e-06, "METEOR": 0.07443383369565626, "ROUGE_L": 0.0817572598659717, "CIDEr": 0.0, "SPICE": {"All": {"pr": 0.06060606060606061, "re": 0.10526315789473684, "f": 0.07692307692307693, "fn": 17.0, "numImages": 1.0, "fp": 31.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}}, "caption": "The image shows a large brick building with several cars parked in front of it. There are also several trees and a few people walking on the sidewalk. The sky is cloudy and there are some clouds in the background.\n\nThe building appears to be an old hospital or institution, with many windows and a large clock tower on top. There are also several cars parked in front of the building, including a white van and a black car. The sidewalk is empty, but there are some trees and bushes nearby. The sky is cloudy and there are some clouds in the background.\n\nThe image is quite dark, with the only light coming from the sun peeking through the clouds. The building is quite large and imposing, with many windows and a clock tower on top. There are also several cars parked in front of the building, including a white van and a black car. The sidewalk is empty, but there are some trees and bushes nearby. The sky is cloudy and there are some clouds in the background.\n\nThe image is quite dark, with the only light coming from the sun peeking through the clouds. The building is quite large and imposing, with many windows and a clock tower on top. There are also several cars parked in front of the building, including a white van and a black car. The sidewalk is empty, but there are some trees and bushes nearby. The sky is cloud"}, "330091": {"image_id": 330091, "Bleu_1": 0.41071428570695157, "Bleu_2": 0.25924465704305294, "Bleu_3": 1.0756606703637384e-06, "Bleu_4": 2.201341899570718e-09, "METEOR": 0.2527701712059532, "ROUGE_L": 0.2978515625, "CIDEr": 5.271998995489172e-08, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.25, "f": 0.2545454545454545, "fn": 21.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.1111111111111111, "f": 0.09999999999999999, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.38461538461538464, "f": 0.41666666666666663, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "This is an image of a skier on a snowy slope. The skier is wearing a red and black jacket and has a snowboard under their feet. They are riding down the slope with their arms outstretched and their face covered in snow. The background is a mountain range with trees and snow on the ground."}, "491851": {"image_id": 491851, "Bleu_1": 0.47826086954442354, "Bleu_2": 0.32969023668323344, "Bleu_3": 0.1729806903297508, "Bleu_4": 2.255489037161007e-05, "METEOR": 0.25883432431227393, "ROUGE_L": 0.4240317775571003, "CIDEr": 0.14034042924161558, "SPICE": {"All": {"pr": 0.0625, "re": 0.1111111111111111, "f": 0.08, "fn": 16.0, "numImages": 1.0, "fp": 30.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.2857142857142857, "f": 0.19047619047619047, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "This is a cluttered room with a computer desk, chair, and other items. There is a window on the wall with blinds open."}, "203661": {"image_id": 203661, "Bleu_1": 0.26829268292028563, "Bleu_2": 0.16379642331674352, "Bleu_3": 0.12731761426913407, "Bleu_4": 0.08584608022925443, "METEOR": 0.2472063460278348, "ROUGE_L": 0.3165307635285397, "CIDEr": 5.373784168538274e-07, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.1724137931034483, "f": 0.22727272727272724, "fn": 24.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3333333333333333, "f": 0.380952380952381, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "This is a small kitchen with a wooden table and chairs. There is a stove and oven on the countertop, as well as a sink and refrigerator. The walls are painted white and there are some potted plants on the windowsill."}, "150875": {"image_id": 150875, "Bleu_1": 0.37499999998437505, "Bleu_2": 0.12768847960837637, "Bleu_3": 9.049548604494648e-07, "Bleu_4": 2.437335780312719e-09, "METEOR": 0.16346956169215587, "ROUGE_L": 0.27477477477477474, "CIDEr": 0.00903074977248461, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.14814814814814814, "f": 0.2, "fn": 23.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.2857142857142857, "f": 0.4, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.15384615384615385, "f": 0.2222222222222222, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "This is a bench made of stone with intricate carvings on it. It is located in a park with trees and flowers around it."}, "99707": {"image_id": 99707, "Bleu_1": 0.5769230769008876, "Bleu_2": 0.37210420375302744, "Bleu_3": 0.2586701938729775, "Bleu_4": 0.19696330877911467, "METEOR": 0.32814993368914, "ROUGE_L": 0.43839835728952764, "CIDEr": 0.07992985249053844, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.06451612903225806, "f": 0.09999999999999999, "fn": 29.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.1111111111111111, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.08333333333333333, "f": 0.125, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}}, "caption": "A person is standing in the snow wearing a purple jacket and holding a snowboard. The person is standing next to a sign that reads \"superstar\"."}, "124647": {"image_id": 124647, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.16816819849581244, "Bleu_3": 0.1041955676448189, "Bleu_4": 1.2326447028857738e-05, "METEOR": 0.200217756480535, "ROUGE_L": 0.2507045561296383, "CIDEr": 9.714397140955759e-11, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.23809523809523808, "f": 0.2777777777777778, "fn": 16.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.7142857142857143, "f": 0.588235294117647, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a young boy wearing a black helmet and standing next to a skateboard ramp. He is looking down at the ground with his hands on his hips. There are other people in the background, some of them skateboarding. The sky is cloudy and there are trees in the background."}, "62167": {"image_id": 62167, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.15339299776643633, "Bleu_3": 0.07830779525362613, "Bleu_4": 1.0001000249872884e-05, "METEOR": 0.1911577621823393, "ROUGE_L": 0.25553560742070613, "CIDEr": 5.381787940754611e-11, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.13333333333333333, "f": 0.0975609756097561, "fn": 13.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.09090909090909091, "re": 0.16666666666666666, "f": 0.11764705882352942, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows a man standing in a grassy field with his dog. The man is holding a leash and the dog is running around him. There are several other dogs in the background, running and playing in the field. The sky is cloudy and there are trees in the background."}, "300221": {"image_id": 300221, "Bleu_1": 0.36842105262188374, "Bleu_2": 0.17283511575720037, "Bleu_3": 9.396955198772326e-07, "Bleu_4": 2.206598690629072e-09, "METEOR": 0.19863575354820703, "ROUGE_L": 0.22659732540861813, "CIDEr": 7.095055929616128e-06, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.09523809523809523, "f": 0.12121212121212123, "fn": 19.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a display of fresh vegetables and fruits in wooden crates. There are carrots, beets, potatoes, and other vegetables arranged in rows on the crates. The display is set up in a market or grocery store."}, "109537": {"image_id": 109537, "Bleu_1": 0.21874999999658204, "Bleu_2": 0.1559023911131256, "Bleu_3": 7.318767556968614e-07, "Bleu_4": 1.592194087739241e-09, "METEOR": 0.167199159059074, "ROUGE_L": 0.2139278557114228, "CIDEr": 6.709642061918405e-18, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.23076923076923078, "f": 0.1846153846153846, "fn": 20.0, "numImages": 1.0, "fp": 33.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23529411764705882, "re": 0.4444444444444444, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}}, "caption": "This image shows a surfer riding a wave on a surfboard. The surfer is wearing a wetsuit and sunglasses, and is standing on the board with one foot on the nose and the other on the tail. The wave is large and white, with foamy white water crashing against the shore. The sky is clear and blue, with a few clouds scattered across it."}, "382715": {"image_id": 382715, "Bleu_1": 0.17808219177838244, "Bleu_2": 0.09946584890635388, "Bleu_3": 5.184376652274839e-07, "Bleu_4": 1.187812522695801e-09, "METEOR": 0.1585011098595372, "ROUGE_L": 0.19542334096109837, "CIDEr": 5.66731142768472e-24, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.25, "f": 0.24390243902439024, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "A person on a skateboard riding down the sidewalk\n\nThe image shows a person on a skateboard riding down a sidewalk in front of a group of buildings. The person is wearing a black jacket and black pants, and has a red hat on their head. There are cars parked on the side of the road, and people walking on the sidewalk. The sky is blue and there are trees in the background."}, "52596": {"image_id": 52596, "Bleu_1": 0.4090909090723141, "Bleu_2": 0.3120938919516558, "Bleu_3": 0.24446720039491812, "Bleu_4": 0.1665240823320508, "METEOR": 0.29974695884461106, "ROUGE_L": 0.38985939497230504, "CIDEr": 0.1542086477372459, "SPICE": {"All": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 21.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The little girl is holding a slice of pizza in her hand and looking at it with a smile on her face."}, "500718": {"image_id": 500718, "Bleu_1": 0.4594594594470417, "Bleu_2": 0.2526139620256896, "Bleu_3": 0.15391899442193274, "Bleu_4": 1.8096701953757755e-05, "METEOR": 0.19619373918639604, "ROUGE_L": 0.31466470154753134, "CIDEr": 8.76429617514035e-05, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.13636363636363635, "f": 0.15, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a group of airplanes parked on the tarmac at an airport. The planes are painted in different colors and have their landing gear extended. There are people standing around the planes, looking at them."}, "182240": {"image_id": 182240, "Bleu_1": 0.2972972972892623, "Bleu_2": 0.20320258681677345, "Bleu_3": 0.15239494387941893, "Bleu_4": 0.10100856226283313, "METEOR": 0.19833867623710316, "ROUGE_L": 0.23088569265707795, "CIDEr": 3.399858705941866e-05, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.2777777777777778, "f": 0.27027027027027023, "fn": 13.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a group of zebras standing in a field of tall grass. They are all facing the same direction and appear to be grazing. The background is a clear blue sky with some white clouds."}, "525083": {"image_id": 525083, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.1811857688307976, "Bleu_3": 0.09139586978860176, "Bleu_4": 1.1611347030414458e-05, "METEOR": 0.20974859944719612, "ROUGE_L": 0.25902335456475584, "CIDEr": 7.59890737352297e-09, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.17391304347826086, "f": 0.17391304347826086, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This is a kitchen with wooden floors and white cabinets. There is a table and chairs in the center of the room, and a refrigerator and stove on one wall. The walls are painted white and there are windows on one side of the room."}, "56821": {"image_id": 56821, "Bleu_1": 0.3888888888780865, "Bleu_2": 0.10540925533597618, "Bleu_3": 6.887995549333558e-07, "Bleu_4": 1.7739491161500997e-09, "METEOR": 0.2370431955282663, "ROUGE_L": 0.2420634920634921, "CIDEr": 8.434116896649226e-05, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.2222222222222222, "f": 0.16666666666666669, "fn": 21.0, "numImages": 1.0, "fp": 39.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.07692307692307693, "re": 0.125, "f": 0.09523809523809525, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2631578947368421, "re": 0.5, "f": 0.3448275862068966, "fn": 5.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}}, "caption": "This is a street scene in a city with tall buildings on either side of the road. There are people walking on the sidewalk and cars driving down the street. The sky is clear and blue."}, "256367": {"image_id": 256367, "Bleu_1": 0.29411764704152255, "Bleu_2": 0.13558153612843557, "Bleu_3": 1.0701301835512707e-06, "Bleu_4": 3.058760346259648e-09, "METEOR": 0.17551119105621982, "ROUGE_L": 0.31082802547770705, "CIDEr": 0.20034331144914297, "SPICE": {"All": {"pr": 0.2, "re": 0.13793103448275862, "f": 0.16326530612244897, "fn": 25.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a train traveling on a railroad track with trees and buildings in the background."}, "42667": {"image_id": 42667, "Bleu_1": 0.22413793103061835, "Bleu_2": 0.1659087424695837, "Bleu_3": 0.09943215161816608, "Bleu_4": 1.1562572145165382e-05, "METEOR": 0.2229169305438626, "ROUGE_L": 0.23131094257854823, "CIDEr": 1.7826931566697058e-14, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.11538461538461539, "f": 0.13333333333333333, "fn": 23.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a young girl sitting on top of a suitcase, looking up at the camera with a curious expression on her face. She is wearing a green shirt and has her hands on the handle of the suitcase. The background is a dark brown color and there are some boxes and other items in the room."}, "388453": {"image_id": 388453, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.15227739752202907, "Bleu_3": 8.077421359130519e-07, "Bleu_4": 1.8710588175603566e-09, "METEOR": 0.16598158906876165, "ROUGE_L": 0.19614147909967844, "CIDEr": 6.54563790269302e-09, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.25, "f": 0.20408163265306123, "fn": 15.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5555555555555556, "f": 0.4761904761904762, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a large room with a high ceiling and large windows. There are several people standing around, talking and looking at something on a table in the center of the room. The walls are painted white and there are several paintings hanging on them."}, "38118": {"image_id": 38118, "Bleu_1": 0.7499999998125003, "Bleu_2": 0.5669467093670424, "Bleu_3": 0.4749571256683354, "Bleu_4": 0.38260294151932694, "METEOR": 0.4063432927421277, "ROUGE_L": 0.5820610687022901, "CIDEr": 1.3003587891771142, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.18518518518518517, "f": 0.20833333333333334, "fn": 22.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.45454545454545453, "f": 0.47619047619047616, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "A person skiing down a snowy mountain slope."}, "305319": {"image_id": 305319, "Bleu_1": 0.19298245613696527, "Bleu_2": 0.11740724488886634, "Bleu_3": 0.06304863686903067, "Bleu_4": 8.253883526780069e-06, "METEOR": 0.18827652953050023, "ROUGE_L": 0.24413950829045164, "CIDEr": 2.772691023143711e-14, "SPICE": {"All": {"pr": 0.4, "re": 0.17142857142857143, "f": 0.24000000000000002, "fn": 29.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.35714285714285715, "f": 0.45454545454545453, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image shows a person surfing on a wave in the ocean. The person is wearing a black wetsuit and has their arms outstretched to balance themselves on the board. The wave is large and white, with foamy white water crashing against the shore. The sky is clear and blue, with a few clouds scattered across it."}, "410484": {"image_id": 410484, "Bleu_1": 0.2786885245855953, "Bleu_2": 0.13630566742459158, "Bleu_3": 0.06803388504799351, "Bleu_4": 8.58394557738532e-06, "METEOR": 0.17511165969626208, "ROUGE_L": 0.22438255386232267, "CIDEr": 1.8057074179812692e-12, "SPICE": {"All": {"pr": 0.125, "re": 0.07407407407407407, "f": 0.09302325581395349, "fn": 25.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a bride and groom cutting a cake together. The cake is blue and white with a red star on top. The bride is wearing a white dress and the groom is wearing a black suit. They are both smiling and holding the cake in their hands. There are plates of food on the table in front of them."}, "454252": {"image_id": 454252, "Bleu_1": 0.423076923060651, "Bleu_2": 0.3186510027137757, "Bleu_3": 0.25673974734782135, "Bleu_4": 0.19585982946153235, "METEOR": 0.3378292154984874, "ROUGE_L": 0.39019189765458434, "CIDEr": 0.03649631503539169, "SPICE": {"All": {"pr": 0.5714285714285714, "re": 0.36363636363636365, "f": 0.4444444444444444, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.75, "re": 0.75, "f": 0.75, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "Here is a short caption for the image:\n\n\"A group of people standing in a wine cellar, holding glasses of wine and smiling at the camera.\""}, "245153": {"image_id": 245153, "Bleu_1": 0.4999999999166667, "Bleu_2": 0.3015113445263697, "Bleu_3": 2.0870640220585245e-06, "Bleu_4": 5.63756031424638e-09, "METEOR": 0.1561862655113871, "ROUGE_L": 0.39102564102564097, "CIDEr": 0.26357363644199183, "SPICE": {"All": {"pr": 0.0967741935483871, "re": 0.2, "f": 0.13043478260869568, "fn": 12.0, "numImages": 1.0, "fp": 28.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.6, "f": 0.33333333333333337, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "Two puffins perched on a grassy hillside overlooking a body of water."}, "528980": {"image_id": 528980, "Bleu_1": 0.2749999999931251, "Bleu_2": 0.14544361846700224, "Bleu_3": 8.226250211193223e-07, "Bleu_4": 1.9694774163640186e-09, "METEOR": 0.17692485271721323, "ROUGE_L": 0.23036253776435048, "CIDEr": 2.8172323665444963e-06, "SPICE": {"All": {"pr": 0.3225806451612903, "re": 0.3225806451612903, "f": 0.3225806451612903, "fn": 21.0, "numImages": 1.0, "fp": 21.0, "tp": 10.0}, "Relation": {"pr": 0.13333333333333333, "re": 0.15384615384615385, "f": 0.14285714285714288, "fn": 11.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.7272727272727273, "re": 0.6666666666666666, "f": 0.6956521739130435, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 8.0}}, "caption": "This is an image of a red and white umbrella on the sidewalk in front of a building. The umbrella is open and has a handle on top. There are cars parked on the street in front of the building."}, "402118": {"image_id": 402118, "Bleu_1": 0.19999999999428575, "Bleu_2": 0.10846522890618356, "Bleu_3": 7.090698915331589e-07, "Bleu_4": 1.8269610522029373e-09, "METEOR": 0.14038958879303176, "ROUGE_L": 0.2469635627530364, "CIDEr": 1.8366862074011497e-05, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.2631578947368421, "f": 0.24390243902439024, "fn": 14.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.4, "f": 0.2857142857142857, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a person snowboarding down a mountain. The person is wearing a white suit and helmet, and is jumping off a ramp. The background is a snowy mountain with trees in the distance."}, "303893": {"image_id": 303893, "Bleu_1": 0.34482758619500603, "Bleu_2": 0.15694120513807777, "Bleu_3": 0.09698473885583787, "Bleu_4": 1.3686241957090147e-05, "METEOR": 0.2097476630311268, "ROUGE_L": 0.29075309818875117, "CIDEr": 0.005064861645575546, "SPICE": {"All": {"pr": 0.4166666666666667, "re": 0.29411764705882354, "f": 0.3448275862068966, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.6666666666666666, "f": 0.7272727272727272, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The image shows two young children sitting on the ground, one holding a bowl of food and the other holding a spoon. They are surrounded by trees and greenery."}, "491836": {"image_id": 491836, "Bleu_1": 0.3170731707239739, "Bleu_2": 0.21808478994970526, "Bleu_3": 0.16959591199162316, "Bleu_4": 0.12658234428753953, "METEOR": 0.25432633489411155, "ROUGE_L": 0.3083032490974729, "CIDEr": 1.3167709238415907e-06, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 30.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a body of water with a small boat in the distance. The sky is clear and blue, with some clouds in the distance. There are trees and rocks along the shore, and a small island in the distance."}, "456816": {"image_id": 456816, "Bleu_1": 0.5833333332847223, "Bleu_2": 0.46056618643171326, "Bleu_3": 0.2768182380335083, "Bleu_4": 3.918189149692743e-05, "METEOR": 0.21205375641048094, "ROUGE_L": 0.43821839080459773, "CIDEr": 0.5249144276335967, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.19047619047619047, "f": 0.16326530612244897, "fn": 17.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "A plate with a doughnut on it sitting on a wooden table."}, "495825": {"image_id": 495825, "Bleu_1": 0.3225806451508845, "Bleu_2": 0.17960530202088465, "Bleu_3": 0.10361280619686483, "Bleu_4": 1.4117915208501987e-05, "METEOR": 0.17735621106421048, "ROUGE_L": 0.24302788844621517, "CIDEr": 0.011952784535290884, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.10344827586206896, "f": 0.1276595744680851, "fn": 26.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 1.0, "re": 0.16666666666666666, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a herd of cows grazing in a green field with mountains in the background. The sky is a bright blue and the sun is setting in the distance."}, "174740": {"image_id": 174740, "Bleu_1": 0.5161290322414152, "Bleu_2": 0.4147806778785671, "Bleu_3": 0.3289501551085606, "Bleu_4": 0.24850685748113083, "METEOR": 0.2388582837327242, "ROUGE_L": 0.41673783091374894, "CIDEr": 0.013556487052812101, "SPICE": {"All": {"pr": 0.11627906976744186, "re": 0.16666666666666666, "f": 0.136986301369863, "fn": 25.0, "numImages": 1.0, "fp": 38.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.05555555555555555, "re": 0.1111111111111111, "f": 0.07407407407407407, "fn": 8.0, "numImages": 1.0, "fp": 17.0, "tp": 1.0}, "Size": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.36363636363636365, "f": 0.2962962962962963, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}}, "caption": "The image shows a box of donuts sitting on a wooden table with a bottle of soda next to it. The donuts appear to be glazed and have sprinkles on top."}, "507037": {"image_id": 507037, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.23510021021100327, "Bleu_3": 0.19180200486333243, "Bleu_4": 0.14646393991657777, "METEOR": 0.2977665693088768, "ROUGE_L": 0.31504196255648803, "CIDEr": 3.018236406122563e-09, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.14285714285714285, "f": 0.1, "fn": 18.0, "numImages": 1.0, "fp": 36.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 6.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}}, "caption": "The image shows a group of people standing outside a building with bicycles parked next to them. The building appears to be a church with a large cross on the front. The people are dressed in casual clothing and are talking and laughing while standing next to their bicycles."}, "57323": {"image_id": 57323, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.18712785740116275, "Bleu_3": 0.10973462200669563, "Bleu_4": 1.262574222030696e-05, "METEOR": 0.28237974770284885, "ROUGE_L": 0.2513243084167157, "CIDEr": 1.0619529811216084e-13, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.2727272727272727, "f": 0.2666666666666666, "fn": 16.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5, "f": 0.5263157894736842, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a group of people riding motorcycles down a street. They are all wearing helmets and riding in a line, with one person leading the way. There are cars parked on the side of the road, and a building in the background. The sky is clear and blue, with no clouds in sight."}, "516038": {"image_id": 516038, "Bleu_1": 0.340909090901343, "Bleu_2": 0.23557764908855597, "Bleu_3": 0.1097335995735907, "Bleu_4": 1.3398579422657672e-05, "METEOR": 0.22737230226004868, "ROUGE_L": 0.25702247191011235, "CIDEr": 6.894373311627368e-08, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.13333333333333333, "f": 0.15384615384615383, "fn": 26.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.18181818181818182, "f": 0.1904761904761905, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a baseball game in progress on a green field. There are several players on the field, including a pitcher throwing a ball to a catcher, and a batter swinging a bat. The crowd is seated in the stands behind the field."}, "433915": {"image_id": 433915, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.13187609467625871, "Bleu_3": 7.338824344329119e-07, "Bleu_4": 1.741216427287497e-09, "METEOR": 0.20439557997040736, "ROUGE_L": 0.2719745222929936, "CIDEr": 5.330115321686343e-08, "SPICE": {"All": {"pr": 0.05263157894736842, "re": 0.058823529411764705, "f": 0.05555555555555555, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image shows a man and woman standing in front of a television screen. The man is wearing a suit and tie, while the woman is wearing a red shirt and black pants. They are both looking at the screen with serious expressions on their faces."}, "17899": {"image_id": 17899, "Bleu_1": 0.2173913043446755, "Bleu_2": 0.11308281825632424, "Bleu_3": 0.05757573375659296, "Bleu_4": 7.333201644638118e-06, "METEOR": 0.1568028836824707, "ROUGE_L": 0.20132013201320131, "CIDEr": 2.4200827446235682e-21, "SPICE": {"All": {"pr": 0.21212121212121213, "re": 0.22580645161290322, "f": 0.21875, "fn": 24.0, "numImages": 1.0, "fp": 26.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6, "re": 1.0, "f": 0.7499999999999999, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Object": {"pr": 0.3333333333333333, "re": 0.36363636363636365, "f": 0.34782608695652173, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA woman is sitting at a table, cutting bread into small pieces. There are several other items on the table, including a loaf of bread, a knife, and a plate. The woman is wearing a pink apron and has a spoon in her hand. The room appears to be a kitchen, with a stove and refrigerator visible in the background."}, "298252": {"image_id": 298252, "Bleu_1": 0.11904761904667424, "Bleu_2": 0.09759000729407571, "Bleu_3": 0.061306062481562146, "Bleu_4": 0.04399555378614175, "METEOR": 0.15555753766968847, "ROUGE_L": 0.14047207829591246, "CIDEr": 4.166649069011193e-80, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.38461538461538464, "f": 0.2325581395348837, "fn": 8.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.6666666666666666, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a display case filled with various types of donuts, including chocolate, glazed, and sprinkled. There are also other baked goods such as croissants and muffins on display. The display case is surrounded by shelves with more baked goods and pastries.\n\nThe image is taken in a bakery or a store that sells baked goods. The lighting is bright and the display case is well organized. The image is taken from a low angle, looking down at the display case.\n\nThe image is in black and white, with a few areas of color, such as the red and yellow of the donuts. The overall mood of the image is cheerful and inviting, with the bright colors and the variety of baked goods on display."}, "222370": {"image_id": 222370, "Bleu_1": 0.16393442622682078, "Bleu_2": 0.07392212709423537, "Bleu_3": 4.5244483301128767e-07, "Bleu_4": 1.124131781190219e-09, "METEOR": 0.11894907918505244, "ROUGE_L": 0.13196322336398056, "CIDEr": 8.009269798118116e-18, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.30434782608695654, "f": 0.31111111111111117, "fn": 16.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5555555555555556, "f": 0.4545454545454546, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a group of people walking down a narrow street lined with tall buildings on either side. The buildings are made of stone and have balconies on the upper floors. There are trees and plants growing in pots on the sidewalk, and a few cars parked on the street. The sky is blue and there are clouds in it."}, "374448": {"image_id": 374448, "Bleu_1": 0.1707317073149911, "Bleu_2": 0.07951978726797392, "Bleu_3": 4.2916089669623353e-07, "Bleu_4": 1.0001343308016615e-09, "METEOR": 0.14516340032438627, "ROUGE_L": 0.21196911196911197, "CIDEr": 2.943242194860567e-29, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.18181818181818182, "f": 0.19999999999999998, "fn": 27.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.07692307692307693, "f": 0.09090909090909093, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.38461538461538464, "f": 0.41666666666666663, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a large, open room with high ceilings and wooden beams. There are several long tables set up in the room, each with several people sitting at them. The walls are painted a warm, earthy color and there are several large windows that let in natural light. The floor is made of dark wood and there are several chairs and benches scattered throughout the room. A large, ornate chandelier hangs from the ceiling, casting a warm glow over the room."}, "181278": {"image_id": 181278, "Bleu_1": 0.1641791044751615, "Bleu_2": 0.049875466804631625, "Bleu_3": 3.3699246996643596e-07, "Bleu_4": 8.793669802427087e-10, "METEOR": 0.1677567464390343, "ROUGE_L": 0.14987714987714987, "CIDEr": 2.1431952851868668e-19, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.15384615384615385, "f": 0.16326530612244897, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of young boys playing baseball on a field. They are wearing white and blue uniforms with the number 1 on their jerseys. One of the boys is throwing a ball while another is catching it. There are several spectators watching from the sidelines. The image appears to be taken in a park or field with trees and buildings visible in the background."}, "373789": {"image_id": 373789, "Bleu_1": 0.36842105262188374, "Bleu_2": 0.2640100002346085, "Bleu_3": 0.17975728622846687, "Bleu_4": 0.11350052389324858, "METEOR": 0.16295766721443938, "ROUGE_L": 0.23940345368916802, "CIDEr": 0.0005887281266467625, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.17857142857142858, "f": 0.23255813953488372, "fn": 23.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "This is an image of a plate with two pieces of toast on it. One piece of toast has chicken on it and the other has cheese on it. The plate is on a countertop in a kitchen."}, "251124": {"image_id": 251124, "Bleu_1": 0.4374999999863282, "Bleu_2": 0.26563982405609077, "Bleu_3": 1.329908324170127e-06, "Bleu_4": 3.001005413145576e-09, "METEOR": 0.2559938382876929, "ROUGE_L": 0.39610389610389607, "CIDEr": 0.0020507096244342144, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.08333333333333333, "f": 0.13333333333333333, "fn": 22.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.2222222222222222, "f": 0.3333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "The image shows a bicycle parked on a bench in front of a city skyline at night. The sky is filled with bright lights and the buildings are reflected in the water."}, "162249": {"image_id": 162249, "Bleu_1": 0.3333333333253969, "Bleu_2": 0.18033392692914046, "Bleu_3": 0.11759123766324173, "Bleu_4": 0.08035540036756333, "METEOR": 0.25283575833011523, "ROUGE_L": 0.3374827109266943, "CIDEr": 1.056249046193065e-06, "SPICE": {"All": {"pr": 0.08, "re": 0.1, "f": 0.08888888888888889, "fn": 18.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "This is a bathroom with a large tub in the center of the room. There is a sink and toilet in the corner of the room. The walls are painted pink and there are two windows on either side of the room."}, "551908": {"image_id": 551908, "Bleu_1": 0.2727272727223141, "Bleu_2": 0.20100756304815393, "Bleu_3": 0.13175185157163616, "Bleu_4": 0.09684433212908221, "METEOR": 0.23516044899560642, "ROUGE_L": 0.3145616763526234, "CIDEr": 2.2437451839871923e-10, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.23809523809523808, "f": 0.23255813953488372, "fn": 16.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a plate of food with a piece of fish, broccoli, and potatoes. The fish is cooked and has a golden brown color. The broccoli is steamed and has a green color. The potatoes are boiled and have a white color. The dish is served on a white plate with a red border."}, "366367": {"image_id": 366367, "Bleu_1": 0.33333333332716053, "Bleu_2": 0.2747211278922427, "Bleu_3": 0.1936051597528738, "Bleu_4": 0.12988310144706322, "METEOR": 0.22581779888719195, "ROUGE_L": 0.25507765830346474, "CIDEr": 1.966100376670961e-12, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.06896551724137931, "f": 0.09090909090909091, "fn": 27.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.09090909090909091, "f": 0.13333333333333333, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA young girl is standing in front of a whiteboard with various words and phrases written on it. She is holding a small tablet in her hand and looking at it intently. The room is filled with various educational materials and posters on the walls."}, "231343": {"image_id": 231343, "Bleu_1": 0.32727272726677686, "Bleu_2": 0.23354968324417125, "Bleu_3": 0.1931346714834013, "Bleu_4": 0.14278239474701712, "METEOR": 0.27655293184846563, "ROUGE_L": 0.23788300835654594, "CIDEr": 1.5887402483219304e-08, "SPICE": {"All": {"pr": 0.25, "re": 0.4166666666666667, "f": 0.3125, "fn": 7.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.75, "f": 0.4285714285714285, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is an image of a baseball player in the middle of a game. He is wearing a black and white uniform and has a bat in his hand. The other players on the field are watching him as he prepares to swing at the ball. The crowd in the stands is cheering him on."}, "236290": {"image_id": 236290, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.10942520359115704, "Bleu_3": 0.06169095833758949, "Bleu_4": 8.277965966610606e-06, "METEOR": 0.14038527767935308, "ROUGE_L": 0.14796846573681016, "CIDEr": 7.587345440024749e-13, "SPICE": {"All": {"pr": 0.2, "re": 0.13793103448275862, "f": 0.16326530612244897, "fn": 25.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.08333333333333333, "f": 0.125, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a person standing on a staircase with a suitcase in their hand. The staircase is made of metal and has a railing on either side. The person is wearing a black jacket and pants, and has a white shirt underneath. The background is a blurred image of a city skyline."}, "189095": {"image_id": 189095, "Bleu_1": 0.24324324323666918, "Bleu_2": 0.14237369935897354, "Bleu_3": 0.10502043920185458, "Bleu_4": 1.3585813340224244e-05, "METEOR": 0.15360524462268085, "ROUGE_L": 0.2697126013264554, "CIDEr": 3.885058117576917e-05, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.16666666666666666, "f": 0.186046511627907, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows two brown bears standing on the ground, one of them is biting the other's ear. The bears are standing in front of a rocky outcropping, with trees and bushes visible in the background."}, "426546": {"image_id": 426546, "Bleu_1": 0.3170731707239739, "Bleu_2": 0.19908326484038252, "Bleu_3": 0.12667132083265856, "Bleu_4": 0.0855190415985804, "METEOR": 0.20112406821992654, "ROUGE_L": 0.30434782608695654, "CIDEr": 4.2728232318833375e-05, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.15384615384615385, "f": 0.1702127659574468, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This image shows a plate of food with two sandwiches, fries, and a drink on the table. The sandwiches are made with meat and cheese, and the fries are served with ketchup and mustard. The drink is a glass of soda."}, "114119": {"image_id": 114119, "Bleu_1": 0.3199999999936, "Bleu_2": 0.18070158057739935, "Bleu_3": 0.08794832144810152, "Bleu_4": 1.0968473790380014e-05, "METEOR": 0.20601765534120814, "ROUGE_L": 0.2357639783560938, "CIDEr": 2.9865301577262235e-10, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.09523809523809523, "f": 0.09302325581395349, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a cat sleeping on top of a clock. The clock has the numbers 12, 3, 6, and 9 on it. The cat is laying on its back with its paws tucked under its body. The cat's eyes are closed and it appears to be sleeping peacefully."}, "290828": {"image_id": 290828, "Bleu_1": 0.23913043477741028, "Bleu_2": 0.16300321563702572, "Bleu_3": 0.10649352950670186, "Bleu_4": 0.07279898126120386, "METEOR": 0.16557233679139444, "ROUGE_L": 0.24238410596026488, "CIDEr": 2.9708180356473268e-08, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.4117647058823529, "f": 0.34146341463414637, "fn": 10.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a giraffe standing on a ledge overlooking a body of water. There are people standing on the other side of the ledge, looking at the giraffe. The giraffe is eating leaves from a tree. The image is taken in a park or zoo."}, "64103": {"image_id": 64103, "Bleu_1": 0.45454545452479345, "Bleu_2": 0.36037498506145293, "Bleu_3": 0.29615092273975135, "Bleu_4": 0.22866722230456127, "METEOR": 0.2549467865195706, "ROUGE_L": 0.41876430205949655, "CIDEr": 0.07503041203511843, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.2916666666666667, "f": 0.30434782608695654, "fn": 17.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "Two birds are swimming in a body of water, one is holding its beak open and the other is looking at it."}, "194756": {"image_id": 194756, "Bleu_1": 0.27906976743537054, "Bleu_2": 0.16302782918400804, "Bleu_3": 8.654590923115623e-07, "Bleu_4": 2.006411049352811e-09, "METEOR": 0.21573187528521112, "ROUGE_L": 0.24881033310673015, "CIDEr": 3.679389476063597e-07, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.17391304347826086, "f": 0.1904761904761905, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a small boat with a man sitting in the front, surrounded by people walking on the sidewalk. The boat is docked at a pier next to a bridge over a river. There are buildings and trees visible in the background."}, "412879": {"image_id": 412879, "Bleu_1": 0.3617021276518787, "Bleu_2": 0.2172062116707298, "Bleu_3": 0.1465157820982506, "Bleu_4": 0.1093471921460413, "METEOR": 0.2714970685480221, "ROUGE_L": 0.2781758957654723, "CIDEr": 1.3777383970733134e-08, "SPICE": {"All": {"pr": 0.13513513513513514, "re": 0.20833333333333334, "f": 0.1639344262295082, "fn": 19.0, "numImages": 1.0, "fp": 32.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "The woman in the image is playing tennis with a racket and ball on a tennis court. She is wearing a black top and white pants, and her hair is tied back in a ponytail. The background is a green grassy field with trees in the distance."}, "51741": {"image_id": 51741, "Bleu_1": 0.45714285712979597, "Bleu_2": 0.25928148941334883, "Bleu_3": 1.2676801653440607e-06, "Bleu_4": 2.8246833943934737e-09, "METEOR": 0.30653871802035504, "ROUGE_L": 0.34574898785425096, "CIDEr": 0.0008698682819311078, "SPICE": {"All": {"pr": 0.5454545454545454, "re": 0.46153846153846156, "f": 0.4999999999999999, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}, "Relation": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "This is a bathroom with a toilet, sink, and shower. The walls are made of wood and the floor is made of tile. There is a window in the background that lets in natural light."}, "111448": {"image_id": 111448, "Bleu_1": 0.35294117644982703, "Bleu_2": 0.21004201259146, "Bleu_3": 1.432760811493401e-06, "Bleu_4": 3.8071348661994064e-09, "METEOR": 0.17484656415424732, "ROUGE_L": 0.2971985383678441, "CIDEr": 0.4189723991612949, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.11538461538461539, "f": 0.16216216216216214, "fn": 23.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a horse and jockey standing on the track, with people in the background watching."}, "255279": {"image_id": 255279, "Bleu_1": 0.20833333332899312, "Bleu_2": 0.11531640100118269, "Bleu_3": 6.612130898132252e-07, "Bleu_4": 1.5920362546205505e-09, "METEOR": 0.1719493698969791, "ROUGE_L": 0.23036253776435048, "CIDEr": 2.513376771789302e-09, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.13333333333333333, "f": 0.13559322033898305, "fn": 26.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.16666666666666666, "f": 0.11764705882352942, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.2727272727272727, "f": 0.28571428571428564, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "Sure, here is a short caption for the image:\n\nThe black motorcycle is parked on the side of the road, with the rider's helmet and gloves laid on the ground next to it. The bike has a sleek, modern design and appears to be in good condition."}, "243626": {"image_id": 243626, "Bleu_1": 0.5294117646747406, "Bleu_2": 0.3638034375324306, "Bleu_3": 0.20663986647296506, "Bleu_4": 2.8175950488572184e-05, "METEOR": 0.22484772040551296, "ROUGE_L": 0.42707117852975496, "CIDEr": 0.6794061464336336, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.2727272727272727, "f": 0.24999999999999994, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.625, "f": 0.5555555555555556, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "This image shows a plate of food with a piece of meat, green beans, and orange slices."}, "171255": {"image_id": 171255, "Bleu_1": 0.30645161289828304, "Bleu_2": 0.22413828170744018, "Bleu_3": 0.1496167692106403, "Bleu_4": 0.0868004949161612, "METEOR": 0.1927197483663561, "ROUGE_L": 0.22356020942408372, "CIDEr": 3.1710943937442885e-15, "SPICE": {"All": {"pr": 0.0625, "re": 0.07142857142857142, "f": 0.06666666666666667, "fn": 13.0, "numImages": 1.0, "fp": 15.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image shows a group of people standing on the beach, looking out at the ocean. There is a blue tarp set up on the sand, and a few people are sitting under it. In the background, there is a large building with a red roof and white walls. The sky is clear and blue, with a few clouds scattered across it."}, "41119": {"image_id": 41119, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.20957473279408315, "Bleu_3": 0.1390596095466697, "Bleu_4": 0.0865148073184506, "METEOR": 0.1997326019870179, "ROUGE_L": 0.26116207951070336, "CIDEr": 2.665464667437169e-10, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.26666666666666666, "f": 0.23529411764705882, "fn": 11.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.4, "f": 0.3076923076923077, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "This is an image of a green traffic light hanging from a pole in the middle of a busy street. The light is illuminated and there are cars passing by on both sides of the road. The buildings in the background are tall and modern, with large windows and reflective surfaces."}, "84982": {"image_id": 84982, "Bleu_1": 0.4411764705752596, "Bleu_2": 0.20026720118197788, "Bleu_3": 0.10781765773200352, "Bleu_4": 1.4180024988053715e-05, "METEOR": 0.20634264396721308, "ROUGE_L": 0.27618472683368545, "CIDEr": 0.001991982332720634, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.06451612903225806, "f": 0.09523809523809523, "fn": 29.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "This is an image of a street sign with the words \"store\" written on it in red letters. The sign is attached to a pole and there are plants and flowers growing around it."}, "232309": {"image_id": 232309, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.20195126571496114, "Bleu_3": 0.13566654900343936, "Bleu_4": 0.08492670489284881, "METEOR": 0.2731751234903982, "ROUGE_L": 0.2858816637375513, "CIDEr": 5.687002892616449e-09, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.1875, "f": 0.17647058823529413, "fn": 13.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.5, "f": 0.30769230769230765, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a person holding a kite on a beach with a clear blue sky in the background. The person is standing on the sand and the kite is flying in the air. There are waves in the distance and a few people can be seen walking on the beach."}, "438059": {"image_id": 438059, "Bleu_1": 0.3199999999936, "Bleu_2": 0.26802375769878084, "Bleu_3": 0.21881031701976436, "Bleu_4": 0.1912335972953699, "METEOR": 0.3811656951218497, "ROUGE_L": 0.34879288437102923, "CIDEr": 2.7757165218385986e-09, "SPICE": {"All": {"pr": 0.0625, "re": 0.03225806451612903, "f": 0.0425531914893617, "fn": 30.0, "numImages": 1.0, "fp": 15.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.08333333333333333, "f": 0.1, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image shows a black and white cat wearing a red scarf sitting on top of a pile of presents. The cat is looking up at the camera with its eyes. The background is a living room with a Christmas tree in the corner and a fireplace in the center."}, "572861": {"image_id": 572861, "Bleu_1": 0.32432432431555885, "Bleu_2": 0.1643989873008524, "Bleu_3": 9.174380408476639e-07, "Bleu_4": 2.1830457064027044e-09, "METEOR": 0.2091079201713263, "ROUGE_L": 0.27858121479677267, "CIDEr": 9.622738564423485e-05, "SPICE": {"All": {"pr": 0.12, "re": 0.125, "f": 0.12244897959183673, "fn": 21.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a horse and carriage parked in front of a building. The carriage is red and white, with a black and white horse pulling it. There are people standing around the carriage, looking at it."}, "9262": {"image_id": 9262, "Bleu_1": 0.3913043478090738, "Bleu_2": 0.18860838403019278, "Bleu_3": 1.1920676375093199e-06, "Bleu_4": 3.0336688656211814e-09, "METEOR": 0.1433572327493314, "ROUGE_L": 0.2544316996871741, "CIDEr": 0.07045841295221851, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.21739130434782608, "f": 0.17241379310344826, "fn": 18.0, "numImages": 1.0, "fp": 30.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.4166666666666667, "f": 0.3846153846153846, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A table with a variety of food and drinks, including sandwiches, fruit, and tea.\""}, "308430": {"image_id": 308430, "Bleu_1": 0.4285714285510205, "Bleu_2": 0.29277002187027, "Bleu_3": 1.6523417248578963e-06, "Bleu_4": 3.97884275511153e-09, "METEOR": 0.17152555651887405, "ROUGE_L": 0.3446327683615819, "CIDEr": 0.14637118781790517, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.09375, "f": 0.15384615384615383, "fn": 29.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.1111111111111111, "f": 0.19999999999999998, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.16666666666666666, "f": 0.26666666666666666, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "This is a pan with a variety of vegetables, including mushrooms, carrots, and green onions, cooking in a pot of water."}, "28071": {"image_id": 28071, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.21290467263078663, "Bleu_3": 1.0024266962117514e-06, "Bleu_4": 2.187390385842088e-09, "METEOR": 0.1916954712340042, "ROUGE_L": 0.3011519473395502, "CIDEr": 7.131369602942747e-07, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.38461538461538464, "f": 0.3225806451612903, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.6, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5, "f": 0.36363636363636365, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "This is an image of a red stop sign on the side of a road in front of a parking lot. The sign is made of metal and has the words \"stop\" written on it in white letters. There are no cars or people in the image."}, "393942": {"image_id": 393942, "Bleu_1": 0.23214285713871177, "Bleu_2": 0.18375590810914594, "Bleu_3": 0.10773900313322693, "Bleu_4": 0.06969646435516218, "METEOR": 0.20986392559175768, "ROUGE_L": 0.2426136363636364, "CIDEr": 4.286982294759229e-12, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.22727272727272727, "f": 0.22222222222222224, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a train crossing a railroad track in the middle of a forest. The train is moving slowly and the tracks are covered in leaves and branches. There is a person standing on the platform of the train, looking out at the forest. The sky is cloudy and there are trees in the background."}, "526751": {"image_id": 526751, "Bleu_1": 0.36666666665444453, "Bleu_2": 0.2514326764768464, "Bleu_3": 0.16528691241294277, "Bleu_4": 0.11372027709677378, "METEOR": 0.2716271072194908, "ROUGE_L": 0.35260115606936415, "CIDEr": 0.008338999791873114, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 20.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.08333333333333333, "f": 0.11764705882352941, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "A small boat is docked at the shore of a river, surrounded by green hills and trees. The sky is clear and blue, with a few clouds scattered across it."}, "440830": {"image_id": 440830, "Bleu_1": 0.340909090901343, "Bleu_2": 0.17807996398101744, "Bleu_3": 0.11472822500028991, "Bleu_4": 0.07790345908043068, "METEOR": 0.2185981988829963, "ROUGE_L": 0.25702247191011235, "CIDEr": 2.146019536165808e-07, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.2, "f": 0.21739130434782608, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The woman is standing next to a pile of luggage, including suitcases and backpacks. She is wearing a white shirt and black pants, and has a black hat on her head. The background is a city street with buildings and cars in the distance."}, "400317": {"image_id": 400317, "Bleu_1": 0.5789473683905818, "Bleu_2": 0.35868505787991106, "Bleu_3": 0.24736365056100337, "Bleu_4": 0.17537670873641137, "METEOR": 0.24044012667135153, "ROUGE_L": 0.38812301166489926, "CIDEr": 0.41807462362112013, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.32142857142857145, "f": 0.2950819672131148, "fn": 19.0, "numImages": 1.0, "fp": 24.0, "tp": 9.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.35714285714285715, "re": 0.5, "f": 0.41666666666666663, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a man playing tennis on a court with a crowd of people watching in the background."}, "565650": {"image_id": 565650, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.12903971808302675, "Bleu_3": 0.07179233837245348, "Bleu_4": 9.576248453510562e-06, "METEOR": 0.21076687594133497, "ROUGE_L": 0.23843648208469054, "CIDEr": 4.319488712432206e-09, "SPICE": {"All": {"pr": 0.15, "re": 0.17647058823529413, "f": 0.16216216216216214, "fn": 14.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "Sure, here is a short caption for the image:\n\n\"A purple umbrella is hanging on the side of a motorcycle parked on the side of the road. The umbrella is open and has a handle attached to it. There are buildings and trees visible in the background.\""}, "286182": {"image_id": 286182, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.23783535599888, "Bleu_3": 0.10957078983962544, "Bleu_4": 1.3303281214014741e-05, "METEOR": 0.2542360090807016, "ROUGE_L": 0.26212400245549416, "CIDEr": 4.234359827319176e-07, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.42857142857142855, "f": 0.29268292682926833, "fn": 8.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.5, "f": 0.1818181818181818, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.6, "f": 0.37499999999999994, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is a table set with various dishes and utensils. There are plates, bowls, and cups on the table. There is also a man sitting at the table, wearing a white shirt and black pants. The room appears to be a kitchen or dining area."}, "232460": {"image_id": 232460, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.2377430106815972, "Bleu_3": 0.13696121871565223, "Bleu_4": 1.563439553406559e-05, "METEOR": 0.3220115245226128, "ROUGE_L": 0.31565329883570503, "CIDEr": 3.460610268301148e-08, "SPICE": {"All": {"pr": 0.2, "re": 0.08823529411764706, "f": 0.12244897959183675, "fn": 31.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.08333333333333333, "f": 0.15384615384615385, "fn": 11.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.16666666666666666, "f": 0.2105263157894737, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a baseball player in a black and gold uniform throwing a ball on a snowy field. The player is wearing a helmet and glove, and the ball is in mid-air. The background is a winter landscape with trees and buildings in the distance."}, "346752": {"image_id": 346752, "Bleu_1": 0.818181818033058, "Bleu_2": 0.6396021489476329, "Bleu_3": 0.44964431293646534, "Bleu_4": 5.8060307534352256e-05, "METEOR": 0.2763606753201802, "ROUGE_L": 0.5763779527559055, "CIDEr": 1.027522754449031, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.08695652173913043, "f": 0.08695652173913043, "fn": 21.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a plate with slices of orange on it."}, "534421": {"image_id": 534421, "Bleu_1": 0.3902439024295063, "Bleu_2": 0.19754591932503954, "Bleu_3": 0.1000208420156093, "Bleu_4": 1.2738608208588955e-05, "METEOR": 0.14923319331792878, "ROUGE_L": 0.2042866711319491, "CIDEr": 4.504300506211204e-06, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.25, "f": 0.2631578947368421, "fn": 15.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This image shows a group of people skiing down a snowy slope. They are all wearing yellow vests and helmets, and one person is holding a ski pole. The background is a winter landscape with trees and mountains in the distance."}, "330967": {"image_id": 330967, "Bleu_1": 0.45238095237018144, "Bleu_2": 0.36387385338642725, "Bleu_3": 0.28508864260491323, "Bleu_4": 0.22079222864558645, "METEOR": 0.3808274945167757, "ROUGE_L": 0.43262411347517726, "CIDEr": 2.354784930099972e-06, "SPICE": {"All": {"pr": 0.2, "re": 0.12, "f": 0.15, "fn": 22.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.07142857142857142, "f": 0.11764705882352941, "fn": 13.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a young woman in a red shirt and blue pants playing tennis on a court. She is holding a tennis racket and swinging it to hit the ball. The background is a green field with trees in the distance."}, "146640": {"image_id": 146640, "Bleu_1": 0.21874999999658204, "Bleu_2": 0.1178511301959019, "Bleu_3": 6.073307510312596e-07, "Bleu_4": 1.384320004255326e-09, "METEOR": 0.1765608877925943, "ROUGE_L": 0.19022869022869024, "CIDEr": 2.2765904608205205e-17, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.13636363636363635, "f": 0.15, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "This is an image of a woman playing tennis with a racket. She is wearing a white shirt and black shorts, and has a blue ribbon tied around her left wrist. There are other people in the background, including a man in a red shirt and a woman in a yellow shirt. The image appears to be taken at a tennis tournament or event."}, "147576": {"image_id": 147576, "Bleu_1": 0.1692307692281657, "Bleu_2": 0.07272180923421494, "Bleu_3": 4.3785428098085625e-07, "Bleu_4": 1.0786965203811752e-09, "METEOR": 0.19922676323529548, "ROUGE_L": 0.2190867111339148, "CIDEr": 3.332812692692638e-19, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.20833333333333334, "f": 0.1818181818181818, "fn": 19.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a view of a canal with several boats docked at the shore. The buildings on either side of the canal are tall and made of brick, with windows and balconies on the upper floors. There is a small car parked on the left side of the image, near the water. The sky is clear and blue, with a few clouds scattered about."}, "19923": {"image_id": 19923, "Bleu_1": 0.3571428571343538, "Bleu_2": 0.30954614409873055, "Bleu_3": 0.267604614229991, "Bleu_4": 0.22263659306313088, "METEOR": 0.2751046423445075, "ROUGE_L": 0.4018445322793148, "CIDEr": 7.01002137567867e-06, "SPICE": {"All": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 24.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows two red cars parked in front of a building with a clock tower in the background. The cars are parked on the street, and there are other buildings visible in the background. The image is in black and white."}, "328940": {"image_id": 328940, "Bleu_1": 0.47368421050138515, "Bleu_2": 0.28097574345930926, "Bleu_3": 0.16683848808490073, "Bleu_4": 2.321091111608818e-05, "METEOR": 0.2911812085351851, "ROUGE_L": 0.3605911330049261, "CIDEr": 0.5241063453804735, "SPICE": {"All": {"pr": 0.4, "re": 0.2727272727272727, "f": 0.3243243243243243, "fn": 16.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8333333333333334, "re": 0.625, "f": 0.7142857142857143, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 5.0}}, "caption": "The image shows two children sitting on a couch, one holding a laptop and the other petting a dog."}, "489829": {"image_id": 489829, "Bleu_1": 0.206349206345931, "Bleu_2": 0.15263515662743288, "Bleu_3": 0.10464059272960032, "Bleu_4": 0.07861308319484854, "METEOR": 0.22089470244444054, "ROUGE_L": 0.22067183462532297, "CIDEr": 2.509051371487485e-17, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.15, "f": 0.11320754716981132, "fn": 17.0, "numImages": 1.0, "fp": 30.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.5, "f": 0.3157894736842105, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a man standing in front of a wall of clocks. He is wearing a black shirt and jeans, and has a serious expression on his face. The clocks on the wall are various shapes and sizes, and some of them have hands that are pointing to different times. The overall atmosphere of the image is one of nostalgia and tradition."}, "406070": {"image_id": 406070, "Bleu_1": 0.21428571428265308, "Bleu_2": 0.13650472655602283, "Bleu_3": 0.06495244273014657, "Bleu_4": 7.997015095562424e-06, "METEOR": 0.17932390606452053, "ROUGE_L": 0.1967741935483871, "CIDEr": 1.974794474961007e-18, "SPICE": {"All": {"pr": 0.0967741935483871, "re": 0.14285714285714285, "f": 0.11538461538461538, "fn": 18.0, "numImages": 1.0, "fp": 28.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.375, "f": 0.26086956521739135, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "This is an image of a person doing a trick on a skateboard in the middle of a city street. The person is wearing a black and white striped shirt and black pants, and has a red and white striped helmet on their head. There are several buildings in the background, including a tall building with a clock tower. The sky is blue and there are clouds in the background."}, "506187": {"image_id": 506187, "Bleu_1": 0.46874999998535166, "Bleu_2": 0.4259713756717724, "Bleu_3": 0.33107796430230185, "Bleu_4": 0.2236689539120156, "METEOR": 0.36009388776680795, "ROUGE_L": 0.4884341637010676, "CIDEr": 0.0035075566525053343, "SPICE": {"All": {"pr": 0.25, "re": 0.22727272727272727, "f": 0.23809523809523808, "fn": 17.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a banana with a smiley face drawn on it. The banana is sitting on a mirror, and the reflection of the banana in the mirror shows a smiley face."}, "299481": {"image_id": 299481, "Bleu_1": 0.5999999998800002, "Bleu_2": 0.3651483715950527, "Bleu_3": 2.55436477410356e-06, "Bleu_4": 6.985342055045127e-09, "METEOR": 0.2383446345364981, "ROUGE_L": 0.5313588850174217, "CIDEr": 0.8340475860852259, "SPICE": {"All": {"pr": 0.7142857142857143, "re": 0.1724137931034483, "f": 0.2777777777777778, "fn": 24.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}, "Relation": {"pr": 0.5, "re": 0.1, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 9.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}}, "caption": "A group of people skiing down a snowy mountain trail."}, "427160": {"image_id": 427160, "Bleu_1": 0.3636363636280992, "Bleu_2": 0.2433035497756459, "Bleu_3": 0.14126216736382222, "Bleu_4": 0.0910591170287744, "METEOR": 0.23061304656975684, "ROUGE_L": 0.2889039242219215, "CIDEr": 1.0183981274256609e-06, "SPICE": {"All": {"pr": 0.0625, "re": 0.06666666666666667, "f": 0.06451612903225808, "fn": 14.0, "numImages": 1.0, "fp": 15.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "This is an image of a group of young boys playing baseball on a field. They are wearing baseball uniforms and helmets, and one of them is holding a bat. The field is surrounded by trees and there is a fence in the background."}, "483531": {"image_id": 483531, "Bleu_1": 0.33333333332222226, "Bleu_2": 0.18569533817075534, "Bleu_3": 1.0718844984982804e-06, "Bleu_4": 2.5987832063232773e-09, "METEOR": 0.16187880445979763, "ROUGE_L": 0.264069264069264, "CIDEr": 0.002533847716230785, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 14.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is a bedroom with two beds, a desk, and a window with curtains. The walls are painted a light beige color and there is a carpet on the floor."}, "269287": {"image_id": 269287, "Bleu_1": 0.39999999999, "Bleu_2": 0.2480694691721357, "Bleu_3": 0.1479554649985627, "Bleu_4": 1.7200767571333467e-05, "METEOR": 0.25462093059764235, "ROUGE_L": 0.2621776504297994, "CIDEr": 1.730461203724403e-05, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.25, "f": 0.2162162162162162, "fn": 12.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is a bathroom with white tiles on the walls and floor. There is a sink in the corner of the room with a mirror above it. There are two windows on the opposite side of the room with curtains."}, "429839": {"image_id": 429839, "Bleu_1": 0.3902439024295063, "Bleu_2": 0.2793721183009322, "Bleu_3": 0.20004168403121855, "Bleu_4": 0.14326891642197143, "METEOR": 0.31012795903040313, "ROUGE_L": 0.36771600803750837, "CIDEr": 9.6508585001472e-06, "SPICE": {"All": {"pr": 0.1388888888888889, "re": 0.25, "f": 0.17857142857142858, "fn": 15.0, "numImages": 1.0, "fp": 31.0, "tp": 5.0}, "Relation": {"pr": 0.07142857142857142, "re": 0.14285714285714285, "f": 0.09523809523809523, "fn": 6.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23529411764705882, "re": 0.5714285714285714, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}}, "caption": "The image shows a small bird perched on a railing in front of a window. The bird is white with black spots and has a long, curved beak. The background is a city street with tall buildings and cars passing by."}, "502024": {"image_id": 502024, "Bleu_1": 0.5333333332977779, "Bleu_2": 0.33806170186806433, "Bleu_3": 0.20638725024557966, "Bleu_4": 2.9256127305132916e-05, "METEOR": 0.2538375320346069, "ROUGE_L": 0.39559014267185466, "CIDEr": 0.4822423250761555, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.21739130434782608, "f": 0.22222222222222224, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is an image of a white game controller with a red button on it."}, "2139": {"image_id": 2139, "Bleu_1": 0.26829268292028563, "Bleu_2": 0.14185186364132965, "Bleu_3": 0.10105205741245243, "Bleu_4": 0.07218766112836282, "METEOR": 0.16908660602560197, "ROUGE_L": 0.26425992779783397, "CIDEr": 4.6238239399996733e-07, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.25, "f": 0.23255813953488372, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This is a photo of a bedroom with a bicycle on the floor. There are several items on the floor, including a bicycle, a suitcase, and a backpack. The walls are painted blue and there are several posters on the wall."}, "283438": {"image_id": 283438, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.17837651699995472, "Bleu_3": 0.12091150252325192, "Bleu_4": 0.09037311357156819, "METEOR": 0.21529721936966245, "ROUGE_L": 0.25296208530805686, "CIDEr": 2.360846518786692e-12, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.3125, "f": 0.2325581395348837, "fn": 11.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a person taking a picture of themselves in front of a mirror. The mirror is made of glass and has a frame around it. The person is standing in front of the mirror, holding a camera in their hand. The room is dimly lit and there are some towels hanging on the wall."}, "1554": {"image_id": 1554, "Bleu_1": 0.5263157894459835, "Bleu_2": 0.34199278400988514, "Bleu_3": 1.9019320107005801e-06, "Bleu_4": 4.553719183884792e-09, "METEOR": 0.2647345978037693, "ROUGE_L": 0.42020665901262916, "CIDEr": 0.18958644190990095, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.07142857142857142, "f": 0.08163265306122448, "fn": 26.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2, "f": 0.1904761904761905, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"Three sheep standing in a field with people watching them\""}, "512254": {"image_id": 512254, "Bleu_1": 0.21212121211478424, "Bleu_2": 2.574643252642948e-09, "Bleu_3": 5.979857148051306e-12, "Bleu_4": 2.905613156422152e-13, "METEOR": 0.10720295545579016, "ROUGE_L": 0.15443037974683543, "CIDEr": 1.8030158447645563e-05, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.25, "f": 0.17777777777777778, "fn": 12.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.375, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a group of elephants standing in a field with their trunks sticking out of the ground. They are all looking at each other and seem to be enjoying the sunshine."}, "447522": {"image_id": 447522, "Bleu_1": 0.206349206345931, "Bleu_2": 0.11538133307473705, "Bleu_3": 0.060207014168626206, "Bleu_4": 7.766002120880987e-06, "METEOR": 0.19092166879652214, "ROUGE_L": 0.19273301737756712, "CIDEr": 2.906315599765365e-17, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.25, "f": 0.1714285714285714, "fn": 9.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.6, "f": 0.35294117647058826, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This image shows a plate of food with broccoli, carrots, and rice. The broccoli is cooked and has a green color, while the carrots are sliced and have a orange color. The rice is cooked and has a white color. There is a fork on the plate and a spoon on the side. The plate is on a table with a white background."}, "183889": {"image_id": 183889, "Bleu_1": 0.3333333333232324, "Bleu_2": 0.17677669529119638, "Bleu_3": 0.10026809779454411, "Bleu_4": 1.3539161486777476e-05, "METEOR": 0.26984530432507764, "ROUGE_L": 0.37162750217580504, "CIDEr": 0.0005746776356928197, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.16129032258064516, "f": 0.17241379310344826, "fn": 26.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.07692307692307693, "f": 0.09523809523809525, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a person standing in front of a wall with several cans of soup on it. The person is holding a cell phone to their ear and looking at the cans."}, "313454": {"image_id": 313454, "Bleu_1": 0.4761904761678005, "Bleu_2": 0.43643578045068265, "Bleu_3": 0.3918135478584406, "Bleu_4": 0.34002156195059, "METEOR": 0.29546736784225447, "ROUGE_L": 0.5211289092295956, "CIDEr": 0.22319578385894157, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 15.0, "numImages": 1.0, "fp": 12.0, "tp": 9.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.6666666666666666, "re": 0.8571428571428571, "f": 0.75, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "A man standing at a podium in front of a large screen displaying the image of a person giving a presentation."}, "20438": {"image_id": 20438, "Bleu_1": 0.32727272726677686, "Bleu_2": 0.2806917861017441, "Bleu_3": 0.2183201693257641, "Bleu_4": 0.17785335406888278, "METEOR": 0.27349719375392123, "ROUGE_L": 0.34269662921348315, "CIDEr": 1.0598917177014026e-10, "SPICE": {"All": {"pr": 0.375, "re": 0.32142857142857145, "f": 0.3461538461538462, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 9.0}, "Relation": {"pr": 0.1, "re": 0.2, "f": 0.13333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.09090909090909091, "f": 0.14285714285714288, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.6363636363636364, "re": 0.5833333333333334, "f": 0.6086956521739131, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 7.0}}, "caption": "The image shows a black and white dog lying on a bed with a blue blanket. The dog is looking up at the camera with its eyes closed. The bed is covered in a blue blanket and there are pillows on the bed. The room is dimly lit and there are curtains on the windows."}, "357229": {"image_id": 357229, "Bleu_1": 0.6129032257866805, "Bleu_2": 0.5348097842762262, "Bleu_3": 0.36671068538988416, "Bleu_4": 0.20485811195062104, "METEOR": 0.36391248256792647, "ROUGE_L": 0.49074818986323415, "CIDEr": 0.0334126548806459, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.35714285714285715, "f": 0.30303030303030304, "fn": 9.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a pizza on a plate with cheese and toppings. There is a fork and knife on the plate, and a red and white checkered tablecloth on the table."}, "311081": {"image_id": 311081, "Bleu_1": 0.37777777776938276, "Bleu_2": 0.22696949467458388, "Bleu_3": 0.1338131642598596, "Bleu_4": 1.5454743722279543e-05, "METEOR": 0.2614653375005999, "ROUGE_L": 0.3233929754804506, "CIDEr": 4.545293246470302e-08, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.21052631578947367, "f": 0.1904761904761905, "fn": 15.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a bathroom with a white bathtub, toilet, and sink. The walls are painted white and there is a window on the left side of the room. The floor is made of tiles and there is a shower curtain hanging from the ceiling."}, "561563": {"image_id": 561563, "Bleu_1": 0.47826086954442354, "Bleu_2": 0.36115755924124826, "Bleu_3": 0.2315979476693905, "Bleu_4": 0.15786779060858716, "METEOR": 0.3110654659896386, "ROUGE_L": 0.407119021134594, "CIDEr": 0.08972853148857537, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.2, "f": 0.16216216216216214, "fn": 12.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is a bathroom with a toilet, sink, and shower. The walls are painted green and there is a rug on the floor."}, "191693": {"image_id": 191693, "Bleu_1": 0.253731343279795, "Bleu_2": 0.19607178002098768, "Bleu_3": 0.16057266751851043, "Bleu_4": 0.11802908403777448, "METEOR": 0.2452446339437844, "ROUGE_L": 0.25679919812896757, "CIDEr": 1.7122768712350472e-18, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.3, "f": 0.3076923076923077, "fn": 14.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.6666666666666666, "f": 0.5333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "This is an image of a man playing a guitar on a stage in front of a large audience. He is wearing a suit and tie and is sitting on a stool with his feet up on the edge of the stage. There are microphones and speakers set up on the stage, and a large screen behind him displays the words \"The Beatles\" in bold black letters."}, "379837": {"image_id": 379837, "Bleu_1": 0.5909090908822315, "Bleu_2": 0.37509017673027106, "Bleu_3": 0.27634665580696127, "Bleu_4": 0.1825585845283238, "METEOR": 0.3330914558652968, "ROUGE_L": 0.5036697247706422, "CIDEr": 0.717613032694995, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.1, "f": 0.16216216216216217, "fn": 27.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1111111111111111, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.18181818181818182, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "The woman is holding a cake with candles on it and the child is sitting in a high chair at the table."}, "575088": {"image_id": 575088, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.13719886811129003, "Bleu_3": 0.10484363678213088, "Bleu_4": 0.08324415466849458, "METEOR": 0.2323232258966692, "ROUGE_L": 0.2780626780626781, "CIDEr": 3.35905718374785e-09, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.08695652173913043, "f": 0.10526315789473685, "fn": 21.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.18181818181818182, "f": 0.2222222222222222, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The man in the white suit is sitting on a bench, looking at his phone. He has a book in his hand and is wearing sunglasses. There are people walking by on the sidewalk, some of them carrying bags or shopping. The sky is blue and there are clouds in it."}, "354832": {"image_id": 354832, "Bleu_1": 0.27906976743537054, "Bleu_2": 0.2156655464018017, "Bleu_3": 0.1895147329784242, "Bleu_4": 0.1707889374767856, "METEOR": 0.314426274154418, "ROUGE_L": 0.34882058613295214, "CIDEr": 2.392461478893131e-07, "SPICE": {"All": {"pr": 0.17073170731707318, "re": 0.1794871794871795, "f": 0.17500000000000002, "fn": 32.0, "numImages": 1.0, "fp": 34.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.07692307692307693, "f": 0.08333333333333334, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}}, "caption": "The image shows a group of people playing frisbee in a park. One person is throwing the frisbee while another person is catching it. The other people in the group are watching and cheering. The grass is green and the sky is blue."}, "222332": {"image_id": 222332, "Bleu_1": 0.3265306122382341, "Bleu_2": 0.2182178902314926, "Bleu_3": 0.12654285084562092, "Bleu_4": 1.4487343343293782e-05, "METEOR": 0.2581789931158049, "ROUGE_L": 0.27566171723692706, "CIDEr": 1.1381615415395245e-09, "SPICE": {"All": {"pr": 0.25, "re": 0.23809523809523808, "f": 0.24390243902439024, "fn": 16.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a man in a blue shirt and white shorts playing tennis on a green court. He is holding a tennis racket in his right hand and is about to hit the ball with his left hand. There are several other people watching him from the sidelines."}, "387850": {"image_id": 387850, "Bleu_1": 0.2857142857097506, "Bleu_2": 0.17960530202390107, "Bleu_3": 0.10188560350198986, "Bleu_4": 0.06479579222080305, "METEOR": 0.1734039838919359, "ROUGE_L": 0.19273301737756712, "CIDEr": 1.558945176109631e-18, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.16666666666666666, "f": 0.21621621621621623, "fn": 20.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a group of people standing in front of a bus stop. There are several people standing in line, waiting for the bus to arrive. One woman is sitting on a bench, looking at her phone. The bus stop has a sign that reads, \"Bus Stop\" in English. The scene is taken at a busy intersection with many cars passing by."}, "178810": {"image_id": 178810, "Bleu_1": 0.36363636362534446, "Bleu_2": 0.26111648392551057, "Bleu_3": 0.18756107491702115, "Bleu_4": 0.14482189301937412, "METEOR": 0.28584173390069834, "ROUGE_L": 0.31853785900783294, "CIDEr": 0.00139615869001266, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.1, "f": 0.1081081081081081, "fn": 18.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "This is an image of a fire hydrant on the side of a street. The hydrant is red and has a small handle on top. There are trees and buildings in the background."}, "333303": {"image_id": 333303, "Bleu_1": 0.5294117646747406, "Bleu_2": 0.40674460838530657, "Bleu_3": 0.22259604833645616, "Bleu_4": 2.9792440366740352e-05, "METEOR": 0.20663677130044844, "ROUGE_L": 0.40720961281708945, "CIDEr": 0.5946092078689074, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.16666666666666666, "f": 0.2285714285714286, "fn": 20.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a kitchen with a blender on the counter and a refrigerator in the background."}, "539075": {"image_id": 539075, "Bleu_1": 0.3888888888780865, "Bleu_2": 0.23570226038887507, "Bleu_3": 1.1778306710176523e-06, "Bleu_4": 2.6526726487835123e-09, "METEOR": 0.21561172758239142, "ROUGE_L": 0.2420634920634921, "CIDEr": 5.789642685341095e-05, "SPICE": {"All": {"pr": 0.4, "re": 0.38461538461538464, "f": 0.39215686274509803, "fn": 16.0, "numImages": 1.0, "fp": 15.0, "tp": 10.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.5833333333333334, "re": 0.7, "f": 0.6363636363636365, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 7.0}}, "caption": "Sure, here is a short caption of the image:\n\n\"A group of motorcycles on display at a motorcycle show. The bikes are parked on the floor and there are people standing around them, looking at them.\""}, "61624": {"image_id": 61624, "Bleu_1": 0.34693877550312374, "Bleu_2": 0.19010380264692892, "Bleu_3": 0.09161387440820473, "Bleu_4": 1.1370550193640665e-05, "METEOR": 0.23187708153594813, "ROUGE_L": 0.23091482649842268, "CIDEr": 5.602562494603216e-10, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.125, "f": 0.14814814814814814, "fn": 14.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "This is an image of an airplane on the runway at an airport. The plane is a large jet with a white and red tail and a black nose. It is parked on the runway with its engines running. There are people standing around the plane, looking at it."}, "174567": {"image_id": 174567, "Bleu_1": 0.2758620689560048, "Bleu_2": 0.09925833339360927, "Bleu_3": 7.145896656646382e-07, "Bleu_4": 1.9355268993636575e-09, "METEOR": 0.2518204257774033, "ROUGE_L": 0.23260247855100094, "CIDEr": 0.004029881993169777, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.15, "f": 0.16216216216216214, "fn": 17.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a kitchen with a countertop and stove. There are three laptops on the counter, one with a broken screen and two with their screens turned off."}, "549327": {"image_id": 549327, "Bleu_1": 0.36666666665444453, "Bleu_2": 0.22488822254677632, "Bleu_3": 1.2178443832845925e-06, "Bleu_4": 2.859913561085799e-09, "METEOR": 0.21049174224566372, "ROUGE_L": 0.2350674373795761, "CIDEr": 0.0021372960417309207, "SPICE": {"All": {"pr": 0.375, "re": 0.10344827586206896, "f": 0.16216216216216217, "fn": 26.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.3, "f": 0.4285714285714285, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "This is a man standing in a kitchen with a refrigerator and a microwave. He is holding a bag of groceries and appears to be preparing to put them away."}, "553847": {"image_id": 553847, "Bleu_1": 0.4999999999642858, "Bleu_2": 0.277350098092042, "Bleu_3": 1.8576267964549764e-06, "Bleu_4": 4.913270547748174e-09, "METEOR": 0.1873424440130257, "ROUGE_L": 0.2982885085574572, "CIDEr": 0.5949508273564821, "SPICE": {"All": {"pr": 0.2, "re": 0.18181818181818182, "f": 0.1904761904761905, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The boy is holding a guitar in his hands and smiling at the camera."}, "390283": {"image_id": 390283, "Bleu_1": 0.3571428571343538, "Bleu_2": 0.16165520152449506, "Bleu_3": 8.677070481028558e-07, "Bleu_4": 2.0230829597025574e-09, "METEOR": 0.18559892686472085, "ROUGE_L": 0.22197962154294032, "CIDEr": 3.6416439910536076e-07, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.2222222222222222, "f": 0.27272727272727276, "fn": 21.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.6666666666666666, "f": 0.7058823529411765, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 6.0}}, "caption": "The image shows a man lying on an inflatable raft in the middle of a balcony. He is wearing a red and white striped shirt, a white hat, and sunglasses. The balcony has white curtains and a blue sky in the background."}, "451859": {"image_id": 451859, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.13862658669016847, "Bleu_3": 0.10349919939527817, "Bleu_4": 0.0812021816747775, "METEOR": 0.2591955873417871, "ROUGE_L": 0.24710648148148148, "CIDEr": 8.075799754060368e-12, "SPICE": {"All": {"pr": 0.375, "re": 0.24, "f": 0.2926829268292683, "fn": 19.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.5555555555555556, "f": 0.5882352941176471, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "This is an image of a field filled with colorful kites flying in the sky. There are people standing on the field, watching the kites fly. The sky is clear and blue, with a few clouds scattered about. The image is taken at sunset, with the sun setting behind the trees in the background."}, "276840": {"image_id": 276840, "Bleu_1": 0.378378378368152, "Bleu_2": 0.25112360116008, "Bleu_3": 0.15331300785465152, "Bleu_4": 0.10146459445274897, "METEOR": 0.31369545354618217, "ROUGE_L": 0.3797665369649806, "CIDEr": 3.454025515094603e-05, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.06896551724137931, "f": 0.07272727272727274, "fn": 27.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.08333333333333333, "re": 0.07692307692307693, "f": 0.08, "fn": 12.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "This image shows a group of people standing in front of a snowy mountain slope. They are all wearing ski gear and some are holding skis. The snow is deep and there are trees in the background."}, "74139": {"image_id": 74139, "Bleu_1": 0.37142857141795926, "Bleu_2": 0.276533159369469, "Bleu_3": 0.2100616765893022, "Bleu_4": 0.13045857367564195, "METEOR": 0.2146496738949481, "ROUGE_L": 0.3839496459480724, "CIDEr": 0.00028397305349018876, "SPICE": {"All": {"pr": 0.5, "re": 0.1875, "f": 0.2727272727272727, "fn": 26.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.0625, "f": 0.09523809523809523, "fn": 15.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.16666666666666666, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "This is a pizza with various toppings on it. The crust is golden brown and the cheese is melted. There are also vegetables such as tomatoes, onions, and bell peppers on top of the pizza."}, "235252": {"image_id": 235252, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.11155016321612385, "Bleu_3": 0.06290089214849724, "Bleu_4": 8.441965712987706e-06, "METEOR": 0.14611522008438482, "ROUGE_L": 0.24233825198637912, "CIDEr": 2.0289922760011968e-10, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.18181818181818182, "f": 0.1568627450980392, "fn": 18.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.375, "f": 0.26086956521739135, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA group of giraffes stand in a dry, barren landscape with no trees or vegetation in sight. They are all looking out into the distance, possibly searching for food or water. The sky is clear and blue, with a few clouds scattered about."}, "104893": {"image_id": 104893, "Bleu_1": 0.30952380951644, "Bleu_2": 0.1942853726806771, "Bleu_3": 9.808593569034828e-07, "Bleu_4": 2.217884382453587e-09, "METEOR": 0.2040833236905166, "ROUGE_L": 0.2469635627530364, "CIDEr": 1.75074002206877e-06, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.2222222222222222, "f": 0.17391304347826086, "fn": 14.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This is an image of a train traveling along a track next to a building with a clock tower. The train is yellow and has a number on the side. The building has a tall clock tower and is surrounded by trees."}, "446459": {"image_id": 446459, "Bleu_1": 0.1730769230735947, "Bleu_2": 0.08238525545556362, "Bleu_3": 5.139367340347396e-07, "Bleu_4": 1.2901292604257922e-09, "METEOR": 0.14297087806822814, "ROUGE_L": 0.15024630541871922, "CIDEr": 6.292316678695152e-11, "SPICE": {"All": {"pr": 0.058823529411764705, "re": 0.05263157894736842, "f": 0.05555555555555555, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA zebra stands in a fenced enclosure, looking at the camera. The zebra has a long, striped coat and a long mane. The fence is made of wood and has a gate that is open. There are trees and bushes in the background."}, "549167": {"image_id": 549167, "Bleu_1": 0.36842105262188374, "Bleu_2": 0.22312917498915605, "Bleu_3": 0.14037186543654434, "Bleu_4": 0.09428509488367463, "METEOR": 0.23054905674584505, "ROUGE_L": 0.28728414442700156, "CIDEr": 5.4494865205132896e-06, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.18518518518518517, "f": 0.19607843137254902, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This image shows a plate of food with broccoli, almonds, and rice. The food is arranged in a neat and organized manner on the plate. The background is white and there are no other objects in the image."}, "18519": {"image_id": 18519, "Bleu_1": 0.2857142857097506, "Bleu_2": 0.20365326998738056, "Bleu_3": 0.12682106573097573, "Bleu_4": 0.07635820950311076, "METEOR": 0.2382013168705496, "ROUGE_L": 0.21664129883307962, "CIDEr": 1.269577212809652e-16, "SPICE": {"All": {"pr": 0.1, "re": 0.15, "f": 0.12, "fn": 17.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a skateboarder performing a trick on a halfpipe in a park. The skateboarder is wearing black pants and a black shirt, and has a helmet on his head. The halfpipe is made of concrete and has a blue and green graffiti design on it. The skateboarder is jumping off the edge of the halfpipe and landing on the other side."}, "528786": {"image_id": 528786, "Bleu_1": 0.18181818181582055, "Bleu_2": 0.09782319760762491, "Bleu_3": 0.050343199759815306, "Bleu_4": 6.443883521707754e-06, "METEOR": 0.16919894413715483, "ROUGE_L": 0.17843710823234432, "CIDEr": 1.5711284005394522e-25, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.3333333333333333, "f": 0.1951219512195122, "fn": 8.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.2, "f": 0.13333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a large statue of a woman on horseback, standing on a pedestal in the middle of a park. The statue is made of bronze and has intricate details, including the woman's hair and the horse's mane. In the background, there are several people walking on the sidewalk and a red double-decker bus driving by. The statue appears to be a popular tourist attraction, as there are several people taking pictures of it."}, "156756": {"image_id": 156756, "Bleu_1": 0.27272727272107444, "Bleu_2": 0.17807996398101744, "Bleu_3": 0.09105985252795226, "Bleu_4": 1.1649284258883924e-05, "METEOR": 0.267135860917685, "ROUGE_L": 0.32620320855614976, "CIDEr": 2.256666867592124e-07, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.17647058823529413, "f": 0.20000000000000004, "fn": 14.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "A man is riding a brown horse through a herd of cows in a barn. The man is wearing a cowboy hat and holding onto the reins of the horse. The cows are standing in the background, looking at the man and the horse."}, "433204": {"image_id": 433204, "Bleu_1": 0.30357142856600766, "Bleu_2": 0.1661246598082537, "Bleu_3": 7.995116869126861e-07, "Bleu_4": 1.7621774723973468e-09, "METEOR": 0.20058309037900873, "ROUGE_L": 0.22858672376873657, "CIDEr": 7.232835092631828e-13, "SPICE": {"All": {"pr": 0.12195121951219512, "re": 0.23809523809523808, "f": 0.16129032258064516, "fn": 16.0, "numImages": 1.0, "fp": 36.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2857142857142857, "f": 0.2105263157894737, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "The image shows a group of people riding motorcycles down a street in front of a building with a blue roof. There are trees on either side of the road and a few cars parked on the side of the road. The sky is cloudy and there are no other people or vehicles in the image."}, "203201": {"image_id": 203201, "Bleu_1": 0.26829268292028563, "Bleu_2": 0.2166823008689824, "Bleu_3": 0.16886802358325678, "Bleu_4": 0.13963522201453288, "METEOR": 0.32357350361707465, "ROUGE_L": 0.32520944402132523, "CIDEr": 1.040032198149337e-06, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.1, "f": 0.10714285714285714, "fn": 27.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2727272727272727, "f": 0.23076923076923075, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "This is a black and white photograph of a young boy holding a baseball bat. He is standing in the middle of a grassy field, wearing a white shirt and blue pants. The background is a clear sky with some clouds."}, "522940": {"image_id": 522940, "Bleu_1": 0.4999999999833334, "Bleu_2": 0.37139067634151063, "Bleu_3": 0.17015105805045755, "Bleu_4": 2.066736214400286e-05, "METEOR": 0.22782302105360097, "ROUGE_L": 0.3846846846846847, "CIDEr": 0.025399289203656885, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.2692307692307692, "f": 0.2916666666666667, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a stop sign on the side of a road with snow-covered mountains in the background. The sign has the words \"stop\" written on it in white letters."}, "202507": {"image_id": 202507, "Bleu_1": 0.30769230768441824, "Bleu_2": 0.20121090914115636, "Bleu_3": 1.0304662546247208e-06, "Bleu_4": 2.3480087200537226e-09, "METEOR": 0.24301808870539743, "ROUGE_L": 0.1931908155186065, "CIDEr": 4.379169656038042e-06, "SPICE": {"All": {"pr": 0.28, "re": 0.30434782608695654, "f": 0.2916666666666667, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.45454545454545453, "f": 0.45454545454545453, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "There are several baskets filled with apples, oranges, and other fruits on display. The apples are red, green, and yellow, while the oranges are yellow and green. The other fruits are also various colors, including red, green, and yellow."}, "390463": {"image_id": 390463, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.15649215928402857, "Bleu_3": 0.10067569617030046, "Bleu_4": 0.06826042950277836, "METEOR": 0.17721649358022842, "ROUGE_L": 0.1937738246505718, "CIDEr": 1.7179087128764707e-10, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.2, "f": 0.1951219512195122, "fn": 16.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "A table with a cupcake on it, surrounded by other cupcakes and a sign that says \"Happy Birthday\"\n\nThe image shows a table with a cupcake on it, surrounded by other cupcakes and a sign that says \"Happy Birthday\". The cupcakes are decorated with blue and pink frosting and sprinkles."}, "531324": {"image_id": 531324, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.08347838711095647, "Bleu_3": 5.585079625938627e-07, "Bleu_4": 1.4538040525271515e-09, "METEOR": 0.12392426850258176, "ROUGE_L": 0.20962199312714774, "CIDEr": 6.495951644001241e-08, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.2, "f": 0.1923076923076923, "fn": 20.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.5, "f": 0.41666666666666663, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a street with several bicycles parked on the side of the road. There are buildings on either side of the street, with windows and balconies visible. The sky is clear and blue, with a few clouds scattered across it."}, "576667": {"image_id": 576667, "Bleu_1": 0.28205128204405006, "Bleu_2": 0.22794037622152502, "Bleu_3": 0.19148595889172806, "Bleu_4": 0.16712525121349192, "METEOR": 0.3689031915750566, "ROUGE_L": 0.386381631037213, "CIDEr": 2.749773342188301e-06, "SPICE": {"All": {"pr": 0.2413793103448276, "re": 0.30434782608695654, "f": 0.2692307692307692, "fn": 16.0, "numImages": 1.0, "fp": 22.0, "tp": 7.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.125, "f": 0.1, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6, "re": 0.3333333333333333, "f": 0.42857142857142855, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.75, "f": 0.8571428571428571, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This is a bathroom with a toilet, sink, and mirror. The walls are made of wood and the floor is made of tile. There is a window on one side of the room and a door on the other."}, "44068": {"image_id": 44068, "Bleu_1": 0.3333333333253969, "Bleu_2": 0.2385593618010997, "Bleu_3": 0.1923243679468048, "Bleu_4": 0.1643518441152205, "METEOR": 0.3345181851949059, "ROUGE_L": 0.3551673944687045, "CIDEr": 5.744115369692785e-07, "SPICE": {"All": {"pr": 0.22580645161290322, "re": 0.2413793103448276, "f": 0.23333333333333334, "fn": 22.0, "numImages": 1.0, "fp": 24.0, "tp": 7.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.08333333333333333, "f": 0.08333333333333333, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}}, "caption": "The image shows a brown teddy bear sitting on a wooden chair in front of a window. The chair has a red and white striped cushion and a wooden backrest. The window has a view of a garden with trees and flowers."}, "399790": {"image_id": 399790, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.17039568890752202, "Bleu_3": 0.15160009862142101, "Bleu_4": 0.13731503563402134, "METEOR": 0.30004421782082114, "ROUGE_L": 0.330722891566265, "CIDEr": 2.122774718083492e-11, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.08333333333333333, "f": 0.08, "fn": 22.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.2857142857142857, "f": 0.19047619047619047, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "The image shows a baseball player pitching a ball on a field. The player is wearing a red and white uniform and has a glove on their right hand. The catcher is standing behind home plate, ready to catch the ball. The background is a green grass field with a dirt infield."}, "462371": {"image_id": 462371, "Bleu_1": 0.25396825396422273, "Bleu_2": 0.16933350266421118, "Bleu_3": 0.11213961682443135, "Bleu_4": 0.06962761002916071, "METEOR": 0.23300959123040266, "ROUGE_L": 0.22485518694049497, "CIDEr": 8.166403171118378e-17, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.12121212121212122, "f": 0.12903225806451615, "fn": 29.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "This is a black and white photograph of a group of people gathered around a table with a cake on it. The people are all smiling and looking at the cake. There are some candles on the table and a few people are holding glasses of champagne. The background is a dark room with a few chairs and a table in the foreground."}, "547783": {"image_id": 547783, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.20966962740242623, "Bleu_3": 0.15869361519057593, "Bleu_4": 0.1292209085410068, "METEOR": 0.33057029422489065, "ROUGE_L": 0.2969401947148818, "CIDEr": 4.088130213421649e-09, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.26666666666666666, "f": 0.21621621621621623, "fn": 11.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This image shows a group of giraffes standing in a field with a blue sky in the background. The giraffes are all looking up at the sky, as if they are watching something. The grass is green and there are no other animals in the field."}, "296524": {"image_id": 296524, "Bleu_1": 0.32499999999187507, "Bleu_2": 0.24152294576370853, "Bleu_3": 0.14534086179176417, "Bleu_4": 1.6972287007198145e-05, "METEOR": 0.328339725437948, "ROUGE_L": 0.31961077844311375, "CIDEr": 1.3752679794507786e-05, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.18181818181818182, "f": 0.15384615384615383, "fn": 18.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.125, "f": 0.10526315789473685, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This is a man wearing a blue shirt and holding a red scarf in his hand. He is standing in front of a wooden table with a painting on it. There are several paintings on the walls in the background."}, "165522": {"image_id": 165522, "Bleu_1": 0.7999999999200001, "Bleu_2": 0.5962847939370028, "Bleu_3": 0.3542195230211848, "Bleu_4": 5.019724248194722e-05, "METEOR": 0.3025667339240407, "ROUGE_L": 0.5729492798998121, "CIDEr": 1.0461912334525896, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.2222222222222222, "f": 0.16666666666666669, "fn": 14.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "A man and woman walking on the beach with surfboards."}, "424192": {"image_id": 424192, "Bleu_1": 0.22033898304711294, "Bleu_2": 0.12327121291697288, "Bleu_3": 6.436001859611395e-07, "Bleu_4": 1.4771177397808513e-09, "METEOR": 0.16343289149013646, "ROUGE_L": 0.19192448872574724, "CIDEr": 3.7943851943087795e-14, "SPICE": {"All": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 14.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is an image of a room with a bed, a table, and a chair. The walls are made of stone and there is a large wooden door in the background. The floor is made of wood and there is a rug on it. There is a small window on the wall and a chandelier hanging from the ceiling."}, "232760": {"image_id": 232760, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.14580296087694455, "Bleu_3": 0.07676176340636935, "Bleu_4": 9.95793413350648e-06, "METEOR": 0.27990297128553343, "ROUGE_L": 0.27566171723692706, "CIDEr": 7.798112724326694e-10, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.16666666666666666, "f": 0.14545454545454548, "fn": 20.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3333333333333333, "f": 0.27272727272727276, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a person standing on the beach holding a surfboard. The sun is shining down on the person and the waves are crashing on the shore. The person is wearing a black wetsuit and sunglasses. The beach is sandy and there are some rocks in the background."}, "369998": {"image_id": 369998, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.20782052056698208, "Bleu_3": 0.10174919922777484, "Bleu_4": 1.2738938828213386e-05, "METEOR": 0.22227038339794655, "ROUGE_L": 0.2616154395997141, "CIDEr": 1.2723586661957395e-07, "SPICE": {"All": {"pr": 0.4444444444444444, "re": 0.18181818181818182, "f": 0.2580645161290322, "fn": 18.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.18181818181818182, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.6666666666666666, "re": 0.2857142857142857, "f": 0.4, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "The image is a stuffed animal, a teddy bear, sitting on a pink background. The bear is made of soft, fluffy material and has big, round eyes and a cute, smiling face. The bear is wearing a small, white collar around its neck."}, "134213": {"image_id": 134213, "Bleu_1": 0.5185185184993142, "Bleu_2": 0.3459163477621225, "Bleu_3": 0.2123296873626401, "Bleu_4": 2.5130737266766878e-05, "METEOR": 0.2237100608510976, "ROUGE_L": 0.41391009329940626, "CIDEr": 0.02132382598259641, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.3076923076923077, "f": 0.3076923076923077, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.75, "f": 0.6666666666666665, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This is a photo of a wall with a clock hanging on it. The clock has a large face and is surrounded by other signs and advertisements."}, "539453": {"image_id": 539453, "Bleu_1": 0.2727272727223141, "Bleu_2": 0.1880253582691385, "Bleu_3": 0.13869867869725044, "Bleu_4": 0.1113867982641246, "METEOR": 0.21752341532093597, "ROUGE_L": 0.2513243084167157, "CIDEr": 7.525590661977015e-13, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.10526315789473684, "f": 0.125, "fn": 17.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a group of people playing frisbee on a grassy field. They are all wearing casual clothing and are standing in a circle around the frisbee. One person is throwing the frisbee while the others watch and try to catch it. The sky is clear and blue, with some clouds in the distance."}, "18982": {"image_id": 18982, "Bleu_1": 0.4999999999166667, "Bleu_2": 0.3015113445263697, "Bleu_3": 2.0870640220585245e-06, "Bleu_4": 5.63756031424638e-09, "METEOR": 0.2145902585327078, "ROUGE_L": 0.43821839080459773, "CIDEr": 0.6392599068409401, "SPICE": {"All": {"pr": 0.1, "re": 0.1111111111111111, "f": 0.10526315789473685, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The man is sitting on a bus, talking on his cell phone."}, "338153": {"image_id": 338153, "Bleu_1": 0.2424242424168963, "Bleu_2": 0.15075567228424214, "Bleu_3": 0.09016995990182317, "Bleu_4": 1.2503053621425558e-05, "METEOR": 0.15138742089416973, "ROUGE_L": 0.21922731356693623, "CIDEr": 0.00026638531186456017, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.21739130434782608, "f": 0.2127659574468085, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a traffic light at an intersection with a red and green light on the top and bottom respectively. There are also pedestrian crossing signs on the side of the road."}, "31620": {"image_id": 31620, "Bleu_1": 0.3124999999951172, "Bleu_2": 0.22271770159017942, "Bleu_3": 0.1686901318572603, "Bleu_4": 0.14084041646300657, "METEOR": 0.3098192957785291, "ROUGE_L": 0.2853430353430354, "CIDEr": 7.602762643871812e-12, "SPICE": {"All": {"pr": 0.1875, "re": 0.15, "f": 0.16666666666666663, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "This is a photo of a bride and groom cutting their wedding cake at a reception. The bride is wearing a white wedding dress and the groom is wearing a black tuxedo. They are standing in front of a large tent with colorful streamers and balloons hanging from the ceiling. There are several guests standing around the table, watching the couple cut their cake."}, "325992": {"image_id": 325992, "Bleu_1": 0.35999999998560006, "Bleu_2": 0.2738612787414004, "Bleu_3": 0.18683338156585433, "Bleu_4": 0.1312155138590171, "METEOR": 0.19387279314286404, "ROUGE_L": 0.3096446700507614, "CIDEr": 0.03827212300223968, "SPICE": {"All": {"pr": 0.0975609756097561, "re": 0.18181818181818182, "f": 0.12698412698412698, "fn": 18.0, "numImages": 1.0, "fp": 37.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 16.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}}, "caption": "The image shows a desk with a laptop on it, a pair of sunglasses on the table, and a cup of coffee on the side."}, "55840": {"image_id": 55840, "Bleu_1": 0.5862068965315101, "Bleu_2": 0.43407792538548917, "Bleu_3": 0.3033499140529261, "Bleu_4": 0.2152643286704308, "METEOR": 0.2617368011081236, "ROUGE_L": 0.44976958525345617, "CIDEr": 0.06260915224235995, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.07407407407407407, "f": 0.07843137254901962, "fn": 25.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a black cat sitting on a windowsill, looking out the window at night. There is a glass of wine on the windowsill next to the cat."}, "32708": {"image_id": 32708, "Bleu_1": 0.35135135134185547, "Bleu_2": 0.2613777310992162, "Bleu_3": 0.22709459150255668, "Bleu_4": 0.20371727825395644, "METEOR": 0.2673854041650235, "ROUGE_L": 0.3596168017686072, "CIDEr": 0.00012782720133821548, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.10344827586206896, "f": 0.10714285714285715, "fn": 26.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.2727272727272727, "f": 0.24999999999999994, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This is a man sitting on the floor with a white shirt on and glasses on his face. He is holding a pair of headphones in his hand and has a look of concentration on his face."}, "20774": {"image_id": 20774, "Bleu_1": 0.4999999999750001, "Bleu_2": 0.3627381250363917, "Bleu_3": 0.24452013829061922, "Bleu_4": 0.17124730448017517, "METEOR": 0.36205317938916587, "ROUGE_L": 0.44417475728155337, "CIDEr": 0.4719659000431581, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.10526315789473684, "f": 0.11764705882352941, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "This is an image of a group of people walking down a sidewalk in front of a building with umbrellas."}, "471450": {"image_id": 471450, "Bleu_1": 0.17543859648815024, "Bleu_2": 0.1480872194371519, "Bleu_3": 0.11683621692619879, "Bleu_4": 0.08766821695974851, "METEOR": 0.19468734758454892, "ROUGE_L": 0.18187239117471676, "CIDEr": 1.786851399681752e-14, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.23076923076923078, "f": 0.22222222222222224, "fn": 20.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a group of brown bears standing in a grassy field. They are looking at something in the distance, possibly a bird or other wildlife. The bears are standing in a line, with one standing in the front and the others behind him. The background is a green field with some trees in the distance."}, "123627": {"image_id": 123627, "Bleu_1": 0.2833333333286111, "Bleu_2": 0.15495579832397718, "Bleu_3": 0.07452967430537745, "Bleu_4": 9.231626041864584e-06, "METEOR": 0.20317961118390418, "ROUGE_L": 0.1937738246505718, "CIDEr": 9.13326554711556e-13, "SPICE": {"All": {"pr": 0.35, "re": 0.4117647058823529, "f": 0.37837837837837834, "fn": 10.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.25, "re": 0.4, "f": 0.3076923076923077, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.8, "f": 0.5714285714285714, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a horse race taking place on a track with a crowd of people watching from the stands. The horses are racing in a straight line, with one horse leading the other. The crowd is cheering and waving their arms as they watch the race. The sky is clear and blue, with some clouds visible in the distance."}, "145436": {"image_id": 145436, "Bleu_1": 0.6666666666296297, "Bleu_2": 0.4428074427447238, "Bleu_3": 0.2305525590301582, "Bleu_4": 3.006454568869563e-05, "METEOR": 0.37217436143572996, "ROUGE_L": 0.3696969696969697, "CIDEr": 0.5217745137249604, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.16, "f": 0.1818181818181818, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.2727272727272727, "f": 0.3157894736842105, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a cutting board with several oranges on it, a glass of juice, and a knife."}, "246590": {"image_id": 246590, "Bleu_1": 0.4324324324207451, "Bleu_2": 0.26846242207825327, "Bleu_3": 0.18348760816953266, "Bleu_4": 0.11610083023204879, "METEOR": 0.31845519726768123, "ROUGE_L": 0.3797665369649806, "CIDEr": 6.940454401590401e-05, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.2, "f": 0.21428571428571427, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a yellow motorcycle parked on the side of the road with its front tire raised and a bicycle rack attached to the back. There are people walking by and a few bicycles parked nearby."}, "430681": {"image_id": 430681, "Bleu_1": 0.36585365852766216, "Bleu_2": 0.25303041366748835, "Bleu_3": 0.14862901964760822, "Bleu_4": 0.09641215953986118, "METEOR": 0.1882066637247387, "ROUGE_L": 0.31916285153695223, "CIDEr": 7.1861905438385575e-06, "SPICE": {"All": {"pr": 0.25, "re": 0.04878048780487805, "f": 0.0816326530612245, "fn": 39.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 12.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image shows a brown bear standing in a stream, drinking water. The bear is standing on the rocks in the stream, and its fur is wet from the water. There are trees and greenery in the background of the image."}, "359136": {"image_id": 359136, "Bleu_1": 0.5357142856951531, "Bleu_2": 0.3149703941628988, "Bleu_3": 0.15626271772175815, "Bleu_4": 1.9765441872602017e-05, "METEOR": 0.30779444493909364, "ROUGE_L": 0.37720848056537104, "CIDEr": 0.054690329468490576, "SPICE": {"All": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 21.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Relation": {"pr": 0.5, "re": 0.1111111111111111, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image shows a woman lying on the floor in a bathroom. She is wearing black boots and a black top. There is a bathtub in the background."}, "399349": {"image_id": 399349, "Bleu_1": 0.18518518518175586, "Bleu_2": 0.10238251947041137, "Bleu_3": 5.863398711091723e-07, "Bleu_4": 1.410001343225771e-09, "METEOR": 0.1966603159859255, "ROUGE_L": 0.2445589919816724, "CIDEr": 6.038049434439856e-11, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.125, "f": 0.10256410256410256, "fn": 14.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "A man is riding a horse down a dirt road in front of a small shack. The man is wearing a cowboy hat and holding the reins of the horse with his left hand. The horse is brown and has a saddle on its back. In the background, there are several dogs running around."}, "523677": {"image_id": 523677, "Bleu_1": 0.2727272727223141, "Bleu_2": 0.14213381090113214, "Bleu_3": 0.09135163170376533, "Bleu_4": 1.1003640569767388e-05, "METEOR": 0.18469054759486808, "ROUGE_L": 0.22724853645556145, "CIDEr": 1.2757164898145312e-11, "SPICE": {"All": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 18.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "This is a view of a pizza shop with several pizzas on display in the window. There are two cashiers behind the counter, one of whom is ringing up an order. The other is taking a drink from the refrigerator. The walls are painted white and there are several tables and chairs in the background."}, "309900": {"image_id": 309900, "Bleu_1": 0.31645569619852587, "Bleu_2": 0.22064789081753303, "Bleu_3": 0.14676627777011084, "Bleu_4": 0.10569309745607565, "METEOR": 0.25976466461233916, "ROUGE_L": 0.2728751525010167, "CIDEr": 2.922908120711203e-19, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.16, "f": 0.14814814814814817, "fn": 21.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "This is a picture of a man standing in front of a television with a remote control in his hand. He is wearing white sneakers and a black shirt. There are two other men sitting on the couch in the background, one of them is holding a controller and the other is playing a video game on the television. The room is well lit and there are no other objects in the room besides the television and the furniture."}, "14557": {"image_id": 14557, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.22430886163262467, "Bleu_3": 0.1426495013657782, "Bleu_4": 0.08685806487299262, "METEOR": 0.20561643138369043, "ROUGE_L": 0.29151732377538825, "CIDEr": 8.125180503792536e-11, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.2, "f": 0.2380952380952381, "fn": 20.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.125, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a large, ornate building with a clock tower on top. The clock face is visible on the front of the building, with the hands pointing to 12 o'clock. The building appears to be made of stone and has a large, arched entrance. The sky is clear and blue behind the building."}, "191381": {"image_id": 191381, "Bleu_1": 0.47999999998080006, "Bleu_2": 0.4242640686946045, "Bleu_3": 0.3151627539628544, "Bleu_4": 0.23096862759339423, "METEOR": 0.28799152982758025, "ROUGE_L": 0.4182174338883448, "CIDEr": 0.06556240838904948, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.16666666666666666, "f": 0.1276595744680851, "fn": 15.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2857142857142857, "f": 0.2105263157894737, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "This is a bathroom with a toilet and a sink. The floor is made of concrete and there is a blue mop on the ground."}, "267571": {"image_id": 267571, "Bleu_1": 0.3846153846005918, "Bleu_2": 0.3038218101131809, "Bleu_3": 0.19740230336695266, "Bleu_4": 0.1352328506594843, "METEOR": 0.2769530545893443, "ROUGE_L": 0.3131416837782341, "CIDEr": 0.03763937843498887, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.16, "f": 0.2105263157894737, "fn": 21.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4, "f": 0.47058823529411764, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a giraffe standing in a field with a fence in the background. The giraffe has a long neck and spots on its fur."}, "322654": {"image_id": 322654, "Bleu_1": 0.3749999999882814, "Bleu_2": 0.245934688411173, "Bleu_3": 0.1263298870441362, "Bleu_4": 1.6237908183879646e-05, "METEOR": 0.24132269459663325, "ROUGE_L": 0.31551724137931036, "CIDEr": 0.000511058348233145, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.13333333333333333, "f": 0.1111111111111111, "fn": 13.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A group of people are sitting on the sidewalk, looking at their phones. The street sign in the background reads 'Hudson River Drive.'\""}, "553667": {"image_id": 553667, "Bleu_1": 0.255813953482423, "Bleu_2": 0.19116707482361836, "Bleu_3": 0.13879948748981807, "Bleu_4": 0.0904223727483559, "METEOR": 0.21842392322346887, "ROUGE_L": 0.22377109317681584, "CIDEr": 1.8884193500697433e-07, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.09523809523809523, "f": 0.08163265306122448, "fn": 19.0, "numImages": 1.0, "fp": 26.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a young girl holding a sandwich in her hand, with a look of concentration on her face. She is wearing a green shirt and has her hair in braids. The background is a dark brown table with a checkered pattern."}, "214698": {"image_id": 214698, "Bleu_1": 0.21739130434310025, "Bleu_2": 0.12038585308312308, "Bleu_3": 0.06906098117642889, "Bleu_4": 9.355294087801786e-06, "METEOR": 0.24050069706080843, "ROUGE_L": 0.24830393487109906, "CIDEr": 1.0662993378992869e-08, "SPICE": {"All": {"pr": 0.0967741935483871, "re": 0.1, "f": 0.09836065573770492, "fn": 27.0, "numImages": 1.0, "fp": 28.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is an image of a street with a stop sign in the middle of the road. There are houses on either side of the street and a tree in the background. The sky is cloudy and there are no cars or people in the image."}, "271240": {"image_id": 271240, "Bleu_1": 0.19047619047316708, "Bleu_2": 0.07838618016570782, "Bleu_3": 0.04652821474121839, "Bleu_4": 6.401024350662979e-06, "METEOR": 0.183328859607645, "ROUGE_L": 0.1856925418569254, "CIDEr": 4.69962929039338e-16, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.15384615384615385, "f": 0.14545454545454548, "fn": 22.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.15384615384615385, "f": 0.1904761904761905, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "This image shows a snow covered road with two stop signs on either side. The road is covered in snow and there are no cars or people in sight. The stop signs are covered in snow and have white letters on them that read \"stop\" in English. The image is taken from a high angle, looking down on the road and stop signs."}, "406959": {"image_id": 406959, "Bleu_1": 0.22413793103061835, "Bleu_2": 0.15360164850632854, "Bleu_3": 0.0944520178886516, "Bleu_4": 1.1125454403138954e-05, "METEOR": 0.1850722558125967, "ROUGE_L": 0.259298618490967, "CIDEr": 2.8722995397571444e-14, "SPICE": {"All": {"pr": 0.12121212121212122, "re": 0.14814814814814814, "f": 0.13333333333333333, "fn": 23.0, "numImages": 1.0, "fp": 29.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.3333333333333333, "f": 0.2962962962962963, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "This is a close up of a clock tower in the city. The clock has two large faces on either side of it, one with Roman numerals and the other with Arabic numerals. The clock is mounted on a tall pole and has a decorative design on the top. The sky is clear and blue in the background."}, "575624": {"image_id": 575624, "Bleu_1": 0.5348837209177935, "Bleu_2": 0.4222494211186315, "Bleu_3": 0.3516560468460581, "Bleu_4": 0.29535755172478995, "METEOR": 0.39040390608841774, "ROUGE_L": 0.5022165927802406, "CIDEr": 6.6761763793930365e-06, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.15384615384615385, "f": 0.20512820512820515, "fn": 22.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "This is an image of a barn with cows grazing in the field. The barn is made of wood and has a red roof. There are several cows lying on the grass in front of the barn. The sky is clear and blue."}, "565813": {"image_id": 565813, "Bleu_1": 0.3999999999885715, "Bleu_2": 0.265684465654326, "Bleu_3": 0.18582888161281605, "Bleu_4": 0.14151579458703112, "METEOR": 0.19025249696479538, "ROUGE_L": 0.34487632508833926, "CIDEr": 0.0012732830482684381, "SPICE": {"All": {"pr": 0.18421052631578946, "re": 0.21875, "f": 0.19999999999999998, "fn": 25.0, "numImages": 1.0, "fp": 31.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.09090909090909091, "f": 0.09523809523809525, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.35294117647058826, "re": 0.5454545454545454, "f": 0.42857142857142855, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}}, "caption": "The image shows a large ship traveling through the water with the Statue of Liberty in the background. The sky is cloudy and there is a lot of smoke coming from the ship's smokestack."}, "544071": {"image_id": 544071, "Bleu_1": 0.9090909089256201, "Bleu_2": 0.6741998623375959, "Bleu_3": 0.4657164750911581, "Bleu_4": 5.960994272089826e-05, "METEOR": 0.2913218815995116, "ROUGE_L": 0.4803149606299213, "CIDEr": 0.9230603872131429, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 12.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.6, "f": 0.35294117647058826, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "A group of zebras graze in a field surrounded by trees."}, "185335": {"image_id": 185335, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.20957473279408315, "Bleu_3": 0.09641854808598063, "Bleu_4": 1.1689882104179119e-05, "METEOR": 0.22198024999302526, "ROUGE_L": 0.2544392801811465, "CIDEr": 7.0422343895083486e-09, "SPICE": {"All": {"pr": 0.08823529411764706, "re": 0.15789473684210525, "f": 0.11320754716981131, "fn": 16.0, "numImages": 1.0, "fp": 31.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.42857142857142855, "f": 0.3, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The laptop is sitting on a desk in a room with a window in the background. There is a television in the corner of the room, and a bookshelf to the left of the laptop. The laptop has a screen that is displaying a website with images and text on it."}, "573094": {"image_id": 573094, "Bleu_1": 0.42857142856122454, "Bleu_2": 0.3825460278287837, "Bleu_3": 0.34268889343744235, "Bleu_4": 0.29153008557685195, "METEOR": 0.32179019092783806, "ROUGE_L": 0.4220125786163522, "CIDEr": 4.868199267082827e-05, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.13636363636363635, "f": 0.1395348837209302, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2, "f": 0.1904761904761905, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "This is a living room with a Christmas tree in the corner. There are two chairs in front of the television and a couch in the background. The walls are painted white and there are windows on either side of the room."}, "485951": {"image_id": 485951, "Bleu_1": 0.31914893616342244, "Bleu_2": 0.2355932146939368, "Bleu_3": 0.15467190426812086, "Bleu_4": 1.7029245450294905e-05, "METEOR": 0.23282544654072282, "ROUGE_L": 0.30367143746110764, "CIDEr": 1.686840352114998e-07, "SPICE": {"All": {"pr": 0.5, "re": 0.17857142857142858, "f": 0.2631578947368421, "fn": 23.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.09090909090909091, "f": 0.16666666666666669, "fn": 10.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.3333333333333333, "f": 0.42857142857142855, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This image shows a kitchen with wooden cabinets and black appliances. The countertops are made of granite and the floor is made of hardwood. There is a refrigerator, stove, and dishwasher in the kitchen. The walls are painted white and there are no windows in the room."}, "310879": {"image_id": 310879, "Bleu_1": 0.4374999999726563, "Bleu_2": 0.3818813078883236, "Bleu_3": 0.27516060405615367, "Bleu_4": 3.5579828676919246e-05, "METEOR": 0.19378079595226191, "ROUGE_L": 0.4212707182320442, "CIDEr": 0.35117714584267046, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.34782608695652173, "f": 0.32653061224489793, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 8.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5384615384615384, "re": 0.6363636363636364, "f": 0.5833333333333334, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 7.0}}, "caption": "A flock of birds standing in the water with their heads tilted downwards, looking for food."}, "339368": {"image_id": 339368, "Bleu_1": 0.4999999999821429, "Bleu_2": 0.27216552696600854, "Bleu_3": 1.4176345675574154e-06, "Bleu_4": 3.2672940260811183e-09, "METEOR": 0.2529027043801177, "ROUGE_L": 0.34528301886792445, "CIDEr": 0.031967971411051156, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.08333333333333333, "f": 0.0930232558139535, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A street scene in a coastal town with green buildings and cars parked on the side of the road.\""}, "115412": {"image_id": 115412, "Bleu_1": 0.26315789472991696, "Bleu_2": 0.18857857159614894, "Bleu_3": 0.09959267428089767, "Bleu_4": 1.2961448381185112e-05, "METEOR": 0.19397752772480223, "ROUGE_L": 0.2793893129770992, "CIDEr": 9.107481274374148e-06, "SPICE": {"All": {"pr": 0.5, "re": 0.26666666666666666, "f": 0.3478260869565218, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.2, "f": 0.33333333333333337, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.5, "f": 0.6, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image shows a small, yellow, and white candle sitting on top of a white surface. The candle has a small, white, and yellow flower on top of it. There is a cell phone next to the candle."}, "144694": {"image_id": 144694, "Bleu_1": 0.3829787233961069, "Bleu_2": 0.2235033479141667, "Bleu_3": 0.1304553364641582, "Bleu_4": 1.4987638789540041e-05, "METEOR": 0.22982633583465575, "ROUGE_L": 0.2621883826599533, "CIDEr": 1.6056366404353573e-07, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.19047619047619047, "f": 0.20512820512820512, "fn": 17.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a soccer game being played on a field with a goal at each end. There are two teams of players in orange and blue uniforms, with one player in white and black stripes. The players are running and kicking the ball on the field."}, "160728": {"image_id": 160728, "Bleu_1": 0.2343749999963379, "Bleu_2": 0.1363861813953473, "Bleu_3": 6.694472319171738e-07, "Bleu_4": 1.4892060909898447e-09, "METEOR": 0.14132745565705393, "ROUGE_L": 0.2029467680608365, "CIDEr": 1.7841778309847653e-16, "SPICE": {"All": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.42857142857142855, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "This image shows a group of people standing on the beach in front of a body of water. There are several boats in the water, and people are standing on the shore, some of them holding surfboards. The sky is clear and blue, with a few clouds scattered across it. The landscape is rocky and hilly, with trees and bushes growing on the hillsides."}, "56250": {"image_id": 56250, "Bleu_1": 0.2419354838670656, "Bleu_2": 0.15426254515919732, "Bleu_3": 0.0734722339356085, "Bleu_4": 9.054811853820704e-06, "METEOR": 0.16233378013300329, "ROUGE_L": 0.22147302904564312, "CIDEr": 1.4094891885928132e-16, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.21212121212121213, "f": 0.23728813559322037, "fn": 26.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5454545454545454, "f": 0.6, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "This image shows a table set up for a wedding reception. There is a white tablecloth on the table and a white wedding dress on top of it. There are also two chairs at the table, one with a black suit on it and the other with a white dress on it. The room has a dark wood floor and white walls."}, "462840": {"image_id": 462840, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.17842851423634928, "Bleu_3": 0.10987673829748816, "Bleu_4": 0.07288780213290265, "METEOR": 0.2380080142378576, "ROUGE_L": 0.29372312983662946, "CIDEr": 6.03056660504002e-09, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.0625, "f": 0.06896551724137931, "fn": 15.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "The image shows a dog sitting on the back of a pickup truck, looking out the window. The dog is wearing a collar and appears to be enjoying the ride. The truck is parked at the side of the road, and there are other cars passing by in the background."}, "234518": {"image_id": 234518, "Bleu_1": 0.2727272727190084, "Bleu_2": 0.1599005372617867, "Bleu_3": 9.378053745851064e-07, "Bleu_4": 2.2898351849923084e-09, "METEOR": 0.20099097687447257, "ROUGE_L": 0.25738396624472576, "CIDEr": 0.00039813872354304907, "SPICE": {"All": {"pr": 0.5, "re": 0.12, "f": 0.1935483870967742, "fn": 22.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.3, "f": 0.4285714285714285, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA young woman in green shirt and black pants is throwing a frisbee in the park. There are trees and grass in the background."}, "291680": {"image_id": 291680, "Bleu_1": 0.3333333333277778, "Bleu_2": 0.16807316136037864, "Bleu_3": 0.07867853199299277, "Bleu_4": 9.614428458587299e-06, "METEOR": 0.1906070413273444, "ROUGE_L": 0.2839851024208566, "CIDEr": 2.4218721646478277e-11, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.09523809523809523, "f": 0.09302325581395349, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.08333333333333333, "f": 0.1111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image shows a baseball player in the middle of a swing, with his bat raised and ready to hit the ball. The other players on the field are watching him intently, and the umpire is standing behind him with his arms crossed. The background is a green field with a dirt infield and a white fence in the distance."}, "470604": {"image_id": 470604, "Bleu_1": 0.20930232557652792, "Bleu_2": 2.232350488629506e-09, "Bleu_3": 4.953516746581624e-12, "Bleu_4": 2.347849360404158e-13, "METEOR": 0.24387641314003913, "ROUGE_L": 0.22377109317681584, "CIDEr": 2.695716075164124e-08, "SPICE": {"All": {"pr": 0.08571428571428572, "re": 0.11538461538461539, "f": 0.09836065573770493, "fn": 23.0, "numImages": 1.0, "fp": 32.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.17647058823529413, "re": 0.3, "f": 0.22222222222222224, "fn": 7.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}}, "caption": "The image shows a young boy holding a tennis racket in his hand. He is wearing a white shirt and shorts, and has a smile on his face. The background of the image is a white wall with a window in the background."}, "568981": {"image_id": 568981, "Bleu_1": 0.14999999999812502, "Bleu_2": 0.097435470368019, "Bleu_3": 0.062439083781274864, "Bleu_4": 7.498419095061256e-06, "METEOR": 0.16305245225487489, "ROUGE_L": 0.17821368948247077, "CIDEr": 8.447323438090725e-30, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.19047619047619047, "f": 0.1702127659574468, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA group of people are standing on the sidewalk next to a skate park. One person is taking a photo of another person who is standing on a skateboard, while another person is holding a camera and taking a photo of the first person. The skate park has ramps and rails, and there are several people skateboarding in the background. The sky is cloudy and there is water on the ground."}, "177357": {"image_id": 177357, "Bleu_1": 0.26785714285235973, "Bleu_2": 0.22068370737221082, "Bleu_3": 0.12172849691773917, "Bleu_4": 1.358235968559138e-05, "METEOR": 0.23925450170291285, "ROUGE_L": 0.2426136363636364, "CIDEr": 4.3779737742398323e-13, "SPICE": {"All": {"pr": 0.125, "re": 0.15, "f": 0.13636363636363635, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is an image of a surfer riding a wave on a surfboard. The surfer is wearing a black wetsuit and has his arms outstretched as he jumps off the wave. The wave is white and has a lot of foam on top of it. The sky is blue and there are clouds in the background."}, "233112": {"image_id": 233112, "Bleu_1": 0.27906976743537054, "Bleu_2": 0.14118624159718107, "Bleu_3": 0.09907033493163236, "Bleu_4": 1.2486557620082349e-05, "METEOR": 0.16004436432032546, "ROUGE_L": 0.2778139232270657, "CIDEr": 8.219728445631472e-06, "SPICE": {"All": {"pr": 0.16, "re": 0.15384615384615385, "f": 0.1568627450980392, "fn": 22.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.3333333333333333, "f": 0.32, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "This is a bathroom with a shower, toilet, and sink. There are several items on the counter, including towels, toothbrushes, and toothpaste. The floor is made of white tiles and there is a red sign on the wall that says \"Caution Wet Floor\"."}, "150016": {"image_id": 150016, "Bleu_1": 0.24999999998750005, "Bleu_2": 0.11470786692939464, "Bleu_3": 9.008198915145454e-07, "Bleu_4": 2.560744480418492e-09, "METEOR": 0.13145539906103287, "ROUGE_L": 0.22208737864077668, "CIDEr": 0.031677596668227226, "SPICE": {"All": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 20.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "A herd of cows grazes on a green hillside, with mountains in the background. The sky is blue and cloudy."}, "359126": {"image_id": 359126, "Bleu_1": 0.36363636362534446, "Bleu_2": 0.26111648392551057, "Bleu_3": 0.1638496909924511, "Bleu_4": 1.9568336426722607e-05, "METEOR": 0.2174756184817092, "ROUGE_L": 0.28306264501160094, "CIDEr": 0.0017334136749095133, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.11538461538461539, "f": 0.11111111111111112, "fn": 23.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.2727272727272727, "f": 0.24999999999999994, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a man standing at a podium, wearing a suit and tie, and giving a speech. The background is a large banner with the words \"growth jobs 2020\" written on it."}, "295242": {"image_id": 295242, "Bleu_1": 0.23076923076331368, "Bleu_2": 0.11020775375273378, "Bleu_3": 6.89828064793551e-07, "Bleu_4": 1.7377208785097004e-09, "METEOR": 0.16835642596578457, "ROUGE_L": 0.1931908155186065, "CIDEr": 1.120879383763889e-06, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.35294117647058826, "f": 0.30769230769230765, "fn": 11.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.25, "f": 0.15384615384615383, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a white jetliner taking off from a runway at an airport. The plane has a red tail and white wings, and is surrounded by clouds. The sky is blue and there are trees in the background."}, "357888": {"image_id": 357888, "Bleu_1": 0.4848484848337925, "Bleu_2": 0.3256694736294419, "Bleu_3": 0.21732243131836967, "Bleu_4": 0.1360028792323118, "METEOR": 0.27735657794844704, "ROUGE_L": 0.34971334971334966, "CIDEr": 0.0007760304440645016, "SPICE": {"All": {"pr": 0.5333333333333333, "re": 0.25, "f": 0.3404255319148936, "fn": 24.0, "numImages": 1.0, "fp": 7.0, "tp": 8.0}, "Relation": {"pr": 0.4, "re": 0.13333333333333333, "f": 0.2, "fn": 13.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Cardinality": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.5, "f": 0.588235294117647, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A man stands in a kitchen holding a bouquet of flowers. He is wearing an orange shirt and has a smile on his face.\""}, "509223": {"image_id": 509223, "Bleu_1": 0.22413793103061835, "Bleu_2": 0.12541522083027962, "Bleu_3": 0.08251143768244948, "Bleu_4": 0.05653207720335858, "METEOR": 0.2029552433478773, "ROUGE_L": 0.19904285403524036, "CIDEr": 2.4913829695752564e-14, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.045454545454545456, "f": 0.05882352941176471, "fn": 21.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}}, "caption": "This is an image of a person skiing down a snowy slope. The person is wearing green and black clothing and has a pair of skis on their feet. They are holding onto the poles with both hands and appear to be in control of the skis. The background is a snowy mountain with trees in the distance."}, "314992": {"image_id": 314992, "Bleu_1": 0.39999999998400004, "Bleu_2": 0.28867513458302535, "Bleu_3": 0.19351158546623434, "Bleu_4": 2.3956565611738468e-05, "METEOR": 0.260929377712134, "ROUGE_L": 0.35847208619000986, "CIDEr": 0.026215365757547626, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.13636363636363635, "f": 0.15, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The woman is holding a small flashlight in her hand and smiling at the camera. She is wearing a black jacket and carrying a backpack."}, "370448": {"image_id": 370448, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.20304239863369572, "Bleu_3": 0.12521356825154964, "Bleu_4": 0.08318453241921067, "METEOR": 0.21784335455503676, "ROUGE_L": 0.31407322654462244, "CIDEr": 1.781029121858967e-05, "SPICE": {"All": {"pr": 0.1, "re": 0.05555555555555555, "f": 0.07142857142857142, "fn": 34.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.18181818181818182, "f": 0.19999999999999998, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "This is an image of a city street with tall buildings on either side. There are cars parked on the side of the road and people walking down the sidewalk. The sky is clear and there are trees on both sides of the street."}, "279933": {"image_id": 279933, "Bleu_1": 0.2424242424205693, "Bleu_2": 0.161577306904246, "Bleu_3": 0.07416407518272491, "Bleu_4": 8.970363701009124e-06, "METEOR": 0.15340757377763697, "ROUGE_L": 0.21055226824457596, "CIDEr": 3.329122388622612e-19, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.15, "f": 0.15384615384615385, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is an image of a train traveling along a railroad track. The train is moving at a slow pace and has a long line of cars behind it. The train is painted in a blue and white color scheme and has a large engine at the front. There are trees and fields on either side of the track, and the sky is clear and blue."}, "349616": {"image_id": 349616, "Bleu_1": 0.5199999999792001, "Bleu_2": 0.294392028865574, "Bleu_3": 0.15561140325389933, "Bleu_4": 2.0343486922522005e-05, "METEOR": 0.20982197697039429, "ROUGE_L": 0.3462630085146642, "CIDEr": 0.029479048836884427, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.23809523809523808, "f": 0.22727272727272724, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4, "f": 0.34782608695652173, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "A group of horses are standing on the beach in front of a cliff. The sky is cloudy and there are rocks in the background."}, "477671": {"image_id": 477671, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.18666334823214084, "Bleu_3": 0.09550351820629131, "Bleu_4": 1.2224986162514046e-05, "METEOR": 0.16121283302215392, "ROUGE_L": 0.3292847503373819, "CIDEr": 1.2419837991884163e-07, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.14285714285714285, "f": 0.1702127659574468, "fn": 24.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3333333333333333, "f": 0.380952380952381, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a man standing in front of a store with a sign that reads, \"Halloween 99.\" The man is wearing a costume and holding a broom. There are pumpkins and other decorations on the sidewalk in front of the store."}, "301317": {"image_id": 301317, "Bleu_1": 0.378378378368152, "Bleu_2": 0.22924343512884385, "Bleu_3": 0.1145096068514652, "Bleu_4": 1.449645171861387e-05, "METEOR": 0.2964201274159124, "ROUGE_L": 0.27858121479677267, "CIDEr": 2.8921009571682066e-05, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.25, "f": 0.23255813953488372, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a man playing tennis on a court. He is wearing a yellow shirt and black shorts, and has a racket in his hand. The background is a green field with trees in the distance."}, "551052": {"image_id": 551052, "Bleu_1": 0.3636363636198348, "Bleu_2": 0.22792115290866924, "Bleu_3": 0.13746108160529513, "Bleu_4": 1.9228544752192987e-05, "METEOR": 0.16098567679674353, "ROUGE_L": 0.3351648351648352, "CIDEr": 0.035291423731108655, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.12121212121212122, "f": 0.17777777777777776, "fn": 29.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.2857142857142857, "f": 0.4210526315789473, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The image shows a small brown rat with a green leaf in its mouth, standing on the edge of a white sink."}, "556005": {"image_id": 556005, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.10735372697093548, "Bleu_3": 6.304134548019102e-07, "Bleu_4": 1.5360875768147853e-09, "METEOR": 0.22563413618440353, "ROUGE_L": 0.308080808080808, "CIDEr": 1.2716712953666807e-08, "SPICE": {"All": {"pr": 0.0625, "re": 0.1111111111111111, "f": 0.08, "fn": 16.0, "numImages": 1.0, "fp": 30.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2857142857142857, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a red poinsettia flower sitting on a wooden table. The table has a white vase with water and a small candle on it. There is also a wooden chair next to the table. The background is a wooden floor with a pattern of wood grain."}, "32056": {"image_id": 32056, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.1714285714251079, "Bleu_3": 0.14519947954201504, "Bleu_4": 0.11823053204528565, "METEOR": 0.2090203922246731, "ROUGE_L": 0.25386444708680145, "CIDEr": 6.455798505553594e-10, "SPICE": {"All": {"pr": 0.23333333333333334, "re": 0.2916666666666667, "f": 0.2592592592592593, "fn": 17.0, "numImages": 1.0, "fp": 23.0, "tp": 7.0}, "Relation": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a young man standing in a school hallway, smiling and holding up his hand in a gesture of greeting. He is wearing a red sweater and white shirt, and has a tie around his neck. The background is a blurred image of other students in the hallway."}, "329604": {"image_id": 329604, "Bleu_1": 0.38461538460552275, "Bleu_2": 0.22496063532707972, "Bleu_3": 0.11100361229353628, "Bleu_4": 1.3961343379881599e-05, "METEOR": 0.2737477854432501, "ROUGE_L": 0.22846441947565538, "CIDEr": 5.217153326359768e-06, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.13636363636363635, "f": 0.10909090909090909, "fn": 19.0, "numImages": 1.0, "fp": 30.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.2222222222222222, "f": 0.17391304347826086, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "The woman is walking through the woods with an umbrella in her hand. She is wearing a black jacket and jeans, and has a backpack on her back. The trees are bare and there is snow on the ground."}, "577364": {"image_id": 577364, "Bleu_1": 0.18749999999707034, "Bleu_2": 0.07715167497983091, "Bleu_3": 4.5789546565906544e-07, "Bleu_4": 1.1200626064039016e-09, "METEOR": 0.14954090587731148, "ROUGE_L": 0.15561224489795916, "CIDEr": 4.811229536733725e-18, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.14285714285714285, "f": 0.1515151515151515, "fn": 30.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.2857142857142857, "f": 0.29629629629629634, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows an elephant and its baby standing in a dirt area. The elephant is large and gray, with a long trunk and tusks. The baby elephant is smaller and has a shorter trunk and tusks. They are both standing next to each other, with their heads down and their ears up. The background is a green field with trees in the distance."}, "575643": {"image_id": 575643, "Bleu_1": 0.3157894736675901, "Bleu_2": 0.1324532356993396, "Bleu_3": 1.010552174586843e-06, "Bleu_4": 2.833929617442683e-09, "METEOR": 0.1618437342250549, "ROUGE_L": 0.3053817271589487, "CIDEr": 0.0833647171098802, "SPICE": {"All": {"pr": 0.16, "re": 0.16, "f": 0.16, "fn": 21.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA zebra standing in a field, looking at the camera."}, "422918": {"image_id": 422918, "Bleu_1": 0.4137931034340072, "Bleu_2": 0.3438409530246834, "Bleu_3": 0.29728128073381627, "Bleu_4": 0.25214324242770014, "METEOR": 0.3742500467826563, "ROUGE_L": 0.5059907834101383, "CIDEr": 0.014532926689778021, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.20833333333333334, "f": 0.22222222222222224, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The woman is sitting on the couch, using her laptop. She is wearing a pink shirt and black shorts. There is a lamp on the table next to her."}, "324189": {"image_id": 324189, "Bleu_1": 0.21999999999560005, "Bleu_2": 0.13401187884939042, "Bleu_3": 0.09078730341863991, "Bleu_4": 0.06316759949914878, "METEOR": 0.11696668533303506, "ROUGE_L": 0.22333414693678305, "CIDEr": 4.11046500245966e-10, "SPICE": {"All": {"pr": 0.15, "re": 0.15789473684210525, "f": 0.15384615384615385, "fn": 16.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.6, "f": 0.37499999999999994, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This image shows a small wooden table sitting on top of a pile of branches and leaves in a grassy area. The table has a small plant growing out of it, and there are several other plants growing around it. The background is made up of tall trees and buildings."}, "466901": {"image_id": 466901, "Bleu_1": 0.4482758620535078, "Bleu_2": 0.33476703169424327, "Bleu_3": 0.23178266456896568, "Bleu_4": 2.6306760830581542e-05, "METEOR": 0.23848307376331848, "ROUGE_L": 0.3597304128053918, "CIDEr": 0.009175004720047855, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.15384615384615385, "f": 0.15384615384615385, "fn": 22.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a group of people standing around a table with several missiles on it. They are all wearing military uniforms and looking at the missiles with interest."}, "560637": {"image_id": 560637, "Bleu_1": 0.4102564102458909, "Bleu_2": 0.27490643727245323, "Bleu_3": 0.18299102222839972, "Bleu_4": 0.1142211983420398, "METEOR": 0.2162869399613097, "ROUGE_L": 0.3287143956889915, "CIDEr": 7.114807223441546e-06, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.15789473684210525, "f": 0.15789473684210525, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is a black and white image of a horse standing in a field. The horse is brown and white and has a long mane. It is standing in the middle of a field with trees in the background."}, "228867": {"image_id": 228867, "Bleu_1": 0.3809523809433107, "Bleu_2": 0.19278507708010587, "Bleu_3": 9.758032910433397e-07, "Bleu_4": 2.209304398110063e-09, "METEOR": 0.18198089970750797, "ROUGE_L": 0.3001230012300123, "CIDEr": 2.930559488985348e-05, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.25, "f": 0.2553191489361702, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a room with a bed, a desk, and a chair. There are people standing in the room, looking at something on the desk. The walls are painted yellow and there is a window on one side of the room."}, "393226": {"image_id": 393226, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.15291943545714587, "Bleu_3": 0.09983569293155374, "Bleu_4": 0.06819851521727724, "METEOR": 0.19582358033126082, "ROUGE_L": 0.19242902208201892, "CIDEr": 2.644327218961636e-10, "SPICE": {"All": {"pr": 0.2, "re": 0.08, "f": 0.11428571428571428, "fn": 23.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2, "f": 0.26666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a blue ice cream truck driving down a street with a red and white striped crosswalk. There are several buildings on either side of the street, including a small grocery store and a restaurant. The sky is cloudy and there are some trees in the background."}, "413320": {"image_id": 413320, "Bleu_1": 0.17647058823010386, "Bleu_2": 0.1034175379959161, "Bleu_3": 6.939786934219503e-07, "Bleu_4": 1.8120458368313503e-09, "METEOR": 0.10183347171124166, "ROUGE_L": 0.20165289256198346, "CIDEr": 2.4351824430686572e-05, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.07692307692307693, "f": 0.1, "fn": 24.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a yellow submarine floating on the water in the middle of a city park. There are buildings and trees in the background, and people can be seen walking along the shore."}, "15303": {"image_id": 15303, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.15475060698405138, "Bleu_3": 0.07772573699771664, "Bleu_4": 9.84421602524371e-06, "METEOR": 0.1811866516129309, "ROUGE_L": 0.25341246290801184, "CIDEr": 1.0894031061502279e-11, "SPICE": {"All": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 15.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a surfer riding a wave on a surfboard. The surfer is wearing a black wetsuit and has his arms outstretched as he jumps off the wave. The water is choppy and there are whitecaps on the surface. The sky is cloudy and there are some birds flying in the distance."}, "124215": {"image_id": 124215, "Bleu_1": 0.8461538460887575, "Bleu_2": 0.6504436355358721, "Bleu_3": 0.4252903702473842, "Bleu_4": 5.266403878016922e-05, "METEOR": 0.38257943573142167, "ROUGE_L": 0.5970636215334422, "CIDEr": 1.4719264785874557, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "A computer mouse and keyboard sit on a desk next to a laptop."}, "396461": {"image_id": 396461, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.21573723181113055, "Bleu_3": 0.10039161882933353, "Bleu_4": 1.2245315087875368e-05, "METEOR": 0.24007901991430708, "ROUGE_L": 0.27371794871794874, "CIDEr": 8.117738200929921e-09, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.13636363636363635, "f": 0.12499999999999997, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is a kitchen with a white refrigerator, stove, and sink. There are two windows on the wall opposite the sink and a window on the wall next to the stove. The floor is made of hardwood and there are two chairs in the corner of the room."}, "414196": {"image_id": 414196, "Bleu_1": 0.6190476190181406, "Bleu_2": 0.49761335150383107, "Bleu_3": 0.42762251761962405, "Bleu_4": 0.3378762084149547, "METEOR": 0.47223568511670205, "ROUGE_L": 0.5514124293785311, "CIDEr": 0.20007391697835214, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.25, "f": 0.2553191489361702, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.6, "f": 0.5714285714285713, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image shows a person holding a cell phone in their hand, with the screen displaying an image of a flower."}, "543713": {"image_id": 543713, "Bleu_1": 0.23214285713871177, "Bleu_2": 0.14527180078437643, "Bleu_3": 7.311216202480129e-07, "Bleu_4": 1.6478711585270885e-09, "METEOR": 0.19143682832586206, "ROUGE_L": 0.2476798143851508, "CIDEr": 3.990657198333729e-14, "SPICE": {"All": {"pr": 0.12, "re": 0.0967741935483871, "f": 0.10714285714285714, "fn": 28.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a white sheep standing in a green field with a fence in the background. The sheep is looking directly at the camera with its head tilted to the side. There are several other sheep in the background grazing on the grass. The sky is clear and blue with a few clouds scattered about."}, "214753": {"image_id": 214753, "Bleu_1": 0.4838709677263268, "Bleu_2": 0.33601075250510387, "Bleu_3": 0.22688713393833193, "Bleu_4": 0.16995165295452114, "METEOR": 0.2934253322771573, "ROUGE_L": 0.48605577689243035, "CIDEr": 0.025348469131337287, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.17857142857142858, "f": 0.2127659574468085, "fn": 23.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "Two people are riding horses on the beach. The horses are brown and black, and they are walking on the sand. There are waves crashing against the shore in the background."}, "80163": {"image_id": 80163, "Bleu_1": 0.7999999999466668, "Bleu_2": 0.6324555319900065, "Bleu_3": 0.49742263460378094, "Bleu_4": 0.31823566219589394, "METEOR": 0.35184343680335434, "ROUGE_L": 0.6005625879043601, "CIDEr": 1.124184576343588, "SPICE": {"All": {"pr": 0.2, "re": 0.08333333333333333, "f": 0.11764705882352941, "fn": 22.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}}, "caption": "A young boy is playing tennis on a court with a net in the background."}, "20147": {"image_id": 20147, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.15075567228616532, "Bleu_3": 0.07494071883573872, "Bleu_4": 9.439944120577903e-06, "METEOR": 0.15943712388429568, "ROUGE_L": 0.22426470588235295, "CIDEr": 1.4353781309334895e-12, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.2222222222222222, "f": 0.24489795918367346, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.2857142857142857, "f": 0.4, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a herd of zebras grazing in a grassy field. The zebras are standing in a line, with their heads down and their stripes visible. In the background, there is a large herd of wildebeest grazing on the same field. The sky is clear and blue, with a few white clouds scattered across it."}, "479939": {"image_id": 479939, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.14564381624761055, "Bleu_3": 7.901421228222159e-07, "Bleu_4": 1.8512564664694888e-09, "METEOR": 0.18240441936253265, "ROUGE_L": 0.228721409823772, "CIDEr": 1.6948993211711245e-07, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.2, "f": 0.2631578947368421, "fn": 20.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.14285714285714285, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "This image shows a person skiing down a snowy slope. The person is wearing a red jacket and black pants, and they are holding a ski pole in their right hand. The snow is covered in trees and there is a mountain in the background."}, "48037": {"image_id": 48037, "Bleu_1": 0.4999999999750001, "Bleu_2": 0.16222142112243812, "Bleu_3": 1.1349619434831917e-06, "Bleu_4": 3.0452555558176168e-09, "METEOR": 0.20594059405940596, "ROUGE_L": 0.22208737864077668, "CIDEr": 0.14184671412451572, "SPICE": {"All": {"pr": 0.2, "re": 0.14814814814814814, "f": 0.1702127659574468, "fn": 23.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is a refrigerator in a kitchen. It has a white door and shelves inside for storing food and drinks."}, "321706": {"image_id": 321706, "Bleu_1": 0.39999999998666674, "Bleu_2": 0.23488808779791684, "Bleu_3": 0.18081247989280658, "Bleu_4": 0.12164110620828757, "METEOR": 0.27805822088798526, "ROUGE_L": 0.39757914338919925, "CIDEr": 0.0026783377319294704, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.06451612903225806, "f": 0.07999999999999999, "fn": 29.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.18181818181818182, "f": 0.18181818181818182, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "This is a bathroom with a toilet, sink, and mirror. The walls are white and the floor is made of tile. There is a shower curtain hanging in the shower."}, "295076": {"image_id": 295076, "Bleu_1": 0.2749999999931251, "Bleu_2": 0.20568833779665252, "Bleu_3": 0.13058358239001738, "Bleu_4": 0.08807770766281207, "METEOR": 0.20932649713591978, "ROUGE_L": 0.27199762187871585, "CIDEr": 3.0120762445752236e-06, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.2, "f": 0.20833333333333331, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This is an image of an airplane taking off from a runway. The plane is white with red and blue stripes on the tail and wings. It is flying over a body of water with a city in the background."}, "408363": {"image_id": 408363, "Bleu_1": 0.13953488371768527, "Bleu_2": 0.05763904176906714, "Bleu_3": 4.327295461557813e-07, "Bleu_4": 1.1930191477552194e-09, "METEOR": 0.1518863054408734, "ROUGE_L": 0.21254355400696864, "CIDEr": 1.1533793578328009e-07, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.15384615384615385, "f": 0.1702127659574468, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This image shows a group of people standing in front of a building with balloons tied to the door. The people are wearing red and white clothing and have balloons tied to their hats. The building has a sign that reads, \"No Parking.\""}, "301641": {"image_id": 301641, "Bleu_1": 0.4444444444320988, "Bleu_2": 0.2519763153323855, "Bleu_3": 0.12314407142557375, "Bleu_4": 1.5423454131176364e-05, "METEOR": 0.26938873365316274, "ROUGE_L": 0.29901960784313725, "CIDEr": 4.4372964035286686e-05, "SPICE": {"All": {"pr": 0.08823529411764706, "re": 0.12, "f": 0.10169491525423728, "fn": 22.0, "numImages": 1.0, "fp": 31.0, "tp": 3.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.2222222222222222, "f": 0.17391304347826086, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "This is an image of a speedboat traveling through the water. The boat is white and has a black hull, with two people on board. The water is calm and there are clouds in the sky."}, "383112": {"image_id": 383112, "Bleu_1": 0.30952380951644, "Bleu_2": 0.1942853726806771, "Bleu_3": 9.808593569034828e-07, "Bleu_4": 2.217884382453587e-09, "METEOR": 0.15349757126106686, "ROUGE_L": 0.2279521674140508, "CIDEr": 3.71993842182006e-07, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.09090909090909091, "f": 0.13636363636363635, "fn": 30.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2727272727272727, "f": 0.3529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a busy street with many cars, buses, and pedestrians crossing the road. There are buildings on either side of the street, with signs and advertisements on them. The sky is cloudy and there are some trees in the background."}, "286660": {"image_id": 286660, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.1565560727682472, "Bleu_3": 0.09934208621394808, "Bleu_4": 1.1893260654297589e-05, "METEOR": 0.2735991747175867, "ROUGE_L": 0.22536945812807885, "CIDEr": 4.0332884417759467e-10, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.15789473684210525, "f": 0.13333333333333333, "fn": 16.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The woman is holding a stuffed animal in her arms, smiling at the camera. The stuffed animal is a brown bear with a big smile on its face. The woman is wearing a black dress and has long blonde hair. The background is dark and there are some lights in the room."}, "5033": {"image_id": 5033, "Bleu_1": 0.13461538461279587, "Bleu_2": 0.07265696587798288, "Bleu_3": 0.04726374935529322, "Bleu_4": 6.813136779964552e-06, "METEOR": 0.15208022141013913, "ROUGE_L": 0.15365239294710328, "CIDEr": 6.325865368803382e-13, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.26666666666666666, "f": 0.18181818181818182, "fn": 11.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.4, "f": 0.26666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.18181818181818182, "re": 0.4, "f": 0.25000000000000006, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A small lighthouse stands on a rocky cliffside, surrounded by trees and greenery. The lighthouse has a rustic, old-fashioned look, with a metal roof and a lantern on top. The scene is peaceful and serene, with a train track running through the background.\""}, "218310": {"image_id": 218310, "Bleu_1": 0.3999999999800001, "Bleu_2": 0.3244428422448761, "Bleu_3": 0.25984142029224355, "Bleu_4": 0.21314568969954792, "METEOR": 0.296202893110778, "ROUGE_L": 0.4644670050761421, "CIDEr": 0.20238889728937398, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.24, "f": 0.2608695652173913, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.6, "f": 0.6, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "Two colorful parrots perched on a wooden branch, one with its wings spread and the other with its beak open."}, "459265": {"image_id": 459265, "Bleu_1": 0.35135135134185547, "Bleu_2": 0.19758299278252553, "Bleu_3": 0.10370754607930319, "Bleu_4": 1.3458232889827183e-05, "METEOR": 0.26793308805060756, "ROUGE_L": 0.2848249027237354, "CIDEr": 1.8864064549340758e-05, "SPICE": {"All": {"pr": 0.12, "re": 0.1875, "f": 0.14634146341463414, "fn": 13.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a woman in white tennis dress playing tennis on a court. She is holding a racket and running towards the net to hit the ball. There are people in the background watching her play."}, "55528": {"image_id": 55528, "Bleu_1": 0.3333333333253969, "Bleu_2": 0.25503068521918915, "Bleu_3": 0.18666445436887247, "Bleu_4": 0.14955825207429813, "METEOR": 0.26416909505919595, "ROUGE_L": 0.3028368794326241, "CIDEr": 1.1086628903544044e-06, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.17647058823529413, "f": 0.13636363636363638, "fn": 14.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The man is sitting in a chair, holding a bag of groceries in his lap. He is wearing glasses and has a serious expression on his face. The background is a living room with a couch, a coffee table, and a television."}, "205866": {"image_id": 205866, "Bleu_1": 0.20312499999682618, "Bleu_2": 0.11356419064308597, "Bleu_3": 0.059251185419462594, "Bleu_4": 7.641705980461596e-06, "METEOR": 0.14942183068998177, "ROUGE_L": 0.17545541706615533, "CIDEr": 2.787654452949934e-16, "SPICE": {"All": {"pr": 0.043478260869565216, "re": 0.07142857142857142, "f": 0.05405405405405405, "fn": 13.0, "numImages": 1.0, "fp": 22.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.25, "f": 0.13333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows a person standing on the beach next to a group of kayaks. The person is wearing a hat and sunglasses, and is looking out at the ocean. There are several kayaks on the sand next to the person, and they appear to be unoccupied. The sky is clear and blue, and there are no other people or objects in the image."}, "290875": {"image_id": 290875, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.14401064146758893, "Bleu_3": 0.0939614522123186, "Bleu_4": 0.06414506805775248, "METEOR": 0.19448904486931942, "ROUGE_L": 0.23047858942065497, "CIDEr": 2.215449353548161e-11, "SPICE": {"All": {"pr": 0.05555555555555555, "re": 0.06666666666666667, "f": 0.0606060606060606, "fn": 14.0, "numImages": 1.0, "fp": 17.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows two baseball players standing on a baseball field, one holding a baseball bat and the other holding a baseball glove. They are both wearing baseball uniforms with the numbers 1 and 2 on their jerseys. The background is a green grass field with a few spectators in the stands."}, "153896": {"image_id": 153896, "Bleu_1": 0.4838709677263268, "Bleu_2": 0.2540002539920509, "Bleu_3": 1.3054395556610798e-06, "Bleu_4": 2.985575568232099e-09, "METEOR": 0.2955092896531161, "ROUGE_L": 0.3925985518905873, "CIDEr": 0.0033575265547987525, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.19230769230769232, "f": 0.25, "fn": 21.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.16666666666666666, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a man playing tennis on a court with a blue background. He is wearing a white shirt and black shorts, and has a tennis racket in his hand."}, "69914": {"image_id": 69914, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.11375929179665137, "Bleu_3": 6.415924230513621e-07, "Bleu_4": 1.5315603357857856e-09, "METEOR": 0.19660021689302837, "ROUGE_L": 0.19074421513445905, "CIDEr": 9.615987744399029e-11, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.19047619047619047, "f": 0.19047619047619047, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is a kitchen with a stove, refrigerator, and sink. There are two people standing in the kitchen, one of them is cooking something on the stove while the other is washing dishes in the sink. The room is well lit and has a lot of counter space for food preparation."}, "404517": {"image_id": 404517, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.14401064146758893, "Bleu_3": 0.0939614522123186, "Bleu_4": 1.1406785378264661e-05, "METEOR": 0.20610067589551184, "ROUGE_L": 0.22536945812807885, "CIDEr": 4.9660578876546206e-11, "SPICE": {"All": {"pr": 0.3125, "re": 0.29411764705882354, "f": 0.30303030303030304, "fn": 12.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The woman is playing fetch with her dog in the grass. The dog is running after the ball and the woman is throwing it. The woman is wearing a white shirt and jeans, and the dog is wearing a yellow collar. The background is a green field with trees in the distance."}, "455548": {"image_id": 455548, "Bleu_1": 0.24999999999305564, "Bleu_2": 0.18898223649928916, "Bleu_3": 0.14660927139345212, "Bleu_4": 0.09885362315999967, "METEOR": 0.3298103792955046, "ROUGE_L": 0.38730158730158726, "CIDEr": 0.00015595657068271957, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.17391304347826086, "f": 0.1904761904761905, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a group of zebras standing in a grassy field. They are all facing the same direction and appear to be grazing. There are trees in the background and a clear blue sky above."}, "346965": {"image_id": 346965, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.2399704669849505, "Bleu_3": 0.17777222549589156, "Bleu_4": 0.1294614399070719, "METEOR": 0.24802376727978678, "ROUGE_L": 0.30262225372076546, "CIDEr": 3.734409377981317e-06, "SPICE": {"All": {"pr": 0.35, "re": 0.30434782608695654, "f": 0.3255813953488372, "fn": 16.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.5454545454545454, "f": 0.5454545454545454, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The man is holding a small dog in his arms while walking down the street. The dog is wearing a red collar and tag. The man is wearing a black shirt and jeans. The storefronts in the background are visible through the window."}, "342649": {"image_id": 342649, "Bleu_1": 0.47368421050138515, "Bleu_2": 0.3627381250353841, "Bleu_3": 0.24922359747069828, "Bleu_4": 3.136258669327066e-05, "METEOR": 0.23752495076795715, "ROUGE_L": 0.42020665901262916, "CIDEr": 0.32966785131794096, "SPICE": {"All": {"pr": 0.10869565217391304, "re": 0.20833333333333334, "f": 0.14285714285714285, "fn": 19.0, "numImages": 1.0, "fp": 41.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 21.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2777777777777778, "re": 0.5, "f": 0.35714285714285715, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}}, "caption": "Two birds are sitting on a wooden bench, looking at a piece of food that is on the ground."}, "545292": {"image_id": 545292, "Bleu_1": 0.2545454545408265, "Bleu_2": 0.1373143068093302, "Bleu_3": 7.085740383081723e-07, "Bleu_4": 1.6172907070693962e-09, "METEOR": 0.17401295628176627, "ROUGE_L": 0.207506520013607, "CIDEr": 3.137949278618429e-13, "SPICE": {"All": {"pr": 0.25, "re": 0.1724137931034483, "f": 0.20408163265306123, "fn": 24.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.07692307692307693, "f": 0.10526315789473684, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "Sure! Here is a short caption for the image:\n\nThis image shows an elephant standing in a grassy area with trees in the background. The elephant is wearing a green tarp around its body and has a trunk in its mouth. The elephant is looking down at the ground and appears to be eating something."}, "172716": {"image_id": 172716, "Bleu_1": 0.23728813558919856, "Bleu_2": 0.18091268062725444, "Bleu_3": 0.11987486713703241, "Bleu_4": 0.07447304260680035, "METEOR": 0.18943045181471105, "ROUGE_L": 0.2326975476839237, "CIDEr": 2.3322131185765974e-15, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.10344827586206896, "f": 0.1395348837209302, "fn": 26.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "This is an image of a skateboarder performing a trick on a half pipe. The skateboarder is wearing a helmet and knee pads, and is holding onto the handlebars of the skateboard with one hand while performing the trick with the other. The background of the image is a concrete half pipe with a metal rail around the edge."}, "153506": {"image_id": 153506, "Bleu_1": 0.818181818033058, "Bleu_2": 0.756787468523232, "Bleu_3": 0.7254690150137174, "Bleu_4": 0.6989307621403409, "METEOR": 0.4260990818515791, "ROUGE_L": 0.768503937007874, "CIDEr": 2.637383279173201, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.26666666666666666, "f": 0.18604651162790697, "fn": 11.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.6, "f": 0.37499999999999994, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "A plate with a sandwich, fries, and a drink on it."}, "375769": {"image_id": 375769, "Bleu_1": 0.5925925925706447, "Bleu_2": 0.36980013080285973, "Bleu_3": 0.22199406782100037, "Bleu_4": 2.5983833012138955e-05, "METEOR": 0.20434618230872614, "ROUGE_L": 0.42627533193570927, "CIDEr": 0.059961458364461886, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "A young boy is sitting at a table outside with a cup of coffee in front of him. There are bicycles parked in front of the table."}, "460145": {"image_id": 460145, "Bleu_1": 0.1704545454526085, "Bleu_2": 0.11710992076680038, "Bleu_3": 0.07821139988056207, "Bleu_4": 0.04870772136975489, "METEOR": 0.19613038012859288, "ROUGE_L": 0.19334389857369255, "CIDEr": 9.730581963200024e-35, "SPICE": {"All": {"pr": 0.125, "re": 0.13043478260869565, "f": 0.1276595744680851, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a flock of sheep grazing on the side of the road. The sheep are standing in the middle of the road, with their heads down and their woolly coats blowing in the wind. In the background, there is a mountain range with snow covered peaks. The sky is overcast with clouds, and there is a light dusting of snow on the ground. The car in the background is driving down the road, with its windows rolled up and the driver looking out at the sheep."}, "15883": {"image_id": 15883, "Bleu_1": 0.18181818181542703, "Bleu_2": 0.09160572248147028, "Bleu_3": 0.05080288918519724, "Bleu_4": 6.754312828570961e-06, "METEOR": 0.14962715463028145, "ROUGE_L": 0.14649375600384246, "CIDEr": 5.0730425899870834e-20, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.21875, "f": 0.2641509433962264, "fn": 25.0, "numImages": 1.0, "fp": 14.0, "tp": 7.0}, "Relation": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.09090909090909091, "f": 0.14285714285714288, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5, "f": 0.4347826086956522, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "This image shows a group of people standing around a table with various food items on it. One person is cutting up a piece of meat, while another person is preparing a plate of food. There are several other people in the background, some of whom are also preparing food. The atmosphere appears to be festive and social, with people chatting and laughing while they work."}, "562073": {"image_id": 562073, "Bleu_1": 0.24561403508341031, "Bleu_2": 0.16222142112789117, "Bleu_3": 0.11280412717972553, "Bleu_4": 0.0853891717612208, "METEOR": 0.15850517351909124, "ROUGE_L": 0.20504201680672268, "CIDEr": 1.666867981417091e-14, "SPICE": {"All": {"pr": 0.125, "re": 0.18181818181818182, "f": 0.14814814814814814, "fn": 18.0, "numImages": 1.0, "fp": 28.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5714285714285714, "f": 0.38095238095238093, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a group of people standing in front of a store with various electronic devices and gadgets on display. Some of the people are holding shopping bags, while others are looking at the products on the shelves. The store appears to be well lit and organized, with rows of shelves and displays of various products."}, "334469": {"image_id": 334469, "Bleu_1": 0.2666666666622222, "Bleu_2": 0.16467739391575578, "Bleu_3": 0.11194045746119323, "Bleu_4": 0.08375853894095578, "METEOR": 0.1856694663510685, "ROUGE_L": 0.24796747967479674, "CIDEr": 1.972989893162517e-10, "SPICE": {"All": {"pr": 0.3, "re": 0.2, "f": 0.24, "fn": 24.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.38461538461538464, "f": 0.41666666666666663, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a group of people standing on the shore of a lake, looking at something in the water. One person is holding a fishing rod and another is holding a bucket. There are several other people in the background, some of whom are also holding fishing rods. The sky is cloudy and there are trees in the background."}, "541018": {"image_id": 541018, "Bleu_1": 0.36666666665444453, "Bleu_2": 0.29749915482305944, "Bleu_3": 0.21166297628112732, "Bleu_4": 0.1368966223525974, "METEOR": 0.20475341106846207, "ROUGE_L": 0.2961165048543689, "CIDEr": 0.016184887719259463, "SPICE": {"All": {"pr": 0.1875, "re": 0.3157894736842105, "f": 0.23529411764705882, "fn": 13.0, "numImages": 1.0, "fp": 26.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5714285714285714, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a plate of food, including fries and a bowl of soup, sitting on a wooden table in front of a man wearing a black shirt and jeans."}, "48692": {"image_id": 48692, "Bleu_1": 0.3230769230719526, "Bleu_2": 0.20095923811400926, "Bleu_3": 0.12435565865791477, "Bleu_4": 0.07462790357333475, "METEOR": 0.24019960147408365, "ROUGE_L": 0.28651949271958665, "CIDEr": 5.3134185521763275e-17, "SPICE": {"All": {"pr": 0.8571428571428571, "re": 0.24, "f": 0.375, "fn": 19.0, "numImages": 1.0, "fp": 1.0, "tp": 6.0}, "Relation": {"pr": 0.6666666666666666, "re": 0.18181818181818182, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.36363636363636365, "f": 0.5333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 4.0}}, "caption": "This image shows a small market stall with a variety of fruits and vegetables on display. The stall is made of wood and has a red and white striped awning above it. There are several baskets of fruit and vegetables on the ground, including bananas, apples, and tomatoes. The stall is located in front of a building with a brick wall and a wooden door."}, "292324": {"image_id": 292324, "Bleu_1": 0.23809523809145886, "Bleu_2": 0.1639564589433648, "Bleu_3": 0.120798740306719, "Bleu_4": 0.09689230892564124, "METEOR": 0.21969790452097993, "ROUGE_L": 0.2569773565034228, "CIDEr": 2.0025381960522788e-17, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.17391304347826086, "f": 0.15999999999999998, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This is a living room with a couch, coffee table, and chairs. The walls are painted white and there are large windows on one side of the room that let in natural light. The floor is made of hardwood and there is a rug in the center of the room. The room is well lit and has a nice view of the outdoors."}, "375484": {"image_id": 375484, "Bleu_1": 0.206349206345931, "Bleu_2": 0.15263515662743288, "Bleu_3": 0.07255373472380146, "Bleu_4": 8.932170758370765e-06, "METEOR": 0.19536527103977988, "ROUGE_L": 0.21863799283154117, "CIDEr": 1.7011820964191491e-15, "SPICE": {"All": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 0.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}}, "caption": "This is a small, cluttered office space with a desk, chair, and computer. The walls are painted a light blue color and there are several shelves and cabinets in the room. The desk has a laptop on it and there are several other electronic devices on the shelves. The room is well lit by a large window and a lamp on the desk."}, "245667": {"image_id": 245667, "Bleu_1": 0.3953488372001082, "Bleu_2": 0.23765185737325192, "Bleu_3": 0.14018757444877172, "Bleu_4": 0.09109974122666077, "METEOR": 0.28966556764036067, "ROUGE_L": 0.3400696864111499, "CIDEr": 8.22370907509524e-07, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.2631578947368421, "f": 0.21739130434782608, "fn": 14.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a group of people skiing down a snowy slope. They are wearing ski gear and helmets, and one person is holding a ski pole. The trees in the background are covered in snow, and there is a cloudy sky above."}, "119729": {"image_id": 119729, "Bleu_1": 0.7272727271404961, "Bleu_2": 0.5393598898700768, "Bleu_3": 0.4013422918623043, "Bleu_4": 0.2998221388749698, "METEOR": 0.31143220255200077, "ROUGE_L": 0.5454545454545454, "CIDEr": 1.699063110419746, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.2631578947368421, "f": 0.20833333333333334, "fn": 14.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "A person is holding a bunch of bananas on their hand."}, "274014": {"image_id": 274014, "Bleu_1": 0.6470588234913496, "Bleu_2": 0.4021998332455238, "Bleu_3": 0.27836043274885724, "Bleu_4": 3.5230890315089664e-05, "METEOR": 0.21235853451860306, "ROUGE_L": 0.42707117852975496, "CIDEr": 0.304327822924068, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.21739130434782608, "f": 0.22727272727272724, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "Here is a short caption of the image:\n\n\"A group of skiers on a snowy mountain slope\""}, "305412": {"image_id": 305412, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.18314741859482844, "Bleu_3": 0.08640378216299736, "Bleu_4": 1.060491082518161e-05, "METEOR": 0.2433551310858301, "ROUGE_L": 0.21585279547062985, "CIDEr": 1.2772869478236266e-12, "SPICE": {"All": {"pr": 0.0967741935483871, "re": 0.08823529411764706, "f": 0.09230769230769231, "fn": 31.0, "numImages": 1.0, "fp": 28.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.2727272727272727, "f": 0.24999999999999994, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This is an image of a sink in a bathroom. The sink is made of stainless steel and has a drain hole in the bottom. The sink is surrounded by tiles on the walls and floor. There is no water in the sink, but there is a small puddle of water on the floor."}, "83656": {"image_id": 83656, "Bleu_1": 0.3090909090852893, "Bleu_2": 0.2620817976974896, "Bleu_3": 0.19811454724826918, "Bleu_4": 0.16535941983280275, "METEOR": 0.2833668052051354, "ROUGE_L": 0.27555053642010163, "CIDEr": 8.379772026423164e-13, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.14285714285714285, "f": 0.1702127659574468, "fn": 24.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.25, "f": 0.2727272727272727, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a brown cow standing on the beach in front of the ocean. The cow is looking out at the water and appears to be enjoying the view. The sky is clear and blue, with a few clouds scattered across it. The sand is white and the waves are crashing against the shore."}, "360480": {"image_id": 360480, "Bleu_1": 0.378378378368152, "Bleu_2": 0.22924343512884385, "Bleu_3": 0.1145096068514652, "Bleu_4": 1.449645171861387e-05, "METEOR": 0.2665255329963438, "ROUGE_L": 0.3418734987990392, "CIDEr": 1.3645762479290724e-05, "SPICE": {"All": {"pr": 0.1875, "re": 0.20689655172413793, "f": 0.19672131147540986, "fn": 23.0, "numImages": 1.0, "fp": 26.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.4166666666666667, "f": 0.3846153846153846, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a woman in a white shirt and green shorts holding a tennis racket and preparing to hit a ball on a tennis court. The background is a green field with trees in the distance."}, "14226": {"image_id": 14226, "Bleu_1": 0.6363636363347108, "Bleu_2": 0.5773502691627578, "Bleu_3": 0.4641588833391417, "Bleu_4": 0.3203089683391272, "METEOR": 0.3878095808770534, "ROUGE_L": 0.5420310296191819, "CIDEr": 0.3203259755332927, "SPICE": {"All": {"pr": 0.45, "re": 0.42857142857142855, "f": 0.4390243902439024, "fn": 12.0, "numImages": 1.0, "fp": 11.0, "tp": 9.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.3333333333333333, "f": 0.4444444444444444, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.75, "f": 0.6666666666666665, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "A man in a suit and tie is sitting at a table on a train with a laptop in front of him."}, "121417": {"image_id": 121417, "Bleu_1": 0.4838709677263268, "Bleu_2": 0.38100038098807637, "Bleu_3": 0.3272278714308386, "Bleu_4": 0.2943648977475439, "METEOR": 0.35540085854522974, "ROUGE_L": 0.4817902588854761, "CIDEr": 0.01532614982949937, "SPICE": {"All": {"pr": 0.47619047619047616, "re": 0.4, "f": 0.43478260869565216, "fn": 15.0, "numImages": 1.0, "fp": 11.0, "tp": 10.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.7, "re": 0.6363636363636364, "f": 0.6666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 7.0}}, "caption": "The image shows a woman sitting on a bench under an umbrella. She is wearing a black jacket and pink shoes. There are people walking on the street in the background."}, "417911": {"image_id": 417911, "Bleu_1": 0.3584905660309719, "Bleu_2": 0.21967782188085846, "Bleu_3": 9.81749639652121e-07, "Bleu_4": 2.085729875019735e-09, "METEOR": 0.2234481270597961, "ROUGE_L": 0.27774615822424586, "CIDEr": 2.2043785379344258e-07, "SPICE": {"All": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 16.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}}, "caption": "This image shows a man surfing on a wave in the ocean. He is wearing a black wetsuit and holding onto his surfboard as he rides the wave. The water is choppy and there are whitecaps on the surface of the ocean. The sky is cloudy and there are some birds flying overhead."}, "33005": {"image_id": 33005, "Bleu_1": 0.23076923076568048, "Bleu_2": 0.13427153888031182, "Bleu_3": 0.06589854024909178, "Bleu_4": 8.242499385671624e-06, "METEOR": 0.23603496323556844, "ROUGE_L": 0.2190867111339148, "CIDEr": 2.1915553888171244e-19, "SPICE": {"All": {"pr": 0.1875, "re": 0.21428571428571427, "f": 0.19999999999999998, "fn": 22.0, "numImages": 1.0, "fp": 26.0, "tp": 6.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.125, "f": 0.10526315789473685, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a man playing tennis on a court with a net in the background. He is wearing a white shirt and black shorts, and has a racket in his hand. The court is made of concrete and there are lines on it to mark the boundaries of the game. The sky is dark and there are streetlights on either side of the court."}, "292435": {"image_id": 292435, "Bleu_1": 0.15942028985276205, "Bleu_2": 0.11860226036325001, "Bleu_3": 0.07488250687001746, "Bleu_4": 0.05022261216515104, "METEOR": 0.13009213325138705, "ROUGE_L": 0.15151515151515152, "CIDEr": 1.7581591568247413e-21, "SPICE": {"All": {"pr": 0.125, "re": 0.13043478260869565, "f": 0.1276595744680851, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a group of bears standing on the ground in front of a fence. They are all looking at each other and appear to be in a playful mood. The fence is made of wood and has a gate that is open. There are some trees in the background and a small pond with water in it. The overall atmosphere of the image is peaceful and serene."}, "328354": {"image_id": 328354, "Bleu_1": 0.382352941165225, "Bleu_2": 0.2152807725945954, "Bleu_3": 0.1131410407724618, "Bleu_4": 1.4701941950111202e-05, "METEOR": 0.2178426322590564, "ROUGE_L": 0.22932330827067668, "CIDEr": 0.001889881749983485, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.1875, "f": 0.24489795918367344, "fn": 26.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.13333333333333333, "f": 0.2222222222222222, "fn": 13.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "This is an image of an old, abandoned room with a broken chair and a broken sink. The walls are covered in graffiti and there are broken windows on the side of the building."}, "367610": {"image_id": 367610, "Bleu_1": 0.24999999999431824, "Bleu_2": 0.10783277320095921, "Bleu_3": 6.517545715819412e-07, "Bleu_4": 1.6120076571355242e-09, "METEOR": 0.15691100638598235, "ROUGE_L": 0.17579250720461098, "CIDEr": 6.016057241483881e-08, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.23809523809523808, "f": 0.23255813953488372, "fn": 16.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a herd of sheep walking along a road next to a river. There are several people standing on the side of the road, watching the sheep pass by. The sky is clear and blue, with some trees visible in the distance."}, "187352": {"image_id": 187352, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.14458880781007946, "Bleu_3": 8.055078690642645e-07, "Bleu_4": 1.9133137334560038e-09, "METEOR": 0.24683946038759372, "ROUGE_L": 0.25957446808510637, "CIDEr": 2.543413855874032e-07, "SPICE": {"All": {"pr": 0.04, "re": 0.03333333333333333, "f": 0.03636363636363636, "fn": 29.0, "numImages": 1.0, "fp": 24.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.1111111111111111, "f": 0.09523809523809525, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The image shows a man playing tennis on a court at night. He is wearing a yellow shirt and black shorts, and has a racket in his hand. The court is illuminated by bright lights, and there are buildings in the background."}, "403820": {"image_id": 403820, "Bleu_1": 0.3499999999912501, "Bleu_2": 0.23204774044025306, "Bleu_3": 0.1415143113286697, "Bleu_4": 1.66360355848947e-05, "METEOR": 0.252996450838571, "ROUGE_L": 0.28416149068322977, "CIDEr": 2.4160709178908024e-06, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 12.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.2, "f": 0.1111111111111111, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "This is an image of a small airplane flying in the sky. The plane is white and red and has a large propeller on the back. It is flying through a clear blue sky with some clouds in the background."}, "248353": {"image_id": 248353, "Bleu_1": 0.5217391304120984, "Bleu_2": 0.344350221559779, "Bleu_3": 0.2243557191518718, "Bleu_4": 2.7412292652641044e-05, "METEOR": 0.3153262977594623, "ROUGE_L": 0.21205098493626884, "CIDEr": 0.04819111866821684, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.24, "f": 0.2608695652173913, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.18181818181818182, "f": 0.2222222222222222, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is an image of a ski resort with several people skiing down the slopes. There are trees and mountains in the background."}, "472067": {"image_id": 472067, "Bleu_1": 0.2777777777700618, "Bleu_2": 0.19920476821678648, "Bleu_3": 0.1671322184283994, "Bleu_4": 0.14353141358611074, "METEOR": 0.23527028101530964, "ROUGE_L": 0.32947530864197533, "CIDEr": 0.00018446414280819026, "SPICE": {"All": {"pr": 0.06944444444444445, "re": 0.2631578947368421, "f": 0.10989010989010987, "fn": 14.0, "numImages": 1.0, "fp": 67.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 22.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.5, "f": 0.16666666666666669, "fn": 2.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Size": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.5, "f": 0.16666666666666669, "fn": 3.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}}, "caption": "The image shows a group of people sitting on the grass with umbrellas. They are all smiling and looking at something in front of them. The background is green and there are trees in the distance."}, "318080": {"image_id": 318080, "Bleu_1": 0.30769230768441824, "Bleu_2": 0.23807595834181774, "Bleu_3": 0.1662583773973145, "Bleu_4": 1.89021858127867e-05, "METEOR": 0.30013077994535303, "ROUGE_L": 0.3098244086489624, "CIDEr": 3.5278579171947065e-05, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.15384615384615385, "f": 0.16326530612244897, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1111111111111111, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows two brown bears standing on a log, looking at each other. One of the bears is growling and the other is licking its nose. The bears are standing in a clearing surrounded by trees and rocks."}, "491062": {"image_id": 491062, "Bleu_1": 0.34482758619500603, "Bleu_2": 0.19221293610287601, "Bleu_3": 0.11101981187859314, "Bleu_4": 1.5146316522555611e-05, "METEOR": 0.21218024319956852, "ROUGE_L": 0.32649420160570913, "CIDEr": 0.004325523093466744, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.13333333333333333, "f": 0.18181818181818182, "fn": 26.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.07692307692307693, "f": 0.11764705882352941, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a plate of grilled cheese sandwiches with tomato slices on the side. There is a glass of red wine on the table next to the plate."}, "514787": {"image_id": 514787, "Bleu_1": 0.2295081967175491, "Bleu_2": 0.12369537763223652, "Bleu_3": 0.06377027796019516, "Bleu_4": 8.177239806403723e-06, "METEOR": 0.18111644625506373, "ROUGE_L": 0.22228006246746487, "CIDEr": 1.098838948119541e-14, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.12, "f": 0.1276595744680851, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This is a collage of images of people playing video games on their computers. The images are arranged in a grid format, with each image showing a different person playing a different game. Some of the people are wearing green shirts, while others are wearing other colors. The images are all taken from different angles, showing the people from different perspectives."}, "443963": {"image_id": 443963, "Bleu_1": 0.35135135134185547, "Bleu_2": 0.2419887570845995, "Bleu_3": 0.1884491176127898, "Bleu_4": 0.1408585945661569, "METEOR": 0.21791963566388461, "ROUGE_L": 0.31466470154753134, "CIDEr": 6.822433420144544e-05, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.23809523809523808, "f": 0.19607843137254902, "fn": 16.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "This is a bathroom with a sink, toilet, and shower. The walls are painted white and the floor is made of tile. There is a window on one side of the room that lets in natural light."}, "423173": {"image_id": 423173, "Bleu_1": 0.4242424242295685, "Bleu_2": 0.2302830932288319, "Bleu_3": 0.1506829579238831, "Bleu_4": 0.10333984099207438, "METEOR": 0.23969086983199128, "ROUGE_L": 0.39967239967239965, "CIDEr": 0.002566454479165611, "SPICE": {"All": {"pr": 0.5, "re": 0.1875, "f": 0.2727272727272727, "fn": 13.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.125, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "The image shows a person wearing a helmet and riding a motorcycle with a stuffed bear on the back. The person is driving down a street with trees and buildings in the background."}, "392575": {"image_id": 392575, "Bleu_1": 0.2711864406733697, "Bleu_2": 0.21623201167707057, "Bleu_3": 0.17010044797960264, "Bleu_4": 0.13692951948068943, "METEOR": 0.24175681947999025, "ROUGE_L": 0.26767430521696733, "CIDEr": 2.5566122043174684e-12, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.23809523809523808, "f": 0.20408163265306123, "fn": 16.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5, "f": 0.45454545454545453, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "This is an image of a food truck parked on the sidewalk in front of a building. There are people standing around the truck, looking at the menu on the side of the truck. The truck has a red and white striped awning over the top of it. There are trees and buildings in the background of the image."}, "29596": {"image_id": 29596, "Bleu_1": 0.2142857142818878, "Bleu_2": 0.12483755678422238, "Bleu_3": 0.08326112070177698, "Bleu_4": 0.05744638728503178, "METEOR": 0.2092148568288258, "ROUGE_L": 0.2663755458515284, "CIDEr": 5.963800034399782e-13, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.3076923076923077, "f": 0.13114754098360656, "fn": 9.0, "numImages": 1.0, "fp": 44.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 19.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.21052631578947367, "re": 0.5714285714285714, "f": 0.3076923076923077, "fn": 3.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}}, "caption": "This is a living room with a couch, coffee table, and television. The walls are painted a light yellow color and there are curtains on the windows. The floor is made of hardwood and there is a rug on it. The room is well lit by the large window and the lamps on the coffee table."}, "571804": {"image_id": 571804, "Bleu_1": 0.1475409836041387, "Bleu_2": 1.568125120442029e-09, "Bleu_3": 3.4671274317427597e-12, "Bleu_4": 1.637270190247646e-13, "METEOR": 0.14012738853503187, "ROUGE_L": 0.16495402920497565, "CIDEr": 8.146162542615266e-18, "SPICE": {"All": {"pr": 0.45454545454545453, "re": 0.21739130434782608, "f": 0.29411764705882354, "fn": 18.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.75, "re": 0.3, "f": 0.4285714285714285, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "This is a display case with several ceramic items on it. There are two sinks, a toilet, and a bidet on the wall. The sink has a faucet and a drain, while the toilet has a seat and a handle. The bidet has a spray nozzle and a handle. The display case is made of wood and has a glass door."}, "530706": {"image_id": 530706, "Bleu_1": 0.35897435896515456, "Bleu_2": 0.21733262130578967, "Bleu_3": 0.10847992362433123, "Bleu_4": 1.3722599955620144e-05, "METEOR": 0.2417534563033786, "ROUGE_L": 0.2741573033707865, "CIDEr": 7.548792102206737e-05, "SPICE": {"All": {"pr": 0.4444444444444444, "re": 0.19047619047619047, "f": 0.26666666666666666, "fn": 17.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.3333333333333333, "f": 0.46153846153846156, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image shows a group of people sitting at desks in a computer lab. They are all wearing casual clothing and are working on their computers. The room is well lit and there are several windows in the background."}, "475995": {"image_id": 475995, "Bleu_1": 0.19999999999692308, "Bleu_2": 0.07905694150298374, "Bleu_3": 4.629276868992862e-07, "Bleu_4": 1.1247006460052186e-09, "METEOR": 0.14383517210504546, "ROUGE_L": 0.14087759815242493, "CIDEr": 9.56298565832656e-17, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.06896551724137931, "f": 0.0851063829787234, "fn": 27.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a group of people standing on a ledge overlooking a city skyline. They are all looking at a dog that is sitting on the ground. The dog is a white husky with blue eyes and a fluffy coat. The people are all wearing casual clothing, such as t-shirts and jeans. The sky is clear and blue, with a few clouds scattered about."}, "558242": {"image_id": 558242, "Bleu_1": 0.23728813558919856, "Bleu_2": 0.12792458327416775, "Bleu_3": 0.06596968170956508, "Bleu_4": 8.461771328960578e-06, "METEOR": 0.1499808530883995, "ROUGE_L": 0.2010326266066132, "CIDEr": 4.571047757561486e-14, "SPICE": {"All": {"pr": 0.25806451612903225, "re": 0.3333333333333333, "f": 0.29090909090909095, "fn": 16.0, "numImages": 1.0, "fp": 23.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.35714285714285715, "re": 0.625, "f": 0.45454545454545453, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a baseball player in the process of throwing a ball to another player on the field. The player is wearing a blue and white uniform with the number 10 on the back. The other player is wearing a red and white uniform with the number 2 on the back. The image is in black and white."}, "449191": {"image_id": 449191, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.1577557537051747, "Bleu_3": 7.925015807505884e-07, "Bleu_4": 1.785258390372746e-09, "METEOR": 0.23615129358407103, "ROUGE_L": 0.26293103448275856, "CIDEr": 7.66574406526727e-12, "SPICE": {"All": {"pr": 0.3125, "re": 0.17857142857142858, "f": 0.22727272727272727, "fn": 23.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.38461538461538464, "f": 0.4545454545454546, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "This image shows a man standing in the back of a truck, holding a suitcase. The truck is parked in a parking lot with other cars and buildings in the background. The man is wearing a blue shirt and jeans, and has a smile on his face as he holds the suitcase."}, "380993": {"image_id": 380993, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.13719886811129003, "Bleu_3": 0.07269451760681338, "Bleu_4": 9.458362067955946e-06, "METEOR": 0.14296244957306514, "ROUGE_L": 0.18154761904761904, "CIDEr": 3.9588487265571106e-11, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 15.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.7142857142857143, "f": 0.5263157894736842, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a group of people standing under an umbrella on a rainy day. They are all wearing different colored clothing and have their arms around each other. The umbrella is open and provides protection from the rain. The image is in black and white and has a blurry effect."}, "25069": {"image_id": 25069, "Bleu_1": 0.3571428571343538, "Bleu_2": 0.20869596777739105, "Bleu_3": 1.028780463218628e-06, "Bleu_4": 2.2986660387844333e-09, "METEOR": 0.15278440490267386, "ROUGE_L": 0.22197962154294032, "CIDEr": 4.6637011452903825e-06, "SPICE": {"All": {"pr": 0.15555555555555556, "re": 0.30434782608695654, "f": 0.2058823529411765, "fn": 16.0, "numImages": 1.0, "fp": 38.0, "tp": 7.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.14285714285714285, "f": 0.1, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0625, "re": 0.16666666666666666, "f": 0.09090909090909091, "fn": 5.0, "numImages": 1.0, "fp": 15.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3125, "re": 0.5, "f": 0.38461538461538464, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}}, "caption": "The image shows a person skateboarding down the sidewalk on a sunny day. The person is wearing a white shirt and black pants, and has a black helmet on their head. There are trees and buildings in the background of the image."}, "301963": {"image_id": 301963, "Bleu_1": 0.46153846152071015, "Bleu_2": 0.27174648818404223, "Bleu_3": 0.20977124924927762, "Bleu_4": 0.16831972515625002, "METEOR": 0.2506194194224977, "ROUGE_L": 0.42277227722772265, "CIDEr": 0.04757420346502009, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.2857142857142857, "f": 0.24000000000000002, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5, "f": 0.4347826086956522, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "This is a living room with a wooden floor, a couch, a chair, and a window with blinds. There is also a cat on the couch."}, "444304": {"image_id": 444304, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.22281245492303936, "Bleu_3": 0.14793835438670558, "Bleu_4": 0.09209953959056319, "METEOR": 0.2150459502159849, "ROUGE_L": 0.23461538461538461, "CIDEr": 7.386446311352654e-10, "SPICE": {"All": {"pr": 0.1282051282051282, "re": 0.25, "f": 0.1694915254237288, "fn": 15.0, "numImages": 1.0, "fp": 34.0, "tp": 5.0}, "Relation": {"pr": 0.05263157894736842, "re": 0.14285714285714285, "f": 0.07692307692307693, "fn": 6.0, "numImages": 1.0, "fp": 18.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.4444444444444444, "f": 0.32, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}}, "caption": "The image shows a man sitting on a bed, looking at a television. He is wearing a yellow shirt and blue pants. The room has a white wall with a window and a door. There is a small table next to the bed with a lamp on it."}, "505728": {"image_id": 505728, "Bleu_1": 0.12820512820348456, "Bleu_2": 0.08160886385580174, "Bleu_3": 0.04441745698031002, "Bleu_4": 5.846553820567694e-06, "METEOR": 0.13452504485148206, "ROUGE_L": 0.16094986807387862, "CIDEr": 2.757171863475179e-29, "SPICE": {"All": {"pr": 0.08, "re": 0.11764705882352941, "f": 0.09523809523809526, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This image shows a woman in a white apron and gloves mixing something in a bowl on a counter in a kitchen. There are several other kitchen utensils and ingredients on the counter, including a mixing bowl, measuring cups, and a spatula. The woman is wearing a white apron and gloves, and her hair is tied back in a ponytail. The background of the image is a kitchen with white walls, a stainless steel refrigerator, and a stove."}, "170893": {"image_id": 170893, "Bleu_1": 0.33333333332716053, "Bleu_2": 0.2507849312830716, "Bleu_3": 0.15366451712909157, "Bleu_4": 0.09184122179475869, "METEOR": 0.2243680436384526, "ROUGE_L": 0.24970760233918127, "CIDEr": 1.851556057894882e-11, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.17391304347826086, "f": 0.16326530612244897, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a dog sitting on the floor next to a toilet, looking up at the toilet paper hanging from the roll. The dog is wearing a blue collar and has its tongue sticking out of its mouth. The background is a white bathroom with a shower curtain hanging from the shower rod."}, "40711": {"image_id": 40711, "Bleu_1": 0.06302521008376881, "Bleu_2": 0.04612410705654702, "Bleu_3": 0.03303705378986325, "Bleu_4": 0.01979174183105885, "METEOR": 0.09917489270194213, "ROUGE_L": 0.08602319022250078, "CIDEr": 2.4796351817214265e-307, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.10714285714285714, "f": 0.14634146341463414, "fn": 25.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.23076923076923078, "f": 0.3, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a group of people standing in front of a building with a clock tower on top. The building has a lot of ornate details, including carvings and statues. There are also some people walking down the street in the background.\n\nThe image is taken in a city with tall buildings and narrow streets. The sky is cloudy and there are some trees in the background.\n\nThe image is taken in the afternoon, as there are people walking around and the sun is shining. The lighting is soft and warm, with shadows on the ground.\n\nThe image is taken from a low angle, looking up at the building. The camera is positioned near the ground, so the people in the background are small.\n\nThe image is taken in a European city, possibly in Germany or Austria. The architecture of the building is typical of the region, with intricate details and ornate carvings.\n\nThe image is taken in the winter, as there is snow on the ground and the sky is cloudy. The lighting is soft and warm, with shadows on the ground.\n\nThe image is taken in a busy city, with people walking down the street and cars driving by. The building is old and has a lot of history, with intricate details and ornate carvings.\n\nThe image is taken in the evening, as the sun is setting and the sky is turning pink and orange"}, "510734": {"image_id": 510734, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.2704409323110328, "Bleu_3": 0.21208636850185317, "Bleu_4": 0.1434957165837282, "METEOR": 0.21618852671306968, "ROUGE_L": 0.23680124223602486, "CIDEr": 5.362267914264456e-09, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.3333333333333333, "f": 0.23255813953488372, "fn": 10.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.14285714285714285, "f": 0.1, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.6666666666666666, "f": 0.42105263157894735, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "A black and white image of a bench in the middle of a park with people sitting on it. The bench is made of wood and has a backrest. The people are sitting on the bench, looking at their phones. There are trees and buildings in the background."}, "171067": {"image_id": 171067, "Bleu_1": 0.09999999999923079, "Bleu_2": 0.06819943394652073, "Bleu_3": 0.04777026036852094, "Bleu_4": 5.412741367379838e-06, "METEOR": 0.14274862984541148, "ROUGE_L": 0.1318002932325025, "CIDEr": 1.304929294696562e-84, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.15384615384615385, "f": 0.09302325581395349, "fn": 11.0, "numImages": 1.0, "fp": 28.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 16.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.4, "f": 0.23529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "This is a wooden clock with a cuckoo bird on top of it. The clock has a red and white design with a cuckoo bird on top of it. The clock has a small window on the front that shows the time.\n\nThe clock is made of wood and has a cuckoo bird on top of it. The bird is made of metal and has a small beak and wings. The clock has a small window on the front that shows the time.\n\nThe clock is a traditional German design and is known as a cuckoo clock. The cuckoo bird is a common feature of these clocks and is known for its distinctive call. The clock is a beautiful piece of craftsmanship and is a great addition to any home."}, "41572": {"image_id": 41572, "Bleu_1": 0.30952380951644, "Bleu_2": 0.1942853726806771, "Bleu_3": 0.12358053507490456, "Bleu_4": 1.4831886783244554e-05, "METEOR": 0.20993378341337662, "ROUGE_L": 0.22197962154294032, "CIDEr": 1.1161519338603303e-06, "SPICE": {"All": {"pr": 0.46153846153846156, "re": 0.20689655172413793, "f": 0.28571428571428575, "fn": 23.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.3076923076923077, "f": 0.4, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "This is an image of a baseball player swinging a bat at a ball on a field. The player is wearing a baseball uniform and has a glove on his hand. There are trees and buildings in the background of the image."}, "488720": {"image_id": 488720, "Bleu_1": 0.34883720929421314, "Bleu_2": 0.24112141107953186, "Bleu_3": 0.16203281746698117, "Bleu_4": 0.10155170980557418, "METEOR": 0.2715722554716367, "ROUGE_L": 0.30262225372076546, "CIDEr": 1.0487924735611506e-06, "SPICE": {"All": {"pr": 0.2, "re": 0.17391304347826086, "f": 0.18604651162790697, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a person snowboarding down a mountain slope. The person is wearing a black and white snowboarding suit and has their hands on the board. The mountain in the background is covered in snow and has a few trees on it."}, "350675": {"image_id": 350675, "Bleu_1": 0.33333333332716053, "Bleu_2": 0.17733172552966228, "Bleu_3": 8.456484271613048e-07, "Bleu_4": 1.8556661260475451e-09, "METEOR": 0.22376284273171135, "ROUGE_L": 0.28367380833748546, "CIDEr": 2.481198713352259e-09, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.18181818181818182, "f": 0.2222222222222222, "fn": 18.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a person holding a kite in their hand, with the sun shining behind them. The kite is made of white and blue fabric and has a yellow tail. The person is standing on a grassy field with trees in the background. The sky is clear and blue with fluffy white clouds."}, "350309": {"image_id": 350309, "Bleu_1": 0.3333333333247864, "Bleu_2": 0.2094269541404072, "Bleu_3": 0.10583300875248391, "Bleu_4": 1.3470702101939834e-05, "METEOR": 0.27171732747357347, "ROUGE_L": 0.32570556826849734, "CIDEr": 6.1234991245729844e-06, "SPICE": {"All": {"pr": 0.08163265306122448, "re": 0.15384615384615385, "f": 0.10666666666666666, "fn": 22.0, "numImages": 1.0, "fp": 45.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 16.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.36363636363636365, "f": 0.27586206896551724, "fn": 7.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}}, "caption": "This is an image of a bus parked in front of a building at night. The bus is yellow and has the words \"City Bus\" written on the side. There are other cars parked in the lot as well."}, "98261": {"image_id": 98261, "Bleu_1": 0.39999999998666674, "Bleu_2": 0.20341905107934563, "Bleu_3": 1.1390472475032032e-06, "Bleu_4": 2.7199778234000264e-09, "METEOR": 0.20074230156131198, "ROUGE_L": 0.21981981981981977, "CIDEr": 0.0016219034698656625, "SPICE": {"All": {"pr": 0.5714285714285714, "re": 0.09302325581395349, "f": 0.16, "fn": 39.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.06666666666666667, "f": 0.1111111111111111, "fn": 14.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.17647058823529413, "f": 0.2857142857142857, "fn": 14.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image shows two birds perched on a metal rod. One bird is yellow and the other is brown. They are looking at each other and appear to be communicating."}, "314412": {"image_id": 314412, "Bleu_1": 0.43478260867674867, "Bleu_2": 0.344350221559779, "Bleu_3": 0.2826704932237456, "Bleu_4": 0.2180019395504151, "METEOR": 0.226355922682909, "ROUGE_L": 0.379746835443038, "CIDEr": 0.11439474716531284, "SPICE": {"All": {"pr": 0.2413793103448276, "re": 0.2692307692307692, "f": 0.2545454545454545, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5714285714285714, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "This image shows a plate of food with grilled meat, vegetables, and sauce. There are also two forks and knives on the plate."}, "481654": {"image_id": 481654, "Bleu_1": 0.22580645160926122, "Bleu_2": 0.17208707350147742, "Bleu_3": 0.12544934931070312, "Bleu_4": 0.07605684515235847, "METEOR": 0.21459825166907928, "ROUGE_L": 0.2264050901378579, "CIDEr": 9.490096738866102e-17, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.2222222222222222, "f": 0.21621621621621623, "fn": 14.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a person kite surfing in the ocean with a clear blue sky in the background. The person is standing on a board with a kite attached to it, and they are holding onto the handle of the kite as they fly through the air. The water is calm and there are no other boats or people in the area."}, "355956": {"image_id": 355956, "Bleu_1": 0.43902439023319456, "Bleu_2": 0.31429363308854874, "Bleu_3": 0.21638252462819646, "Bleu_4": 0.15195963350283706, "METEOR": 0.2672277829495527, "ROUGE_L": 0.3617494440326167, "CIDEr": 0.00022912795804998424, "SPICE": {"All": {"pr": 0.15, "re": 0.11538461538461539, "f": 0.13043478260869565, "fn": 23.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a group of children playing baseball on a dirt field. They are wearing baseball uniforms and are standing in front of a fence. There is a large building in the background with a sign that reads, \"Baseball Field\"."}, "411754": {"image_id": 411754, "Bleu_1": 0.43478260867674867, "Bleu_2": 0.2811607785452645, "Bleu_3": 1.5555956733899503e-06, "Bleu_4": 3.7039494075864308e-09, "METEOR": 0.25987206226184345, "ROUGE_L": 0.339265850945495, "CIDEr": 0.0657590137784385, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.14285714285714285, "f": 0.1379310344827586, "fn": 24.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.3, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "This is a man sitting at a table in a room with other people. He is using a cell phone to text someone."}, "360767": {"image_id": 360767, "Bleu_1": 0.5999999999600001, "Bleu_2": 0.4140393355768242, "Bleu_3": 0.3407378427051567, "Bleu_4": 0.2849557760109488, "METEOR": 0.25679083725295854, "ROUGE_L": 0.5291201982651798, "CIDEr": 0.40982696531618046, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.17857142857142858, "f": 0.24390243902439027, "fn": 23.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "A group of people riding bicycles along a canal with a bridge in the background."}, "477673": {"image_id": 477673, "Bleu_1": 0.18571428571163268, "Bleu_2": 0.08985841174457912, "Bleu_3": 4.915143342216874e-07, "Bleu_4": 1.1538077193687323e-09, "METEOR": 0.18988740707880206, "ROUGE_L": 0.17832781134281814, "CIDEr": 3.4882580864682907e-22, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.17857142857142858, "f": 0.24390243902439027, "fn": 23.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.08333333333333333, "f": 0.125, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a small kitten sitting inside a backpack. The kitten is looking up at the camera with its big eyes. The backpack is made of black and gray fabric and has a zipper on the top. There is a small pouch on the side of the backpack that the kitten is sitting in. The floor is made of wood and there are some toys scattered around the room."}, "484069": {"image_id": 484069, "Bleu_1": 0.5384615383786985, "Bleu_2": 0.36689969279504947, "Bleu_3": 0.23044502514829485, "Bleu_4": 3.326024950007662e-05, "METEOR": 0.2762426961092967, "ROUGE_L": 0.5343065693430658, "CIDEr": 1.1579338562805204, "SPICE": {"All": {"pr": 0.13513513513513514, "re": 0.35714285714285715, "f": 0.19607843137254902, "fn": 9.0, "numImages": 1.0, "fp": 32.0, "tp": 5.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.2, "f": 0.11764705882352941, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.6666666666666666, "f": 0.36363636363636365, "fn": 2.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}}, "caption": "This is a bowl of creamy broccoli soup with croutons on the side."}, "88345": {"image_id": 88345, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.22228757208608238, "Bleu_3": 0.1714752440578388, "Bleu_4": 0.13323584375722833, "METEOR": 0.2503886813861545, "ROUGE_L": 0.26116207951070336, "CIDEr": 2.355822703358359e-10, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.13636363636363635, "f": 0.16666666666666663, "fn": 19.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The woman in the image is smiling and standing in front of a bar. She is wearing a black and white dress and has her hair styled with long, curly strands hanging down from her head. There are lights hanging from the ceiling and a clock on the wall behind her."}, "250258": {"image_id": 250258, "Bleu_1": 0.3902439024295063, "Bleu_2": 0.24194335155767877, "Bleu_3": 0.14425501641879765, "Bleu_4": 1.6764951224507223e-05, "METEOR": 0.25820789263352323, "ROUGE_L": 0.35905820797907134, "CIDEr": 8.235807645525189e-06, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.17391304347826086, "f": 0.1904761904761905, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a baseball player standing on the field, looking out at the crowd. He is wearing a white jersey with the number 27 on the back and black pants. The crowd is seated in the stands, watching the game."}, "545288": {"image_id": 545288, "Bleu_1": 0.27272727272107444, "Bleu_2": 0.21070705493664102, "Bleu_3": 0.16170481491531974, "Bleu_4": 0.11984053756396974, "METEOR": 0.2461454856093158, "ROUGE_L": 0.2197406340057637, "CIDEr": 2.2723699725644026e-08, "SPICE": {"All": {"pr": 0.12, "re": 0.23076923076923078, "f": 0.15789473684210525, "fn": 10.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.16666666666666666, "re": 0.4, "f": 0.23529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "This is an image of a person skiing down a snowy slope. The person is wearing a black and white ski suit and has a black ski pole in their hand. The snow is covered in trees and there are mountains in the background."}, "195594": {"image_id": 195594, "Bleu_1": 0.3333333333253969, "Bleu_2": 0.201619459631519, "Bleu_3": 0.12667132083273588, "Bleu_4": 0.08496549121092281, "METEOR": 0.2092987898318215, "ROUGE_L": 0.3028368794326241, "CIDEr": 3.9472716323508216e-07, "SPICE": {"All": {"pr": 0.16, "re": 0.18181818181818182, "f": 0.1702127659574468, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This is a black and white image of a man standing next to a drain pipe. He is wearing a black shirt and jeans, and has a skateboard in his hand. The background is a grassy field with trees in the distance."}, "271402": {"image_id": 271402, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.2659080117331791, "Bleu_3": 0.2257862427272305, "Bleu_4": 0.16933280344199816, "METEOR": 0.3017722237240802, "ROUGE_L": 0.38730158730158726, "CIDEr": 3.068151189843222e-07, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.09090909090909091, "f": 0.12000000000000001, "fn": 30.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows two young girls standing on a tennis court, one holding a tennis racket and the other holding a skateboard. They are both wearing white tennis outfits and sneakers. The background is a fenced in tennis court with a net in the center."}, "121572": {"image_id": 121572, "Bleu_1": 0.29487179486801446, "Bleu_2": 0.2143689482011329, "Bleu_3": 0.16175935280135822, "Bleu_4": 0.12257495217288374, "METEOR": 0.27237231503085385, "ROUGE_L": 0.26375786163522014, "CIDEr": 3.24916935503169e-23, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.23529411764705882, "f": 0.22857142857142856, "fn": 13.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.4, "f": 0.3076923076923077, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a group of red double decker buses parked on the side of a city street. The buses are lined up in a row, with one in the front and the others behind it. The buses are painted in red and white, with the words \"double decker\" written on the side. There are people walking down the street, looking at the buses. The buildings on either side of the street are tall and made of brick."}, "398748": {"image_id": 398748, "Bleu_1": 0.8571428570816327, "Bleu_2": 0.7262730391486911, "Bleu_3": 0.5602211879040704, "Bleu_4": 0.42284283425196, "METEOR": 0.35510078446672155, "ROUGE_L": 0.7359249329758714, "CIDEr": 1.097651720436716, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.19230769230769232, "f": 0.17857142857142855, "fn": 21.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "A seagull stands on a beach with a body of water in the background."}, "50159": {"image_id": 50159, "Bleu_1": 0.4583333333142362, "Bleu_2": 0.31565436976372857, "Bleu_3": 0.23862030429939607, "Bleu_4": 0.15948715930717874, "METEOR": 0.21630324317992097, "ROUGE_L": 0.4518518518518518, "CIDEr": 0.1504498204711902, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.16666666666666666, "f": 0.20338983050847456, "fn": 30.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.07142857142857142, "f": 0.09090909090909091, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3076923076923077, "f": 0.33333333333333337, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "A man and woman are skiing down a snowy mountain. They are wearing ski gear and carrying backpacks. The sky is clear and blue."}, "71850": {"image_id": 71850, "Bleu_1": 0.37999999999240003, "Bleu_2": 0.1525296893116513, "Bleu_3": 7.855174634741559e-07, "Bleu_4": 1.7920182118967283e-09, "METEOR": 0.24541269915517314, "ROUGE_L": 0.2852466682253917, "CIDEr": 3.5486672497894907e-09, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.22727272727272727, "f": 0.18867924528301885, "fn": 17.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a green traffic light hanging from a pole in the middle of a busy street. The light is surrounded by tall buildings on either side, with windows and balconies visible on the upper floors. The sky is clear and blue, with a few clouds scattered across it."}, "363321": {"image_id": 363321, "Bleu_1": 0.1710526315766967, "Bleu_2": 0.09551338658691873, "Bleu_3": 0.04976976491776065, "Bleu_4": 6.410523211270908e-06, "METEOR": 0.1807533162395191, "ROUGE_L": 0.13714028776978418, "CIDEr": 2.3214548892753014e-27, "SPICE": {"All": {"pr": 0.45454545454545453, "re": 0.1724137931034483, "f": 0.25000000000000006, "fn": 24.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}, "Relation": {"pr": 0.4, "re": 0.2, "f": 0.26666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.23076923076923078, "f": 0.3157894736842105, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a group of children standing near a giraffe at a zoo. The children are looking at the giraffe and one of them is feeding it. The giraffe is standing on its hind legs and reaching its long neck to eat from the child's hand. The children are wearing hats and sunglasses, and the giraffe is wearing a halter and a tag on its neck. The background is a fence and some trees."}, "19102": {"image_id": 19102, "Bleu_1": 0.29999999999250004, "Bleu_2": 0.23204774044025303, "Bleu_3": 0.1619934477030545, "Bleu_4": 0.1035315355582459, "METEOR": 0.19648833485506345, "ROUGE_L": 0.18429003021148035, "CIDEr": 1.9324892133990936e-05, "SPICE": {"All": {"pr": 0.08571428571428572, "re": 0.1875, "f": 0.11764705882352938, "fn": 13.0, "numImages": 1.0, "fp": 32.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 16.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.375, "f": 0.26086956521739135, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "The image shows two zebras standing in a field with trees in the background. The zebras are black and white with long manes and tails. They are looking directly at the camera with their heads tilted slightly to the side."}, "223764": {"image_id": 223764, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.19711142525707728, "Bleu_3": 9.52219404908826e-07, "Bleu_4": 2.104697094558331e-09, "METEOR": 0.20768165557567528, "ROUGE_L": 0.26571250777846916, "CIDEr": 3.153197612196858e-08, "SPICE": {"All": {"pr": 0.1, "re": 0.11764705882352941, "f": 0.1081081081081081, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The woman is standing in front of a mirror, holding a towel over her head. She is wearing a black shirt and pants, and has a tattoo on her left arm. The mirror is reflecting her image, and there are some droplets of water on the countertop."}, "115118": {"image_id": 115118, "Bleu_1": 0.7499999999375001, "Bleu_2": 0.4522670168272435, "Bleu_3": 0.2734827537714344, "Bleu_4": 3.8827267771481786e-05, "METEOR": 0.2772935206174219, "ROUGE_L": 0.43821839080459773, "CIDEr": 0.9611382938220997, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.17391304347826086, "f": 0.2222222222222222, "fn": 19.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "A train traveling on a railroad track with several cars carrying cargo."}, "546222": {"image_id": 546222, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.19847906537508855, "Bleu_3": 0.09712260421875578, "Bleu_4": 1.2152843817707948e-05, "METEOR": 0.2617586380017016, "ROUGE_L": 0.32084155161078237, "CIDEr": 7.309404297713542e-08, "SPICE": {"All": {"pr": 0.03571428571428571, "re": 0.0625, "f": 0.045454545454545456, "fn": 15.0, "numImages": 1.0, "fp": 27.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "This is a man standing next to a horse in a field. The man has a beard and is wearing a green hat and sunglasses. The horse is brown and has a white blaze on its forehead. There are trees and fences in the background."}, "167122": {"image_id": 167122, "Bleu_1": 0.37499999999062505, "Bleu_2": 0.2594372608248164, "Bleu_3": 0.1745021516446632, "Bleu_4": 0.10947127055916415, "METEOR": 0.24763331964327684, "ROUGE_L": 0.2981843575418994, "CIDEr": 3.582345213803896e-05, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.17391304347826086, "f": 0.1568627450980392, "fn": 19.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2727272727272727, "f": 0.2608695652173913, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a car parked in front of a building at night. The car's headlights are on, illuminating the area around it. There are no people in the image, but there are some lights on in the building."}, "542605": {"image_id": 542605, "Bleu_1": 0.33333333332407417, "Bleu_2": 0.21821789022984422, "Bleu_3": 0.16136438271820902, "Bleu_4": 0.12632368169568278, "METEOR": 0.272954092584186, "ROUGE_L": 0.3276550030693677, "CIDEr": 0.00014680892273088888, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.2777777777777778, "f": 0.20408163265306123, "fn": 13.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "Sure, here is a short caption for the image:\n\nA group of people on motorcycles ride down a street lined with shops and restaurants. The sun is shining and there are palm trees in the background."}, "356733": {"image_id": 356733, "Bleu_1": 0.20967741935145687, "Bleu_2": 0.17588636300376279, "Bleu_3": 0.127289044383558, "Bleu_4": 0.0914403259624082, "METEOR": 0.20505666797262498, "ROUGE_L": 0.25077081192189105, "CIDEr": 1.856499286853487e-16, "SPICE": {"All": {"pr": 0.5, "re": 0.09523809523809523, "f": 0.16, "fn": 19.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 1.0, "re": 0.16666666666666666, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}}, "caption": "The image shows a group of teddy bears sitting on a couch. They are all wearing blue jeans and white shirts. One of the bears is holding a stuffed animal in its hand. The bears are arranged in a line on the couch, with one bear sitting in the middle. The background of the image is a brown and white striped rug."}, "279846": {"image_id": 279846, "Bleu_1": 0.382352941165225, "Bleu_2": 0.2636640221444497, "Bleu_3": 1.295141607895443e-06, "Bleu_4": 2.8933269905362777e-09, "METEOR": 0.20422383259147917, "ROUGE_L": 0.25206611570247933, "CIDEr": 0.0007769148631229241, "SPICE": {"All": {"pr": 0.6666666666666666, "re": 0.23076923076923078, "f": 0.3428571428571429, "fn": 20.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 5.0}}, "caption": "This is an image of a plate with a pizza on it. The pizza has cheese, bacon, and eggs on it. There are two glasses of wine on the table next to the plate."}, "326368": {"image_id": 326368, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.19603921176003908, "Bleu_3": 0.13300573168298876, "Bleu_4": 0.08367437134425945, "METEOR": 0.2911006250551568, "ROUGE_L": 0.3285457809694794, "CIDEr": 3.335530913364752e-10, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.12903225806451613, "f": 0.14814814814814814, "fn": 27.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.23076923076923078, "f": 0.2608695652173913, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A man is standing next to two Harley Davidson motorcycles on a beach. The man is wearing a leather jacket and sunglasses, and the motorcycles are parked on the sand. In the background, there is a body of water and some trees.\""}, "577868": {"image_id": 577868, "Bleu_1": 0.5384615384201185, "Bleu_2": 0.36689969282327245, "Bleu_3": 0.23044502516602136, "Bleu_4": 3.3260249502635095e-05, "METEOR": 0.26350669042156716, "ROUGE_L": 0.5457798985982703, "CIDEr": 0.4754434677337962, "SPICE": {"All": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 10.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows two halves of a blood orange on a blue plate."}, "558107": {"image_id": 558107, "Bleu_1": 0.6874999999570314, "Bleu_2": 0.5664215155622997, "Bleu_3": 0.45088987146905807, "Bleu_4": 0.3446073376795577, "METEOR": 0.46347040922039384, "ROUGE_L": 0.48157894736842105, "CIDEr": 1.5968620957543083, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.15789473684210525, "f": 0.18181818181818182, "fn": 16.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a red fire hydrant with a leopard print hat on top of it."}, "378311": {"image_id": 378311, "Bleu_1": 0.2916666666545139, "Bleu_2": 0.19504737439306988, "Bleu_3": 0.12002890534307711, "Bleu_4": 1.693984999796846e-05, "METEOR": 0.20502003142015837, "ROUGE_L": 0.3177083333333333, "CIDEr": 0.05665108782676418, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.13043478260869565, "f": 0.16216216216216214, "fn": 20.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is a kitchen with several ovens and stoves lined up against the walls. There are also several tables and chairs in the room."}, "578168": {"image_id": 578168, "Bleu_1": 0.4074074073923183, "Bleu_2": 0.3311896883635246, "Bleu_3": 0.23610849866565936, "Bleu_4": 2.721328088631675e-05, "METEOR": 0.284137207097557, "ROUGE_L": 0.3440496333897349, "CIDEr": 0.0220086722145875, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.0625, "f": 0.08163265306122448, "fn": 30.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.18181818181818182, "f": 0.23529411764705885, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "This is an image of a train car with blue seats and a white ceiling. There are no people in the car, and the windows are open."}, "81552": {"image_id": 81552, "Bleu_1": 0.6999999998600002, "Bleu_2": 0.6236095643341374, "Bleu_3": 0.5263632996930899, "Bleu_4": 0.4518010017056429, "METEOR": 0.3980060258818823, "ROUGE_L": 0.6802973977695167, "CIDEr": 2.360221482807086, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.46153846153846156, "f": 0.2448979591836735, "fn": 7.0, "numImages": 1.0, "fp": 30.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.8, "f": 0.4210526315789473, "fn": 1.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a cat sleeping on a red couch."}, "51576": {"image_id": 51576, "Bleu_1": 0.27027027026296574, "Bleu_2": 0.1732917482985969, "Bleu_3": 0.09502311009068282, "Bleu_4": 1.2603820262448582e-05, "METEOR": 0.18500346337376086, "ROUGE_L": 0.2293233082706767, "CIDEr": 2.6042719046167286e-05, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.09090909090909091, "f": 0.1142857142857143, "fn": 20.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image shows a herd of zebras grazing in a green field. They are standing in a line, with their heads down and their stripes visible. There are trees in the background, and the sky is cloudy."}, "270571": {"image_id": 270571, "Bleu_1": 0.6191984997331017, "Bleu_2": 0.4063986276844881, "Bleu_3": 0.3295597275093693, "Bleu_4": 0.2740623716911265, "METEOR": 0.3336538336190373, "ROUGE_L": 0.543026706231454, "CIDEr": 1.181317833360795, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.15789473684210525, "f": 0.13043478260869565, "fn": 16.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The woman is holding a knife and cutting up some food on the counter."}, "510559": {"image_id": 510559, "Bleu_1": 0.37209302324716065, "Bleu_2": 0.18824832212957474, "Bleu_3": 0.09525609865690522, "Bleu_4": 1.212424196299872e-05, "METEOR": 0.2112989409768176, "ROUGE_L": 0.28561872909699, "CIDEr": 1.3040956862291802e-06, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.2, "f": 0.16, "fn": 16.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5714285714285714, "f": 0.38095238095238093, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a woman surfing on a wave in the ocean. She is wearing a pink wetsuit and has her arms outstretched as she rides the wave. The sky is cloudy and there are waves crashing on the shore in the background."}, "529065": {"image_id": 529065, "Bleu_1": 0.23684210525692528, "Bleu_2": 0.13857638305004102, "Bleu_3": 8.110083286556016e-07, "Bleu_4": 1.9758409157987315e-09, "METEOR": 0.22079787102676726, "ROUGE_L": 0.28728414442700156, "CIDEr": 3.136122421708081e-06, "SPICE": {"All": {"pr": 0.07547169811320754, "re": 0.2, "f": 0.10958904109589042, "fn": 16.0, "numImages": 1.0, "fp": 49.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 25.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.17391304347826086, "re": 0.4444444444444444, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}}, "caption": "This image shows a person skateboarding on a ramp in a dark room. The person is wearing a black hoodie and jeans, and has a skateboard under their foot. The walls of the room are covered in graffiti."}, "289659": {"image_id": 289659, "Bleu_1": 0.35483870966597303, "Bleu_2": 0.2431867285489846, "Bleu_3": 0.18289464893778182, "Bleu_4": 0.1445835022636036, "METEOR": 0.18540506701871656, "ROUGE_L": 0.26872246696035246, "CIDEr": 0.0017822065359553666, "SPICE": {"All": {"pr": 0.15, "re": 0.16666666666666666, "f": 0.15789473684210525, "fn": 15.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA giraffe stands in a grassy field, looking at something on the ground. The giraffe has a long neck and spotted fur."}, "558585": {"image_id": 558585, "Bleu_1": 0.6315789473351802, "Bleu_2": 0.4588314677163038, "Bleu_3": 0.291493687914218, "Bleu_4": 3.527295712498206e-05, "METEOR": 0.3755840599383525, "ROUGE_L": 0.4796854521625164, "CIDEr": 0.17307063860334043, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.22727272727272727, "f": 0.23255813953488372, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "A mother duck and her ducklings swim in a pond with a reflection of the sky in the water."}, "463669": {"image_id": 463669, "Bleu_1": 0.41463414633135043, "Bleu_2": 0.32196045810044155, "Bleu_3": 0.23686641674494138, "Bleu_4": 0.16262571440776885, "METEOR": 0.32883393032893005, "ROUGE_L": 0.38391608391608395, "CIDEr": 1.0919293918699158e-05, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.16, "f": 0.1818181818181818, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is a black and white image of a cat lying on a blue blanket. The cat is laying on its side with its paws tucked under its body. The cat's eyes are closed and it appears to be sleeping."}, "116046": {"image_id": 116046, "Bleu_1": 0.19512195121475318, "Bleu_2": 0.1209716757788394, "Bleu_3": 0.07212750820939885, "Bleu_4": 9.968499639428789e-06, "METEOR": 0.12005309862703602, "ROUGE_L": 0.18583396801218582, "CIDEr": 4.32368242558739e-08, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.18518518518518517, "f": 0.17241379310344826, "fn": 22.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a group of people standing in front of a whiteboard with a diagram on it. They are all wearing casual clothing and looking at the diagram intently. There is a laptop on the table in front of them."}, "533508": {"image_id": 533508, "Bleu_1": 0.46874999998535166, "Bleu_2": 0.3012072483288726, "Bleu_3": 1.446116209595764e-06, "Bleu_4": 3.1956035588831537e-09, "METEOR": 0.1769911504424779, "ROUGE_L": 0.3367507886435331, "CIDEr": 0.0012675141387944542, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.1111111111111111, "f": 0.09999999999999999, "fn": 24.0, "numImages": 1.0, "fp": 30.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.13333333333333333, "re": 0.18181818181818182, "f": 0.15384615384615383, "fn": 9.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}}, "caption": "This is a large, white church with a tall steeple and a large dome on top. The building is surrounded by trees and greenery, and there are people walking in the foreground."}, "89555": {"image_id": 89555, "Bleu_1": 0.2023809523785431, "Bleu_2": 0.15615136014210537, "Bleu_3": 0.08409481678741602, "Bleu_4": 9.256688871884123e-06, "METEOR": 0.17726296590548266, "ROUGE_L": 0.19645732689210949, "CIDEr": 4.55122679199235e-33, "SPICE": {"All": {"pr": 0.1, "re": 0.13636363636363635, "f": 0.11538461538461538, "fn": 19.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.375, "f": 0.2727272727272727, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a cat lying on a bed, with its paws tucked under its body and its head resting on the pillow. The cat is wearing a pink collar with a tag on it. The bed is covered with a blue and white striped blanket, and there is a vase of flowers on the nightstand next to the bed. The room has a white ceiling and white walls, and there is a window on the left side of the image with curtains open."}, "472295": {"image_id": 472295, "Bleu_1": 0.20967741935145687, "Bleu_2": 0.13109795466387256, "Bleu_3": 0.06591944272673252, "Bleu_4": 8.347321532539378e-06, "METEOR": 0.181969395056124, "ROUGE_L": 0.15968586387434555, "CIDEr": 6.726473882641467e-17, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.15, "f": 0.125, "fn": 17.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3333333333333333, "f": 0.27272727272727276, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This is a photograph of a person skiing down a snowy mountain slope. The person is wearing a red jacket and blue pants, and they are holding a ski pole in their right hand. The snow is deep and powdery, and there are trees on either side of the slope. The sky is cloudy and there are some clouds in the background."}, "27221": {"image_id": 27221, "Bleu_1": 0.23913043477741028, "Bleu_2": 0.1457945082861785, "Bleu_3": 0.07846510342081583, "Bleu_4": 1.029533066265393e-05, "METEOR": 0.18533327954573509, "ROUGE_L": 0.2367399741267788, "CIDEr": 1.1595371944049448e-07, "SPICE": {"All": {"pr": 0.4444444444444444, "re": 0.15384615384615385, "f": 0.2285714285714286, "fn": 22.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.09090909090909091, "f": 0.14285714285714288, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The woman is sitting on the steps of a building, looking at her phone. She is wearing a black sweater and black pants, and has her hair pulled back in a ponytail. The building behind her has a large window with a view of the city."}, "435185": {"image_id": 435185, "Bleu_1": 0.4242424242295685, "Bleu_2": 0.30463589791309564, "Bleu_3": 0.14412306446248796, "Bleu_4": 1.777337082847116e-05, "METEOR": 0.21132758251459374, "ROUGE_L": 0.3396976929196499, "CIDEr": 0.0015317865453036042, "SPICE": {"All": {"pr": 0.34782608695652173, "re": 0.42105263157894735, "f": 0.380952380952381, "fn": 11.0, "numImages": 1.0, "fp": 15.0, "tp": 8.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.6666666666666666, "f": 0.631578947368421, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "This is an image of a green glass vase with a red rose in it. The vase is sitting on a white tablecloth and there are other green glass objects on the table."}, "393805": {"image_id": 393805, "Bleu_1": 0.7430381995735735, "Bleu_2": 0.7326455450859374, "Bleu_3": 0.6535803740836913, "Bleu_4": 0.4959623816571399, "METEOR": 0.27464711463596864, "ROUGE_L": 0.5700934579439253, "CIDEr": 1.6857686772352376, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.35714285714285715, "f": 0.24390243902439024, "fn": 9.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6666666666666666, "f": 0.4444444444444444, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "Two zebras are fighting in the grass."}, "535151": {"image_id": 535151, "Bleu_1": 0.6666666665555557, "Bleu_2": 0.4264014326385389, "Bleu_3": 2.629535893869793e-06, "Bleu_4": 6.704226836958771e-09, "METEOR": 0.20932842997714965, "ROUGE_L": 0.39713541666666663, "CIDEr": 0.257178321925304, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.14285714285714285, "f": 0.1702127659574468, "fn": 24.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "A wooden cutting board with a knife and various vegetables on it."}, "13490": {"image_id": 13490, "Bleu_1": 0.43333333331888896, "Bleu_2": 0.2733361367859988, "Bleu_3": 0.1387007121316575, "Bleu_4": 1.7730381369880694e-05, "METEOR": 0.2871697332108684, "ROUGE_L": 0.37854609929078015, "CIDEr": 0.005517649533439873, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.2857142857142857, "f": 0.3, "fn": 15.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a slice of green bread on a cutting board with a knife next to it. There is also a jar of peanut butter on the cutting board."}, "504091": {"image_id": 504091, "Bleu_1": 0.43589743588625907, "Bleu_2": 0.33868842842057195, "Bleu_3": 0.2103003922771325, "Bleu_4": 0.15076895886062214, "METEOR": 0.32557838664242544, "ROUGE_L": 0.4112359550561798, "CIDEr": 3.2624203084710925e-05, "SPICE": {"All": {"pr": 0.044444444444444446, "re": 0.08695652173913043, "f": 0.058823529411764705, "fn": 21.0, "numImages": 1.0, "fp": 43.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 18.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.2222222222222222, "f": 0.14814814814814814, "fn": 7.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}}, "caption": "The image shows a man in an orange shirt holding a tennis racket and preparing to hit a ball on a tennis court. The court is surrounded by trees and there are other people playing tennis in the background."}, "555696": {"image_id": 555696, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.1956151991049542, "Bleu_3": 0.11764652669092619, "Bleu_4": 1.3716549481276805e-05, "METEOR": 0.19248915753434687, "ROUGE_L": 0.2622527944969905, "CIDEr": 2.092238891672966e-09, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.13793103448275862, "f": 0.16, "fn": 25.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a soccer game in progress. There are several players on the field, including one who is kicking the ball towards the goal. The other players are trying to block the shot. The crowd is cheering and there are several people in the stands watching the game."}, "183437": {"image_id": 183437, "Bleu_1": 0.1690140845046618, "Bleu_2": 0.10987463131816817, "Bleu_3": 0.055930485641128104, "Bleu_4": 7.122118815224206e-06, "METEOR": 0.14119121438306564, "ROUGE_L": 0.1714285714285714, "CIDEr": 2.325291900060387e-23, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.23809523809523808, "f": 0.22727272727272724, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a group of people riding on the back of an elephant. The elephant is walking down a dirt road with trees and buildings in the background. The people are sitting on the elephant's back, holding onto its ears and trunk. One person is standing on the elephant's back, holding onto its tail. The elephant is wearing a saddle and has a rope tied around its neck."}, "393743": {"image_id": 393743, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.15182109665359528, "Bleu_3": 0.10007189813274586, "Bleu_4": 1.2216054866635074e-05, "METEOR": 0.2271352388486404, "ROUGE_L": 0.2401574803149606, "CIDEr": 7.64017415017818e-09, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.13157894736842105, "f": 0.1492537313432836, "fn": 33.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.08333333333333333, "f": 0.09523809523809525, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.1875, "f": 0.21428571428571427, "fn": 13.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "A young girl in a soccer uniform stands on a soccer field, holding a soccer ball in her hands. She is looking up at the sky with a serious expression on her face. The background of the image is a green grass field with trees in the distance."}, "441873": {"image_id": 441873, "Bleu_1": 0.29999999999500004, "Bleu_2": 0.1886616557167528, "Bleu_3": 0.12256134399477547, "Bleu_4": 1.340591378711483e-05, "METEOR": 0.28457042602115074, "ROUGE_L": 0.23410087719298245, "CIDEr": 3.1534355381653464e-15, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.125, "f": 0.13043478260869565, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.25, "f": 0.2727272727272727, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "A young boy is holding a kite and flying it in the sky. The kite has a red and white striped tail and a blue body with a white wing. The boy is wearing a black shirt and shorts, and his hair is messy. The background is a rocky beach with some trees and a blue ocean in the distance."}, "454810": {"image_id": 454810, "Bleu_1": 0.2777777777700618, "Bleu_2": 0.1259881576661928, "Bleu_3": 7.757590387941911e-07, "Bleu_4": 1.939396682572253e-09, "METEOR": 0.20400772699641587, "ROUGE_L": 0.25673400673400676, "CIDEr": 1.449461607168169e-05, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.15, "f": 0.14285714285714282, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is a kitchen with a sink, stove, and refrigerator. There are several utensils on the counter, including a kettle, toaster, and blender. The walls are painted white and there are blue curtains in the window."}, "173598": {"image_id": 173598, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.10735372697093548, "Bleu_3": 0.063041345480191, "Bleu_4": 8.638055235544587e-06, "METEOR": 0.20725535263850192, "ROUGE_L": 0.19110275689223058, "CIDEr": 5.848674852328202e-09, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.21428571428571427, "f": 0.2553191489361702, "fn": 22.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a baseball game in progress on a large field with a crowd of people watching from the stands. The players are wearing their team's uniforms and are playing on the field. The umpire is standing behind home plate, ready to call the next pitch."}, "262274": {"image_id": 262274, "Bleu_1": 0.13761467889782006, "Bleu_2": 0.08743717709702774, "Bleu_3": 4.1495674289302847e-07, "Bleu_4": 9.060990045016577e-10, "METEOR": 0.12881383842753447, "ROUGE_L": 0.11727010573534125, "CIDEr": 1.6927689309310923e-57, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.06896551724137931, "f": 0.10526315789473684, "fn": 27.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.18181818181818182, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "The image shows a lifeguard stand on a beach with people walking on the sand. The sky is clear and blue, and there are palm trees in the background.\n\nThe lifeguard stand is white and has a red and yellow flag on top. There are several surfboards and beach umbrellas on the sand nearby.\n\nThe people in the image are walking towards the lifeguard stand, some of them carrying surfboards and others walking with their dogs. The beach is empty except for the people and the lifeguard stand.\n\nThe overall mood of the image is peaceful and serene, with the calm ocean and clear sky creating a relaxing atmosphere."}, "451284": {"image_id": 451284, "Bleu_1": 0.10810810810737766, "Bleu_2": 0.07670354916679706, "Bleu_3": 0.0431952527738745, "Bleu_4": 4.855511804363418e-06, "METEOR": 0.11658037334477914, "ROUGE_L": 0.11869353717859626, "CIDEr": 1.5141641524673074e-113, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.17391304347826086, "f": 0.17777777777777776, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "A laptop is sitting on a bed with a cup of coffee next to it. There is a blanket on the bed and a lamp on the nightstand.\n\nThe laptop has a screen open with a spreadsheet on it. The cup of coffee has a spoon in it and is sitting on top of a mug. The mug has a handle on it and is sitting on top of a plate. The plate has a saucer on it.\n\nThere is a book on the nightstand next to the laptop. The book has a cover on it and is open to a page with writing on it. There is also a pen on the nightstand next to the book.\n\nThe room is well lit and there are curtains on the windows. The floor is covered in a rug and there is a chair in the corner of the room."}, "254750": {"image_id": 254750, "Bleu_1": 0.36363636362534446, "Bleu_2": 0.26111648392551057, "Bleu_3": 0.20643767470015953, "Bleu_4": 0.17222322558680261, "METEOR": 0.3057085836942883, "ROUGE_L": 0.38822593476531425, "CIDEr": 0.0018028295686260748, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.23529411764705882, "f": 0.19999999999999998, "fn": 13.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is a bathroom with a toilet, sink, and shower. The walls are white and the floor is tiled. There is a window on the left side of the room with curtains open."}, "321557": {"image_id": 321557, "Bleu_1": 0.22222222221869492, "Bleu_2": 0.189320611412659, "Bleu_3": 0.14322274352926753, "Bleu_4": 0.11009091786306532, "METEOR": 0.2633386755180416, "ROUGE_L": 0.22920021470746108, "CIDEr": 2.4440218978566794e-18, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.23809523809523808, "f": 0.22727272727272724, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a black motorcycle parked on the side of a building. The motorcycle has a sleek design and is parked next to a window with a view of the street outside. The tires are black and the bike has a black seat and handlebars. The motorcycle is parked in front of a building with a large window and a white door."}, "489920": {"image_id": 489920, "Bleu_1": 0.25806451612486997, "Bleu_2": 0.2253148686982713, "Bleu_3": 0.20377120700392579, "Bleu_4": 0.1779994336683129, "METEOR": 0.30022971152067746, "ROUGE_L": 0.30776992936427855, "CIDEr": 3.9838006479341514e-16, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.2413793103448276, "f": 0.27450980392156865, "fn": 22.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.625, "f": 0.5555555555555556, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "This is a black and white photograph of a bench sitting in front of a brick wall. The bench is made of wood and has a smooth, flat surface. The wall behind the bench is made of brick and has a pattern of squares and rectangles on it. There are no other objects in the image, just the bench and the wall."}, "197398": {"image_id": 197398, "Bleu_1": 0.5999999999760001, "Bleu_2": 0.3872983346049271, "Bleu_3": 0.23539531025786062, "Bleu_4": 2.774870273442235e-05, "METEOR": 0.2679017317740704, "ROUGE_L": 0.39588355275356946, "CIDEr": 0.1467133546986021, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.2, "f": 0.21276595744680854, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a sandwich on a plate with a drink next to it. There is a person sitting at a table in the background."}, "301981": {"image_id": 301981, "Bleu_1": 0.34782608694139894, "Bleu_2": 0.2177862025825042, "Bleu_3": 1.3120402049391552e-06, "Bleu_4": 3.2598893461057542e-09, "METEOR": 0.3334674999023782, "ROUGE_L": 0.407119021134594, "CIDEr": 0.047174940197664814, "SPICE": {"All": {"pr": 0.28, "re": 0.2692307692307692, "f": 0.27450980392156865, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA giraffe stands in a enclosure at a zoo, looking out at the visitors."}, "5486": {"image_id": 5486, "Bleu_1": 0.19148936169805347, "Bleu_2": 0.09124485969890858, "Bleu_3": 5.698161672784481e-07, "Bleu_4": 1.4319831453628615e-09, "METEOR": 0.19284185063864645, "ROUGE_L": 0.1667805878332194, "CIDEr": 1.975589023053085e-09, "SPICE": {"All": {"pr": 0.5454545454545454, "re": 0.3157894736842105, "f": 0.39999999999999997, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.75, "re": 0.42857142857142855, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.75, "re": 0.6, "f": 0.6666666666666665, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "This is a living room with a wooden table and chairs, a couch, and a bookshelf. There is a window on the left side of the room with curtains. The walls are painted a light yellow color and there is a large chandelier hanging from the ceiling."}, "548485": {"image_id": 548485, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.18233123936852927, "Bleu_3": 0.11306584792083928, "Bleu_4": 0.07528274645181147, "METEOR": 0.2578964347608675, "ROUGE_L": 0.27799479166666663, "CIDEr": 1.3588166482941123e-08, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.17391304347826086, "f": 0.17391304347826086, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "This is a bathroom with a white tiled floor, a white bathtub, and a white toilet. There is a shower curtain hanging on the wall and a sink with a faucet and mirror above it. The walls are painted white and there are no windows in the room."}, "400596": {"image_id": 400596, "Bleu_1": 0.333333333325926, "Bleu_2": 0.2611164839276783, "Bleu_3": 0.16817978480756843, "Bleu_4": 0.10316158870782567, "METEOR": 0.2772593621833057, "ROUGE_L": 0.2922655715263518, "CIDEr": 1.0148821074374978e-06, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.2631578947368421, "f": 0.3125, "fn": 14.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "This is a bathroom with a green countertop and a white sink. There is a window on the left side of the room and a mirror on the right side. The floor is made of hardwood and there are two wooden chairs in the room."}, "227730": {"image_id": 227730, "Bleu_1": 0.16363636363338846, "Bleu_2": 0.123091490977074, "Bleu_3": 0.08299846557886467, "Bleu_4": 1.0240041382038528e-05, "METEOR": 0.21747561848170918, "ROUGE_L": 0.21542083578575633, "CIDEr": 1.559639420947881e-13, "SPICE": {"All": {"pr": 0.03333333333333333, "re": 0.034482758620689655, "f": 0.03389830508474576, "fn": 28.0, "numImages": 1.0, "fp": 29.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.07692307692307693, "re": 0.07692307692307693, "f": 0.07692307692307693, "fn": 12.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}}, "caption": "The image shows a cat lying in a bowl of water. The cat is laying on its side with its paws tucked under its body and its head resting on the edge of the bowl. The bowl is filled with water and there are some papers and other objects on the counter next to it."}, "553998": {"image_id": 553998, "Bleu_1": 0.21276595744228163, "Bleu_2": 0.1799372899254913, "Bleu_3": 0.08960727674188575, "Bleu_4": 1.1308221067043766e-05, "METEOR": 0.22524260485605588, "ROUGE_L": 0.33414485696895924, "CIDEr": 2.093825344692355e-08, "SPICE": {"All": {"pr": 0.3, "re": 0.13043478260869565, "f": 0.18181818181818182, "fn": 20.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A truck is parked in front of a tree with branches hanging down. The truck has a large load of logs on the back, and the driver is standing next to it, looking at something on his phone.\""}, "306173": {"image_id": 306173, "Bleu_1": 0.11702127659449979, "Bleu_2": 0.07931876501501778, "Bleu_3": 0.040893538045061344, "Bleu_4": 5.235771284676671e-06, "METEOR": 0.19648822976804875, "ROUGE_L": 0.14066102997694083, "CIDEr": 3.6615576250722086e-45, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.17391304347826086, "f": 0.2162162162162162, "fn": 19.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a small kitten sleeping on top of a pile of papers on a desk. The kitten is curled up and has its eyes closed, looking very content. The papers are scattered around the kitten, with some of them open and others closed. There is a pen lying next to the kitten, as if it had been left there by someone who was working on the papers. The overall atmosphere of the image is one of peacefulness and tranquility, with the kitten seeming to be the only living thing in the room."}, "418281": {"image_id": 418281, "Bleu_1": 0.4814814814636489, "Bleu_2": 0.2721655269656347, "Bleu_3": 0.20714883372228218, "Bleu_4": 0.16497440012151016, "METEOR": 0.27103532702947014, "ROUGE_L": 0.38006230529595014, "CIDEr": 0.00995064310615602, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.21428571428571427, "f": 0.26666666666666666, "fn": 22.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.45454545454545453, "f": 0.5263157894736842, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image shows a cow standing in a field with trees in the background. There is a small building in the distance with a spire on top."}, "348654": {"image_id": 348654, "Bleu_1": 0.35897435896515456, "Bleu_2": 0.2571514254230454, "Bleu_3": 0.12135529099637384, "Bleu_4": 1.4926858358180366e-05, "METEOR": 0.2453609785749934, "ROUGE_L": 0.39019189765458434, "CIDEr": 8.642325377980523e-06, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.10526315789473684, "f": 0.10810810810810811, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "A black and white image of a desk with a phone on it. The phone is charging and there is a laptop on the desk as well. There is a white mouse on the desk next to the laptop."}, "577821": {"image_id": 577821, "Bleu_1": 0.34482758619500603, "Bleu_2": 0.22194838080144763, "Bleu_3": 0.12219311400302733, "Bleu_4": 1.6275776313020367e-05, "METEOR": 0.2562212746479907, "ROUGE_L": 0.29075309818875117, "CIDEr": 0.0038337969277281543, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.23076923076923078, "f": 0.1935483870967742, "fn": 20.0, "numImages": 1.0, "fp": 30.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.3333333333333333, "f": 0.2608695652173913, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "This is a clock tower in a city with a blue sky and white buildings in the background. The clock has two hands and a face with Roman numerals."}, "509819": {"image_id": 509819, "Bleu_1": 0.6874999999570314, "Bleu_2": 0.42817441926118477, "Bleu_3": 0.23570626875117834, "Bleu_4": 3.168053533620014e-05, "METEOR": 0.29110719356849013, "ROUGE_L": 0.4013157894736842, "CIDEr": 0.9947342286127727, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.2777777777777778, "f": 0.2380952380952381, "fn": 13.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "This image shows a table with various sewing tools, including scissors, a ruler, and a pencil."}, "356937": {"image_id": 356937, "Bleu_1": 0.1692307692281657, "Bleu_2": 0.07272180923421494, "Bleu_3": 4.3785428098085625e-07, "Bleu_4": 1.0786965203811752e-09, "METEOR": 0.1645145167089913, "ROUGE_L": 0.15649050795279631, "CIDEr": 3.433160704101654e-20, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.12, "f": 0.15384615384615383, "fn": 22.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.08333333333333333, "f": 0.11764705882352941, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "This is an image of a person skiing down a snowy road. The person is wearing a blue jacket and pants, and has a pair of skis on their feet. The road is lined with trees on either side, and there are snowbanks on either side of the road. The sky is clear and blue, and there are no other people or vehicles in sight."}, "145215": {"image_id": 145215, "Bleu_1": 0.26190476189852613, "Bleu_2": 0.17871654962201275, "Bleu_3": 0.0927733381723083, "Bleu_4": 1.1961929431463712e-05, "METEOR": 0.2892763313595142, "ROUGE_L": 0.2663755458515284, "CIDEr": 2.8295014622670877e-07, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.1724137931034483, "f": 0.2173913043478261, "fn": 24.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a person standing on the beach, looking out at the ocean. The waves are crashing against the shore and the person is holding a surfboard. The sky is cloudy and there is a sense of calmness in the atmosphere."}, "368367": {"image_id": 368367, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.18233123936852927, "Bleu_3": 0.12942808646135376, "Bleu_4": 0.09907766622892053, "METEOR": 0.2666063229892049, "ROUGE_L": 0.2401574803149606, "CIDEr": 3.4753102635835557e-09, "SPICE": {"All": {"pr": 0.2413793103448276, "re": 0.35, "f": 0.2857142857142857, "fn": 13.0, "numImages": 1.0, "fp": 22.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.45454545454545453, "f": 0.45454545454545453, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The woman is smiling and talking on her cell phone while sitting at a table outside. She is wearing a black tank top and shorts, and has a tattoo on her left arm. The background is a restaurant with a patio area and tables set up for dining."}, "190756": {"image_id": 190756, "Bleu_1": 0.22727272726756204, "Bleu_2": 0.14540168172223333, "Bleu_3": 0.07954810829018738, "Bleu_4": 1.0526316596948142e-05, "METEOR": 0.2508871121667864, "ROUGE_L": 0.25702247191011235, "CIDEr": 4.0846851112619427e-08, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 24.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.07142857142857142, "f": 0.1, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.4166666666666667, "f": 0.5, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image shows a person performing a stunt on a dirt bike in the air. The person is wearing a helmet and is holding onto the handlebars of the bike as they jump off a ramp. The sky is clear and blue behind them."}, "170849": {"image_id": 170849, "Bleu_1": 0.6153846153609468, "Bleu_2": 0.415099617313932, "Bleu_3": 0.24305681724053524, "Bleu_4": 2.8109226562566195e-05, "METEOR": 0.2803777739190147, "ROUGE_L": 0.45101663585951934, "CIDEr": 0.0457110589207959, "SPICE": {"All": {"pr": 0.125, "re": 0.15, "f": 0.13636363636363635, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "A group of seagulls are flying over a beach with people walking on it. The sky is cloudy and there are palm trees in the background."}, "22842": {"image_id": 22842, "Bleu_1": 0.3928571428431123, "Bleu_2": 0.24124895480980643, "Bleu_3": 0.13081348353639377, "Bleu_4": 1.729833809317658e-05, "METEOR": 0.24484124652371725, "ROUGE_L": 0.40283018867924525, "CIDEr": 0.005674466562910417, "SPICE": {"All": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 18.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.2857142857142857, "f": 0.4444444444444445, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "This image shows a dish of broccoli and cheese casserole with a fork on the side. The dish is in a white container with a lid on top."}, "307166": {"image_id": 307166, "Bleu_1": 0.34999999998250003, "Bleu_2": 0.2350811729787503, "Bleu_3": 0.14534086178782885, "Bleu_4": 2.061477352044535e-05, "METEOR": 0.2072205963782802, "ROUGE_L": 0.3546511627906977, "CIDEr": 0.06704940174147642, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.08333333333333333, "f": 0.07407407407407407, "fn": 22.0, "numImages": 1.0, "fp": 28.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.2, "f": 0.12500000000000003, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "This image shows a table with several pizzas on it. There are also some drinks and utensils on the table."}, "384401": {"image_id": 384401, "Bleu_1": 0.5199999999792001, "Bleu_2": 0.3291402942887518, "Bleu_3": 0.16762730266737055, "Bleu_4": 2.1510618470053686e-05, "METEOR": 0.2085893720621509, "ROUGE_L": 0.38566912539515275, "CIDEr": 0.052147344251620285, "SPICE": {"All": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "This is a pizza in a pan on a stove. The crust is golden brown and the cheese is melted. There are no toppings visible."}, "127880": {"image_id": 127880, "Bleu_1": 0.3809523809433107, "Bleu_2": 0.28917761562015887, "Bleu_3": 0.2029752640180059, "Bleu_4": 0.1439042708815865, "METEOR": 0.2557127908004215, "ROUGE_L": 0.29047619047619044, "CIDEr": 6.832086096791239e-06, "SPICE": {"All": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 14.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.5714285714285714, "f": 0.6666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The image shows a young girl sitting on the floor holding a toy in her hand. She is wearing a pink shirt and has long blonde hair. The background is a white tiled floor with a toilet and sink in the corner."}, "98839": {"image_id": 98839, "Bleu_1": 0.7499999999531252, "Bleu_2": 0.5916079782717537, "Bleu_3": 0.464158883330242, "Bleu_4": 0.3521856535578892, "METEOR": 0.3113869639249568, "ROUGE_L": 0.4212707182320442, "CIDEr": 0.815274541589375, "SPICE": {"All": {"pr": 0.047619047619047616, "re": 0.09523809523809523, "f": 0.06349206349206349, "fn": 19.0, "numImages": 1.0, "fp": 40.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 20.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2857142857142857, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The cat is sitting on the couch in front of the television, looking at the screen."}, "114684": {"image_id": 114684, "Bleu_1": 0.18867924527945892, "Bleu_2": 0.12047318414543881, "Bleu_3": 0.0657764151723667, "Bleu_4": 8.685806487296046e-06, "METEOR": 0.1485342019543974, "ROUGE_L": 0.1763005780346821, "CIDEr": 1.5470390389269876e-12, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.2916666666666667, "f": 0.27450980392156865, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.5454545454545454, "f": 0.4999999999999999, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The woman is sitting on a bench in the park, eating a sandwich. She is wearing a pink jacket and has her hair tied back in a ponytail. The bench is made of wood and has a few scratches on it. There are some trees in the background, and the sky is cloudy."}, "107781": {"image_id": 107781, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.13862658669016847, "Bleu_3": 0.09041487870756197, "Bleu_4": 0.06170031538925975, "METEOR": 0.21851367216868106, "ROUGE_L": 0.23487348734873487, "CIDEr": 1.7203472099264217e-11, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 16.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a tennis match in progress on a clay court. There are several people in the stands watching the match, and the players are wearing tennis clothes and shoes. The court is covered in red clay, and there are lines marked on it to indicate where the players should hit the ball."}, "109370": {"image_id": 109370, "Bleu_1": 0.34782608694896033, "Bleu_2": 0.21535276081853263, "Bleu_3": 0.12822107162674182, "Bleu_4": 1.4879983094072411e-05, "METEOR": 0.25019391689476883, "ROUGE_L": 0.3403897254207263, "CIDEr": 3.3376400070505365e-07, "SPICE": {"All": {"pr": 0.041666666666666664, "re": 0.05263157894736842, "f": 0.04651162790697675, "fn": 18.0, "numImages": 1.0, "fp": 23.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.1, "f": 0.0909090909090909, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The image shows a man in white tennis attire holding a tennis racket and standing on a tennis court. He is wearing white shoes and has a determined expression on his face. The background is a green grassy field with a few spectators in the stands."}, "46252": {"image_id": 46252, "Bleu_1": 0.38461538460798816, "Bleu_2": 0.21271781490162772, "Bleu_3": 0.09672659665842728, "Bleu_4": 1.1657633846364334e-05, "METEOR": 0.20331617111329478, "ROUGE_L": 0.2921655833048238, "CIDEr": 6.942660531205059e-10, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.2222222222222222, "f": 0.21818181818181817, "fn": 21.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.45454545454545453, "f": 0.45454545454545453, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a baseball player hitting a ball on a field with a catcher watching from behind home plate. The player is wearing a red jersey and white pants, while the catcher is wearing a blue jersey and white pants. The background is a green field with trees in the distance."}, "523517": {"image_id": 523517, "Bleu_1": 0.2575757575718549, "Bleu_2": 0.15419540776397248, "Bleu_3": 0.0905727666025965, "Bleu_4": 0.05860208768717415, "METEOR": 0.23352370006810494, "ROUGE_L": 0.2079680498733684, "CIDEr": 8.979777017935592e-17, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.12, "f": 0.11764705882352941, "fn": 22.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is an image of a baseball player swinging a bat at a baseball during a game. The player is wearing a baseball uniform and has a determined look on his face. The other players on the field are watching him closely as he swings the bat. The background of the image is a green field with a dirt infield and a dugout in the background."}, "293591": {"image_id": 293591, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.19296124624292718, "Bleu_3": 0.11741874968995038, "Bleu_4": 0.07744617268822214, "METEOR": 0.19724775472562178, "ROUGE_L": 0.28018372703412076, "CIDEr": 6.572660993395438e-10, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.2, "f": 0.1951219512195122, "fn": 16.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a group of zebras standing next to a large boulder in a rocky area. The zebras are grazing on the grass and seem to be enjoying the sunny weather. In the background, there is a large tree with branches that stretch up towards the sky."}, "554340": {"image_id": 554340, "Bleu_1": 0.30769230768441824, "Bleu_2": 0.20121090914115636, "Bleu_3": 1.0304662546247208e-06, "Bleu_4": 2.3480087200537226e-09, "METEOR": 0.21684745212595435, "ROUGE_L": 0.2601279317697228, "CIDEr": 5.606837234106829e-06, "SPICE": {"All": {"pr": 0.3888888888888889, "re": 0.30434782608695654, "f": 0.34146341463414637, "fn": 16.0, "numImages": 1.0, "fp": 11.0, "tp": 7.0}, "Relation": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.8333333333333334, "f": 0.6666666666666667, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "This is an image of a piece of bread that has been dropped on the ground. The bread is lying on its side and has a bite taken out of it. There is a yellow line in the background."}, "335827": {"image_id": 335827, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.2014440620697061, "Bleu_3": 0.12263904310164322, "Bleu_4": 1.4391446615915733e-05, "METEOR": 0.16309909622998237, "ROUGE_L": 0.2367399741267788, "CIDEr": 4.717377086109459e-08, "SPICE": {"All": {"pr": 0.22580645161290322, "re": 0.25, "f": 0.23728813559322032, "fn": 21.0, "numImages": 1.0, "fp": 24.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.6666666666666666, "f": 0.5454545454545455, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "This is a photograph of a church with a tall steeple and stained glass windows. The building is made of stone and has a red door. There are several people standing outside the church, looking at something on the ground. The sky is clear and blue."}, "529348": {"image_id": 529348, "Bleu_1": 0.5833333332847223, "Bleu_2": 0.39886201757398354, "Bleu_3": 0.25150606040109846, "Bleu_4": 3.6462858615851904e-05, "METEOR": 0.2625515114816112, "ROUGE_L": 0.5187074829931972, "CIDEr": 1.2485178733179227, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.16666666666666666, "f": 0.17142857142857143, "fn": 15.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "Two zebras are standing under a green umbrella in a grassy area."}, "414529": {"image_id": 414529, "Bleu_1": 0.36842105262188374, "Bleu_2": 0.24442576475815658, "Bleu_3": 0.11839421659852312, "Bleu_4": 1.4756414813318596e-05, "METEOR": 0.3092979097289007, "ROUGE_L": 0.3531114327062228, "CIDEr": 0.000311967125794161, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.25, "f": 0.22727272727272727, "fn": 15.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a man playing tennis on a court. He is wearing a white shirt and black shorts, and has a tennis racket in his hand. The court is green and there are spectators in the stands."}, "446881": {"image_id": 446881, "Bleu_1": 0.3571428571343538, "Bleu_2": 0.29514066804336486, "Bleu_3": 0.22164403183852815, "Bleu_4": 0.17012032085747555, "METEOR": 0.3467667390616062, "ROUGE_L": 0.37044534412955465, "CIDEr": 5.196058167740995e-06, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.18181818181818182, "f": 0.2285714285714286, "fn": 18.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "This is a living room with a couch, coffee table, and television. There are two chairs in front of the television and a rug on the floor. The walls are painted white and there are windows on one side of the room."}, "33835": {"image_id": 33835, "Bleu_1": 0.3214285714170919, "Bleu_2": 0.10910894511402736, "Bleu_3": 7.707540024261883e-07, "Bleu_4": 2.0687206009477373e-09, "METEOR": 0.24198159543510517, "ROUGE_L": 0.34528301886792445, "CIDEr": 0.0027867566563021836, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.1, "f": 0.14634146341463417, "fn": 27.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A group of people are gathered around a computer, playing video games. They are all smiling and having fun.\""}, "259452": {"image_id": 259452, "Bleu_1": 0.4074074073923183, "Bleu_2": 0.30662207032435856, "Bleu_3": 0.22428282780473585, "Bleu_4": 0.17510627353462763, "METEOR": 0.2599891097899013, "ROUGE_L": 0.41256038647342996, "CIDEr": 0.03587040644026604, "SPICE": {"All": {"pr": 0.15, "re": 0.17647058823529413, "f": 0.16216216216216214, "fn": 14.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a city skyline with tall buildings and a busy road in the foreground. The sky is cloudy and there are trees in the background."}, "76648": {"image_id": 76648, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.1399708424419251, "Bleu_3": 7.41784871677873e-07, "Bleu_4": 1.7166589196261759e-09, "METEOR": 0.19580188562751058, "ROUGE_L": 0.27128335451080055, "CIDEr": 3.895580831603103e-10, "SPICE": {"All": {"pr": 0.45454545454545453, "re": 0.23809523809523808, "f": 0.31249999999999994, "fn": 16.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4444444444444444, "f": 0.5333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image shows a street sign with the words \"stop\" written on it in white letters. The sign is mounted on a green and white pole in the middle of the street. There are bicycles parked on both sides of the street, and buildings can be seen in the background."}, "251582": {"image_id": 251582, "Bleu_1": 0.26829268292028563, "Bleu_2": 0.16379642331674352, "Bleu_3": 8.82771032769294e-07, "Bleu_4": 2.0627194143358034e-09, "METEOR": 0.15023474178403756, "ROUGE_L": 0.25756509500351865, "CIDEr": 9.68202651708843e-07, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.17391304347826086, "f": 0.1702127659574468, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a zebra standing next to a tree, with its baby in its mouth. The zebra is wearing a collar and has a tag on its ear. The tree has leaves and branches that are swaying in the wind."}, "313182": {"image_id": 313182, "Bleu_1": 0.5882352940830451, "Bleu_2": 0.42874646283026363, "Bleu_3": 0.2904780222281507, "Bleu_4": 3.637499566860159e-05, "METEOR": 0.2604115744362526, "ROUGE_L": 0.4860004552697473, "CIDEr": 0.6792436852208719, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.3333333333333333, "f": 0.32, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 8.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.15384615384615385, "f": 0.18181818181818185, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.7142857142857143, "f": 0.588235294117647, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a purple bus parked on the side of a street with people walking by."}, "479099": {"image_id": 479099, "Bleu_1": 0.21311475409486702, "Bleu_2": 0.11919584838724184, "Bleu_3": 6.221428039423803e-07, "Bleu_4": 1.4274488769439242e-09, "METEOR": 0.14949718464212855, "ROUGE_L": 0.18702095043433828, "CIDEr": 4.101393765902056e-15, "SPICE": {"All": {"pr": 0.13157894736842105, "re": 0.22727272727272727, "f": 0.16666666666666666, "fn": 17.0, "numImages": 1.0, "fp": 33.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.3333333333333333, "f": 0.14285714285714288, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.4444444444444444, "f": 0.32, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}}, "caption": "This image shows a garden with a brick wall in the background and various plants and flowers in the foreground. There is a bench in the center of the garden, surrounded by a path made of stone. The plants and flowers are arranged in a symmetrical pattern, with different colors and shapes. The overall effect is one of serenity and tranquility."}, "88084": {"image_id": 88084, "Bleu_1": 0.34210526314889206, "Bleu_2": 0.23553456043175583, "Bleu_3": 0.16658760276667972, "Bleu_4": 0.10720498931970826, "METEOR": 0.3021633520173375, "ROUGE_L": 0.3531114327062228, "CIDEr": 4.544782550664753e-05, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.11764705882352941, "f": 0.1509433962264151, "fn": 30.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.08333333333333333, "f": 0.1, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "This is an image of a red fire hydrant on the side of a city street. The hydrant is made of white concrete and has a red handle on top. There are no other objects in the image."}, "147577": {"image_id": 147577, "Bleu_1": 0.29999999999500004, "Bleu_2": 0.20168779363245437, "Bleu_3": 0.15192657487117783, "Bleu_4": 0.10532078688575773, "METEOR": 0.20084907501835025, "ROUGE_L": 0.29353803849679194, "CIDEr": 1.068172366933878e-14, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.2, "f": 0.16, "fn": 16.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.1, "re": 0.08333333333333333, "f": 0.0909090909090909, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This image shows a mural on the side of a building depicting people walking through a train station. The mural is painted in bright colors and features people of different races and ages, as well as a train engine and cars. The mural appears to be a representation of a bustling train station, with people rushing to catch their trains."}, "6789": {"image_id": 6789, "Bleu_1": 0.40624999998730477, "Bleu_2": 0.2804086879058332, "Bleu_3": 0.13787553963788365, "Bleu_4": 1.7338675531051076e-05, "METEOR": 0.21716420371967463, "ROUGE_L": 0.24053627760252363, "CIDEr": 0.0013050217479931283, "SPICE": {"All": {"pr": 0.25, "re": 0.29411764705882354, "f": 0.27027027027027023, "fn": 12.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5, "f": 0.36363636363636365, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a street with several cars parked on the side of the road. There are power lines running along the side of the road and a building in the background."}, "408501": {"image_id": 408501, "Bleu_1": 0.6190476190181406, "Bleu_2": 0.4309458036646331, "Bleu_3": 0.3083691961453375, "Bleu_4": 0.23891455817181373, "METEOR": 0.31067945497387023, "ROUGE_L": 0.46362649294245384, "CIDEr": 0.20609319294851564, "SPICE": {"All": {"pr": 0.12, "re": 0.08823529411764706, "f": 0.10169491525423728, "fn": 31.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a yellow and blue train traveling down the tracks next to a building with windows and a roof."}, "379784": {"image_id": 379784, "Bleu_1": 0.22413793103061835, "Bleu_2": 0.10861276726025744, "Bleu_3": 5.950104277147966e-07, "Bleu_4": 1.3989518286920131e-09, "METEOR": 0.18622174205554207, "ROUGE_L": 0.16850828729281767, "CIDEr": 9.317710486141371e-15, "SPICE": {"All": {"pr": 0.13513513513513514, "re": 0.17857142857142858, "f": 0.15384615384615385, "fn": 23.0, "numImages": 1.0, "fp": 32.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3125, "re": 0.4166666666666667, "f": 0.35714285714285715, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}}, "caption": "This image shows a man skateboarding down a ramp made of graffiti covered concrete. The man is wearing a black shirt and blue jeans, and he is holding onto the handlebars of his skateboard with one hand while he rides it with the other. The sun is shining in the background, casting a warm glow over the scene."}, "209808": {"image_id": 209808, "Bleu_1": 0.37499999999062505, "Bleu_2": 0.19611613513321832, "Bleu_3": 0.1265001431634541, "Bleu_4": 0.08600383785666736, "METEOR": 0.22550595731288245, "ROUGE_L": 0.23036253776435048, "CIDEr": 1.5374773860138384e-06, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.18518518518518517, "f": 0.22727272727272727, "fn": 22.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.36363636363636365, "f": 0.4210526315789474, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "There are two plates on the table with a burger and fries on them. The burger has two buns and a patty made of ground beef, lettuce, tomato, and cheese. The fries are in a bowl next to the burger."}, "82696": {"image_id": 82696, "Bleu_1": 0.6842105262797785, "Bleu_2": 0.38993176788930844, "Bleu_3": 0.20757550605447114, "Bleu_4": 2.734337277990397e-05, "METEOR": 0.2691647408036729, "ROUGE_L": 0.511377245508982, "CIDEr": 0.48853626168493897, "SPICE": {"All": {"pr": 0.11627906976744186, "re": 0.35714285714285715, "f": 0.1754385964912281, "fn": 9.0, "numImages": 1.0, "fp": 38.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.08333333333333333, "re": 0.25, "f": 0.125, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.23529411764705882, "re": 0.6666666666666666, "f": 0.3478260869565218, "fn": 2.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}}, "caption": "A black and white bird stands on the floor in front of a group of chairs in a cafeteria."}, "531349": {"image_id": 531349, "Bleu_1": 0.2181818181778513, "Bleu_2": 0.17978662998689882, "Bleu_3": 0.1450116762655686, "Bleu_4": 0.11516796881559117, "METEOR": 0.22849987870360577, "ROUGE_L": 0.25676488274203246, "CIDEr": 3.170885291240961e-13, "SPICE": {"All": {"pr": 0.2, "re": 0.14814814814814814, "f": 0.1702127659574468, "fn": 23.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is a red double decker bus parked on the side of a busy street in a city. The bus has a large sign on the front that reads \"Hong Kong\" in Chinese characters. The bus is surrounded by tall buildings and skyscrapers, and there are people walking on the sidewalk in front of it."}, "285114": {"image_id": 285114, "Bleu_1": 0.28947368420290864, "Bleu_2": 0.15320195579385062, "Bleu_3": 8.671123520251266e-07, "Bleu_4": 2.0774927578554473e-09, "METEOR": 0.21013878118214896, "ROUGE_L": 0.1829085457271364, "CIDEr": 9.808241440926776e-06, "SPICE": {"All": {"pr": 0.06060606060606061, "re": 0.08, "f": 0.0689655172413793, "fn": 23.0, "numImages": 1.0, "fp": 31.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "This is an image of an airport terminal at night. There are several planes parked on the tarmac, and people are walking around the terminal. The building has a large glass facade and a sign that reads \"Airport\"."}, "228771": {"image_id": 228771, "Bleu_1": 0.32499999999187507, "Bleu_2": 0.20412414522676303, "Bleu_3": 0.10311813598199678, "Bleu_4": 1.312051431427763e-05, "METEOR": 0.23380510985365496, "ROUGE_L": 0.2621776504297994, "CIDEr": 6.381245792551479e-06, "SPICE": {"All": {"pr": 0.125, "re": 0.15789473684210525, "f": 0.13953488372093023, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This is a street sign with the words \"little italy college street\" written on it. The sign is made of metal and has a red and white color scheme. It is mounted on a pole next to a brick building."}, "147259": {"image_id": 147259, "Bleu_1": 0.43589743588625907, "Bleu_2": 0.33868842842057195, "Bleu_3": 0.24933868574072204, "Bleu_4": 0.18958192902983748, "METEOR": 0.36149626137225727, "ROUGE_L": 0.3559445660102115, "CIDEr": 3.863811125943054e-05, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.11538461538461539, "f": 0.11320754716981132, "fn": 23.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.2727272727272727, "f": 0.24999999999999994, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This is an image of a dog playing fetch with a frisbee in a park. The dog is jumping in the air and catching the frisbee with its mouth. There are people watching the dog play in the background."}, "525899": {"image_id": 525899, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.18594210949553755, "Bleu_3": 0.09092135343040635, "Bleu_4": 1.1368320017948453e-05, "METEOR": 0.22853454087251235, "ROUGE_L": 0.23461538461538461, "CIDEr": 1.224787036541431e-09, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.4117647058823529, "f": 0.3181818181818182, "fn": 10.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.14285714285714285, "f": 0.10526315789473685, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a person surfing on a wave in the ocean. The person is wearing a black wetsuit and holding a surfboard. The water is choppy and there are waves crashing against the shore. The sky is cloudy and there are some birds flying in the distance."}, "384788": {"image_id": 384788, "Bleu_1": 0.7999999999466668, "Bleu_2": 0.6324555319900065, "Bleu_3": 0.49742263460378094, "Bleu_4": 0.31823566219589394, "METEOR": 0.28401979904030167, "ROUGE_L": 0.4979591836734694, "CIDEr": 1.1224744684189103, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.11538461538461539, "f": 0.16216216216216214, "fn": 23.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.23076923076923078, "f": 0.33333333333333337, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "A cup of hot chocolate sits on a saucer next to a plate of cookies."}, "464265": {"image_id": 464265, "Bleu_1": 0.24675324675004215, "Bleu_2": 0.19738550848535039, "Bleu_3": 0.1012821908977142, "Bleu_4": 1.0885337164780287e-05, "METEOR": 0.1842967468394623, "ROUGE_L": 0.21260969689425532, "CIDEr": 1.5238517988634796e-25, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.16666666666666666, "f": 0.11764705882352942, "fn": 15.0, "numImages": 1.0, "fp": 30.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.3333333333333333, "f": 0.2608695652173913, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a woman standing in front of a display of fresh produce in a market. There are several baskets of fruits and vegetables on the counter, including apples, oranges, carrots, and lettuce. The woman is wearing a white shirt and black pants, and she is looking at the produce with a curious expression on her face. The background of the image is a bright and colorful market with many other customers shopping for their groceries."}, "399452": {"image_id": 399452, "Bleu_1": 0.7980538110608693, "Bleu_2": 0.6762057946055686, "Bleu_3": 0.5216010964217963, "Bleu_4": 0.3936932246084364, "METEOR": 0.2988185936409389, "ROUGE_L": 0.4680306905370844, "CIDEr": 1.3537113836948889, "SPICE": {"All": {"pr": 0.5, "re": 0.23809523809523808, "f": 0.3225806451612903, "fn": 16.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.8, "re": 0.4444444444444444, "f": 0.5714285714285714, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "A plate of food with a sandwich, fries, and a drink on the table."}, "540926": {"image_id": 540926, "Bleu_1": 0.36363636362534446, "Bleu_2": 0.2383656473040621, "Bleu_3": 0.12237946382258257, "Bleu_4": 1.5721757596698785e-05, "METEOR": 0.21516651442447093, "ROUGE_L": 0.31853785900783294, "CIDEr": 0.0002505470987479296, "SPICE": {"All": {"pr": 0.2, "re": 0.22727272727272727, "f": 0.21276595744680854, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a group of people sitting at a table with laptops and papers in front of them. They are all wearing business attire and appear to be working on their laptops."}, "507187": {"image_id": 507187, "Bleu_1": 0.33333333332407417, "Bleu_2": 0.21821789022984422, "Bleu_3": 0.14096477244685904, "Bleu_4": 1.7068857826300113e-05, "METEOR": 0.2506192605475117, "ROUGE_L": 0.29047619047619044, "CIDEr": 2.155471293147099e-05, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.21739130434782608, "f": 0.26315789473684204, "fn": 18.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a group of people standing around a green motorcycle on the grass. The people are dressed in casual clothing and are looking at the motorcycle. There are other cars and bikes parked nearby."}, "494320": {"image_id": 494320, "Bleu_1": 0.26315789472991696, "Bleu_2": 0.16866980207552001, "Bleu_3": 9.245364897036987e-07, "Bleu_4": 2.1798470960469237e-09, "METEOR": 0.1617982716308728, "ROUGE_L": 0.19709208400646203, "CIDEr": 3.4581796618512503e-06, "SPICE": {"All": {"pr": 0.4, "re": 0.17391304347826086, "f": 0.24242424242424243, "fn": 19.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.42857142857142855, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "This is an image of a train parked in a train station. The train is black and has a number of people standing on the platform next to it. There are also other trains parked in the background."}, "546203": {"image_id": 546203, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.08102873913224524, "Bleu_3": 5.344862889225302e-07, "Bleu_4": 1.380829650333459e-09, "METEOR": 0.14967930559871, "ROUGE_L": 0.2053872053872054, "CIDEr": 5.760611646422951e-09, "SPICE": {"All": {"pr": 0.12, "re": 0.11538461538461539, "f": 0.11764705882352941, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a group of people standing on a ski slope, wearing ski gear and holding skis. They are all wearing helmets and goggles, and some of them are holding poles. The background is a mountainous landscape with trees and buildings in the distance."}, "157862": {"image_id": 157862, "Bleu_1": 0.34146341462581803, "Bleu_2": 0.2613286875248416, "Bleu_3": 0.2190215959975318, "Bleu_4": 0.18236198178139834, "METEOR": 0.30424819237090794, "ROUGE_L": 0.35234657039711187, "CIDEr": 2.4597344079778157e-05, "SPICE": {"All": {"pr": 0.03571428571428571, "re": 0.041666666666666664, "f": 0.03846153846153846, "fn": 23.0, "numImages": 1.0, "fp": 27.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.08333333333333333, "f": 0.08333333333333333, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The woman is sitting on the toilet, holding a bottle of water in her hand. She is wearing a colorful dress and has long brown hair. The bathroom has a white sink and toilet, and there are flowers on the wall."}, "467966": {"image_id": 467966, "Bleu_1": 0.4193548386961499, "Bleu_2": 0.26437184629550714, "Bleu_3": 0.1340738673392395, "Bleu_4": 1.7128470920484556e-05, "METEOR": 0.22505495422117236, "ROUGE_L": 0.3224669603524229, "CIDEr": 0.0013530729516932117, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.09523809523809523, "f": 0.11428571428571427, "fn": 19.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.16666666666666666, "f": 0.23529411764705882, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "Sure, here is a short caption for the image:\n\nA small plane sits on the shore of a large body of water, surrounded by birds and a mountain in the background."}, "574856": {"image_id": 574856, "Bleu_1": 0.27397260273597296, "Bleu_2": 0.10684346079119829, "Bleu_3": 5.437665834850141e-07, "Bleu_4": 1.231076032621299e-09, "METEOR": 0.15904161641579492, "ROUGE_L": 0.1922557406573615, "CIDEr": 1.1746078977359435e-24, "SPICE": {"All": {"pr": 0.09375, "re": 0.15789473684210525, "f": 0.11764705882352941, "fn": 16.0, "numImages": 1.0, "fp": 29.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.375, "f": 0.2727272727272727, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a train traveling along a railroad track through a rural landscape. The train is made up of two locomotives, one black and one red, pulling a series of passenger cars behind it. The train is moving at a slow pace, with smoke billowing from the chimneys of the locomotives. Trees and bushes line the track on either side, and a small body of water can be seen in the distance."}, "290957": {"image_id": 290957, "Bleu_1": 0.2909090909038017, "Bleu_2": 0.194191754997615, "Bleu_3": 0.14171480766163438, "Bleu_4": 0.08601230531574432, "METEOR": 0.2151431024380338, "ROUGE_L": 0.24110671936758893, "CIDEr": 2.5754671424074995e-12, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.2, "f": 0.25641025641025644, "fn": 20.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.06666666666666667, "f": 0.09523809523809522, "fn": 14.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5714285714285714, "f": 0.5714285714285714, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a brown horse grazing in a green field. The horse is standing on its hind legs and has a white blaze on its forehead. The horse's mane is long and flowing, and its tail is long and straight. The background of the image is a clear blue sky with some clouds."}, "456519": {"image_id": 456519, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.18898223650071672, "Bleu_3": 0.09125318612878565, "Bleu_4": 1.1336958836408244e-05, "METEOR": 0.22162172177536554, "ROUGE_L": 0.27566171723692706, "CIDEr": 1.1781261588307194e-09, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.09090909090909091, "f": 0.13793103448275862, "fn": 20.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image shows a tennis player hitting a ball with a racket on a blue tennis court. The player is wearing a yellow shirt and white shorts, and has a determined expression on his face. The ball is flying through the air and the player is in mid swing."}, "82933": {"image_id": 82933, "Bleu_1": 0.1960784313687044, "Bleu_2": 0.10846522890718008, "Bleu_3": 0.06215293828145826, "Bleu_4": 8.409805259069613e-06, "METEOR": 0.16838554122815003, "ROUGE_L": 0.19513755598208574, "CIDEr": 4.295770586149994e-12, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.13636363636363635, "f": 0.12244897959183673, "fn": 19.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.375, "f": 0.26086956521739135, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "The image shows a herd of cows grazing in a green meadow surrounded by mountains. The cows are brown and white with black spots on their coats. One of the cows is standing in the foreground, looking directly at the camera. The background is a beautiful mountain range with snow-capped peaks."}, "224037": {"image_id": 224037, "Bleu_1": 0.24999999999609374, "Bleu_2": 0.1543033499596618, "Bleu_3": 0.09157909313181302, "Bleu_4": 0.059568243639593815, "METEOR": 0.19510873139717996, "ROUGE_L": 0.1881167763157895, "CIDEr": 1.9377028862765634e-16, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.15, "f": 0.13043478260869565, "fn": 17.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "This image shows a small fishing boat docked at a pier in a coastal town. The boat is white with blue stripes and has a small cabin on the front. There are several people standing on the pier, including a man in a yellow life jacket and a woman in a red shirt. In the background, there are buildings and trees along the shore."}, "523660": {"image_id": 523660, "Bleu_1": 0.30769230768441824, "Bleu_2": 0.20121090914115636, "Bleu_3": 0.1486189512948787, "Bleu_4": 0.09771922616320827, "METEOR": 0.2679443478034987, "ROUGE_L": 0.2683677958644963, "CIDEr": 1.73748353891842e-05, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.05, "f": 0.060606060606060615, "fn": 19.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The woman is standing in the kitchen, wearing a white apron and holding a spatula in her hand. She is smiling and looking at the camera. The walls are blue and there are cabinets and countertops in the background."}, "26762": {"image_id": 26762, "Bleu_1": 0.22891566264784438, "Bleu_2": 0.12942150723509543, "Bleu_3": 0.05913473149738886, "Bleu_4": 7.130327458437382e-06, "METEOR": 0.20638242427393616, "ROUGE_L": 0.17535934291581107, "CIDEr": 3.79384910629849e-32, "SPICE": {"All": {"pr": 0.08, "re": 0.08333333333333333, "f": 0.08163265306122448, "fn": 22.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows two elephants standing in a green field, one of them is suckling its young. The mother elephant is standing on the right side of the image, while the baby elephant is on the left side. The mother elephant has its trunk wrapped around the baby elephant's head, while the baby elephant is nuzzling its mother's ear. The image is taken from a bird's eye view, and the grass in the background is swaying gently in the wind."}, "554934": {"image_id": 554934, "Bleu_1": 0.7619047618684808, "Bleu_2": 0.6761234037498121, "Bleu_3": 0.621965238045881, "Bleu_4": 0.5718458251064399, "METEOR": 0.4865339418630198, "ROUGE_L": 0.6623235613463625, "CIDEr": 0.7513755070716592, "SPICE": {"All": {"pr": 0.05263157894736842, "re": 0.06896551724137931, "f": 0.05970149253731343, "fn": 27.0, "numImages": 1.0, "fp": 36.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.13333333333333333, "re": 0.16666666666666666, "f": 0.14814814814814814, "fn": 10.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}}, "caption": "This is a living room with a couch, coffee table, and chairs. There are also two trees painted on the wall."}, "197278": {"image_id": 197278, "Bleu_1": 0.6111111110771605, "Bleu_2": 0.464420363986264, "Bleu_3": 0.3777932312096391, "Bleu_4": 0.3222538601694964, "METEOR": 0.4028490987153735, "ROUGE_L": 0.6304909560723514, "CIDEr": 0.38269279328631084, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.18181818181818182, "f": 0.15384615384615383, "fn": 18.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4, "f": 0.34782608695652173, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "This is an image of an outhouse in the middle of a field with trees in the background."}, "37119": {"image_id": 37119, "Bleu_1": 0.3870967741810615, "Bleu_2": 0.32128773155046275, "Bleu_3": 0.24237254658051569, "Bleu_4": 0.1785790714879889, "METEOR": 0.27624479770828103, "ROUGE_L": 0.3330300272975432, "CIDEr": 0.001200338783421337, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.15384615384615385, "f": 0.21052631578947367, "fn": 22.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "This image shows a group of cows standing in a barn. They are all wearing collars and are looking at the camera. The barn has a red roof and white walls."}, "105120": {"image_id": 105120, "Bleu_1": 0.14444444444283952, "Bleu_2": 0.056973174141105504, "Bleu_3": 3.3287873565222063e-07, "Bleu_4": 8.069278908304469e-10, "METEOR": 0.1135586015102209, "ROUGE_L": 0.0926347760060744, "CIDEr": 1.1836711206285403e-38, "SPICE": {"All": {"pr": 0.6363636363636364, "re": 0.2, "f": 0.30434782608695654, "fn": 28.0, "numImages": 1.0, "fp": 4.0, "tp": 7.0}, "Relation": {"pr": 0.25, "re": 0.0625, "f": 0.1, "fn": 15.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.35714285714285715, "f": 0.5263157894736842, "fn": 9.0, "numImages": 1.0, "fp": 0.0, "tp": 5.0}}, "caption": "The image shows a cat and a mouse playing with each other on a bed. The cat is lying on its back with its paws in the air, while the mouse is sitting on its hind legs and holding an orange in its front paws. The cat is looking up at the mouse with a curious expression on its face, while the mouse is looking down at the cat with a mischievous grin on its face. The image is well-lit and in focus, with a blue and white color scheme."}, "378962": {"image_id": 378962, "Bleu_1": 0.16129032257804374, "Bleu_2": 0.05142084838639913, "Bleu_3": 3.5321765941052274e-07, "Bleu_4": 9.296485652188588e-10, "METEOR": 0.10220673755965143, "ROUGE_L": 0.15673175745118192, "CIDEr": 2.6885545126435666e-17, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.16666666666666666, "f": 0.17142857142857143, "fn": 15.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\nThe image shows a bustling outdoor market with several vendors selling fresh produce, including fruits and vegetables. People are walking by, some carrying bags of groceries, while others are simply enjoying the sights and sounds of the market. The atmosphere is lively and vibrant, with bright colors and lively chatter filling the air."}, "468902": {"image_id": 468902, "Bleu_1": 0.17721518987117452, "Bleu_2": 0.10658305713629813, "Bleu_3": 0.052839886200105254, "Bleu_4": 6.637705917319927e-06, "METEOR": 0.18149397554809063, "ROUGE_L": 0.18147046323841903, "CIDEr": 5.441960936472975e-26, "SPICE": {"All": {"pr": 0.5, "re": 0.16129032258064516, "f": 0.24390243902439024, "fn": 26.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.08333333333333333, "f": 0.125, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.2857142857142857, "f": 0.4210526315789473, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The image shows a brown and white cow lying on its side in the grass, with its head resting on its front legs. The cow is wearing a collar and tag around its neck. In the background, there is a small white dog standing on its hind legs, looking at the cow. The dog is wearing a red collar and tag around its neck. The image is taken in a field with green grass and trees in the background."}, "342260": {"image_id": 342260, "Bleu_1": 0.2340425531865098, "Bleu_2": 0.10087498788996685, "Bleu_3": 6.092349727774223e-07, "Bleu_4": 1.5056549290355162e-09, "METEOR": 0.2142099267648894, "ROUGE_L": 0.19869706840390877, "CIDEr": 4.149824766529308e-10, "SPICE": {"All": {"pr": 0.1, "re": 0.12, "f": 0.1090909090909091, "fn": 22.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.375, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This is an image of a man skiing down a snowy hill. He is wearing a blue and white suit with a red hat and goggles on his face. There are other people skiing in the background, and a sign in the distance that reads \"Ski Race.\""}, "373170": {"image_id": 373170, "Bleu_1": 0.33333333331944454, "Bleu_2": 0.17025130614450176, "Bleu_3": 1.096274741670838e-06, "Bleu_4": 2.814392937738109e-09, "METEOR": 0.15417671839182662, "ROUGE_L": 0.2479674796747967, "CIDEr": 0.02704225968974898, "SPICE": {"All": {"pr": 0.5555555555555556, "re": 0.2631578947368421, "f": 0.35714285714285715, "fn": 14.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "This is a classroom with green walls, green chairs, and a whiteboard on the wall. There are no students or teachers in the room."}, "521292": {"image_id": 521292, "Bleu_1": 0.25641025640368187, "Bleu_2": 0.1642880193591135, "Bleu_3": 0.09001951896101365, "Bleu_4": 1.1931001236118978e-05, "METEOR": 0.2023471210809452, "ROUGE_L": 0.22846441947565538, "CIDEr": 8.739285092822819e-06, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.22727272727272727, "f": 0.22222222222222224, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The woman is holding a cell phone to her ear and looking down at the ground. She has short red hair and is wearing a black shirt and jeans. The background is a blurred image of trees and sky."}, "30925": {"image_id": 30925, "Bleu_1": 0.21951219511659734, "Bleu_2": 0.12830983841207666, "Bleu_3": 0.075015631511707, "Bleu_4": 1.0266394015672685e-05, "METEOR": 0.19960703653335726, "ROUGE_L": 0.25756509500351865, "CIDEr": 2.4784926797985707e-06, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.13793103448275862, "f": 0.1702127659574468, "fn": 25.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a giraffe standing in front of a pond with water lilies floating on the surface. The giraffe is looking down at its reflection in the water. The trees in the background are bare and the sky is clear."}, "335450": {"image_id": 335450, "Bleu_1": 0.714285714234694, "Bleu_2": 0.5741692517206252, "Bleu_3": 0.3017399903278499, "Bleu_4": 3.975360175943345e-05, "METEOR": 0.2493774070029477, "ROUGE_L": 0.42957746478873243, "CIDEr": 0.9740379432545726, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.1724137931034483, "f": 0.18867924528301888, "fn": 24.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.45454545454545453, "f": 0.45454545454545453, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "A brown horse standing in a green field with a fence in the background."}, "303944": {"image_id": 303944, "Bleu_1": 0.20289855072169713, "Bleu_2": 0.13380139498043359, "Bleu_3": 0.09289433815876937, "Bleu_4": 0.05903450822210373, "METEOR": 0.2510293922524537, "ROUGE_L": 0.2047961630695444, "CIDEr": 9.326044966722735e-21, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.18518518518518517, "f": 0.21739130434782608, "fn": 22.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a pair of suitcases on wheels in a room with a brick wall and a wooden floor. The suitcases are black and have wheels on the bottom. There is a picture of a man hanging on the wall next to the suitcases.\n\nThe caption for this image could be: \"A pair of suitcases on wheels in a room with a brick wall and a wooden floor.\""}, "567683": {"image_id": 567683, "Bleu_1": 0.30188679244713423, "Bleu_2": 0.18663625434394554, "Bleu_3": 0.11095595432564728, "Bleu_4": 1.2856432048790682e-05, "METEOR": 0.16354260868186518, "ROUGE_L": 0.22195269860521533, "CIDEr": 4.022018987065149e-12, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.16, "f": 0.2105263157894737, "fn": 21.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "Here is a caption for the image:\n\n\"A group of motorcyclists parked on the side of the road, with their bikes lined up next to each other. Some of them are wearing helmets and jackets, while others are not. The sky is clear and blue, with a few clouds scattered in the distance.\""}, "377577": {"image_id": 377577, "Bleu_1": 0.24999999999431824, "Bleu_2": 0.13206763594580717, "Bleu_3": 0.0746072740739093, "Bleu_4": 1.0032055246769756e-05, "METEOR": 0.2104064253886188, "ROUGE_L": 0.214185393258427, "CIDEr": 1.21995475874052e-07, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.3, "f": 0.25531914893617025, "fn": 14.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The woman is standing on the sidewalk, holding an umbrella over her head. She is wearing a black jacket and jeans, and has a purse slung over her shoulder. The building behind her is painted orange and has a white awning over the windows."}, "316258": {"image_id": 316258, "Bleu_1": 0.5789473683905818, "Bleu_2": 0.4392976850832163, "Bleu_3": 0.283160693887166, "Bleu_4": 3.451395513737833e-05, "METEOR": 0.23244265791840663, "ROUGE_L": 0.43832335329341315, "CIDEr": 0.3581457061133941, "SPICE": {"All": {"pr": 0.10416666666666667, "re": 0.18518518518518517, "f": 0.13333333333333333, "fn": 22.0, "numImages": 1.0, "fp": 43.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 18.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3125, "re": 0.5, "f": 0.38461538461538464, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}}, "caption": "The image shows a group of people in boats on the river, with buildings and trees in the background."}, "298689": {"image_id": 298689, "Bleu_1": 0.3499999999912501, "Bleu_2": 0.21182963642871727, "Bleu_3": 0.1331700655625649, "Bleu_4": 1.5894780290442998e-05, "METEOR": 0.2930367920681062, "ROUGE_L": 0.23680124223602486, "CIDEr": 7.124001479269861e-06, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.2222222222222222, "f": 0.21621621621621623, "fn": 14.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a person performing a trick on a snowboard in the mountains. The person is wearing a green jacket, black pants, and a helmet. The background is a mountainous landscape with trees and a river in the distance."}, "144878": {"image_id": 144878, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.19794866371815809, "Bleu_3": 0.09345903743205192, "Bleu_4": 1.1479990094513044e-05, "METEOR": 0.23176611180260565, "ROUGE_L": 0.29865361077111385, "CIDEr": 1.4859747588545393e-07, "SPICE": {"All": {"pr": 0.09302325581395349, "re": 0.16666666666666666, "f": 0.11940298507462685, "fn": 20.0, "numImages": 1.0, "fp": 39.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 20.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a truck parked on a dirt road in the middle of a desert. The truck has a blue and white body with a large metal box on the back. There is a person standing next to the truck, looking at it. The sky is clear and blue."}, "265950": {"image_id": 265950, "Bleu_1": 0.2278481012629386, "Bleu_2": 0.17925519389035605, "Bleu_3": 0.10777664873159405, "Bleu_4": 1.1328961695003375e-05, "METEOR": 0.26025767617092077, "ROUGE_L": 0.25342750311591195, "CIDEr": 2.3792883245360864e-28, "SPICE": {"All": {"pr": 0.1875, "re": 0.17647058823529413, "f": 0.1818181818181818, "fn": 28.0, "numImages": 1.0, "fp": 26.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.07142857142857142, "f": 0.09523809523809523, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.45454545454545453, "f": 0.3846153846153846, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}}, "caption": "The image shows a baseball player in the process of pitching a ball on a baseball field. The player is wearing a red and white jersey with the number 7 on the back, and has a glove on his left hand. The ball is in the air, and the player is standing on the mound, ready to throw the next pitch. The background is a green grass field with a dirt infield and a white fence in the distance."}, "440793": {"image_id": 440793, "Bleu_1": 0.31914893616342244, "Bleu_2": 0.20402970888419056, "Bleu_3": 0.0974371940073651, "Bleu_4": 1.2041494936393692e-05, "METEOR": 0.20713768965470877, "ROUGE_L": 0.2781758957654723, "CIDEr": 1.1554891215622374e-07, "SPICE": {"All": {"pr": 0.058823529411764705, "re": 0.058823529411764705, "f": 0.058823529411764705, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image shows a group of people skiing down a snowy slope. They are all wearing black and white clothing and have their skis on their feet. The slope is covered in snow and there are some trees in the background. The sky is clear and blue."}, "359592": {"image_id": 359592, "Bleu_1": 0.5555555555246915, "Bleu_2": 0.47828670262560663, "Bleu_3": 0.30579394060263637, "Bleu_4": 0.20895311115411017, "METEOR": 0.24235724076021758, "ROUGE_L": 0.5271604938271606, "CIDEr": 0.5820806002095272, "SPICE": {"All": {"pr": 0.15, "re": 0.15, "f": 0.15, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a plate of food with a piece of meat and a side of mashed potatoes."}, "152176": {"image_id": 152176, "Bleu_1": 0.41176470587024233, "Bleu_2": 0.2736170867397671, "Bleu_3": 0.16725873794533458, "Bleu_4": 0.11084119214220596, "METEOR": 0.2298212562795071, "ROUGE_L": 0.3024793388429752, "CIDEr": 0.0002777165222035087, "SPICE": {"All": {"pr": 0.2, "re": 0.13043478260869565, "f": 0.15789473684210528, "fn": 20.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a bicycle parked next to a river with a bridge in the background. The sky is clear and blue, and there are trees and grass on either side of the river."}, "520478": {"image_id": 520478, "Bleu_1": 0.29268292682212976, "Bleu_2": 0.17107978454943554, "Bleu_3": 0.09087496586948689, "Bleu_4": 1.1854610697110774e-05, "METEOR": 0.20254543972678116, "ROUGE_L": 0.2713120830244626, "CIDEr": 1.7988635615387933e-06, "SPICE": {"All": {"pr": 0.4166666666666667, "re": 0.21739130434782608, "f": 0.2857142857142857, "fn": 18.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8333333333333334, "re": 0.5555555555555556, "f": 0.6666666666666667, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 5.0}}, "caption": "The image shows a man playing tennis on a court with a net in the background. He is wearing a white shirt and black shorts and is holding a tennis racket in his hand. The image is in black and white."}, "253421": {"image_id": 253421, "Bleu_1": 0.23188405796765385, "Bleu_2": 0.13057679112202067, "Bleu_3": 0.06337029472199883, "Bleu_4": 7.880037991327068e-06, "METEOR": 0.18295120920945657, "ROUGE_L": 0.24629878869448185, "CIDEr": 1.0054391628703336e-19, "SPICE": {"All": {"pr": 0.12, "re": 0.14285714285714285, "f": 0.13043478260869565, "fn": 18.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a vase with flowers sitting on a wooden table. The flowers are a mix of different colors, including pink, yellow, and white. The vase is made of a dark red glass and has a handle on the side. The table is made of wood and has a smooth surface. The light from the window behind the table casts a shadow on the wall behind the vase."}, "182175": {"image_id": 182175, "Bleu_1": 0.4999999999772728, "Bleu_2": 0.3086066999098223, "Bleu_3": 1.6823908656597404e-06, "Bleu_4": 3.978842755121578e-09, "METEOR": 0.183254129390619, "ROUGE_L": 0.2791762013729977, "CIDEr": 0.09832798986859939, "SPICE": {"All": {"pr": 0.16, "re": 0.2, "f": 0.17777777777777778, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This is a bathroom with a toilet, sink, and floor tiles. The walls are cracked and there is debris on the floor."}, "401327": {"image_id": 401327, "Bleu_1": 0.27586206896076104, "Bleu_2": 0.18405922400671818, "Bleu_3": 0.10655791496998812, "Bleu_4": 0.06848549721346939, "METEOR": 0.19628400348103406, "ROUGE_L": 0.2456846950517837, "CIDEr": 3.137104627509889e-14, "SPICE": {"All": {"pr": 0.21212121212121213, "re": 0.21875, "f": 0.21538461538461537, "fn": 25.0, "numImages": 1.0, "fp": 26.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.42857142857142855, "f": 0.4799999999999999, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "This image shows a computer desk with a mouse and keyboard on top of it. The desk is made of metal and has a shiny finish. The mouse and keyboard are both connected to the computer via cables. The desk is in a modern office setting, with a white wall behind it and a window to the left."}, "391596": {"image_id": 391596, "Bleu_1": 0.3793103448145066, "Bleu_2": 0.23278142562159646, "Bleu_3": 0.1261375218310181, "Bleu_4": 1.666824532264052e-05, "METEOR": 0.28547090422995275, "ROUGE_L": 0.39617739840415667, "CIDEr": 0.006374169616203703, "SPICE": {"All": {"pr": 0.15, "re": 0.15789473684210525, "f": 0.15384615384615385, "fn": 16.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This image shows a group of people lying on the beach with umbrellas. In the background, there is a boat in the water. The sky is clear and blue."}, "504439": {"image_id": 504439, "Bleu_1": 0.24999999999375005, "Bleu_2": 0.17902871850532517, "Bleu_3": 0.09448305700214403, "Bleu_4": 1.2287542170045073e-05, "METEOR": 0.21014150238186344, "ROUGE_L": 0.23036253776435048, "CIDEr": 1.5019700406689728e-06, "SPICE": {"All": {"pr": 0.15, "re": 0.125, "f": 0.13636363636363635, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows two zebras standing in a field with trees in the background. The zebras are black and white with distinctive stripes on their bodies. They are looking at each other and appear to be in a playful mood."}, "538858": {"image_id": 538858, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.1671899541887144, "Bleu_3": 0.08130907204696848, "Bleu_4": 1.0132385609889835e-05, "METEOR": 0.1923076923076923, "ROUGE_L": 0.21863799283154117, "CIDEr": 2.6986586054463654e-13, "SPICE": {"All": {"pr": 0.375, "re": 0.2727272727272727, "f": 0.3157894736842105, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "The image shows a group of young men playing baseball on a field with a fence in the background. The men are wearing blue and white uniforms and are standing in the outfield, throwing the ball to each other. There is a large building in the background with a flag flying from the top."}, "577212": {"image_id": 577212, "Bleu_1": 0.34210526314889206, "Bleu_2": 0.21501265303422734, "Bleu_3": 0.10869473591519455, "Bleu_4": 1.3840104608852469e-05, "METEOR": 0.20531025057704794, "ROUGE_L": 0.27191679049034173, "CIDEr": 9.410916968465491e-05, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.35714285714285715, "f": 0.24390243902439024, "fn": 9.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.75, "f": 0.5454545454545454, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "This is a kitchen with a large island in the center and a sink and stove on the counter. The walls are painted white and there are wooden floors. There are tools and materials scattered around the room."}, "314495": {"image_id": 314495, "Bleu_1": 0.29999999999250004, "Bleu_2": 0.15191090505870355, "Bleu_3": 0.08468336402372788, "Bleu_4": 1.1318741601733969e-05, "METEOR": 0.20042292668178235, "ROUGE_L": 0.2691176470588235, "CIDEr": 1.4609539998658601e-06, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.13793103448275862, "f": 0.1951219512195122, "fn": 25.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.36363636363636365, "f": 0.4705882352941177, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image shows a brown and white longhorn cow standing behind a wooden fence. The cow has large horns and is looking directly at the camera with its eyes. The background is a dirt road with trees in the distance."}, "250564": {"image_id": 250564, "Bleu_1": 0.32432432431555885, "Bleu_2": 0.189831599145298, "Bleu_3": 0.1272232018279771, "Bleu_4": 0.08821755394408795, "METEOR": 0.2477853514506211, "ROUGE_L": 0.2930344275420336, "CIDEr": 1.4370538397646674e-05, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.23529411764705882, "f": 0.17391304347826086, "fn": 13.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5714285714285714, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows two elephants standing in a grassy field. They are both brown and have large ears. One of them is holding a small branch in its trunk. The sky is clear and blue behind them."}, "230862": {"image_id": 230862, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.2516911128489292, "Bleu_3": 0.19662512090145046, "Bleu_4": 0.16688708658701973, "METEOR": 0.28122205529104477, "ROUGE_L": 0.35219399538106233, "CIDEr": 2.2912546347488953e-09, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.14285714285714285, "f": 0.17391304347826086, "fn": 24.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.2727272727272727, "f": 0.3157894736842105, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a person sitting on a couch with their legs crossed, looking at a laptop. The laptop is open and has a blue screen with white text on it. The person is wearing jeans and a t-shirt. The background is a beige color with a brown couch in the foreground."}, "451571": {"image_id": 451571, "Bleu_1": 0.5882352940830451, "Bleu_2": 0.4696682182853713, "Bleu_3": 0.3086789594799614, "Bleu_4": 0.21409092658369572, "METEOR": 0.2883531297625142, "ROUGE_L": 0.4662420382165604, "CIDEr": 0.8507777014519804, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.08, "f": 0.07272727272727272, "fn": 23.0, "numImages": 1.0, "fp": 28.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "The image shows a plate with grilled corn on the cob and a side dish of vegetables."}, "361586": {"image_id": 361586, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.0933181271719728, "Bleu_3": 0.05547797716282366, "Bleu_4": 7.644480232985446e-06, "METEOR": 0.1677718373329856, "ROUGE_L": 0.18100890207715134, "CIDEr": 1.0657098305910668e-11, "SPICE": {"All": {"pr": 0.125, "re": 0.20833333333333334, "f": 0.15625, "fn": 19.0, "numImages": 1.0, "fp": 35.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5555555555555556, "f": 0.4166666666666667, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}}, "caption": "This is an image of a train station with people standing in front of it. There are several signs and advertisements on the walls, as well as a ticket counter and a baggage claim area. The floor is made of white tiles and there are several chairs and tables scattered throughout the area."}, "213162": {"image_id": 213162, "Bleu_1": 0.41860465115305573, "Bleu_2": 0.2823724831943621, "Bleu_3": 0.15726435388931506, "Bleu_4": 0.09930193778314661, "METEOR": 0.2858175360396562, "ROUGE_L": 0.37770897832817335, "CIDEr": 3.6232676261259815e-06, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.1, "f": 0.12903225806451613, "fn": 18.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The woman is holding a tennis racket and swinging it at a ball on a tennis court. She is wearing a black shirt and shorts, and has blonde hair. The background is a green grass tennis court with a net in the center."}, "549766": {"image_id": 549766, "Bleu_1": 0.47368421050138515, "Bleu_2": 0.28097574345930926, "Bleu_3": 0.16683848808490073, "Bleu_4": 2.321091111608818e-05, "METEOR": 0.2233676265554817, "ROUGE_L": 0.3053817271589487, "CIDEr": 0.15176759017820557, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.15, "f": 0.1764705882352941, "fn": 17.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The giraffe is standing in the bush, looking around. It has a long neck and spots on its body."}, "537727": {"image_id": 537727, "Bleu_1": 0.5909090908822315, "Bleu_2": 0.4108907017875376, "Bleu_3": 0.20361395690735576, "Bleu_4": 2.5817682616759057e-05, "METEOR": 0.2674119472847316, "ROUGE_L": 0.4969450101832994, "CIDEr": 0.15913810183728544, "SPICE": {"All": {"pr": 0.8, "re": 0.36363636363636365, "f": 0.5000000000000001, "fn": 14.0, "numImages": 1.0, "fp": 2.0, "tp": 8.0}, "Relation": {"pr": 0.5, "re": 0.1111111111111111, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.75, "re": 0.5, "f": 0.6, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.5714285714285714, "f": 0.7272727272727273, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 4.0}}, "caption": "This is a living room with a wooden table and chairs, a window with curtains, and a wooden wheel in the corner."}, "307523": {"image_id": 307523, "Bleu_1": 0.20833333332899312, "Bleu_2": 0.09415544714235627, "Bleu_3": 5.776228382887613e-07, "Bleu_4": 1.4385671494946425e-09, "METEOR": 0.14206291976977453, "ROUGE_L": 0.20013123359580048, "CIDEr": 1.9550737640960476e-09, "SPICE": {"All": {"pr": 0.12, "re": 0.15789473684210525, "f": 0.13636363636363635, "fn": 16.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.375, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a person skateboarding on the sidewalk at night. The person is wearing a black jacket and black pants, and has a black hat on their head. The skateboard is black and has white wheels. The background is a dark building with windows and a door."}, "74617": {"image_id": 74617, "Bleu_1": 0.45238095237018144, "Bleu_2": 0.2779132460930944, "Bleu_3": 0.1245239344489204, "Bleu_4": 1.4916724676305332e-05, "METEOR": 0.26804072697340964, "ROUGE_L": 0.27354260089686094, "CIDEr": 5.398704007712339e-06, "SPICE": {"All": {"pr": 0.13157894736842105, "re": 0.25, "f": 0.1724137931034483, "fn": 15.0, "numImages": 1.0, "fp": 33.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.29411764705882354, "re": 0.625, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}}, "caption": "The image shows two young men playing tennis on a court with a net in the background. One of them is holding a tennis racket and the other is hitting the ball with his racket. The image is in black and white."}, "547854": {"image_id": 547854, "Bleu_1": 0.3278688524536415, "Bleu_2": 0.2665300196296314, "Bleu_3": 0.15343360950405116, "Bleu_4": 0.08883485095156074, "METEOR": 0.2717656644953934, "ROUGE_L": 0.3168831168831168, "CIDEr": 7.253366847546249e-14, "SPICE": {"All": {"pr": 0.3888888888888889, "re": 0.22580645161290322, "f": 0.2857142857142857, "fn": 24.0, "numImages": 1.0, "fp": 11.0, "tp": 7.0}, "Relation": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.46153846153846156, "f": 0.4999999999999999, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image shows a young girl sitting at a table with her hands on her hips, looking at the camera. She is wearing a red and white polka dot dress and has a ponytail. In front of her is a plate with a slice of pizza on it. The background is a white wall with a red and white checkered tablecloth."}, "360943": {"image_id": 360943, "Bleu_1": 0.4999999999642858, "Bleu_2": 0.392232270247274, "Bleu_3": 0.23404631037024026, "Bleu_4": 3.2857020445327865e-05, "METEOR": 0.2601766366286921, "ROUGE_L": 0.47805642633228845, "CIDEr": 0.7317416206300152, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.15384615384615385, "f": 0.2222222222222222, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "A cat sitting on the steps of a house, looking out at the street."}, "535668": {"image_id": 535668, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.2147593846370405, "Bleu_3": 0.19216029128039422, "Bleu_4": 0.16997811347224762, "METEOR": 0.2988056268404979, "ROUGE_L": 0.29151732377538825, "CIDEr": 8.882211613472848e-13, "SPICE": {"All": {"pr": 0.3, "re": 0.34615384615384615, "f": 0.32142857142857145, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 9.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.1, "f": 0.09523809523809525, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.5454545454545454, "f": 0.5217391304347826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a baseball player swinging a bat at a baseball on a field. The player is wearing a red and white uniform and has a glove on his hand. The umpire is standing behind the player, watching him play. The field is made of grass and there are spectators in the stands."}, "558608": {"image_id": 558608, "Bleu_1": 0.3043478260825457, "Bleu_2": 0.17700260809587665, "Bleu_3": 0.07761783227687673, "Bleu_4": 9.174557951608693e-06, "METEOR": 0.23465897193610236, "ROUGE_L": 0.25093046033300687, "CIDEr": 4.89918453651375e-19, "SPICE": {"All": {"pr": 0.12, "re": 0.11538461538461539, "f": 0.11764705882352941, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This image shows a group of people flying kites on a beach. The kites are colorful and shaped like animals, such as butterflies, dragons, and birds. The people are standing on the sand, holding the kites and watching them fly. There are also other people in the background, walking along the beach and enjoying the kite festival. The sky is clear and blue, with a few clouds scattered about."}, "431746": {"image_id": 431746, "Bleu_1": 0.34146341462581803, "Bleu_2": 0.22631728213415833, "Bleu_3": 0.17383755594511796, "Bleu_4": 0.12894939394824442, "METEOR": 0.2583288751507556, "ROUGE_L": 0.26425992779783397, "CIDEr": 1.0823958548661372e-05, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.13636363636363635, "f": 0.12244897959183673, "fn": 19.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The man is holding a cell phone in his hand and smiling at the camera. He is wearing a red shirt and has a friendly expression on his face. The background is dark and there are some lights in the distance."}, "391139": {"image_id": 391139, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.24308621739673564, "Bleu_3": 0.1901110702410287, "Bleu_4": 0.14884133138560784, "METEOR": 0.37079960161430303, "ROUGE_L": 0.336783988957902, "CIDEr": 1.375197059938513e-07, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.2222222222222222, "f": 0.24, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.6, "f": 0.5217391304347826, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "This is a photo of a small dog sitting on a wooden bench in front of a pumpkin patch. The dog is wearing a red collar and has a friendly expression on its face. The background is a field with pumpkins and other fall decorations."}, "426070": {"image_id": 426070, "Bleu_1": 0.3599999999928, "Bleu_2": 0.2571428571376619, "Bleu_3": 0.17662651284533257, "Bleu_4": 0.12374422938762035, "METEOR": 0.3133717726962175, "ROUGE_L": 0.3335358444714459, "CIDEr": 8.117314489860535e-10, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.21739130434782608, "f": 0.2127659574468085, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a man sitting on a couch with his head resting on his hand. He is wearing a pink shirt and jeans. There are several pillows and blankets on the couch. The room appears to be a living room with a coffee table in front of the couch."}, "242679": {"image_id": 242679, "Bleu_1": 0.3793103448145066, "Bleu_2": 0.32920264918260556, "Bleu_3": 0.2522750436620361, "Bleu_4": 0.15763853150693705, "METEOR": 0.24628290266431754, "ROUGE_L": 0.3489037178265014, "CIDEr": 0.005733024168824978, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.15384615384615385, "f": 0.2, "fn": 22.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.18181818181818182, "f": 0.23529411764705885, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "This is a picture of a train car with a toilet and sink in it. There are also some seats and a window on the side of the train."}, "437789": {"image_id": 437789, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.10097563285748058, "Bleu_3": 5.925782346379725e-07, "Bleu_4": 1.4429422918202472e-09, "METEOR": 0.17146021862022556, "ROUGE_L": 0.2238532110091743, "CIDEr": 3.1164011544400966e-11, "SPICE": {"All": {"pr": 0.1, "re": 0.15789473684210525, "f": 0.12244897959183673, "fn": 16.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.125, "f": 0.10526315789473685, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "This image shows a table with several containers of food, including a mug of coffee, a bowl of fruit, and a container of yogurt. There are also several other containers on the table, including one with a sandwich and another with a salad. The table is covered with a white tablecloth."}, "189163": {"image_id": 189163, "Bleu_1": 0.26666666665777783, "Bleu_2": 0.16609095970184817, "Bleu_3": 0.099504942383045, "Bleu_4": 1.3821098063238631e-05, "METEOR": 0.2686151012164949, "ROUGE_L": 0.2839851024208566, "CIDEr": 0.0035940988830616997, "SPICE": {"All": {"pr": 0.08, "re": 0.09523809523809523, "f": 0.08695652173913043, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a person sitting on a bed, reading a book by the light of a lamp. The room is dimly lit and there are curtains on the windows."}, "93887": {"image_id": 93887, "Bleu_1": 0.714285714234694, "Bleu_2": 0.5241424183220805, "Bleu_3": 0.35775231709800853, "Bleu_4": 0.25400289713142493, "METEOR": 0.28320163036218726, "ROUGE_L": 0.5669144981412639, "CIDEr": 1.2903347045094484, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.15384615384615385, "f": 0.20512820512820515, "fn": 22.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.18181818181818182, "f": 0.23529411764705885, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "A white sheep standing in a green field with a fence in the background."}, "236784": {"image_id": 236784, "Bleu_1": 0.7499999999375001, "Bleu_2": 0.6396021490111085, "Bleu_3": 0.5469655075428685, "Bleu_4": 0.4366835442427119, "METEOR": 0.4380421349942609, "ROUGE_L": 0.6224489795918368, "CIDEr": 1.5503498180283806, "SPICE": {"All": {"pr": 0.1, "re": 0.36363636363636365, "f": 0.15686274509803924, "fn": 7.0, "numImages": 1.0, "fp": 36.0, "tp": 4.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.25, "f": 0.13333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.6, "f": 0.3, "fn": 2.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "Two dogs are lying on a couch, one black and one brown."}, "430791": {"image_id": 430791, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.2014440620697061, "Bleu_3": 0.12263904310164322, "Bleu_4": 1.4391446615915733e-05, "METEOR": 0.17227430433592067, "ROUGE_L": 0.2581620314389359, "CIDEr": 1.1136924271982578e-06, "SPICE": {"All": {"pr": 0.17073170731707318, "re": 0.2692307692307692, "f": 0.20895522388059704, "fn": 19.0, "numImages": 1.0, "fp": 34.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.375, "f": 0.23076923076923078, "fn": 5.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.1111111111111111, "re": 0.3333333333333333, "f": 0.16666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4444444444444444, "f": 0.34782608695652173, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a woman standing in front of a wall with red ribbons hanging from the ceiling. The woman is wearing a black dress and has her hands in her pockets. The ribbons are arranged in a pattern on the wall, creating a visual effect."}, "467297": {"image_id": 467297, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.19794866371815809, "Bleu_3": 0.1483569743355745, "Bleu_4": 0.10857104303325285, "METEOR": 0.21157349507912715, "ROUGE_L": 0.23797139141742527, "CIDEr": 2.2971558656267377e-10, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 12.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "A woman is standing in a kitchen, wearing a blue shirt and black pants. She is holding a tray of food in her hands and looking at the oven. There is a stove in the background with pots and pans on it. The walls are covered in a floral pattern."}, "293034": {"image_id": 293034, "Bleu_1": 0.2105263157857803, "Bleu_2": 0.1501878522938693, "Bleu_3": 0.10715424804653019, "Bleu_4": 0.08216107324774442, "METEOR": 0.24353988667489873, "ROUGE_L": 0.2492702860478692, "CIDEr": 4.1718593490950196e-15, "SPICE": {"All": {"pr": 0.6, "re": 0.13043478260869565, "f": 0.21428571428571427, "fn": 20.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.2222222222222222, "f": 0.3333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "The image shows a group of people standing in front of a fence that has a giraffe on the other side. The giraffe is standing on its hind legs and looking at the people. The people are looking at the giraffe and taking pictures of it. There are trees and bushes in the background of the image."}, "7673": {"image_id": 7673, "Bleu_1": 0.24590163934023115, "Bleu_2": 0.16937687147073976, "Bleu_3": 0.07863551474442178, "Bleu_4": 9.5687906301798e-06, "METEOR": 0.19489663641995286, "ROUGE_L": 0.23093564088696594, "CIDEr": 3.610347589007369e-16, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.13043478260869565, "f": 0.11538461538461538, "fn": 20.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.1, "re": 0.2, "f": 0.13333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "Sure, here is a caption for the image:\n\n\"Surfer riding a wave in a river\"\n\nThis image shows a person surfing on a wave in a river. The person is wearing a wetsuit and holding onto the board as they ride the wave. The water is clear and the sky is blue. There are trees and buildings visible in the background."}, "523529": {"image_id": 523529, "Bleu_1": 0.3333333333247864, "Bleu_2": 0.22941573386460196, "Bleu_3": 0.16220166573123573, "Bleu_4": 0.10434360980506845, "METEOR": 0.2593436513635327, "ROUGE_L": 0.2741573033707865, "CIDEr": 4.5331961682416015e-06, "SPICE": {"All": {"pr": 0.3, "re": 0.15789473684210525, "f": 0.20689655172413793, "fn": 16.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.3333333333333333, "f": 0.46153846153846156, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image shows a brown bear standing on the ground, looking up at something. The bear is wearing a collar and has a tag on its neck. The background is a rocky terrain with some trees in the distance."}, "232950": {"image_id": 232950, "Bleu_1": 0.45454545452479345, "Bleu_2": 0.20806259463443724, "Bleu_3": 1.2935583035953797e-06, "Bleu_4": 3.2670148297998828e-09, "METEOR": 0.29120535541030274, "ROUGE_L": 0.3639618138424821, "CIDEr": 0.07387492563808971, "SPICE": {"All": {"pr": 0.1, "re": 0.07142857142857142, "f": 0.08333333333333333, "fn": 26.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.15384615384615385, "f": 0.1904761904761905, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The man is holding a slice of pizza in his hand and looking at it with a surprised expression on his face."}, "529968": {"image_id": 529968, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.21290467263078663, "Bleu_3": 0.12629784955337583, "Bleu_4": 0.08225907050785199, "METEOR": 0.2593990919612488, "ROUGE_L": 0.34945894334818584, "CIDEr": 8.578071995264109e-09, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.15384615384615385, "f": 0.21052631578947367, "fn": 22.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a cat sitting on the back of a motorcycle. The cat is looking straight ahead, with its ears perked up and its tail curled around the handlebars. The motorcycle is parked on the side of the road, with a building visible in the background."}, "421976": {"image_id": 421976, "Bleu_1": 0.26829268292028563, "Bleu_2": 0.14185186364132965, "Bleu_3": 8.020507112003898e-07, "Bleu_4": 1.9195767099451357e-09, "METEOR": 0.19480137478917658, "ROUGE_L": 0.18087472201630836, "CIDEr": 2.6669395648537874e-06, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.21739130434782608, "f": 0.19999999999999998, "fn": 18.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a black and white sheep standing in a straw pile, looking up at a brown and white lamb. The lamb is suckling on the sheep's teats. The background is a barn with wooden beams and a hayloft."}, "104880": {"image_id": 104880, "Bleu_1": 0.4137931034340072, "Bleu_2": 0.21055872189568867, "Bleu_3": 1.1797615444182845e-06, "Bleu_4": 2.8190471506777327e-09, "METEOR": 0.20271799483691721, "ROUGE_L": 0.3010858835143139, "CIDEr": 0.011539033213384873, "SPICE": {"All": {"pr": 0.12121212121212122, "re": 0.16666666666666666, "f": 0.14035087719298245, "fn": 20.0, "numImages": 1.0, "fp": 29.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.3333333333333333, "f": 0.32, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "This is a street sign with the words \"smile\" written on it. The sign is attached to a lamppost and there are buildings on either side of the street."}, "314396": {"image_id": 314396, "Bleu_1": 0.2592592592496571, "Bleu_2": 0.14121975761738967, "Bleu_3": 9.274353348178416e-07, "Bleu_4": 2.4010981784314084e-09, "METEOR": 0.11675734470957623, "ROUGE_L": 0.23040604343720486, "CIDEr": 0.005469417151446981, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.28, "f": 0.2692307692307692, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.5454545454545454, "f": 0.4999999999999999, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "This is a green bag with a logo on it that says \"inova disc golf bag\". It has multiple pockets for storing discs and other golfing accessories."}, "206859": {"image_id": 206859, "Bleu_1": 0.21311475409486702, "Bleu_2": 0.1332650098148157, "Bleu_3": 6.701830194835844e-07, "Bleu_4": 1.5093434225110114e-09, "METEOR": 0.21365505577765478, "ROUGE_L": 0.24574478799476282, "CIDEr": 2.6194393414851686e-14, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.2, "f": 0.17391304347826086, "fn": 16.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This is an image of a man standing in front of a table filled with boxes of apples. He is wearing an orange shirt and has a yellow hat on his head. There are other people in the background, some of whom are also wearing hats. The image appears to be taken at a farmer's market or other outdoor event."}, "498759": {"image_id": 498759, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.16578342426777695, "Bleu_3": 8.681823924888469e-07, "Bleu_4": 1.9987674397634184e-09, "METEOR": 0.24463494915407713, "ROUGE_L": 0.2636887608069164, "CIDEr": 1.045224644318427e-07, "SPICE": {"All": {"pr": 0.0967741935483871, "re": 0.25, "f": 0.13953488372093023, "fn": 9.0, "numImages": 1.0, "fp": 28.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.6, "f": 0.33333333333333337, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a person riding a skateboard down a city street. The person is wearing a helmet and has their arms outstretched to balance themselves on the board. There are cars parked on the side of the road and buildings in the background."}, "151084": {"image_id": 151084, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.18093671611020545, "Bleu_3": 0.11168508570756303, "Bleu_4": 1.319188717929582e-05, "METEOR": 0.2270405183686362, "ROUGE_L": 0.22679390259015986, "CIDEr": 1.234997607019744e-09, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.19047619047619047, "f": 0.18604651162790697, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a man in a black shirt and gray pants standing in a park, holding a frisbee in his hand. The man is wearing sunglasses and has a serious expression on his face. The background of the image is a green field with trees in the distance."}, "485452": {"image_id": 485452, "Bleu_1": 0.33333333332407417, "Bleu_2": 0.21821789022984422, "Bleu_3": 0.17760448409943852, "Bleu_4": 0.13574363002742865, "METEOR": 0.2595941476135867, "ROUGE_L": 0.32348484848484854, "CIDEr": 0.0001485231370281661, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.19230769230769232, "f": 0.25, "fn": 21.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "This is a bathroom with a white sink, toilet, and shower. The walls are painted blue and white stripes. There is a window on the left side of the room with a view of the outside."}, "469896": {"image_id": 469896, "Bleu_1": 0.3170731707239739, "Bleu_2": 0.23555849565513073, "Bleu_3": 0.17853812773859593, "Bleu_4": 0.14559036896617766, "METEOR": 0.28516672949448174, "ROUGE_L": 0.3165307635285397, "CIDEr": 3.31931653419921e-06, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.18518518518518517, "f": 0.19607843137254902, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.45454545454545453, "f": 0.47619047619047616, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "This is a black and white photograph of a woman sitting on a bed, reading a book. She is wearing glasses and has her hair tied back in a ponytail. The room is decorated with floral wallpaper and a pink blanket."}, "310369": {"image_id": 310369, "Bleu_1": 0.2575757575718549, "Bleu_2": 0.16655007576726197, "Bleu_3": 0.12013140659639306, "Bleu_4": 0.08613204987059675, "METEOR": 0.2617368011081236, "ROUGE_L": 0.2731343283582089, "CIDEr": 4.1541706248561176e-20, "SPICE": {"All": {"pr": 0.1875, "re": 0.23076923076923078, "f": 0.20689655172413793, "fn": 10.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6, "f": 0.42857142857142855, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a group of people sitting on a couch, eating pizza. One person is holding a slice of pizza in their hand, while another person is taking a bite of their slice. There are several other people in the background, also eating pizza. The room appears to be a restaurant or cafe, with tables and chairs set up for customers to sit and eat."}, "206381": {"image_id": 206381, "Bleu_1": 0.21568627450557482, "Bleu_2": 2.0769510080946115e-09, "Bleu_3": 4.448553400606042e-12, "Bleu_4": 2.069444562810067e-13, "METEOR": 0.1011561539587297, "ROUGE_L": 0.15259537210756724, "CIDEr": 5.309856672430992e-11, "SPICE": {"All": {"pr": 0.06896551724137931, "re": 0.1111111111111111, "f": 0.0851063829787234, "fn": 16.0, "numImages": 1.0, "fp": 27.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2, "f": 0.1904761904761905, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA group of people are gathered around a barn with several sheep in it. One person is holding a baby lamb, while another person is petting a larger sheep. The atmosphere is cozy and peaceful, with warm lighting and a wooden floor."}, "345930": {"image_id": 345930, "Bleu_1": 0.34883720929421314, "Bleu_2": 0.20378478648001003, "Bleu_3": 0.10042763147054994, "Bleu_4": 1.2614641635707214e-05, "METEOR": 0.23295224166233763, "ROUGE_L": 0.2620596538603167, "CIDEr": 7.831072817799555e-06, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.09090909090909091, "f": 0.08695652173913043, "fn": 20.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "This is an image of a street with a tall building in the background. There are cars parked on the side of the road and a traffic light at the intersection. The sky is clear and blue with some clouds in the distance."}, "252711": {"image_id": 252711, "Bleu_1": 0.2162162162103726, "Bleu_2": 0.10959932486723496, "Bleu_3": 0.07001362613456974, "Bleu_4": 1.0023449325366406e-05, "METEOR": 0.100385918463536, "ROUGE_L": 0.1898832684824903, "CIDEr": 1.0028001254962476e-05, "SPICE": {"All": {"pr": 0.0967741935483871, "re": 0.13636363636363635, "f": 0.11320754716981131, "fn": 19.0, "numImages": 1.0, "fp": 28.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.375, "f": 0.2727272727272727, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a table with several types of donuts on it. There are different types of donuts, including chocolate frosted, glazed, and sprinkled. The donuts are arranged on the table in a neat and organized manner."}, "189744": {"image_id": 189744, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.11459194182328535, "Bleu_3": 6.280739235613542e-07, "Bleu_4": 1.4774310979864886e-09, "METEOR": 0.23440453098286476, "ROUGE_L": 0.207506520013607, "CIDEr": 2.9814448982754397e-13, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.2857142857142857, "f": 0.19047619047619047, "fn": 15.0, "numImages": 1.0, "fp": 36.0, "tp": 6.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.3333333333333333, "f": 0.14285714285714288, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 16.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.625, "f": 0.43478260869565216, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}}, "caption": "The building is a red brick structure with a white facade. It has a large sign on the front that reads \"The Ploughgate\". There are several windows on the first floor, and a large window on the second floor. The building appears to be in good condition, with no visible damage or signs of wear."}, "498547": {"image_id": 498547, "Bleu_1": 0.34146341462581803, "Bleu_2": 0.29217435488817356, "Bleu_3": 0.24837385242505491, "Bleu_4": 0.20040036297956793, "METEOR": 0.34801223307185053, "ROUGE_L": 0.3617494440326167, "CIDEr": 4.074587829030534e-06, "SPICE": {"All": {"pr": 0.3888888888888889, "re": 0.3888888888888889, "f": 0.3888888888888889, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.75, "re": 0.6666666666666666, "f": 0.7058823529411765, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 6.0}}, "caption": "This is a kitchen with a large stove and several pots and pans hanging from the ceiling. There are also several countertops with various kitchen utensils and appliances on them. The walls are painted white and there is a wooden floor."}, "139871": {"image_id": 139871, "Bleu_1": 0.3199999999936, "Bleu_2": 0.13997084244192506, "Bleu_3": 7.417848716778728e-07, "Bleu_4": 1.7166589196261759e-09, "METEOR": 0.24774142469889077, "ROUGE_L": 0.22938079719227877, "CIDEr": 2.799363019236953e-10, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.125, "f": 0.15789473684210525, "fn": 21.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.25, "f": 0.3157894736842105, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "This is an image of a small, white and black airplane sitting on the runway. The plane has a large propeller on the front and a small cockpit on top. There are several people standing around the plane, looking at it. The sky is clear and blue in the background."}, "274792": {"image_id": 274792, "Bleu_1": 0.3571428571301021, "Bleu_2": 0.2300218531057509, "Bleu_3": 0.12672285514146672, "Bleu_4": 1.6891032975685782e-05, "METEOR": 0.13614788666238883, "ROUGE_L": 0.2978515625, "CIDEr": 0.00414033227461726, "SPICE": {"All": {"pr": 0.391304347826087, "re": 0.34615384615384615, "f": 0.36734693877551017, "fn": 17.0, "numImages": 1.0, "fp": 14.0, "tp": 9.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.6363636363636364, "re": 0.7, "f": 0.6666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 7.0}}, "caption": "This is an image of a cake in a mixing bowl with ingredients such as carrots, potatoes, and onions. The cake is being mixed with a wooden spoon."}, "513933": {"image_id": 513933, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.15070298814247132, "Bleu_3": 0.09559242076521159, "Bleu_4": 1.1439974351826208e-05, "METEOR": 0.20561910509030623, "ROUGE_L": 0.21863799283154117, "CIDEr": 2.299861546639891e-11, "SPICE": {"All": {"pr": 0.06451612903225806, "re": 0.07692307692307693, "f": 0.07017543859649122, "fn": 24.0, "numImages": 1.0, "fp": 29.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "The image shows a table with three cakes on it. One of the cakes has the number 18 written on it in blue frosting, while the other two have the letters \"Happy Birthday\" written on them in pink and blue frosting. There are also several candles on the table, with one of them lit."}, "338595": {"image_id": 338595, "Bleu_1": 0.18181818181487608, "Bleu_2": 0.11605177063500235, "Bleu_3": 0.07980300087819453, "Bleu_4": 0.05591310122421515, "METEOR": 0.16286267315858774, "ROUGE_L": 0.24110671936758893, "CIDEr": 5.445582029179567e-13, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 12.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "This is an image of a group of people standing under umbrellas in the rain. They are all wearing raincoats and hats to keep themselves dry. The umbrellas are open and provide protection from the rain. The scene is taken from above, looking down on the people. There are buildings and trees in the background."}, "395": {"image_id": 395, "Bleu_1": 0.4680851063730195, "Bleu_2": 0.36370994124908435, "Bleu_3": 0.24495667480794833, "Bleu_4": 0.16077232350772633, "METEOR": 0.3042009579758526, "ROUGE_L": 0.38607594936708856, "CIDEr": 1.0449984531890382e-07, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.2631578947368421, "f": 0.2127659574468085, "fn": 14.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a man in a red jacket and black pants standing on the sidewalk, talking on his cell phone. The man is wearing a baseball cap and has a beard. The background is a busy street with tall buildings and people walking in the distance."}, "266922": {"image_id": 266922, "Bleu_1": 0.6666666665185187, "Bleu_2": 0.40824829037030635, "Bleu_3": 0.28768479126408814, "Bleu_4": 4.463236136748592e-05, "METEOR": 0.1732013725321393, "ROUGE_L": 0.3986928104575163, "CIDEr": 0.7229292464143959, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.14285714285714285, "f": 0.19047619047619047, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}}, "caption": "A group of people skiing down a snowy slope."}, "502927": {"image_id": 502927, "Bleu_1": 0.1694915254208561, "Bleu_2": 0.1081160058385353, "Bleu_3": 0.07429821419893697, "Bleu_4": 9.250959395998021e-06, "METEOR": 0.18978231959264624, "ROUGE_L": 0.19192448872574724, "CIDEr": 1.9246635486233112e-14, "SPICE": {"All": {"pr": 0.25, "re": 0.23529411764705882, "f": 0.24242424242424243, "fn": 13.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "This is an image of a dirt bike rider racing down a dirt track. The rider is wearing a helmet and gloves, and is holding onto the handlebars of the bike. The track is made of dirt and has several jumps and turns. There are people watching from the sidelines, and a fence can be seen in the background."}, "22660": {"image_id": 22660, "Bleu_1": 0.45454545452479345, "Bleu_2": 0.2548235957069542, "Bleu_3": 0.14807546136987573, "Bleu_4": 2.0331710658749725e-05, "METEOR": 0.21588818074719207, "ROUGE_L": 0.2791762013729977, "CIDEr": 0.0709772680306943, "SPICE": {"All": {"pr": 0.058823529411764705, "re": 0.038461538461538464, "f": 0.04651162790697675, "fn": 25.0, "numImages": 1.0, "fp": 16.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "An empty train station platform with a bench and a sign that reads \"Waiting Room\" in white letters on a black background."}, "273354": {"image_id": 273354, "Bleu_1": 0.24999999999305564, "Bleu_2": 0.169030850940941, "Bleu_3": 0.13609999140079057, "Bleu_4": 0.11117895489532317, "METEOR": 0.2266033062049668, "ROUGE_L": 0.24918300653594777, "CIDEr": 2.6184872521767604e-05, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 14.0, "numImages": 1.0, "fp": 14.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.5555555555555556, "re": 0.625, "f": 0.5882352941176471, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "This is an image of a train moving down the tracks. The train is green and white and has a number on the side. There are buildings in the background and people walking on the sidewalk."}, "449839": {"image_id": 449839, "Bleu_1": 0.4047619047522676, "Bleu_2": 0.28103012762453516, "Bleu_3": 0.18093489867265192, "Bleu_4": 0.11101345123311311, "METEOR": 0.23741453264604342, "ROUGE_L": 0.3403068340306834, "CIDEr": 5.8782129401640906e-05, "SPICE": {"All": {"pr": 0.12, "re": 0.09375, "f": 0.10526315789473684, "fn": 29.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 16.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.25, "f": 0.2727272727272727, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is a wedding photo of a bride and groom standing in front of a tree. The bride is wearing a white dress and the groom is wearing a black suit and tie. They are both smiling and holding bouquets of flowers."}, "278172": {"image_id": 278172, "Bleu_1": 0.32692307691678996, "Bleu_2": 0.24019223070296639, "Bleu_3": 0.19058982840138666, "Bleu_4": 0.16303027846579418, "METEOR": 0.2232415232993638, "ROUGE_L": 0.3105203619909502, "CIDEr": 3.7042203616494634e-10, "SPICE": {"All": {"pr": 0.4166666666666667, "re": 0.29411764705882354, "f": 0.3448275862068966, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5714285714285714, "f": 0.5714285714285714, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a woman sitting at a table with a plate of food in front of her. She is wearing a white shirt and has a glass of wine on the table next to her. There is a window in the background with curtains open, revealing a view of the outside."}, "446574": {"image_id": 446574, "Bleu_1": 0.27906976743537054, "Bleu_2": 0.2156655464018017, "Bleu_3": 0.1504179432467115, "Bleu_4": 1.7078893747678562e-05, "METEOR": 0.23957411050114752, "ROUGE_L": 0.29387474191328283, "CIDEr": 3.0510651549260384e-07, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.08333333333333333, "f": 0.13333333333333333, "fn": 22.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.16666666666666666, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}}, "caption": "This is a bathroom with a bathtub, toilet, and sink. The walls are made of white tiles and the floor is made of wood. There is a shower curtain hanging from the ceiling and a window on the left side of the room."}, "110042": {"image_id": 110042, "Bleu_1": 0.2786885245855953, "Bleu_2": 0.16693966711987615, "Bleu_3": 0.07787935719067435, "Bleu_4": 9.499697370183872e-06, "METEOR": 0.1576938061071865, "ROUGE_L": 0.1905257678292556, "CIDEr": 1.5151288690007168e-15, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.2631578947368421, "f": 0.2631578947368421, "fn": 14.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This image shows a man standing in front of a toilet at an outdoor event. The toilet is surrounded by a sign that reads \"Boil Water Before Drinking\". The man is wearing a green shirt and has a look of concentration on his face. There are several other people in the background, some of whom are also looking at the toilet."}, "166837": {"image_id": 166837, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.11140622746151968, "Bleu_3": 6.461802818873081e-07, "Bleu_4": 1.5648119269441605e-09, "METEOR": 0.1658442125496726, "ROUGE_L": 0.1601049868766404, "CIDEr": 7.451856648783198e-09, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 14.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a yellow and black train traveling on the tracks. The train has a large engine at the front and several cars behind it. The train is moving quickly and appears to be carrying passengers. There are trees and buildings in the background of the image."}, "422375": {"image_id": 422375, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.14458880781007946, "Bleu_3": 8.055078690642645e-07, "Bleu_4": 1.9133137334560038e-09, "METEOR": 0.20831889296703476, "ROUGE_L": 0.3292847503373819, "CIDEr": 1.0369051005083733e-06, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.08, "f": 0.1, "fn": 23.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.18181818181818182, "f": 0.2222222222222222, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The man is standing in front of a mirror, wearing a black shirt and tie. He has a serious expression on his face and is holding a camera in his hand. The mirror is surrounded by a red and white checkered pattern."}, "393836": {"image_id": 393836, "Bleu_1": 0.5199999999792001, "Bleu_2": 0.41633319987622636, "Bleu_3": 0.335254605334741, "Bleu_4": 0.28770035111790315, "METEOR": 0.3271172727315631, "ROUGE_L": 0.5377081292850147, "CIDEr": 0.08261641956776775, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.14814814814814814, "f": 0.14285714285714285, "fn": 23.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.07142857142857142, "re": 0.09090909090909091, "f": 0.08, "fn": 10.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.2727272727272727, "f": 0.23999999999999996, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "This is a bedroom with a bed, nightstand, and lamp. The bed has a quilt on it and there is a lamp on the nightstand."}, "566298": {"image_id": 566298, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.10737969231852026, "Bleu_3": 6.052669898452478e-07, "Bleu_4": 1.4440016772249673e-09, "METEOR": 0.13080265002350192, "ROUGE_L": 0.16666666666666669, "CIDEr": 1.9859333323157964e-11, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.19047619047619047, "f": 0.19047619047619047, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a family of three sitting on a bed, with the father holding a toothbrush and the mother holding a toothbrush and the child holding a toothbrush. The father is smiling and the mother is looking at the camera. The child is looking at the camera with a smile on his face."}, "159240": {"image_id": 159240, "Bleu_1": 0.49999999998611117, "Bleu_2": 0.35856858279021564, "Bleu_3": 0.24731009705865364, "Bleu_4": 2.6019736905414835e-05, "METEOR": 0.30080335817336895, "ROUGE_L": 0.3567251461988304, "CIDEr": 0.0004839346369868451, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.29411764705882354, "f": 0.2631578947368421, "fn": 12.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "This is a living room with an orange wall and a brown couch. There is a television on the wall and a chair in the corner. The room appears to be empty except for the furniture."}, "321805": {"image_id": 321805, "Bleu_1": 0.3333333333263889, "Bleu_2": 0.2663118206400466, "Bleu_3": 0.22099054784881275, "Bleu_4": 0.1860885477163114, "METEOR": 0.23210265734560293, "ROUGE_L": 0.3202099737532808, "CIDEr": 9.52045693840319e-09, "SPICE": {"All": {"pr": 0.24, "re": 0.46153846153846156, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.2857142857142857, "f": 0.2105263157894737, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.8, "f": 0.5000000000000001, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a clock tower in the middle of a park with palm trees and other plants surrounding it. The clock tower is made of stone and has a large clock face on it. The sky is clear and blue, with a few clouds in the distance."}, "54039": {"image_id": 54039, "Bleu_1": 0.3793103448145066, "Bleu_2": 0.2602575457946004, "Bleu_3": 0.1358775263736997, "Bleu_4": 1.7624523616137678e-05, "METEOR": 0.2552605083203011, "ROUGE_L": 0.2595744680851064, "CIDEr": 0.00783190475483268, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.13636363636363635, "f": 0.13636363636363635, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2727272727272727, "f": 0.2608695652173913, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This is an image of a city street with parked motorcycles on the sidewalk. The street is lined with tall buildings and there are people walking on the sidewalk."}, "253477": {"image_id": 253477, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.21128856367777224, "Bleu_3": 0.09829951488589604, "Bleu_4": 1.1987374488426652e-05, "METEOR": 0.2362538260180994, "ROUGE_L": 0.2208811104405552, "CIDEr": 4.558941066455572e-07, "SPICE": {"All": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 14.0, "numImages": 1.0, "fp": 28.0, "tp": 7.0}, "Relation": {"pr": 0.0625, "re": 0.125, "f": 0.08333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 15.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.6, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}}, "caption": "The image shows a man on a surfboard jumping off a dock into the water. The man is wearing a life jacket and has his arms outstretched as he jumps. The water is calm and clear, with a few boats in the distance. The sky is blue and cloudy."}, "363991": {"image_id": 363991, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.1593710424504603, "Bleu_3": 0.07926525909642891, "Bleu_4": 9.990095999341766e-06, "METEOR": 0.22071968607484993, "ROUGE_L": 0.21356050881082975, "CIDEr": 6.220980460182984e-12, "SPICE": {"All": {"pr": 0.0625, "re": 0.045454545454545456, "f": 0.052631578947368425, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}}, "caption": "A person is standing on the beach holding a surfboard. The sky is clear and blue, with a few clouds in the distance. The waves are crashing against the shore, and the water is calm and clear. The person is wearing a wetsuit and sunglasses, and their hair is blowing in the wind."}, "233521": {"image_id": 233521, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.15118578920063636, "Bleu_3": 0.11262478804206155, "Bleu_4": 0.08829955693848537, "METEOR": 0.1920915310543695, "ROUGE_L": 0.255688622754491, "CIDEr": 6.501242390479922e-10, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.18181818181818182, "f": 0.18604651162790697, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The woman is holding a baby in her arms while sitting on the couch. She is wearing a white shirt and black pants. The baby is wearing a white onesie and has a pacifier in its mouth. There is a remote control on the coffee table in front of them."}, "73182": {"image_id": 73182, "Bleu_1": 0.17777777777382722, "Bleu_2": 2.0100756304732486e-09, "Bleu_3": 4.546237434540884e-12, "Bleu_4": 2.1748372490549038e-13, "METEOR": 0.13198307131447157, "ROUGE_L": 0.1643097643097643, "CIDEr": 2.169513823409062e-09, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.16129032258064516, "f": 0.17543859649122806, "fn": 26.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.08333333333333333, "f": 0.1, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a woman riding a red motorcycle on the sidewalk. She is wearing a helmet and has her arms stretched out to the sides as she steers the bike. The background is blurry and there are trees and buildings visible in the distance."}, "84767": {"image_id": 84767, "Bleu_1": 0.2181818181778513, "Bleu_2": 0.12712834523041283, "Bleu_3": 0.06730845772977347, "Bleu_4": 8.750873255009596e-06, "METEOR": 0.12090968173364747, "ROUGE_L": 0.18047337278106512, "CIDEr": 1.8258479752433477e-13, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.25, "f": 0.24390243902439024, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows two people skiing down a snowy slope. One person is wearing a black and white jacket and pants, while the other is wearing a red and black jacket and pants. They are both holding ski poles and smiling at the camera. The background is a snowy mountain with trees in the distance."}, "350874": {"image_id": 350874, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.25588315785430304, "Bleu_3": 0.21364588310060417, "Bleu_4": 0.18885098356592633, "METEOR": 0.2746125576218781, "ROUGE_L": 0.32864411852738695, "CIDEr": 8.362778876619115e-08, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.1, "f": 0.12765957446808512, "fn": 27.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.21428571428571427, "f": 0.25, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a man riding a red motorcycle with a sidecar on a dirt road. The man is wearing a helmet and sunglasses, and the sidecar has a small trailer attached to it. There are trees and buildings in the background, and people are walking on the sidewalk."}, "546659": {"image_id": 546659, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.15639188177115004, "Bleu_3": 7.776932968046644e-07, "Bleu_4": 1.742664253135909e-09, "METEOR": 0.21258359571335902, "ROUGE_L": 0.1783625730994152, "CIDEr": 2.8752989832326813e-12, "SPICE": {"All": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 21.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a black steam locomotive pulling a train through a city street. The train is moving at a slow pace and the tracks are lined with buildings on either side. There are people standing on the platform and watching the train go by. The sky is clear and blue in the background."}, "548843": {"image_id": 548843, "Bleu_1": 0.3636363636280992, "Bleu_2": 0.15927956195690762, "Bleu_3": 8.453247893683395e-07, "Bleu_4": 1.959168274713403e-09, "METEOR": 0.196373779637378, "ROUGE_L": 0.23890339425587467, "CIDEr": 2.033724578995075e-07, "SPICE": {"All": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 24.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a young boy wearing a blue jacket and holding a plate of food. He is standing in front of a group of people who are all wearing glasses. The background is a busy street with cars and buildings in the distance."}, "6783": {"image_id": 6783, "Bleu_1": 0.15873015872763924, "Bleu_2": 0.1011961234515335, "Bleu_3": 0.05516529849430518, "Bleu_4": 7.272967832453326e-06, "METEOR": 0.12407004208372091, "ROUGE_L": 0.1856925418569254, "CIDEr": 6.159281885145769e-18, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.16129032258064516, "f": 0.1818181818181818, "fn": 26.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.18181818181818182, "f": 0.26666666666666666, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2727272727272727, "f": 0.2608695652173913, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a person flying a kite on the water. The person is holding onto the kite with one hand and has the other hand in the air. There are several other kites in the background, flying in the sky. The sky is blue and there are clouds in the distance. The water is calm and there are boats in the background."}, "78420": {"image_id": 78420, "Bleu_1": 0.8999999998200003, "Bleu_2": 0.774596669082261, "Bleu_3": 0.608220199428375, "Bleu_4": 0.42341975783065045, "METEOR": 0.40549956091586586, "ROUGE_L": 0.8, "CIDEr": 2.652968230250697, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.2, "f": 0.19607843137254902, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "A cat is sleeping on top of a laptop computer."}, "96654": {"image_id": 96654, "Bleu_1": 0.23255813952947546, "Bleu_2": 0.14882336590863374, "Bleu_3": 8.14428187387852e-07, "Bleu_4": 1.9170109753033433e-09, "METEOR": 0.13002361020792544, "ROUGE_L": 0.20608108108108109, "CIDEr": 2.599560083747002e-07, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.23809523809523808, "f": 0.17857142857142855, "fn": 16.0, "numImages": 1.0, "fp": 30.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.7142857142857143, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA group of elephants are standing in a river, surrounded by lush green trees and a small waterfall. The elephants are drinking from the river and seem to be enjoying the scenery around them."}, "209548": {"image_id": 209548, "Bleu_1": 0.4242424242295685, "Bleu_2": 0.36410954061600365, "Bleu_3": 0.29495191802590964, "Bleu_4": 0.22506782730688327, "METEOR": 0.3415770504450949, "ROUGE_L": 0.42471714534377725, "CIDEr": 0.001581923497962354, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.19047619047619047, "f": 0.1702127659574468, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a person cutting a cake with a knife. The cake is white with pink roses on it. There are several bottles of alcohol on the table next to the cake."}, "272242": {"image_id": 272242, "Bleu_1": 0.3947368420948754, "Bleu_2": 0.3098662125759413, "Bleu_3": 0.23714027388273473, "Bleu_4": 0.166147754320677, "METEOR": 0.3167965319655202, "ROUGE_L": 0.3830455259026687, "CIDEr": 4.2313447979853354e-05, "SPICE": {"All": {"pr": 0.36, "re": 0.3, "f": 0.3272727272727273, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 9.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5, "f": 0.45454545454545453, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "A laptop computer is sitting on a table in front of a couch. There are two cups of soda on the table next to the laptop. The laptop has a screen that shows an image of a cat."}, "486": {"image_id": 486, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.19669894811330474, "Bleu_3": 0.1351686025680867, "Bleu_4": 0.08559874749328851, "METEOR": 0.2005213230604642, "ROUGE_L": 0.2982103884766477, "CIDEr": 6.966291705491338e-08, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.13333333333333333, "f": 0.17777777777777776, "fn": 26.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "This is a kitchen with a large wooden table in the center of the room. There are several pots and pans hanging from the ceiling, and a stove and oven on the counter. The walls are painted white and there are several windows on the sides of the room."}, "120162": {"image_id": 120162, "Bleu_1": 0.2711864406733697, "Bleu_2": 0.21623201167707057, "Bleu_3": 0.16007065007760923, "Bleu_4": 0.11001306734322121, "METEOR": 0.2570355684019148, "ROUGE_L": 0.29202127659574467, "CIDEr": 2.929656498894333e-11, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.4117647058823529, "f": 0.3181818181818182, "fn": 10.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.4, "f": 0.3076923076923077, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This image shows a group of people playing in the ocean on a sunny day. There are several surfers in the water, and some people are standing on the beach watching them. The sky is clear and blue, and there are no clouds in sight. The waves are crashing against the shore, and the water is calm and peaceful."}, "316522": {"image_id": 316522, "Bleu_1": 0.34146341462581803, "Bleu_2": 0.22631728213415833, "Bleu_3": 0.10951079799876592, "Bleu_4": 1.3634738359895023e-05, "METEOR": 0.2697359519121402, "ROUGE_L": 0.35234657039711187, "CIDEr": 9.967983597885883e-07, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.25, "f": 0.2962962962962963, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.5, "f": 0.5454545454545454, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This is a blue and white bus parked on the side of a street in front of a large brick building. The bus has the words \"journey\" written on the side in white letters. There are no people in the image."}, "292647": {"image_id": 292647, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.14793756076371775, "Bleu_3": 0.07446639778133946, "Bleu_4": 9.43994412057466e-06, "METEOR": 0.18293244944954828, "ROUGE_L": 0.207506520013607, "CIDEr": 3.11567932872706e-12, "SPICE": {"All": {"pr": 0.4166666666666667, "re": 0.1388888888888889, "f": 0.20833333333333334, "fn": 31.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.15384615384615385, "f": 0.25, "fn": 11.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a person surfing on a wave in the ocean. The person is holding onto the sail of a windsurf board and standing on the board as they ride the wave. The sky is blue and there are clouds in the background. The water is choppy and there are whitecaps on the surface."}, "413260": {"image_id": 413260, "Bleu_1": 0.8749999997812503, "Bleu_2": 0.7071067810034577, "Bleu_3": 0.5503212080006054, "Bleu_4": 0.42728700627504257, "METEOR": 0.28660179721339535, "ROUGE_L": 0.625, "CIDEr": 1.2926427462676053, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 18.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.2857142857142857, "f": 0.4444444444444445, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}}, "caption": "Two white sheep grazing in a green field."}, "262162": {"image_id": 262162, "Bleu_1": 0.39999999998400004, "Bleu_2": 0.3162277660039253, "Bleu_3": 0.20563674453180716, "Bleu_4": 2.5073783388398014e-05, "METEOR": 0.27394050677466325, "ROUGE_L": 0.3715736040609137, "CIDEr": 0.06454881713864448, "SPICE": {"All": {"pr": 0.16, "re": 0.16666666666666666, "f": 0.16326530612244897, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is a bedroom with a bed, desk, and chair. The walls are painted white and there are windows on one side of the room."}, "72753": {"image_id": 72753, "Bleu_1": 0.24324324323995616, "Bleu_2": 0.16326908396679413, "Bleu_3": 0.09046941953306391, "Bleu_4": 1.0105592127894059e-05, "METEOR": 0.20270558864493596, "ROUGE_L": 0.19321266968325795, "CIDEr": 4.00975884649254e-24, "SPICE": {"All": {"pr": 0.15, "re": 0.15, "f": 0.15, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a teddy bear sitting on a red tablecloth with a white blanket on top of it. The teddy bear is wearing a blue shirt and has a red bow tie around its neck. There are two other teddy bears sitting next to it, one wearing a green shirt and the other wearing a yellow shirt. The background is a white wall with a red and white striped curtain hanging on it."}, "51880": {"image_id": 51880, "Bleu_1": 0.16363636363338846, "Bleu_2": 0.123091490977074, "Bleu_3": 6.587592578581811e-07, "Bleu_4": 1.5312433400286173e-09, "METEOR": 0.17182125119652433, "ROUGE_L": 0.2127164942461932, "CIDEr": 1.7275887915832662e-13, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.32, "f": 0.30188679245283023, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5454545454545454, "re": 0.6666666666666666, "f": 0.6, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image shows a cat sitting on the hood of a white van. The cat is looking up at the driver's side mirror. There are several other cats in the background, sitting on the ground and on the hood of other vehicles. The image appears to be taken in a parking lot or garage."}, "445055": {"image_id": 445055, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.17837651699995472, "Bleu_3": 8.383535347317198e-07, "Bleu_4": 1.8260027717725488e-09, "METEOR": 0.1698078025798903, "ROUGE_L": 0.2330786026200873, "CIDEr": 5.496644207366788e-11, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.05555555555555555, "f": 0.06451612903225808, "fn": 34.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.13333333333333333, "f": 0.14814814814814814, "fn": 13.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a man and a child standing on the beach, watching a surfer ride a wave into the ocean. The man is wearing a wetsuit and holding a surfboard, while the child is wearing a life jacket and standing on the beach. The sky is cloudy and there are waves crashing against the shore."}, "208971": {"image_id": 208971, "Bleu_1": 0.15999999999786668, "Bleu_2": 0.11389895948877098, "Bleu_3": 0.08108601722276382, "Bleu_4": 0.052164656611632484, "METEOR": 0.14126015908647063, "ROUGE_L": 0.1931252826775215, "CIDEr": 1.2155026903941764e-25, "SPICE": {"All": {"pr": 0.38095238095238093, "re": 0.32, "f": 0.34782608695652173, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 8.0}, "Relation": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "This is a bedroom with a large white bed with white sheets and pillows. There is a large wooden headboard on the bed and a large window with white curtains on the wall. The walls are painted white and there is a large wooden floor. There is a large wooden dresser against one wall and a large wooden desk against another wall. There is also a large wooden chair in the corner of the room."}, "232357": {"image_id": 232357, "Bleu_1": 0.13235294117452423, "Bleu_2": 0.07698214791286553, "Bleu_3": 0.044779444773246295, "Bleu_4": 6.096501558156943e-06, "METEOR": 0.09720915466426595, "ROUGE_L": 0.14805825242718448, "CIDEr": 9.944587209464613e-22, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.13333333333333333, "f": 0.14285714285714288, "fn": 26.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.3076923076923077, "f": 0.3076923076923077, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "This is a photograph of a room with a window on the left side and a door on the right side. There is a sink in the corner of the room, and a stove in the center of the room. There are also some chairs and a table in the room. The walls are painted a light pink color, and there is a ceiling fan in the room."}, "356323": {"image_id": 356323, "Bleu_1": 0.22727272726928377, "Bleu_2": 0.14484136487336885, "Bleu_3": 6.895012868910915e-07, "Bleu_4": 1.5103102625983549e-09, "METEOR": 0.22376966699805606, "ROUGE_L": 0.20628019323671495, "CIDEr": 2.2661453586246868e-17, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.1935483870967742, "f": 0.22641509433962262, "fn": 25.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.5, "f": 0.5217391304347826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "This is an image of a dog standing in a bathtub with its head out of the water. The dog has a brown and white coat and is looking up at the person holding its paw. The person is wearing a white shirt and has their hand on the dog's paw. The background is a white tile wall with a shower head in the corner."}, "112915": {"image_id": 112915, "Bleu_1": 0.18181818181542703, "Bleu_2": 0.052888588533987035, "Bleu_3": 3.522475598614246e-07, "Bleu_4": 9.126428539580221e-10, "METEOR": 0.18093217597864308, "ROUGE_L": 0.15174129353233828, "CIDEr": 2.846717125437236e-19, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.14285714285714285, "f": 0.15, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This is a small room with a concrete wall and a wooden floor. There is a sink in the corner of the room and a mirror hanging on the wall. There are also several pieces of artwork on the walls, including a painting of a tree and a sculpture of a bird. The room is dimly lit by a single light bulb hanging from the ceiling."}, "365068": {"image_id": 365068, "Bleu_1": 0.3584905660309719, "Bleu_2": 0.28762578493487434, "Bleu_3": 0.2349949240730427, "Bleu_4": 0.19865027594414789, "METEOR": 0.26124894921514075, "ROUGE_L": 0.36686714051394204, "CIDEr": 6.561151614264913e-10, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.2, "f": 0.21276595744680854, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.625, "f": 0.5555555555555556, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "This is a black and white photograph of three people sitting on a bench in front of a building. One person is reading a newspaper, while the other two are looking at something else. The building appears to be an old-fashioned general store with a sign that reads \"general store\" in the window."}, "341094": {"image_id": 341094, "Bleu_1": 0.3749999999882814, "Bleu_2": 0.245934688411173, "Bleu_3": 1.2632988704413624e-06, "Bleu_4": 2.8875537785495685e-09, "METEOR": 0.255097866784952, "ROUGE_L": 0.37014563106796117, "CIDEr": 0.005653538064449792, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.18518518518518517, "f": 0.17543859649122806, "fn": 22.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A bear statue stands in front of a car with a warning sign on it, indicating that the area is closed to vehicles.\""}, "492605": {"image_id": 492605, "Bleu_1": 0.21951219511659734, "Bleu_2": 2.3426064282712406e-09, "Bleu_3": 5.2012933861174834e-12, "Bleu_4": 2.4668208722863054e-13, "METEOR": 0.10977701543739278, "ROUGE_L": 0.21463757916959889, "CIDEr": 2.7138465262619756e-07, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.125, "f": 0.16, "fn": 28.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.08333333333333333, "f": 0.125, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of men playing baseball on a field with a fence in the background. The men are wearing baseball uniforms and are holding bats and gloves. The field is green and there are trees in the background."}, "253227": {"image_id": 253227, "Bleu_1": 0.4634146341350387, "Bleu_2": 0.24067993116467287, "Bleu_3": 1.1409634090666182e-06, "Bleu_4": 2.500390777596101e-09, "METEOR": 0.2875781267844101, "ROUGE_L": 0.25120109814687713, "CIDEr": 4.639236972232851e-06, "SPICE": {"All": {"pr": 0.16, "re": 0.23529411764705882, "f": 0.19047619047619052, "fn": 13.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.6666666666666666, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "A black and white clock tower with a bird perched on top of it. The clock has Roman numerals and hands, and the bird is looking down at the clock. The sky is blue and there are clouds in the background."}, "547435": {"image_id": 547435, "Bleu_1": 0.1960784313687044, "Bleu_2": 0.1400280084000279, "Bleu_3": 0.09284415754233383, "Bleu_4": 1.136333016795187e-05, "METEOR": 0.2373400585394267, "ROUGE_L": 0.21441124780316342, "CIDEr": 1.1324755502382581e-10, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a street with a few cars parked on the side of the road. There are also some buildings in the background, including a brick building with a sign that reads \"Welcome to the town of Silverton.\" The sky is cloudy and there are some trees in the background."}, "344415": {"image_id": 344415, "Bleu_1": 0.34782608694139894, "Bleu_2": 0.17782168978184779, "Bleu_3": 1.1461726919834561e-06, "Bleu_4": 2.9456425446875464e-09, "METEOR": 0.21498538132537048, "ROUGE_L": 0.28273464658169173, "CIDEr": 0.018467675257200403, "SPICE": {"All": {"pr": 0.05, "re": 0.0625, "f": 0.05555555555555556, "fn": 15.0, "numImages": 1.0, "fp": 19.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A train station in the city with a large clock tower in the background.\""}, "22192": {"image_id": 22192, "Bleu_1": 0.31818181817458685, "Bleu_2": 0.2852987010721684, "Bleu_3": 0.22655162567453788, "Bleu_4": 0.17078893747688265, "METEOR": 0.3288338554382191, "ROUGE_L": 0.29735376044568246, "CIDEr": 2.2559467651978613e-07, "SPICE": {"All": {"pr": 0.30434782608695654, "re": 0.3333333333333333, "f": 0.31818181818181823, "fn": 14.0, "numImages": 1.0, "fp": 16.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5555555555555556, "re": 0.625, "f": 0.5882352941176471, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "A dog is sitting on top of a pile of clothes on the floor. The dog is looking up at the camera with its tongue hanging out of its mouth. The background is a messy room with a bed, a dresser, and a closet."}, "66960": {"image_id": 66960, "Bleu_1": 0.1868131868111339, "Bleu_2": 0.1511050059800079, "Bleu_3": 0.11546215248381037, "Bleu_4": 0.0967055880557146, "METEOR": 0.21624503324271824, "ROUGE_L": 0.16353887399463807, "CIDEr": 6.526239464157768e-40, "SPICE": {"All": {"pr": 0.043478260869565216, "re": 0.043478260869565216, "f": 0.043478260869565216, "fn": 22.0, "numImages": 1.0, "fp": 22.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.125, "f": 0.10526315789473685, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows three dogs lying on a bed in a room with white walls and a window on the left side. The dogs are brown and black and have different markings on their coats. One of the dogs is sitting up and looking at the camera, while the other two are laying down next to it. The bed is made of a white sheet and has a few pillows on it. There is a window on the left side of the room with curtains open, allowing natural light to enter."}, "38693": {"image_id": 38693, "Bleu_1": 0.2142857142818878, "Bleu_2": 0.13957263155725563, "Bleu_3": 0.10266979059850452, "Bleu_4": 0.07994117708696574, "METEOR": 0.20898047713476742, "ROUGE_L": 0.26940063091482647, "CIDEr": 3.68432326168043e-12, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.26666666666666666, "f": 0.2758620689655172, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a man sitting at a wooden table outside a building with a plate of food in front of him. He is wearing a black shirt and has a serious expression on his face. There are other people standing around the table, looking at him. The background is a blue sky with some clouds."}, "215596": {"image_id": 215596, "Bleu_1": 0.3749999999921875, "Bleu_2": 0.2363282967133546, "Bleu_3": 0.1344109151128908, "Bleu_4": 0.0857082790640443, "METEOR": 0.24634491159461291, "ROUGE_L": 0.33008658008658004, "CIDEr": 1.5961259804499524e-06, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.3, "f": 0.2926829268292683, "fn": 14.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is a bathroom with a large bathtub in the center of the room. There is a chandelier hanging from the ceiling and a window on one side of the room. The walls are painted a light beige color and there is a large mirror on one wall."}, "493321": {"image_id": 493321, "Bleu_1": 0.4814814814636489, "Bleu_2": 0.408248290448452, "Bleu_3": 0.3419951893221728, "Bleu_4": 0.26591479483680136, "METEOR": 0.39881338005659056, "ROUGE_L": 0.4714975845410628, "CIDEr": 0.05998255894573276, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.2, "f": 0.18604651162790697, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4, "f": 0.34782608695652173, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a couple sitting on a bench under an umbrella in a park. The trees are green and there is a river in the background."}, "559884": {"image_id": 559884, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.18516401995076925, "Bleu_3": 0.08939035350783202, "Bleu_4": 1.1103081472064331e-05, "METEOR": 0.2212338144738861, "ROUGE_L": 0.26521739130434785, "CIDEr": 5.349686437957301e-10, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.13043478260869565, "f": 0.12244897959183673, "fn": 20.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.25, "f": 0.1904761904761905, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "This is an image of a construction worker wearing a hard hat and safety vest standing next to a stop sign on the side of the road. The worker is looking down at the sign and appears to be checking it. The background is a blue sky with some clouds."}, "212080": {"image_id": 212080, "Bleu_1": 0.37499999998437505, "Bleu_2": 0.2553769592167526, "Bleu_3": 0.14365262974612145, "Bleu_4": 1.938341802259304e-05, "METEOR": 0.10999090737160053, "ROUGE_L": 0.25416666666666665, "CIDEr": 0.016373039099057428, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.20833333333333334, "f": 0.25641025641025644, "fn": 19.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A group of people standing around a table with drinks and snacks, smiling and chatting.\""}, "511453": {"image_id": 511453, "Bleu_1": 0.5238095237845806, "Bleu_2": 0.4577377081947216, "Bleu_3": 0.35332952049108113, "Bleu_4": 0.22249323813615754, "METEOR": 0.35138917666010155, "ROUGE_L": 0.5514124293785311, "CIDEr": 0.5192283013429567, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.14814814814814814, "f": 0.14285714285714285, "fn": 23.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "Sure! Here is the caption for the image:\n\n\"A plate of pizza with cheese, pepperoni, and french fries on a table\""}, "340511": {"image_id": 340511, "Bleu_1": 0.33333333332407417, "Bleu_2": 0.169030850940941, "Bleu_3": 0.0943664634767626, "Bleu_4": 1.263236816956828e-05, "METEOR": 0.24685433896999404, "ROUGE_L": 0.308080808080808, "CIDEr": 2.5787353704438066e-05, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.13636363636363635, "f": 0.1333333333333333, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This is a kitchen with a stove, oven, and refrigerator. There is a table and chairs in the dining area. The walls are painted green and there is a window on one side of the room."}, "288765": {"image_id": 288765, "Bleu_1": 0.34285714284734703, "Bleu_2": 0.20083857809555095, "Bleu_3": 0.13471111906856947, "Bleu_4": 0.09348998462305054, "METEOR": 0.21716563436479833, "ROUGE_L": 0.2998525315418646, "CIDEr": 0.00021216727880541347, "SPICE": {"All": {"pr": 0.15, "re": 0.21428571428571427, "f": 0.1764705882352941, "fn": 11.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a person holding a hamburger in their hand. The hamburger has lettuce, tomato, and cheese on it. There is also a small container of ketchup on the table next to the hamburger."}, "457037": {"image_id": 457037, "Bleu_1": 0.34146341462581803, "Bleu_2": 0.24445060351331568, "Bleu_3": 0.16626964075217796, "Bleu_4": 0.10487303092067435, "METEOR": 0.22772111852732768, "ROUGE_L": 0.29550173010380626, "CIDEr": 2.837755457682003e-06, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.42857142857142855, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5555555555555556, "f": 0.4761904761904762, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "This is a hotel room with a large bed, a television, and a desk. The walls are painted green and there is a large window with curtains. The floor is made of wood and there are two chairs in the room."}, "408955": {"image_id": 408955, "Bleu_1": 0.5185185184993142, "Bleu_2": 0.3459163477621225, "Bleu_3": 0.2675186426257877, "Bleu_4": 0.19985739740594977, "METEOR": 0.25290060640915685, "ROUGE_L": 0.37917637917637914, "CIDEr": 0.27089936036061446, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.17391304347826086, "f": 0.17777777777777776, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "This is a living room with a couch, coffee table, and television. The walls are painted white and there are windows on either side of the room."}, "374545": {"image_id": 374545, "Bleu_1": 0.4193548386961499, "Bleu_2": 0.2896048475706757, "Bleu_3": 0.14247474403149546, "Bleu_4": 1.792725954943498e-05, "METEOR": 0.2634978980548692, "ROUGE_L": 0.35376967688483846, "CIDEr": 0.004809126948457905, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.15384615384615385, "f": 0.16, "fn": 22.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a park with a large tree in the center, surrounded by people sitting on benches and walking on the grass. There is a flag flying in the background."}, "293390": {"image_id": 293390, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.1811857688307976, "Bleu_3": 9.139586978860178e-07, "Bleu_4": 2.0648219347002615e-09, "METEOR": 0.18868181705923745, "ROUGE_L": 0.24646464646464644, "CIDEr": 3.5835291407111854e-08, "SPICE": {"All": {"pr": 0.12, "re": 0.11538461538461539, "f": 0.11764705882352941, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.2727272727272727, "f": 0.23999999999999996, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "This is an image of a bathroom with a wooden vanity and a sink. The walls are made of wood and there are two windows on the left side of the room. There is a rug on the floor and a toilet in the corner."}, "158994": {"image_id": 158994, "Bleu_1": 0.36956521738327036, "Bleu_2": 0.2219805449057966, "Bleu_3": 0.1497727491355308, "Bleu_4": 0.11180596803198481, "METEOR": 0.2215411272020013, "ROUGE_L": 0.3534183082271147, "CIDEr": 8.577110432411964e-07, "SPICE": {"All": {"pr": 0.14705882352941177, "re": 0.23809523809523808, "f": 0.18181818181818185, "fn": 16.0, "numImages": 1.0, "fp": 29.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5555555555555556, "f": 0.4545454545454546, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a group of buses parked on the side of a street. They are all white with red and blue stripes on the sides and have the words \"express\" written on the front. There are people standing next to the buses, looking at them."}, "486694": {"image_id": 486694, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.18389242811841477, "Bleu_3": 9.159919831148882e-07, "Bleu_4": 2.056135070108479e-09, "METEOR": 0.15734966747407456, "ROUGE_L": 0.2447178389943835, "CIDEr": 2.235159305575807e-08, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.17391304347826086, "f": 0.16326530612244897, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.2727272727272727, "f": 0.28571428571428564, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a blue and yellow train traveling down the tracks on a sunny day. The train has a large cargo car attached to the back and is pulling into a station. There are people standing on the platform watching the train as it approaches."}, "451798": {"image_id": 451798, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.1842190315423256, "Bleu_3": 0.1107243128286132, "Bleu_4": 1.2901292604257922e-05, "METEOR": 0.23248440106640086, "ROUGE_L": 0.25722891566265055, "CIDEr": 2.471364492737183e-09, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.12903225806451613, "f": 0.14035087719298245, "fn": 27.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3076923076923077, "f": 0.33333333333333337, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This is a photo of a room with a red wall, a white ceiling, and a wooden floor. There are several ties hanging on the wall, and a hat rack with hats on it. There is also a shelf with various items on it, including a vase, a book, and a lamp."}, "117407": {"image_id": 117407, "Bleu_1": 0.5294117646747406, "Bleu_2": 0.31506301888719, "Bleu_3": 0.18774477833405423, "Bleu_4": 2.6220676434485454e-05, "METEOR": 0.3591152500474835, "ROUGE_L": 0.4886515353805074, "CIDEr": 0.35878053289350775, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.3333333333333333, "f": 0.2926829268292683, "fn": 12.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.75, "re": 0.375, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "A small cat sits on the edge of a wooden boat in front of a blue building."}, "25560": {"image_id": 25560, "Bleu_1": 0.32499999999187507, "Bleu_2": 0.24152294576370853, "Bleu_3": 0.19725789782932507, "Bleu_4": 0.14271935303010114, "METEOR": 0.283893778443081, "ROUGE_L": 0.3932664756446992, "CIDEr": 2.3706405780734578e-05, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.08108108108108109, "f": 0.11111111111111113, "fn": 34.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.21428571428571427, "f": 0.25, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "A cat is sitting on top of a wooden shelf in front of a television. The cat is looking at the television with its ears perked up. There is a cup of coffee on the table next to the cat."}, "387173": {"image_id": 387173, "Bleu_1": 0.4999999999642858, "Bleu_2": 0.1961161351236371, "Bleu_3": 1.4743993654284733e-06, "Bleu_4": 4.131551590773095e-09, "METEOR": 0.17477676909842196, "ROUGE_L": 0.3620178041543027, "CIDEr": 0.10646986087075136, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.17391304347826086, "f": 0.17391304347826086, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3333333333333333, "f": 0.34782608695652173, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "A man is kayaking on a body of water with boats in the background."}, "345998": {"image_id": 345998, "Bleu_1": 0.15789473683933522, "Bleu_2": 0.0530994244044193, "Bleu_3": 3.714830298881312e-07, "Bleu_4": 9.870878229862096e-10, "METEOR": 0.15672730322384945, "ROUGE_L": 0.20504201680672268, "CIDEr": 1.594305829392904e-14, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.23809523809523808, "f": 0.20408163265306123, "fn": 16.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a young girl riding on the back of a black horse in a fenced in area. The horse is wearing a saddle and bridle, and the girl is holding onto the saddle horn with her left hand. The fence is made of wooden posts with horizontal rails, and there are trees in the background."}, "341041": {"image_id": 341041, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.19069251784568234, "Bleu_3": 0.08765119647604923, "Bleu_4": 1.0616941372977245e-05, "METEOR": 0.24130200004002536, "ROUGE_L": 0.29967248908296945, "CIDEr": 6.154862771725713e-12, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.21739130434782608, "f": 0.24390243902439024, "fn": 18.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.7142857142857143, "f": 0.6250000000000001, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a young boy standing next to a skateboard ramp in a park. He is wearing a white shirt and blue shorts, and has his hands on the handlebars of the skateboard. The ramp is made of concrete and has a smooth surface. There are trees and grass in the background of the image."}, "526711": {"image_id": 526711, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.20597146021314577, "Bleu_3": 0.09955166929523299, "Bleu_4": 1.2380098139763797e-05, "METEOR": 0.21981214532823923, "ROUGE_L": 0.21048999309868874, "CIDEr": 2.3816245412777755e-08, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.15384615384615385, "f": 0.1509433962264151, "fn": 22.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.23076923076923078, "f": 0.24999999999999994, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a large airplane parked on the runway at an airport. The plane has the words \"white house\" written on the side in bold black letters. In the background, there is a city skyline with tall buildings and a river running through it."}, "90476": {"image_id": 90476, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.09356392870058139, "Bleu_3": 5.486731100334785e-07, "Bleu_4": 1.3350097003360843e-09, "METEOR": 0.1410750245754991, "ROUGE_L": 0.17221908526256355, "CIDEr": 2.1002772698093327e-12, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.1875, "f": 0.19999999999999998, "fn": 13.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a small fishing village with several boats docked at the shore. The boats are painted in different colors and have nets and ropes hanging from them. There are also several people standing on the shore, looking out at the boats. The sky is cloudy and there are some buildings in the background."}, "572427": {"image_id": 572427, "Bleu_1": 0.4102564102458909, "Bleu_2": 0.27490643727245323, "Bleu_3": 0.18299102222839972, "Bleu_4": 2.0311720520162125e-05, "METEOR": 0.2572820829434868, "ROUGE_L": 0.3843730308758664, "CIDEr": 0.00042749017307567574, "SPICE": {"All": {"pr": 0.1875, "re": 0.16666666666666666, "f": 0.17647058823529413, "fn": 15.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a stop sign on the side of a road in a residential area. The sign is red and white with the words \"stop\" written in black letters. There are trees and houses visible in the background."}, "350133": {"image_id": 350133, "Bleu_1": 0.6428571428112246, "Bleu_2": 0.5447047793615183, "Bleu_3": 0.46245240143714167, "Bleu_4": 0.3661926362704101, "METEOR": 0.40844249993694226, "ROUGE_L": 0.6335311572700296, "CIDEr": 1.5903625546569653, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2727272727272727, "f": 0.24489795918367346, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "A black cat laying on a wooden bench in front of a red barn."}, "446460": {"image_id": 446460, "Bleu_1": 0.34146341462581803, "Bleu_2": 0.18478728706739583, "Bleu_3": 0.0956664938094049, "Bleu_4": 1.2320376900697154e-05, "METEOR": 0.1666193334331125, "ROUGE_L": 0.25120109814687713, "CIDEr": 4.169817188448656e-06, "SPICE": {"All": {"pr": 0.28, "re": 0.23333333333333334, "f": 0.2545454545454545, "fn": 23.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.18181818181818182, "f": 0.23529411764705885, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.38461538461538464, "re": 0.45454545454545453, "f": 0.41666666666666663, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "This is an image of a large truck driving down the road. The truck has a white and red paint job and is pulling a trailer behind it. There are other cars and trucks driving on the road in the background."}, "95249": {"image_id": 95249, "Bleu_1": 0.27586206896076104, "Bleu_2": 0.19676758717389048, "Bleu_3": 0.15120391375656378, "Bleu_4": 0.11718227243707044, "METEOR": 0.26142521835550087, "ROUGE_L": 0.26961325966850824, "CIDEr": 1.1827484041145625e-14, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.22580645161290322, "f": 0.2641509433962264, "fn": 24.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.625, "re": 0.5, "f": 0.5555555555555556, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image shows a man sitting on a couch eating a hamburger from a box. There are other people in the room, but they are not visible in the image. The man is wearing a green hat and a white shirt. The background of the image is a living room with a brown carpet and a white couch."}, "233961": {"image_id": 233961, "Bleu_1": 0.29999999998500004, "Bleu_2": 0.1777046633186087, "Bleu_3": 1.2060770349385636e-06, "Bleu_4": 3.1872714731477548e-09, "METEOR": 0.12144468574869835, "ROUGE_L": 0.2837209302325582, "CIDEr": 0.038542903319986124, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.2727272727272727, "f": 0.2926829268292683, "fn": 16.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "Sure, here is a short caption for the image:\n\n\"Surfers ride the waves in a river during a sunny day\""}, "520787": {"image_id": 520787, "Bleu_1": 0.5999999999600001, "Bleu_2": 0.4140393355768242, "Bleu_3": 0.23625442483753367, "Bleu_4": 3.237722712904149e-05, "METEOR": 0.3310944454322937, "ROUGE_L": 0.3490701001430615, "CIDEr": 1.2782207376670343, "SPICE": {"All": {"pr": 0.0967741935483871, "re": 0.13636363636363635, "f": 0.11320754716981131, "fn": 19.0, "numImages": 1.0, "fp": 28.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.2, "f": 0.13333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2, "f": 0.17391304347826086, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "There is a plate of pizza on the table with slices of bread on it."}, "349199": {"image_id": 349199, "Bleu_1": 0.5499999999725, "Bleu_2": 0.41675437671185933, "Bleu_3": 0.3070457069121754, "Bleu_4": 0.2415725260884915, "METEOR": 0.3909442908800292, "ROUGE_L": 0.4965116279069768, "CIDEr": 0.27605497430054216, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.07407407407407407, "f": 0.07547169811320754, "fn": 25.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.18181818181818182, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A group of people enjoying the beach on a sunny day\""}, "437119": {"image_id": 437119, "Bleu_1": 0.2586206896507135, "Bleu_2": 0.22340379561822696, "Bleu_3": 0.1527628268869329, "Bleu_4": 0.08972688533036594, "METEOR": 0.21838471655563352, "ROUGE_L": 0.2941221490892393, "CIDEr": 3.205333825264799e-13, "SPICE": {"All": {"pr": 0.24, "re": 0.2, "f": 0.2181818181818182, "fn": 24.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.15384615384615385, "f": 0.2, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a small dog lying on a bed next to a laptop. The dog is brown and white with a black collar around its neck. The bed is made of a patterned fabric with a floral design. There is a lamp on the nightstand next to the bed, and a window is visible in the background."}, "579073": {"image_id": 579073, "Bleu_1": 0.25641025640368187, "Bleu_2": 0.1642880193591135, "Bleu_3": 9.001951896101368e-07, "Bleu_4": 2.121665383933931e-09, "METEOR": 0.16915491320109555, "ROUGE_L": 0.2741573033707865, "CIDEr": 1.1247670441508452e-05, "SPICE": {"All": {"pr": 0.75, "re": 0.18181818181818182, "f": 0.2926829268292683, "fn": 27.0, "numImages": 1.0, "fp": 2.0, "tp": 6.0}, "Relation": {"pr": 0.5, "re": 0.13333333333333333, "f": 0.2105263157894737, "fn": 13.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.2857142857142857, "f": 0.4444444444444445, "fn": 10.0, "numImages": 1.0, "fp": 0.0, "tp": 4.0}}, "caption": "The image shows a man standing in front of a wall with a basketball hoop on it. He is wearing a white shirt and black shorts, and has a basketball in his hand. The background is a beige color."}, "260447": {"image_id": 260447, "Bleu_1": 0.20689655172057078, "Bleu_2": 0.060247523311829976, "Bleu_3": 4.0169533661840285e-07, "Bleu_4": 1.04191411148207e-09, "METEOR": 0.15211549577365138, "ROUGE_L": 0.17192784667418262, "CIDEr": 6.318213056246356e-15, "SPICE": {"All": {"pr": 0.25, "re": 0.17857142857142858, "f": 0.20833333333333331, "fn": 23.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.4166666666666667, "f": 0.43478260869565216, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "This is an image of a subway train traveling along a track at night. The train is painted in red and white, with the words \"Subway\" written on the side. The train is traveling through a tunnel, with the sky visible above it. There are people standing on the platform, looking at the train as it passes by."}, "557517": {"image_id": 557517, "Bleu_1": 0.3902439024295063, "Bleu_2": 0.24194335155767877, "Bleu_3": 0.14425501641879765, "Bleu_4": 1.6764951224507223e-05, "METEOR": 0.29717781471772375, "ROUGE_L": 0.3083032490974729, "CIDEr": 1.5943820704074724e-05, "SPICE": {"All": {"pr": 0.08, "re": 0.07692307692307693, "f": 0.0784313725490196, "fn": 24.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.09090909090909091, "f": 0.09090909090909091, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows a person standing in a grassy field with a large red kite flying in the sky. The person is holding onto the kite and appears to be controlling it. There are trees and buildings visible in the background."}, "36990": {"image_id": 36990, "Bleu_1": 0.33333333332716053, "Bleu_2": 0.2243088616326247, "Bleu_3": 0.1570060918669648, "Bleu_4": 0.11099472319754804, "METEOR": 0.2394793240353187, "ROUGE_L": 0.24710648148148148, "CIDEr": 7.409763568724308e-12, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.23529411764705882, "f": 0.17777777777777778, "fn": 13.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is an image of a red school bus parked on the side of a dirt road in front of a group of houses. The bus has the words \"School Bus\" written on the side in white letters. There are people standing around the bus, looking at it. The sky is clear and blue."}, "28998": {"image_id": 28998, "Bleu_1": 0.29999999999250004, "Bleu_2": 0.2480694691721357, "Bleu_3": 0.1864122047986733, "Bleu_4": 0.11502846551482096, "METEOR": 0.2526477015052123, "ROUGE_L": 0.34078212290502796, "CIDEr": 6.771107891464536e-06, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.22727272727272727, "f": 0.27027027027027023, "fn": 17.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5714285714285714, "f": 0.5714285714285714, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a young boy holding a piece of fruit in his hand. He is standing in front of a table with several other fruits and vegetables on it. The background is a bright blue sky with some clouds."}, "242570": {"image_id": 242570, "Bleu_1": 0.2068965517217598, "Bleu_2": 0.120144259718102, "Bleu_3": 0.06977058652033867, "Bleu_4": 0.04484194677655824, "METEOR": 0.18732282288886937, "ROUGE_L": 0.16454720616570329, "CIDEr": 6.484763089994164e-33, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.09090909090909091, "f": 0.11538461538461539, "fn": 30.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.23076923076923078, "f": 0.27272727272727276, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "A white truck with the words \"TOYOTA\" written on the side is parked on the side of a dirt road. The truck is facing down the road, and there is a person standing in the back of the truck. The person is wearing a black shirt and pants, and they are looking out at the camera. There is a small dog sitting in the front of the truck, and it is also looking at the camera. The sky is cloudy and there are trees in the background."}, "55780": {"image_id": 55780, "Bleu_1": 0.3999999999885715, "Bleu_2": 0.286972021583456, "Bleu_3": 0.23194146337631918, "Bleu_4": 0.1849381946528296, "METEOR": 0.309541649554096, "ROUGE_L": 0.4070058381984987, "CIDEr": 0.00042088435082162365, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.20833333333333334, "f": 0.1923076923076923, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a young girl holding a small dog on a leash while standing on a balcony with her parents. The balcony is surrounded by trees and there are other people in the background."}, "402234": {"image_id": 402234, "Bleu_1": 0.34042553190765057, "Bleu_2": 0.25807943616605344, "Bleu_3": 0.16436342448231112, "Bleu_4": 0.10022838134993461, "METEOR": 0.2987869107814186, "ROUGE_L": 0.31063017186505404, "CIDEr": 7.540501416148155e-09, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.10714285714285714, "f": 0.15384615384615383, "fn": 25.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.18181818181818182, "f": 0.25000000000000006, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows an elephant standing in a grassy field with its baby next to it. The elephant is looking down at the ground while the baby is looking up at its mother. There are trees in the background and a small stream running through the field."}, "23821": {"image_id": 23821, "Bleu_1": 0.18055555555304786, "Bleu_2": 0.12352415133088142, "Bleu_3": 0.07582491015559271, "Bleu_4": 0.05013565066269191, "METEOR": 0.21624711493653198, "ROUGE_L": 0.19768518518518519, "CIDEr": 2.3195711263524036e-24, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.15384615384615385, "f": 0.14285714285714288, "fn": 22.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "Sure, here is a short caption for the image:\n\nThe image shows a red motorcycle parked on the side of a city street. The motorcycle has a sleek, modern design and is parked next to a row of parked cars. The street is lined with tall buildings and there are pedestrians walking on the sidewalk. The image is taken from a low angle, looking up at the motorcycle and the surrounding buildings."}, "468501": {"image_id": 468501, "Bleu_1": 0.19148936169805347, "Bleu_2": 0.0645198590415134, "Bleu_3": 4.522633916831482e-07, "Bleu_4": 1.2041494936393691e-09, "METEOR": 0.08739838225311994, "ROUGE_L": 0.11387678904791537, "CIDEr": 3.7745899033914806e-08, "SPICE": {"All": {"pr": 0.06060606060606061, "re": 0.06451612903225806, "f": 0.0625, "fn": 29.0, "numImages": 1.0, "fp": 31.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.13333333333333333, "re": 0.15384615384615385, "f": 0.14285714285714288, "fn": 11.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}}, "caption": "This is a living room with a fireplace and a television. There are two people in the room, one is sitting on the couch and the other is standing by the fireplace. The walls are painted white and there are windows on the sides of the room."}, "466981": {"image_id": 466981, "Bleu_1": 0.2931034482708086, "Bleu_2": 0.21512668786420022, "Bleu_3": 0.17052338103059098, "Bleu_4": 0.13780414367148194, "METEOR": 0.2778141431416116, "ROUGE_L": 0.3033149171270718, "CIDEr": 4.116728894941733e-10, "SPICE": {"All": {"pr": 0.15151515151515152, "re": 0.17857142857142858, "f": 0.16393442622950818, "fn": 23.0, "numImages": 1.0, "fp": 28.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "This image shows a man standing next to a blue car with the hood up. He is wearing a black coat and gloves, and appears to be checking the engine. The car has a flat tire, and the man is using a jack to lift it up. There is snow on the ground, and the sky is cloudy."}, "563295": {"image_id": 563295, "Bleu_1": 0.6428571428112246, "Bleu_2": 0.31448545099324837, "Bleu_3": 0.20199469188293792, "Bleu_4": 2.9420957078790958e-05, "METEOR": 0.332701238650443, "ROUGE_L": 0.543026706231454, "CIDEr": 0.7180022194876252, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.14285714285714285, "f": 0.1568627450980392, "fn": 24.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a small airplane flying in the sky with a cloudy background."}, "175251": {"image_id": 175251, "Bleu_1": 0.3953488372001082, "Bleu_2": 0.3360904798204093, "Bleu_3": 0.2681691826002812, "Bleu_4": 0.17621754733168996, "METEOR": 0.30994333175150074, "ROUGE_L": 0.3924231593995712, "CIDEr": 7.290294010460096e-05, "SPICE": {"All": {"pr": 0.7777777777777778, "re": 0.3333333333333333, "f": 0.4666666666666666, "fn": 14.0, "numImages": 1.0, "fp": 2.0, "tp": 7.0}, "Relation": {"pr": 1.0, "re": 0.2857142857142857, "f": 0.4444444444444445, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1111111111111111, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.8, "f": 0.8000000000000002, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The image shows a young boy sitting in a bathtub, brushing his teeth with a toothbrush. The boy is smiling and has a toothbrush in his hand. The image is taken in a bathroom with a mirror on the wall behind the boy."}, "114634": {"image_id": 114634, "Bleu_1": 0.23376623376319783, "Bleu_2": 0.18394180184308517, "Bleu_3": 0.1217455792223808, "Bleu_4": 0.07027194436254278, "METEOR": 0.23302374612748084, "ROUGE_L": 0.23653597587246875, "CIDEr": 7.922720885916275e-27, "SPICE": {"All": {"pr": 0.25, "re": 0.09090909090909091, "f": 0.13333333333333333, "fn": 20.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}}, "caption": "A group of people are standing on a sand dune, looking up at a kite flying in the sky. The kite is red and white, with a long tail that is streaming behind it. The people are all wearing sunglasses and hats to protect themselves from the sun. The sky is clear and blue, with a few white clouds scattered across it. The dune is covered in sand and there are some small plants growing on it."}, "32947": {"image_id": 32947, "Bleu_1": 0.4814814814636489, "Bleu_2": 0.2721655269656347, "Bleu_3": 0.14362897932992935, "Bleu_4": 1.8744710838941805e-05, "METEOR": 0.2665708115384858, "ROUGE_L": 0.3663663663663663, "CIDEr": 0.013397834849670807, "SPICE": {"All": {"pr": 0.7, "re": 0.21875, "f": 0.3333333333333333, "fn": 25.0, "numImages": 1.0, "fp": 3.0, "tp": 7.0}, "Relation": {"pr": 0.25, "re": 0.07692307692307693, "f": 0.11764705882352941, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.1, "f": 0.18181818181818182, "fn": 9.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.5555555555555556, "f": 0.7142857142857143, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 5.0}}, "caption": "The image shows a woman standing in a bathroom, wearing a blue dress and holding a toilet brush. The walls are white and the floor is green."}, "458510": {"image_id": 458510, "Bleu_1": 0.5185185184993142, "Bleu_2": 0.315776977798527, "Bleu_3": 1.5858921146365579e-06, "Bleu_4": 3.5904792347098993e-09, "METEOR": 0.2853846048024685, "ROUGE_L": 0.3663663663663663, "CIDEr": 0.03421351027001509, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.2608695652173913, "f": 0.23529411764705882, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.29411764705882354, "re": 0.5555555555555556, "f": 0.3846153846153846, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}}, "caption": "This is an image of a plate of food with chicken enchiladas, rice, and beans. There is a fork and knife on the side of the plate."}, "429074": {"image_id": 429074, "Bleu_1": 0.47826086954442354, "Bleu_2": 0.36115755924124826, "Bleu_3": 0.1838194128820333, "Bleu_4": 2.3606740828063765e-05, "METEOR": 0.23121950811432365, "ROUGE_L": 0.27141268075639596, "CIDEr": 0.050052843734883695, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.25, "f": 0.1764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.1, "re": 0.3333333333333333, "f": 0.15384615384615383, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.5, "f": 0.30769230769230765, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "This is a bathroom with a toilet, sink, and shower. The walls are white and there is a black and white tiled floor."}, "483179": {"image_id": 483179, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.15755219780890306, "Bleu_3": 0.102574725922902, "Bleu_4": 0.06998051681299158, "METEOR": 0.2032350390174619, "ROUGE_L": 0.2401574803149606, "CIDEr": 4.1316113849340473e-10, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.11538461538461539, "f": 0.12765957446808512, "fn": 23.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This is a bathroom with a toilet, sink, and shower. The walls are painted white and the floor is made of tile. There is a wooden vanity with a mirror above it and a towel rack on the wall. The shower has a glass door and a curtain."}, "386227": {"image_id": 386227, "Bleu_1": 0.6428571428112246, "Bleu_2": 0.49724515806196345, "Bleu_3": 0.3454060644761944, "Bleu_4": 0.24739977340888714, "METEOR": 0.24474457468605382, "ROUGE_L": 0.4680306905370844, "CIDEr": 0.855926890301185, "SPICE": {"All": {"pr": 0.12, "re": 0.1, "f": 0.1090909090909091, "fn": 27.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.16666666666666666, "f": 0.16, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "A group of sheep graze in a field with a fence in the background."}, "403315": {"image_id": 403315, "Bleu_1": 0.5882352940830451, "Bleu_2": 0.4696682182853713, "Bleu_3": 0.3533492012932546, "Bleu_4": 0.23693055762206497, "METEOR": 0.34333892505818947, "ROUGE_L": 0.6686967113276492, "CIDEr": 1.0150194845613996, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.25, "f": 0.23809523809523808, "fn": 15.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "A black and white dog is running through a park with a red ball in its mouth."}, "77648": {"image_id": 77648, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.11651034560483009, "Bleu_3": 0.0815823712251846, "Bleu_4": 0.057696334521472034, "METEOR": 0.256434133205689, "ROUGE_L": 0.25722891566265055, "CIDEr": 7.087867804974847e-11, "SPICE": {"All": {"pr": 0.125, "re": 0.08823529411764706, "f": 0.10344827586206896, "fn": 31.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.25, "f": 0.2608695652173913, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is a living room with a large window that looks out onto a patio. There are two couches in the room, one brown and one black, and a coffee table in the center of the room. The walls are painted a light blue color and there are curtains on the windows."}, "248919": {"image_id": 248919, "Bleu_1": 0.5652173912797732, "Bleu_2": 0.32057261019905153, "Bleu_3": 0.16977660468584396, "Bleu_4": 2.2240824547977345e-05, "METEOR": 0.24380295625356424, "ROUGE_L": 0.3534183082271147, "CIDEr": 0.05318574566019357, "SPICE": {"All": {"pr": 0.2, "re": 0.13333333333333333, "f": 0.16, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "This is a kitchen with wooden cabinets and a white refrigerator. There is a table with chairs in the center of the room."}, "386661": {"image_id": 386661, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.18666334823214084, "Bleu_3": 0.09550351820629131, "Bleu_4": 1.2224986162514046e-05, "METEOR": 0.2407941906641232, "ROUGE_L": 0.22197962154294032, "CIDEr": 3.1650277897375794e-07, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.1935483870967742, "f": 0.20689655172413793, "fn": 25.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.46153846153846156, "f": 0.48000000000000004, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a beach with wooden benches and umbrellas set up on the sand. The sky is clear and blue, with a few clouds scattered in the distance. The ocean is visible in the background, with waves crashing against the shore."}, "435308": {"image_id": 435308, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.1593710424504603, "Bleu_3": 7.926525909642893e-07, "Bleu_4": 1.7765182019941675e-09, "METEOR": 0.18993858337598238, "ROUGE_L": 0.2507339988256019, "CIDEr": 1.4913221432009429e-09, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.05405405405405406, "f": 0.06779661016949154, "fn": 35.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.13333333333333333, "f": 0.15384615384615383, "fn": 13.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a person performing a trick on a jet ski in the middle of a lake. The person is wearing a life jacket and has their arms outstretched as they jump off the back of the boat. The water is calm and clear, with trees and houses visible in the background."}, "12570": {"image_id": 12570, "Bleu_1": 0.2857142857061225, "Bleu_2": 0.12964074470667444, "Bleu_3": 0.07985884624255976, "Bleu_4": 1.1231940107977425e-05, "METEOR": 0.19706704237411765, "ROUGE_L": 0.2469635627530364, "CIDEr": 0.00039980635338399855, "SPICE": {"All": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 18.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is a kitchen with a table and chairs in it. There is a stove on the counter and a sink in the corner. There are also some pots and pans hanging from the ceiling."}, "336232": {"image_id": 336232, "Bleu_1": 0.26190476189852613, "Bleu_2": 0.19577417125493551, "Bleu_3": 0.1421861682321534, "Bleu_4": 0.11018801516138978, "METEOR": 0.1952986108422712, "ROUGE_L": 0.2531120331950207, "CIDEr": 1.5944183520753588e-06, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.08, "f": 0.10526315789473685, "fn": 23.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.18181818181818182, "f": 0.25000000000000006, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a busy street with cars, buses, and pedestrians. There are buildings on either side of the street, and trees and other vegetation can be seen in the background. The sky is cloudy and there are some birds flying overhead."}, "412584": {"image_id": 412584, "Bleu_1": 0.45161290321123837, "Bleu_2": 0.17351520647985194, "Bleu_3": 1.0125714893868398e-06, "Bleu_4": 2.4676284196864047e-09, "METEOR": 0.1997954217021579, "ROUGE_L": 0.22202001819836215, "CIDEr": 0.0007721721822270534, "SPICE": {"All": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 24.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.08333333333333333, "f": 0.11764705882352941, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.375, "f": 0.42857142857142855, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "This is an image of a snowy street with cars parked on the side of the road. There are traffic lights at the intersection and a few buildings in the background."}, "264683": {"image_id": 264683, "Bleu_1": 0.1702127659538253, "Bleu_2": 1.9236105428737107e-09, "Bleu_3": 4.348511215471945e-12, "Bleu_4": 2.0791808991436597e-13, "METEOR": 0.14506914568984605, "ROUGE_L": 0.18979464841319227, "CIDEr": 4.149630617618443e-10, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 21.0, "numImages": 1.0, "fp": 30.0, "tp": 6.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.09090909090909091, "f": 0.08695652173913043, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.26666666666666666, "re": 0.5, "f": 0.3478260869565218, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"The Air and Space Museum is filled with a variety of aircraft, including this large passenger jet. The museum showcases the history of aviation and space exploration, with exhibits on everything from early balloons to modern space shuttles.\""}, "172702": {"image_id": 172702, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.15849534045439814, "Bleu_3": 0.1045209718275127, "Bleu_4": 0.07178529103115949, "METEOR": 0.167983611040699, "ROUGE_L": 0.2367399741267788, "CIDEr": 1.3372083155675084e-08, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.17857142857142858, "f": 0.2380952380952381, "fn": 23.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.07692307692307693, "f": 0.13333333333333336, "fn": 12.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a street sign with the words \"Warring Rd\" written in Chinese characters. The sign is mounted on a pole in the middle of a busy street with cars and pedestrians passing by. The streetlights are on, casting a warm glow over the scene."}, "66959": {"image_id": 66959, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.1313579154832357, "Bleu_3": 0.08897106801212075, "Bleu_4": 0.06189082809605832, "METEOR": 0.1960101862830555, "ROUGE_L": 0.2238532110091743, "CIDEr": 1.0978564894029498e-09, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.037037037037037035, "f": 0.05, "fn": 26.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "The image shows a train carrying military personnel on the tracks. The train is painted in camouflage colors and has a large cargo car on the back. There are several soldiers standing on the platform, looking out at the landscape. The sky is cloudy and there are mountains in the distance."}, "35160": {"image_id": 35160, "Bleu_1": 0.2647058823451558, "Bleu_2": 0.08956221510130578, "Bleu_3": 6.30521487401884e-07, "Bleu_4": 1.686298660670985e-09, "METEOR": 0.1703526495964868, "ROUGE_L": 0.22141560798548093, "CIDEr": 3.3402420658729885e-05, "SPICE": {"All": {"pr": 0.25806451612903225, "re": 0.2857142857142857, "f": 0.2711864406779661, "fn": 20.0, "numImages": 1.0, "fp": 23.0, "tp": 8.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.18181818181818182, "f": 0.17391304347826086, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5555555555555556, "f": 0.4545454545454546, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "Two women are standing in front of a body of water, one is holding a plate of food and the other is holding a drink. They are both smiling and looking at the camera."}, "88225": {"image_id": 88225, "Bleu_1": 0.26315789472991696, "Bleu_2": 0.11926756082899304, "Bleu_3": 7.33805098169319e-07, "Bleu_4": 1.8330256088670778e-09, "METEOR": 0.18046761336706446, "ROUGE_L": 0.22659732540861813, "CIDEr": 1.5576855477982478e-05, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 12.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a street with several buses parked on the side of the road. There are people walking on the sidewalk and in the park. The trees are green and there are flowers blooming in the grass."}, "455698": {"image_id": 455698, "Bleu_1": 0.692307692254438, "Bleu_2": 0.6354889092513221, "Bleu_3": 0.527587404866211, "Bleu_4": 0.458143076612076, "METEOR": 0.4196674606844863, "ROUGE_L": 0.696574225122349, "CIDEr": 1.6011552501407234, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.13636363636363635, "f": 0.1395348837209302, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "A herd of zebras grazing in a field with trees in the background."}, "22801": {"image_id": 22801, "Bleu_1": 0.41666666665509267, "Bleu_2": 0.2672612419048945, "Bleu_3": 0.16136438271820902, "Bleu_4": 1.8889796346301664e-05, "METEOR": 0.27920953319435216, "ROUGE_L": 0.33888888888888885, "CIDEr": 4.214854304927923e-05, "SPICE": {"All": {"pr": 0.06451612903225806, "re": 0.07692307692307693, "f": 0.07017543859649122, "fn": 24.0, "numImages": 1.0, "fp": 29.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.18181818181818182, "f": 0.16, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "The woman is holding a frisbee in her hand and smiling at the camera. She is wearing sunglasses and a blue shirt. The background is a park with trees and a city skyline in the distance."}, "542717": {"image_id": 542717, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.17720317768650332, "Bleu_3": 0.12888544137088334, "Bleu_4": 0.08400125671571576, "METEOR": 0.17625338599348897, "ROUGE_L": 0.20691994572591585, "CIDEr": 1.99582866576801e-08, "SPICE": {"All": {"pr": 0.15625, "re": 0.18518518518518517, "f": 0.1694915254237288, "fn": 22.0, "numImages": 1.0, "fp": 27.0, "tp": 5.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.09090909090909091, "f": 0.08333333333333334, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.21428571428571427, "re": 0.25, "f": 0.23076923076923075, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "This image shows a street market in India with various fruits and vegetables on display. There are several people shopping and browsing the stalls, while others are sitting on the sidewalk and enjoying their purchases. The market is surrounded by buildings with green shutters and walls."}, "397151": {"image_id": 397151, "Bleu_1": 0.2419354838670656, "Bleu_2": 0.12595484068769355, "Bleu_3": 6.418390826668297e-07, "Bleu_4": 1.4549786343112914e-09, "METEOR": 0.19542301956996055, "ROUGE_L": 0.21543895055499496, "CIDEr": 1.3204372968981148e-16, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.21428571428571427, "f": 0.1395348837209302, "fn": 11.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a young girl standing on the beach holding a colorful kite. She is wearing a white shirt and black pants, and her hair is tied back in a ponytail. The kite has brightly colored feathers and is flying high in the air. In the background, there are people standing on the beach and watching the girl fly the kite."}, "374041": {"image_id": 374041, "Bleu_1": 0.26190476189852613, "Bleu_2": 0.17871654962201275, "Bleu_3": 0.1338023071149955, "Bleu_4": 0.08852818280776471, "METEOR": 0.2274472425499211, "ROUGE_L": 0.2952973720608575, "CIDEr": 6.377718865440896e-07, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.16, "f": 0.19047619047619052, "fn": 21.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a group of elephants standing in a fenced area. They are wearing harnesses and ropes around their necks, and one of them is sitting on top of a wooden fence. The background is a jungle with trees and plants."}, "321543": {"image_id": 321543, "Bleu_1": 0.5624999999648439, "Bleu_2": 0.19364916729786447, "Bleu_3": 1.3887830606267012e-06, "Bleu_4": 3.788697835944244e-09, "METEOR": 0.21355236139630393, "ROUGE_L": 0.33701657458563533, "CIDEr": 0.39600115302845307, "SPICE": {"All": {"pr": 0.2, "re": 0.13333333333333333, "f": 0.16, "fn": 26.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.08333333333333333, "f": 0.11764705882352941, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "This is a black and white image of a plate with steak, broccoli, and mashed potatoes."}, "225378": {"image_id": 225378, "Bleu_1": 0.2909090909038017, "Bleu_2": 0.164121987969432, "Bleu_3": 7.980300087819457e-07, "Bleu_4": 1.7681275091206876e-09, "METEOR": 0.1905703266914544, "ROUGE_L": 0.21095100864553315, "CIDEr": 6.441739423147163e-13, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.041666666666666664, "f": 0.05714285714285715, "fn": 23.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}}, "caption": "The image shows a group of people playing soccer on a field. There are two players in blue and white uniforms, one is kicking the ball and the other is trying to block it. There are several people in the background watching the game. The sky is cloudy and there are umbrellas on the ground."}, "124659": {"image_id": 124659, "Bleu_1": 0.18644067796294173, "Bleu_2": 0.09820123900819437, "Bleu_3": 0.05530779693696515, "Bleu_4": 7.4138323832307135e-06, "METEOR": 0.1555211162409246, "ROUGE_L": 0.19561731694281131, "CIDEr": 1.6880015918946267e-15, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.13793103448275862, "f": 0.1568627450980392, "fn": 25.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This is a small room with a wooden floor and white walls. There is a desk in the corner with a computer on it and a lamp on the side. There are also some shelves with books and other items on them. The room has a large window with curtains and a door that leads out to a hallway."}, "398304": {"image_id": 398304, "Bleu_1": 0.5405405405259314, "Bleu_2": 0.32419917504420775, "Bleu_3": 0.18177267037648076, "Bleu_4": 2.0501078626750495e-05, "METEOR": 0.23225806451612901, "ROUGE_L": 0.3414975507347796, "CIDEr": 0.00019987134319569253, "SPICE": {"All": {"pr": 0.2, "re": 0.07407407407407407, "f": 0.10810810810810811, "fn": 25.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "This is an image of a bicycle with a handlebar mounted on the front wheel. The handlebar has a mirror attached to it, and the bike is parked in a room with a rug on the floor."}, "77951": {"image_id": 77951, "Bleu_1": 0.9285714285051022, "Bleu_2": 0.8017837256778003, "Bleu_3": 0.6446159946448665, "Bleu_4": 0.46976984507372527, "METEOR": 0.3106926977162979, "ROUGE_L": 0.5965770171149144, "CIDEr": 1.8253732497054003, "SPICE": {"All": {"pr": 0.2, "re": 0.20689655172413793, "f": 0.20338983050847456, "fn": 23.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.5555555555555556, "f": 0.43478260869565216, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "A plate with a piece of toast and a slice of ham on it."}, "136411": {"image_id": 136411, "Bleu_1": 0.4999999999642858, "Bleu_2": 0.33968311021818254, "Bleu_3": 0.212645185125073, "Bleu_4": 3.0576902882039146e-05, "METEOR": 0.2339095284108899, "ROUGE_L": 0.4680306905370844, "CIDEr": 1.1508245619058775, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.18181818181818182, "f": 0.1509433962264151, "fn": 18.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4444444444444444, "f": 0.34782608695652173, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "This is a red and white stop sign on the side of the road."}, "254789": {"image_id": 254789, "Bleu_1": 0.2608695652136106, "Bleu_2": 0.17518714873957753, "Bleu_3": 0.13181552491326118, "Bleu_4": 0.10101113530808208, "METEOR": 0.24873170230491645, "ROUGE_L": 0.28280018544274454, "CIDEr": 1.0098660372808118e-17, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 28.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is an image of a group of people standing around a large truck in a parking lot. The truck has the words \"Appliance Mart\" written on the side in white letters. The people are wearing yellow vests and standing around the truck, looking at something on the ground. There are cones set up in the parking lot to mark off an area for the people to stand in."}, "252573": {"image_id": 252573, "Bleu_1": 0.29629629628532245, "Bleu_2": 0.21350420506538995, "Bleu_3": 0.12216804360518721, "Bleu_4": 1.660219092499284e-05, "METEOR": 0.16486007194880628, "ROUGE_L": 0.31671858774662515, "CIDEr": 0.010312031007353176, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.20833333333333334, "f": 0.2702702702702703, "fn": 19.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.07692307692307693, "f": 0.11764705882352941, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.36363636363636365, "f": 0.4705882352941177, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "A cat is sitting on the floor next to a computer with a keyboard and mouse. The cat is looking at the keyboard and mouse with interest."}, "411184": {"image_id": 411184, "Bleu_1": 0.37254901960053827, "Bleu_2": 0.2589571847366968, "Bleu_3": 0.11102478733520098, "Bleu_4": 1.2994352780076862e-05, "METEOR": 0.21173949683079732, "ROUGE_L": 0.2238532110091743, "CIDEr": 5.96806997493134e-09, "SPICE": {"All": {"pr": 0.375, "re": 0.16666666666666666, "f": 0.23076923076923078, "fn": 15.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image shows a view of a city from a high vantage point, with a bridge crossing over a river in the foreground. The city is made up of tall buildings and has a large harbor in the background. The sky is clear and blue, with a few clouds scattered about."}, "1584": {"image_id": 1584, "Bleu_1": 0.28070175438104034, "Bleu_2": 0.23481448977773262, "Bleu_3": 0.18186373886565452, "Bleu_4": 0.14528679532089564, "METEOR": 0.3100693484449627, "ROUGE_L": 0.3342465753424657, "CIDEr": 8.476645492711175e-13, "SPICE": {"All": {"pr": 0.4, "re": 0.125, "f": 0.19047619047619047, "fn": 14.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.2857142857142857, "f": 0.4, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "The image shows a red double decker bus driving down the street. The bus is parked on the side of the road and has a number 12 written on the side. There are people standing on the sidewalk and in the street, looking at the bus. The sky is clear and there are buildings in the background."}, "422676": {"image_id": 422676, "Bleu_1": 0.37421358067360916, "Bleu_2": 0.20322618501079454, "Bleu_3": 0.1055990117550308, "Bleu_4": 1.3651512237476987e-05, "METEOR": 0.21147317075939848, "ROUGE_L": 0.33701657458563533, "CIDEr": 0.06971997209603349, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.3333333333333333, "f": 0.2439024390243902, "fn": 10.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows three young girls sitting on a bench in a park, smiling and looking at the camera. One of them is holding a sign that reads, \"We are the future.\""}, "104589": {"image_id": 104589, "Bleu_1": 0.370370370356653, "Bleu_2": 0.2067245576408771, "Bleu_3": 0.11956793017371352, "Bleu_4": 1.6336470130381284e-05, "METEOR": 0.17059630786511626, "ROUGE_L": 0.30530530530530536, "CIDEr": 0.005465550949480944, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.13333333333333333, "f": 0.16666666666666669, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a tray with several dishes on it, including a steak, mashed potatoes, and vegetables. There are also two glasses of beer on the table."}, "311922": {"image_id": 311922, "Bleu_1": 0.3333333333247864, "Bleu_2": 0.18731716231147263, "Bleu_3": 9.82466623306346e-07, "Bleu_4": 2.265493021694376e-09, "METEOR": 0.24714283360611206, "ROUGE_L": 0.2771467514766015, "CIDEr": 3.10191825721846e-05, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.16, "f": 0.16326530612244897, "fn": 21.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows two women wearing hats and sunglasses, smiling at the camera. One of them is wearing a striped shirt and the other is wearing a polka dot shirt. They are both wearing sunglasses and hats with stripes."}, "422783": {"image_id": 422783, "Bleu_1": 0.35135135134185547, "Bleu_2": 0.2209045015297887, "Bleu_3": 1.1171556744566545e-06, "Bleu_4": 2.5305536116480563e-09, "METEOR": 0.16664426513874162, "ROUGE_L": 0.24596774193548387, "CIDEr": 1.0059412129046517e-05, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 21.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.3333333333333333, "f": 0.42857142857142855, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This is an image of a microwave oven in a kitchen. It is mounted on the wall and has a digital display on the front. There are some utensils and dishes on the counter next to it."}, "433151": {"image_id": 433151, "Bleu_1": 0.37499999999062505, "Bleu_2": 0.24019223070154896, "Bleu_3": 0.16576208078090784, "Bleu_4": 0.10533275933494715, "METEOR": 0.2880135994335273, "ROUGE_L": 0.3932664756446992, "CIDEr": 6.462743919941523e-06, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.15384615384615385, "f": 0.14285714285714288, "fn": 22.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This is an image of a large, ornate building with a clock tower on top. The building has a large, arched entrance with columns on either side. There are several cars parked on the street in front of the building."}, "306421": {"image_id": 306421, "Bleu_1": 0.20689655172057078, "Bleu_2": 0.15939996379066856, "Bleu_3": 0.1313972082572321, "Bleu_4": 0.10547007257131018, "METEOR": 0.22503684521424974, "ROUGE_L": 0.2643553629469122, "CIDEr": 6.374449606381716e-14, "SPICE": {"All": {"pr": 0.4666666666666667, "re": 0.21212121212121213, "f": 0.29166666666666663, "fn": 26.0, "numImages": 1.0, "fp": 8.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.07692307692307693, "f": 0.1, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8571428571428571, "re": 0.5454545454545454, "f": 0.6666666666666665, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 6.0}}, "caption": "The image shows a small bird perched on a branch of a tree. The bird is looking up at the sky with its beak open, as if it is singing. The sky is blue and cloudless, with a few white clouds in the distance. The tree is old and has a lot of moss growing on its trunk."}, "470513": {"image_id": 470513, "Bleu_1": 0.35483870966597303, "Bleu_2": 0.2431867285489846, "Bleu_3": 0.2013016083348928, "Bleu_4": 0.15536508417020944, "METEOR": 0.2621129692288361, "ROUGE_L": 0.39753287559641576, "CIDEr": 0.007787154457886065, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.25, "f": 0.22727272727272727, "fn": 15.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "A person is standing on the beach holding a surfboard while looking out at the ocean. The sun is setting in the background, casting a warm orange glow over the scene."}, "43605": {"image_id": 43605, "Bleu_1": 0.4418604651060033, "Bleu_2": 0.30770827967021536, "Bleu_3": 0.20982223060171984, "Bleu_4": 0.14659903982479197, "METEOR": 0.24867437758475394, "ROUGE_L": 0.33764950084017, "CIDEr": 3.08452558778572e-06, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.2, "f": 0.25806451612903225, "fn": 16.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.42857142857142855, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image shows a man standing in front of a fence, holding a tennis racket and looking up at the sky. He is wearing a green shirt and white pants. The background is a golf course with trees and buildings in the distance."}, "574785": {"image_id": 574785, "Bleu_1": 0.4999999999642858, "Bleu_2": 0.33968311021818254, "Bleu_3": 0.2679161448978716, "Bleu_4": 0.20448007358569298, "METEOR": 0.2547089533431044, "ROUGE_L": 0.42957746478873243, "CIDEr": 0.7679152582142789, "SPICE": {"All": {"pr": 0.6, "re": 0.2, "f": 0.3, "fn": 24.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.07692307692307693, "f": 0.11764705882352941, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.5555555555555556, "f": 0.7142857142857143, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 5.0}}, "caption": "The image shows a small plane flying in the sky with a cloudy background."}, "52368": {"image_id": 52368, "Bleu_1": 0.2758620689560048, "Bleu_2": 0.14037248126379245, "Bleu_3": 9.003265618082171e-07, "Bleu_4": 2.3017423600024167e-09, "METEOR": 0.22446336532789668, "ROUGE_L": 0.2595744680851064, "CIDEr": 0.005728951210918388, "SPICE": {"All": {"pr": 0.2962962962962963, "re": 0.26666666666666666, "f": 0.28070175438596495, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 8.0}, "Relation": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "Sure, here is a short caption for the image:\n\n\"A beautiful outdoor seating area with red umbrellas and white tables surrounded by lush greenery and trees in the background.\""}, "579900": {"image_id": 579900, "Bleu_1": 0.4117647058581315, "Bleu_2": 0.27785946509625026, "Bleu_3": 1.7265786931171227e-06, "Bleu_4": 4.378826865576807e-09, "METEOR": 0.20402640963477667, "ROUGE_L": 0.42707117852975496, "CIDEr": 0.3856158878400665, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.17391304347826086, "f": 0.1951219512195122, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "This is a pizza with various toppings on it. There are slices of pizza on the plate."}, "208867": {"image_id": 208867, "Bleu_1": 0.5624999999648439, "Bleu_2": 0.19364916729786447, "Bleu_3": 1.3887830606267012e-06, "Bleu_4": 3.788697835944244e-09, "METEOR": 0.26700375413474803, "ROUGE_L": 0.4013157894736842, "CIDEr": 0.41911257827652604, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.20689655172413793, "f": 0.23076923076923075, "fn": 23.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.08333333333333333, "f": 0.09523809523809525, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "A small boat is floating on a lake surrounded by palm trees and a blue sky."}, "421535": {"image_id": 421535, "Bleu_1": 0.34782608694896033, "Bleu_2": 0.26375218935251743, "Bleu_3": 0.16801713501101306, "Bleu_4": 0.12187245684565591, "METEOR": 0.20339165995295894, "ROUGE_L": 0.2378476735118274, "CIDEr": 1.9124364323003847e-07, "SPICE": {"All": {"pr": 0.2, "re": 0.08823529411764706, "f": 0.12244897959183675, "fn": 31.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is an image of a group of people skiing through a tunnel in the snow. They are all wearing ski gear and helmets, and one person is holding a ski pole. The tunnel is made of snow and has a large opening at the end."}, "230877": {"image_id": 230877, "Bleu_1": 0.23188405796765385, "Bleu_2": 0.15450054281980155, "Bleu_3": 0.07089164796193918, "Bleu_4": 8.571568896129325e-06, "METEOR": 0.18691851594600978, "ROUGE_L": 0.2047961630695444, "CIDEr": 2.7638456772553825e-21, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.15, "f": 0.15789473684210525, "fn": 17.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "This is an image of a surfer riding a wave on a surfboard. The surfer is wearing a wetsuit and has his arms outstretched as he rides the wave. The wave is large and white, with foamy white water crashing against the shore. The sky is blue and cloudy, with a few clouds visible in the distance. The surfer is standing on the board, balancing himself on the wave."}, "258815": {"image_id": 258815, "Bleu_1": 0.15686274509496353, "Bleu_2": 0.09701425001261196, "Bleu_3": 0.07269451760681336, "Bleu_4": 0.05318827859424478, "METEOR": 0.17920177610424073, "ROUGE_L": 0.2238532110091743, "CIDEr": 2.2860965720016893e-11, "SPICE": {"All": {"pr": 0.125, "re": 0.07692307692307693, "f": 0.09523809523809525, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}}, "caption": "The image shows a young child sitting in a bathtub, being fed a bottle of formula by an adult. The child is smiling and looking up at the adult with a curious expression on their face. The background of the image is a white bathroom with a shower curtain hanging open."}, "157866": {"image_id": 157866, "Bleu_1": 0.255813953482423, "Bleu_2": 0.15608726297943915, "Bleu_3": 0.08407180233076515, "Bleu_4": 1.1040093985513256e-05, "METEOR": 0.2474710023354311, "ROUGE_L": 0.26852531181217903, "CIDEr": 5.7695712012157567e-08, "SPICE": {"All": {"pr": 0.30434782608695654, "re": 0.25925925925925924, "f": 0.27999999999999997, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5555555555555556, "f": 0.5555555555555556, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "This is a kitchen with wooden cabinets and a large island in the center. There is a stove, oven, and refrigerator on the countertops. The floor is made of hardwood and there is a large window above the sink that provides natural light."}, "154057": {"image_id": 154057, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.19711142525707728, "Bleu_3": 0.13733380275681295, "Bleu_4": 0.08759310373578474, "METEOR": 0.27077570048274435, "ROUGE_L": 0.2781758957654723, "CIDEr": 2.202060181916872e-09, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.3333333333333333, "f": 0.2553191489361702, "fn": 12.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.8571428571428571, "f": 0.5714285714285714, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}}, "caption": "This is a black and white image of a cat sitting on the porch of a house. The cat is looking out the window with its ears perked up. There is a light source coming from inside the house, casting a shadow on the cat's fur."}, "132219": {"image_id": 132219, "Bleu_1": 0.41176470587024233, "Bleu_2": 0.2497770842103635, "Bleu_3": 0.15739649855173027, "Bleu_4": 0.10590241811161, "METEOR": 0.19834564592866996, "ROUGE_L": 0.3239757207890743, "CIDEr": 0.0005919994887836967, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.25, "f": 0.1904761904761905, "fn": 12.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "A young girl is sitting on the grass, holding an egg in her hand. She is wearing a pink dress and black shoes. The background is a green field with trees in the distance."}, "147586": {"image_id": 147586, "Bleu_1": 0.9999999999230771, "Bleu_2": 0.8660254037150458, "Bleu_3": 0.6985747127120858, "Bleu_4": 0.5109955810843175, "METEOR": 0.4239092924616945, "ROUGE_L": 0.6062111801242235, "CIDEr": 2.393444398310672, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.12903225806451613, "f": 0.15999999999999998, "fn": 27.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.08333333333333333, "f": 0.11764705882352941, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.25, "f": 0.3157894736842105, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "A plate of doughnuts and a cup of coffee on a wooden table."}, "134691": {"image_id": 134691, "Bleu_1": 0.7142857142517007, "Bleu_2": 0.49999999997559524, "Bleu_3": 0.40369385376370687, "Bleu_4": 0.32359461840727294, "METEOR": 0.376753536242961, "ROUGE_L": 0.5252152521525214, "CIDEr": 0.2575169779368105, "SPICE": {"All": {"pr": 0.4, "re": 0.16, "f": 0.22857142857142856, "fn": 21.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.3333333333333333, "f": 0.47058823529411764, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "This is a bathroom with a toilet, sink, and bathtub. The walls are painted white and there is a wooden floor."}, "181030": {"image_id": 181030, "Bleu_1": 0.26315789472991696, "Bleu_2": 0.11926756082899304, "Bleu_3": 7.33805098169319e-07, "Bleu_4": 1.8330256088670778e-09, "METEOR": 0.2096754014111667, "ROUGE_L": 0.30112834978843445, "CIDEr": 4.5026594014864226e-05, "SPICE": {"All": {"pr": 0.3125, "re": 0.18518518518518517, "f": 0.2325581395348837, "fn": 22.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "This is an image of a tray with food on it. There are two plates with eggs, bacon, and toast on them. There is also a glass of orange juice and a knife and fork on the tray."}, "227230": {"image_id": 227230, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.17720317768650332, "Bleu_3": 0.08936417387415972, "Bleu_4": 1.1350251107826057e-05, "METEOR": 0.16015129889127924, "ROUGE_L": 0.2581620314389359, "CIDEr": 8.138200293649419e-05, "SPICE": {"All": {"pr": 0.24, "re": 0.2, "f": 0.2181818181818182, "fn": 24.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a person on a windsurfing board, riding a wave in the ocean. The person is wearing a wetsuit and a helmet, and has their arms outstretched to balance themselves on the board. The sky is cloudy and there are trees in the background."}, "337502": {"image_id": 337502, "Bleu_1": 0.41666666664930563, "Bleu_2": 0.3561061557907996, "Bleu_3": 0.2585944374776786, "Bleu_4": 0.1693984999796846, "METEOR": 0.2718583532718619, "ROUGE_L": 0.38125000000000003, "CIDEr": 0.0840180407748416, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.0967741935483871, "f": 0.12244897959183673, "fn": 28.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.09090909090909091, "f": 0.14285714285714288, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.18181818181818182, "f": 0.19999999999999998, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "This is a pizza baking in an oven. The pizza has cheese, vegetables, and meat on it. The pizza is cooking in the oven."}, "488151": {"image_id": 488151, "Bleu_1": 0.23728813558919856, "Bleu_2": 0.19188687491125161, "Bleu_3": 0.12467488596111871, "Bleu_4": 0.07669856313414113, "METEOR": 0.24636696141602815, "ROUGE_L": 0.2558993183009963, "CIDEr": 2.0730294433202333e-14, "SPICE": {"All": {"pr": 0.2, "re": 0.10344827586206896, "f": 0.13636363636363635, "fn": 26.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA young boy is flying a kite in a park on a sunny day. The kite has a red and yellow tail and is being held by the boy with one hand while he runs with the other. The background is a green grassy field with trees in the distance."}, "510861": {"image_id": 510861, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.128337789581408, "Bleu_3": 6.952980477333491e-07, "Bleu_4": 1.626739259997693e-09, "METEOR": 0.18440393176225778, "ROUGE_L": 0.24002248454187747, "CIDEr": 5.951053564727974e-10, "SPICE": {"All": {"pr": 0.15, "re": 0.1111111111111111, "f": 0.12765957446808512, "fn": 24.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of people taking a photo with their phones. They are all smiling and looking at the camera. The background is a large room with a stage in the center. There are chairs set up in front of the stage and a podium on the left side."}, "310524": {"image_id": 310524, "Bleu_1": 0.36363636362534446, "Bleu_2": 0.26111648392551057, "Bleu_3": 1.3004758592304072e-06, "Bleu_4": 2.9261488026226463e-09, "METEOR": 0.23043666947869013, "ROUGE_L": 0.3396976929196499, "CIDEr": 0.0008548631183731452, "SPICE": {"All": {"pr": 0.2, "re": 0.21428571428571427, "f": 0.20689655172413796, "fn": 22.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.18181818181818182, "f": 0.19999999999999998, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a park with benches, trees, and a fountain in the center. People are sitting on the benches and walking around the park. There are also some buildings in the background."}, "234889": {"image_id": 234889, "Bleu_1": 0.34285714284734703, "Bleu_2": 0.22454435656302607, "Bleu_3": 0.16611309419673784, "Bleu_4": 0.13009868452696124, "METEOR": 0.29330890482160277, "ROUGE_L": 0.3951417004048583, "CIDEr": 0.0005805588923420842, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.10526315789473684, "f": 0.12903225806451615, "fn": 17.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a train station with a large glass roof and several trains parked on the platform. People are walking around the station and some are standing on the platform looking at the trains."}, "502402": {"image_id": 502402, "Bleu_1": 0.35483870966597303, "Bleu_2": 0.18837162993777626, "Bleu_3": 1.0695743954365786e-06, "Bleu_4": 2.5710986510668226e-09, "METEOR": 0.15983869779490043, "ROUGE_L": 0.2869238005644403, "CIDEr": 0.0005796365430300907, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.2222222222222222, "f": 0.21621621621621623, "fn": 14.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "This is an image of a bus stop with several people standing around it. The bus is parked in front of the stop and there are people standing on the sidewalk."}, "346707": {"image_id": 346707, "Bleu_1": 0.1999999999966667, "Bleu_2": 0.0823386969578779, "Bleu_3": 4.889449842587157e-07, "Bleu_4": 1.1966751775119417e-09, "METEOR": 0.18784050154404197, "ROUGE_L": 0.1852976913730255, "CIDEr": 1.08742555198923e-14, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.17857142857142858, "f": 0.17543859649122806, "fn": 23.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.4166666666666667, "f": 0.3846153846153846, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a bunch of bananas hanging from a tree. The bananas are yellow and ripe, and they are hanging from the branches of the tree. There is a small amount of debris on the ground around the tree, but it is not clear what it is. The sky is cloudy and there are some clouds in the background."}, "58754": {"image_id": 58754, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.1447907475849832, "Bleu_3": 0.07387419460030926, "Bleu_4": 9.42924728285967e-06, "METEOR": 0.21771216109902522, "ROUGE_L": 0.21863799283154117, "CIDEr": 7.961230583062246e-12, "SPICE": {"All": {"pr": 0.3, "re": 0.13636363636363635, "f": 0.18749999999999997, "fn": 19.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.3333333333333333, "f": 0.42857142857142855, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A skier jumps off a ramp on a snowy mountain slope. The skier is wearing a helmet and goggles, and has a snowboard strapped to their feet. The background is a mountain range with snow covered peaks and trees. The sky is clear and blue.\""}, "504900": {"image_id": 504900, "Bleu_1": 0.3255813953412656, "Bleu_2": 0.152498570329016, "Bleu_3": 8.277818425483375e-07, "Bleu_4": 1.940536983395307e-09, "METEOR": 0.24516129032258066, "ROUGE_L": 0.3238221632382216, "CIDEr": 4.225288892239689e-06, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.11764705882352941, "f": 0.0909090909090909, "fn": 15.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The man is sitting on the bed with his dog, a small white and brown dog with a collar on. The man is holding the dog's leash and petting it. The room is dimly lit and there are curtains on the windows."}, "150013": {"image_id": 150013, "Bleu_1": 0.26229508196291323, "Bleu_2": 0.18700983288178252, "Bleu_3": 0.12115259172487226, "Bleu_4": 0.07441192393197212, "METEOR": 0.21636750150673437, "ROUGE_L": 0.22438255386232267, "CIDEr": 2.0989678163625697e-15, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.16, "f": 0.14545454545454545, "fn": 21.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a bench sitting on top of a snow covered beach with the sun shining in the background. The sky is clear and blue, with some clouds in the distance. The water is calm and there are no waves or boats in sight. The beach is covered in snow and there are some rocks and trees in the foreground."}, "363853": {"image_id": 363853, "Bleu_1": 0.4999999999166667, "Bleu_2": 0.21320071631926954, "Bleu_3": 1.656503812070342e-06, "Bleu_4": 4.7406042590263856e-09, "METEOR": 0.21052631578947367, "ROUGE_L": 0.4149659863945578, "CIDEr": 0.5885895219693478, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.23809523809523808, "f": 0.23809523809523808, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The cat is sitting on the couch and looking at the camera."}, "278636": {"image_id": 278636, "Bleu_1": 0.19298245613696527, "Bleu_2": 0.11740724488886634, "Bleu_3": 0.06304863686903067, "Bleu_4": 8.253883526780069e-06, "METEOR": 0.18543827276889552, "ROUGE_L": 0.17438536306460833, "CIDEr": 1.4093361494404192e-14, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.1875, "f": 0.24000000000000005, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Relation": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image shows a group of young men playing soccer in an indoor court. They are wearing orange shirts and black shorts, and one of them is kicking the ball with his left foot while another one watches from the side. The walls of the court are made of concrete and there are windows on the sides."}, "126995": {"image_id": 126995, "Bleu_1": 0.3499999999941667, "Bleu_2": 0.20377787840542863, "Bleu_3": 0.08945995863925049, "Bleu_4": 1.0586509848341131e-05, "METEOR": 0.237094128746042, "ROUGE_L": 0.22736954206602766, "CIDEr": 1.7824676663126713e-11, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.23076923076923078, "f": 0.25531914893617025, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a man playing tennis on a court. He is wearing white shorts and a white shirt with a black stripe on the sleeves. He is holding a tennis racket in his right hand and is about to hit the ball with his left hand. The net is in the background and there are trees in the distance."}, "100489": {"image_id": 100489, "Bleu_1": 0.45161290321123837, "Bleu_2": 0.36808133742266175, "Bleu_3": 0.24110355711685125, "Bleu_4": 0.14957644445271168, "METEOR": 0.25911150558839646, "ROUGE_L": 0.4043082021541011, "CIDEr": 0.008001801206256518, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.13636363636363635, "f": 0.1935483870967742, "fn": 19.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "This is an image of a bird perched on a branch with leaves in the background. The bird has a blue and white plumage and is looking up at the sky."}, "120475": {"image_id": 120475, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.16803361008003348, "Bleu_3": 8.321444966006323e-07, "Bleu_4": 1.8613958856826033e-09, "METEOR": 0.21273107290998255, "ROUGE_L": 0.2238532110091743, "CIDEr": 5.5380839630748217e-11, "SPICE": {"All": {"pr": 0.08, "re": 0.11764705882352941, "f": 0.09523809523809526, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.4, "f": 0.25000000000000006, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a plate with several types of cookies and a glass of milk on it. There are also some other food items on the plate, such as a sandwich and some fruit. The plate is on a table in front of a window with a view of the outside."}, "409099": {"image_id": 409099, "Bleu_1": 0.704559797022037, "Bleu_2": 0.5557642628184211, "Bleu_3": 0.3961658316427748, "Bleu_4": 0.25890239777874136, "METEOR": 0.3676429755295639, "ROUGE_L": 0.6896984924623116, "CIDEr": 1.4865381969136402, "SPICE": {"All": {"pr": 0.5555555555555556, "re": 0.17857142857142858, "f": 0.2702702702702703, "fn": 23.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}, "Relation": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.3333333333333333, "f": 0.46153846153846156, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "A cake sits on a plate next to a bowl of fruit on a wooden table."}, "67868": {"image_id": 67868, "Bleu_1": 0.4999999999821429, "Bleu_2": 0.4082482904490128, "Bleu_3": 0.3375531905770685, "Bleu_4": 0.29615165358996703, "METEOR": 0.4295279860747683, "ROUGE_L": 0.5388692579505301, "CIDEr": 0.025314136094598774, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.08695652173913043, "f": 0.08695652173913043, "fn": 21.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a red bench sitting in the middle of a flooded field. The water is up to the bench and there are trees in the background."}, "310177": {"image_id": 310177, "Bleu_1": 0.4999999999821429, "Bleu_2": 0.3849001794457496, "Bleu_3": 0.2835269135114829, "Bleu_4": 0.20664181815755847, "METEOR": 0.2800511502146538, "ROUGE_L": 0.49193548387096775, "CIDEr": 0.1858941168962447, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.25, "f": 0.22857142857142856, "fn": 12.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6, "f": 0.42857142857142855, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a plate with a slice of cheese, a slice of ham, and a glass of milk on it. The plate is on a green tablecloth."}, "312724": {"image_id": 312724, "Bleu_1": 0.6923076922011837, "Bleu_2": 0.5370861554452248, "Bleu_3": 0.37431888790603457, "Bleu_4": 4.7855439203054915e-05, "METEOR": 0.22123645300744627, "ROUGE_L": 0.548420241459029, "CIDEr": 0.5914907208359889, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.22727272727272727, "f": 0.22727272727272727, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "A herd of zebras grazes in a grassy field surrounded by tall trees."}, "128180": {"image_id": 128180, "Bleu_1": 0.42222222221283956, "Bleu_2": 0.32489314481966364, "Bleu_3": 0.258049819772092, "Bleu_4": 0.20113161707412777, "METEOR": 0.332950804546501, "ROUGE_L": 0.358612580834803, "CIDEr": 4.86741990354383e-06, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.03225806451612903, "f": 0.046511627906976744, "fn": 30.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.08333333333333333, "f": 0.11764705882352941, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}}, "caption": "This is an image of a plate with a slice of pizza on it. The pizza has cheese, tomato sauce, and pepperoni on it. There is also a fork and knife on the plate. The image is taken from above, looking down at the plate."}, "9668": {"image_id": 9668, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.18666334823214084, "Bleu_3": 0.13773990809586936, "Bleu_4": 0.09047502044032775, "METEOR": 0.20207233545690784, "ROUGE_L": 0.2279521674140508, "CIDEr": 2.2028217313945612e-07, "SPICE": {"All": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 12.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.7142857142857143, "f": 0.5555555555555556, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "This image shows a kitchen with wooden cabinets, a stainless steel refrigerator, and a white sink. There is also a microwave oven on the countertop. The floor is made of hardwood and there is a window to the left of the sink."}, "184700": {"image_id": 184700, "Bleu_1": 0.34146341462581803, "Bleu_2": 0.2613286875248416, "Bleu_3": 0.20610721293670228, "Bleu_4": 0.12320376900697154, "METEOR": 0.2944628039056893, "ROUGE_L": 0.32520944402132523, "CIDEr": 1.0029038311703915e-06, "SPICE": {"All": {"pr": 0.45454545454545453, "re": 0.2777777777777778, "f": 0.3448275862068966, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.2857142857142857, "f": 0.4444444444444445, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.6, "re": 0.6, "f": 0.6, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This is a bathroom with a white sink, toilet, and shower. The walls are painted white and the floor is tiled in black and white. There is a large window on one side of the room that lets in natural light."}, "446909": {"image_id": 446909, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.21470745394187096, "Bleu_3": 0.17112053874527608, "Bleu_4": 0.1351928705097216, "METEOR": 0.3431156809363808, "ROUGE_L": 0.35192307692307695, "CIDEr": 4.195424842431468e-09, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.07142857142857142, "f": 0.09302325581395349, "fn": 26.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.16666666666666666, "f": 0.2105263157894737, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a man sitting on a bench in a park. He is wearing a blue shirt and jeans, and has his arms crossed over his chest. The bench is made of wood and has a green seat cushion. In the background, there are trees and grass."}, "49445": {"image_id": 49445, "Bleu_1": 0.23076923076035508, "Bleu_2": 0.13587324409202112, "Bleu_3": 9.162603270374903e-07, "Bleu_4": 2.4048179388862943e-09, "METEOR": 0.08039854897044552, "ROUGE_L": 0.24158415841584158, "CIDEr": 0.000696195918974939, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.28, "f": 0.2857142857142857, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.16666666666666666, "f": 0.2105263157894737, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5555555555555556, "f": 0.5555555555555556, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a red bandana, a watch, a knife, a lighter, a flashlight, a first aid kit, and a water bottle on a wooden surface."}, "398007": {"image_id": 398007, "Bleu_1": 0.3124999999902345, "Bleu_2": 0.20080483221924839, "Bleu_3": 0.13904403212693783, "Bleu_4": 1.744876789010848e-05, "METEOR": 0.22653830476946413, "ROUGE_L": 0.21034482758620687, "CIDEr": 0.0005621595359586483, "SPICE": {"All": {"pr": 0.6666666666666666, "re": 0.26666666666666666, "f": 0.3809523809523809, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}, "Relation": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.6, "f": 0.6666666666666665, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image shows a train station with a large building in the background. There are people standing on the platform and others walking around the area. The sky is clear and blue."}, "335976": {"image_id": 335976, "Bleu_1": 0.36734693876801333, "Bleu_2": 0.27664166758053954, "Bleu_3": 0.18675222022958107, "Bleu_4": 0.10908370302144318, "METEOR": 0.23403695848648315, "ROUGE_L": 0.3078864353312303, "CIDEr": 9.145096797985437e-10, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.18181818181818182, "f": 0.21621621621621623, "fn": 18.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.375, "f": 0.5454545454545454, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.75, "f": 0.8571428571428571, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}, "Object": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}}, "caption": "This image shows a bowl of broccoli and chicken stir fry with soy sauce and sesame seeds. The broccoli is cooked to a tender, slightly crispy texture and the chicken is cooked through and tender. The dish is served in a white bowl with a spoon on the side."}, "513189": {"image_id": 513189, "Bleu_1": 0.23529411764359862, "Bleu_2": 0.2217339284576717, "Bleu_3": 0.1550113352461657, "Bleu_4": 0.08700500849599996, "METEOR": 0.22897796352283004, "ROUGE_L": 0.23416506717850286, "CIDEr": 1.3963206718006124e-19, "SPICE": {"All": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 35.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}}, "caption": "The image shows a surfer riding a wave on a surfboard in the ocean. The surfer is wearing a wetsuit and standing on the board, balancing on the waves. The sky is clear and blue, with a few clouds scattered across it. The beach is sandy and has some rocks and driftwood on it. The water is choppy and white, with some larger waves breaking on the shore."}, "195211": {"image_id": 195211, "Bleu_1": 0.2205882352908737, "Bleu_2": 0.12830357985477586, "Bleu_3": 0.07930876785254941, "Bleu_4": 0.052633537855042004, "METEOR": 0.24012772342579172, "ROUGE_L": 0.20972495088408644, "CIDEr": 1.590307396916042e-19, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.045454545454545456, "f": 0.06451612903225805, "fn": 21.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}}, "caption": "This is a living room with a wooden floor, a red couch, and a wooden table with chairs. There is a fireplace in the corner of the room with a vase of flowers on top of it. The walls are painted a warm yellow color and there are several paintings on the walls. The room is well lit by large windows that let in plenty of natural light."}, "240185": {"image_id": 240185, "Bleu_1": 0.4285714285510205, "Bleu_2": 0.3872983346018379, "Bleu_3": 0.3404885830458579, "Bleu_4": 0.30603689507726295, "METEOR": 0.29189657108729644, "ROUGE_L": 0.39739413680781754, "CIDEr": 0.2745793087349414, "SPICE": {"All": {"pr": 0.25, "re": 0.19230769230769232, "f": 0.2173913043478261, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.38461538461538464, "f": 0.4347826086956522, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "This is a man wearing a suit and tie, holding a sign that says 5K. He is running in a race."}, "411871": {"image_id": 411871, "Bleu_1": 0.35483870966597303, "Bleu_2": 0.2431867285489846, "Bleu_3": 0.15977319241684967, "Bleu_4": 1.9536125064112438e-05, "METEOR": 0.2385291534799211, "ROUGE_L": 0.41673783091374894, "CIDEr": 0.0019826678774343097, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.13043478260869565, "f": 0.11764705882352941, "fn": 20.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3, "f": 0.24, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "This is a plate of food with a lobster on it. The lobster is cooked and has been cut into pieces. There are also some carrots and potatoes on the plate."}, "256035": {"image_id": 256035, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.1624659147420524, "Bleu_3": 0.10182666119201575, "Bleu_4": 1.2115660853589845e-05, "METEOR": 0.2676904875610459, "ROUGE_L": 0.22536945812807885, "CIDEr": 4.62819304017947e-10, "SPICE": {"All": {"pr": 0.5384615384615384, "re": 0.2916666666666667, "f": 0.3783783783783784, "fn": 17.0, "numImages": 1.0, "fp": 6.0, "tp": 7.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "This is an image of a person skiing down a snowy hill. The person is wearing black and white clothing and has a pair of skis on their feet. They are holding onto the poles and appear to be in mid-stride. The background is a winter landscape with trees and snow-covered hills."}, "562241": {"image_id": 562241, "Bleu_1": 0.2394366197149375, "Bleu_2": 0.14325899215203122, "Bleu_3": 0.08410236902168425, "Bleu_4": 9.67116836131679e-06, "METEOR": 0.17961010154598345, "ROUGE_L": 0.17741153659718853, "CIDEr": 6.719059802868316e-23, "SPICE": {"All": {"pr": 0.15151515151515152, "re": 0.23809523809523808, "f": 0.18518518518518517, "fn": 16.0, "numImages": 1.0, "fp": 28.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.3076923076923077, "re": 0.6666666666666666, "f": 0.42105263157894735, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "This is an image of a person skiing down a snowy slope. The person is wearing a black and white ski suit and has a pair of skis on their feet. They are holding onto the ski poles and appear to be in control of their movements. There are other people in the background, also skiing down the slope. The sky is clear and blue, with some clouds in the distance."}, "275657": {"image_id": 275657, "Bleu_1": 0.4666666666511112, "Bleu_2": 0.2537081316938597, "Bleu_3": 0.13197861940352346, "Bleu_4": 1.7081922403555685e-05, "METEOR": 0.2807696228263456, "ROUGE_L": 0.27477477477477474, "CIDEr": 0.0015225677231378008, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.10526315789473684, "f": 0.11764705882352941, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "There are several plates of food on the table, including pizza, pasta, and salad. A man is sitting at the table with a glass of wine in front of him."}, "310705": {"image_id": 310705, "Bleu_1": 0.4090909090723141, "Bleu_2": 0.3418817293630038, "Bleu_3": 0.25978516538374236, "Bleu_4": 0.2072668558958737, "METEOR": 0.37911431551380603, "ROUGE_L": 0.48855835240274603, "CIDEr": 0.12179254050719063, "SPICE": {"All": {"pr": 0.16, "re": 0.14814814814814814, "f": 0.15384615384615383, "fn": 23.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.1, "re": 0.08333333333333333, "f": 0.0909090909090909, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a man sitting on a couch, wearing a suit and tie, and holding a cell phone to his ear."}, "62170": {"image_id": 62170, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.18994132206127556, "Bleu_3": 0.09289852098623474, "Bleu_4": 1.1618322588062582e-05, "METEOR": 0.20419608932825137, "ROUGE_L": 0.27056139906222276, "CIDEr": 1.0514359416393e-08, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.13793103448275862, "f": 0.1702127659574468, "fn": 25.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a group of elephants standing in a grassy field. One of the elephants is holding a tusk in its mouth, while the other two are grazing on the grass. The sun is setting in the background, casting a warm orange glow over the scene."}, "426777": {"image_id": 426777, "Bleu_1": 0.423076923060651, "Bleu_2": 0.3186510027137757, "Bleu_3": 0.16173590601410584, "Bleu_4": 2.070965553349939e-05, "METEOR": 0.2320702613563446, "ROUGE_L": 0.32515991471215355, "CIDEr": 0.04862961202376433, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.09090909090909091, "f": 0.09090909090909091, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5, "f": 0.5263157894736842, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "This image shows a slice of pizza with broccoli and nuts on top. The pizza is cut into slices and is on a wooden cutting board."}, "176312": {"image_id": 176312, "Bleu_1": 0.4814814814636489, "Bleu_2": 0.3042903097136056, "Bleu_3": 0.2231443166854656, "Bleu_4": 0.17443918989183035, "METEOR": 0.3769543237416115, "ROUGE_L": 0.4556489262371616, "CIDEr": 0.021265799776383452, "SPICE": {"All": {"pr": 0.4117647058823529, "re": 0.28, "f": 0.3333333333333333, "fn": 18.0, "numImages": 1.0, "fp": 10.0, "tp": 7.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "This is a woman standing in front of a sign that reads \"tour stop\" in green letters. She is wearing a black coat and carrying a purse."}, "540694": {"image_id": 540694, "Bleu_1": 0.39583333332508686, "Bleu_2": 0.20520703953870822, "Bleu_3": 0.09709768883661148, "Bleu_4": 1.1942727997804106e-05, "METEOR": 0.21210658032206509, "ROUGE_L": 0.23461538461538461, "CIDEr": 6.419140520352276e-09, "SPICE": {"All": {"pr": 0.45454545454545453, "re": 0.19230769230769232, "f": 0.27027027027027023, "fn": 21.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.8, "re": 0.3333333333333333, "f": 0.47058823529411764, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The giraffe is standing next to a car with its head peeking out of the window. The car has a license plate on it and there are other cars parked in the background. The giraffe is looking at something in the distance, possibly another animal or a person."}, "30478": {"image_id": 30478, "Bleu_1": 0.23809523808956923, "Bleu_2": 0.15240998561606448, "Bleu_3": 0.10511522304355243, "Bleu_4": 0.07387254484889373, "METEOR": 0.16082584910414258, "ROUGE_L": 0.22344322344322343, "CIDEr": 5.147204125012043e-07, "SPICE": {"All": {"pr": 0.3125, "re": 0.19230769230769232, "f": 0.2380952380952381, "fn": 21.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "This is an image of a train in a factory. The train is parked on the tracks and there are people standing around it. The train has green and white stripes on it and it looks like it is made of metal."}, "345139": {"image_id": 345139, "Bleu_1": 0.3174603174552784, "Bleu_2": 0.20239224690306698, "Bleu_3": 0.12629700576227398, "Bleu_4": 0.09052415449788018, "METEOR": 0.270138838882021, "ROUGE_L": 0.27566171723692706, "CIDEr": 2.6036463061877225e-16, "SPICE": {"All": {"pr": 0.125, "re": 0.23809523809523808, "f": 0.16393442622950818, "fn": 16.0, "numImages": 1.0, "fp": 35.0, "tp": 5.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.1111111111111111, "f": 0.09999999999999999, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.4444444444444444, "f": 0.2962962962962963, "fn": 5.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}}, "caption": "The man is wearing a green shirt and black pants, and he is holding a beer in his hand. He is sitting at a table with several other people, all of whom are also holding beers. There are several beer glasses on the table, as well as a sign that reads \"Guinness Beer\". The man is smiling and appears to be enjoying himself."}, "299688": {"image_id": 299688, "Bleu_1": 0.46153846146745575, "Bleu_2": 0.27735009806905647, "Bleu_3": 0.1912293963503063, "Bleu_4": 2.8917849327562545e-05, "METEOR": 0.15060573257844018, "ROUGE_L": 0.33841886269070737, "CIDEr": 0.5072575475887333, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.2608695652173913, "f": 0.19672131147540983, "fn": 17.0, "numImages": 1.0, "fp": 32.0, "tp": 6.0}, "Relation": {"pr": 0.07142857142857142, "re": 0.16666666666666666, "f": 0.1, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2631578947368421, "re": 0.5, "f": 0.3448275862068966, "fn": 5.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}}, "caption": "A dog and a cat are playing with a ball on the floor."}, "337446": {"image_id": 337446, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.18210783976741574, "Bleu_3": 0.11216649288903491, "Bleu_4": 0.07442312429536306, "METEOR": 0.18080415605251068, "ROUGE_L": 0.26940063091482647, "CIDEr": 2.2544088957441597e-10, "SPICE": {"All": {"pr": 0.04, "re": 0.058823529411764705, "f": 0.04761904761904763, "fn": 16.0, "numImages": 1.0, "fp": 24.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.2, "f": 0.12500000000000003, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "Two horses are running in a field of tall grass. One horse is white with brown spots and the other is brown with white spots. They are running in opposite directions, with their manes flowing in the wind. The background is a green hill with trees in the distance."}, "386589": {"image_id": 386589, "Bleu_1": 0.2181818181778513, "Bleu_2": 0.15569978882944752, "Bleu_3": 0.09707559423882012, "Bleu_4": 0.06476370820324036, "METEOR": 0.21836327406734882, "ROUGE_L": 0.24610951008645532, "CIDEr": 2.785795241541185e-13, "SPICE": {"All": {"pr": 0.28, "re": 0.23333333333333334, "f": 0.2545454545454545, "fn": 23.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.08333333333333333, "f": 0.09523809523809525, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a woman riding a brown horse in a green field. The woman is wearing a black and white outfit and has a helmet on her head. The horse is wearing a saddle and bridle and is running across the field. There are several other horses in the background, grazing in the field."}, "438495": {"image_id": 438495, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.24141120717629194, "Bleu_3": 0.1863906467785316, "Bleu_4": 0.14495567782211874, "METEOR": 0.2828904035327655, "ROUGE_L": 0.34163036714374606, "CIDEr": 1.634105630984678e-08, "SPICE": {"All": {"pr": 0.1388888888888889, "re": 0.25, "f": 0.17857142857142858, "fn": 15.0, "numImages": 1.0, "fp": 31.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.5, "f": 0.3478260869565218, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "This is a kitchen with white cabinets and a white countertop. There is a sink in the corner of the room and a stove on the wall. The floor is made of tiles and there is a window on the wall that looks out onto a balcony."}, "451150": {"image_id": 451150, "Bleu_1": 0.4374999999726563, "Bleu_2": 0.1707825127549637, "Bleu_3": 1.2771823872371912e-06, "Bleu_4": 3.5579828676919253e-09, "METEOR": 0.2429053627661014, "ROUGE_L": 0.2659883720930233, "CIDEr": 0.34280262016910923, "SPICE": {"All": {"pr": 0.5555555555555556, "re": 0.2, "f": 0.29411764705882354, "fn": 20.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.2727272727272727, "f": 0.42857142857142855, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}}, "caption": "The image shows a box filled with different types of donuts, including chocolate, glazed, and sprinkled."}, "308799": {"image_id": 308799, "Bleu_1": 0.4399999999824001, "Bleu_2": 0.33166247902199714, "Bleu_3": 0.26744939109643207, "Bleu_4": 0.20421283703004012, "METEOR": 0.24803941881889519, "ROUGE_L": 0.4182174338883448, "CIDEr": 0.051308257009004946, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.13636363636363635, "f": 0.15384615384615383, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "This image shows a kitchen with black cabinets and a stainless steel oven. There is a wooden floor and a white refrigerator in the corner."}, "218874": {"image_id": 218874, "Bleu_1": 0.2777777777700618, "Bleu_2": 0.17817416126992966, "Bleu_3": 0.12314407142557375, "Bleu_4": 0.08673245635138281, "METEOR": 0.16949340932715476, "ROUGE_L": 0.2675438596491228, "CIDEr": 0.00017541956308211103, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.08333333333333333, "f": 0.10256410256410255, "fn": 22.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a group of people standing on the shore of a body of water, looking out at a large ship in the distance. The sky is cloudy and there are umbrellas on the ground."}, "197444": {"image_id": 197444, "Bleu_1": 0.36363636362534446, "Bleu_2": 0.3535533905823927, "Bleu_3": 0.30447299999386296, "Bleu_4": 0.24768304255349338, "METEOR": 0.33057029422489065, "ROUGE_L": 0.37162750217580504, "CIDEr": 0.0026241955648745856, "SPICE": {"All": {"pr": 0.25806451612903225, "re": 0.3333333333333333, "f": 0.29090909090909095, "fn": 16.0, "numImages": 1.0, "fp": 23.0, "tp": 8.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.5454545454545454, "f": 0.4999999999999999, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image shows a white plate topped with a slice of cake, a scoop of ice cream, and a sprinkle of red berries. There is also a glass of wine on the table."}, "98683": {"image_id": 98683, "Bleu_1": 0.2545454545408265, "Bleu_2": 0.16817499303341832, "Bleu_3": 0.10219406022809462, "Bleu_4": 1.1969290421672298e-05, "METEOR": 0.2533066865533301, "ROUGE_L": 0.28126801152737757, "CIDEr": 2.781652720107534e-13, "SPICE": {"All": {"pr": 0.0625, "re": 0.041666666666666664, "f": 0.05, "fn": 23.0, "numImages": 1.0, "fp": 15.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image shows a group of people playing with kites in a green field on a sunny day. The kites are flying high in the sky, with their tails streaming behind them. The people are standing on the grass, watching the kites fly. In the background, there is a blue sky with fluffy white clouds."}, "539768": {"image_id": 539768, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.07754322001996182, "Bleu_3": 5.112402630440968e-07, "Bleu_4": 1.3200963130423504e-09, "METEOR": 0.1306827166356257, "ROUGE_L": 0.18769230769230769, "CIDEr": 7.710108403224579e-09, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.17391304347826086, "f": 0.2105263157894737, "fn": 19.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "This is an image of a street with a lamppost on the corner. The street is lined with tall buildings on either side, and there are cars parked along the side of the road. The sky is clear and blue, with a few clouds scattered across it."}, "201301": {"image_id": 201301, "Bleu_1": 0.47826086954442354, "Bleu_2": 0.39009474878540096, "Bleu_3": 0.2790920009871206, "Bleu_4": 0.21592878550037442, "METEOR": 0.304886887906666, "ROUGE_L": 0.47490615876546644, "CIDEr": 0.25531286121644947, "SPICE": {"All": {"pr": 0.20588235294117646, "re": 0.28, "f": 0.23728813559322035, "fn": 18.0, "numImages": 1.0, "fp": 27.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}}, "caption": "The image shows a person holding a hamburger in their hand while sitting at a table with a laptop and other food items."}, "211260": {"image_id": 211260, "Bleu_1": 0.33333333332407417, "Bleu_2": 0.23904572186014378, "Bleu_3": 0.14979742339353158, "Bleu_4": 0.10046152640266261, "METEOR": 0.30632716748013367, "ROUGE_L": 0.4121621621621622, "CIDEr": 0.0005039798046675616, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.1875, "f": 0.21818181818181817, "fn": 26.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 12.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is a bedroom with a desk, chair, and laptop on it. There are also some speakers and a lamp on the desk. The walls are painted blue and there is a window in the background."}, "32812": {"image_id": 32812, "Bleu_1": 0.47499999998812503, "Bleu_2": 0.24677405839016386, "Bleu_3": 0.11702315519115573, "Bleu_4": 1.4426248920984584e-05, "METEOR": 0.22446336532789668, "ROUGE_L": 0.2691176470588235, "CIDEr": 4.296210434336604e-06, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.19047619047619047, "f": 0.2222222222222222, "fn": 17.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "This image shows a woman playing tennis on a blue court. She is wearing a black and white striped shirt and shorts, and has a yellow racket in her hand. She is running towards the net to hit the ball."}, "16838": {"image_id": 16838, "Bleu_1": 0.30434782607372407, "Bleu_2": 0.11761799221901122, "Bleu_3": 8.70113839085501e-07, "Bleu_4": 2.395656561164293e-09, "METEOR": 0.1451403887688985, "ROUGE_L": 0.25128733264675596, "CIDEr": 0.04926489902988159, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.36363636363636365, "f": 0.2352941176470588, "fn": 7.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.1, "re": 0.3333333333333333, "f": 0.15384615384615383, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6, "f": 0.42857142857142855, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is an image of a toy car with a clock on the dashboard. The clock is displaying the time in red numbers."}, "219771": {"image_id": 219771, "Bleu_1": 0.5666666666477778, "Bleu_2": 0.39537556711291433, "Bleu_3": 0.2558552265290319, "Bleu_4": 0.1578173616659044, "METEOR": 0.2666248507600702, "ROUGE_L": 0.4377990430622009, "CIDEr": 0.008342834711757521, "SPICE": {"All": {"pr": 0.1875, "re": 0.13636363636363635, "f": 0.15789473684210525, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The man is sitting at a table in a large room with a lot of windows. He is holding a hot dog in his hand and looking at the camera."}, "151432": {"image_id": 151432, "Bleu_1": 0.19999999999714288, "Bleu_2": 0.12038585308403696, "Bleu_3": 0.07525880719348353, "Bleu_4": 0.050222612165161905, "METEOR": 0.16561489851586308, "ROUGE_L": 0.2006578947368421, "CIDEr": 8.755006069333017e-22, "SPICE": {"All": {"pr": 0.25, "re": 0.15151515151515152, "f": 0.18867924528301888, "fn": 28.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3076923076923077, "f": 0.33333333333333337, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a small bird standing on the beach at sunset. The bird is looking out to sea, with its head tilted back and its beak pointing upwards. The sky is orange and pink, with clouds in the distance. The waves are crashing against the shore, and there are some rocks in the foreground. The bird is standing on a small patch of sand that is covered in foam."}, "5934": {"image_id": 5934, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.20304239863369572, "Bleu_3": 0.09938207498160095, "Bleu_4": 1.2438988916952376e-05, "METEOR": 0.285281738664667, "ROUGE_L": 0.2924657534246575, "CIDEr": 7.4740369234982e-08, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.14285714285714285, "f": 0.18867924528301885, "fn": 30.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a baseball glove sitting on top of a bench. The glove is made of leather and has a white stitching pattern on the palm. The fingers are open and the thumb is closed. There is a baseball sitting inside the glove."}, "271471": {"image_id": 271471, "Bleu_1": 0.7999999998400004, "Bleu_2": 0.6666666665296299, "Bleu_3": 0.5503212080324162, "Bleu_4": 0.3928146508141954, "METEOR": 0.3715208482395866, "ROUGE_L": 0.6, "CIDEr": 2.653212034468198, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.12121212121212122, "f": 0.15384615384615385, "fn": 29.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.08333333333333333, "f": 0.11764705882352941, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.2727272727272727, "f": 0.28571428571428564, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "A plate of bananas on a counter in a restaurant."}, "473754": {"image_id": 473754, "Bleu_1": 0.387755102032903, "Bleu_2": 0.25421614885264626, "Bleu_3": 0.17651819096861232, "Bleu_4": 0.12435410952935055, "METEOR": 0.25458091330930344, "ROUGE_L": 0.25221500295333726, "CIDEr": 2.2131558447792452e-08, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 14.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a couple standing on the beach at sunset, holding surfboards. The man is wearing a black shirt and shorts, while the woman is wearing a green bikini top and white shorts. They are standing in front of the ocean, with the sun setting in the background."}, "140043": {"image_id": 140043, "Bleu_1": 0.5217391304120984, "Bleu_2": 0.344350221559779, "Bleu_3": 0.2243557191518718, "Bleu_4": 2.7412292652641044e-05, "METEOR": 0.2819368507624545, "ROUGE_L": 0.4151273575734007, "CIDEr": 0.22733744896607955, "SPICE": {"All": {"pr": 0.3, "re": 0.12, "f": 0.17142857142857143, "fn": 22.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2727272727272727, "f": 0.3529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a plate of food with bacon, eggs, and toast. There are also two glasses of orange juice on the table."}, "283904": {"image_id": 283904, "Bleu_1": 0.2340425531865098, "Bleu_2": 0.15949736033709896, "Bleu_3": 0.10417771493236237, "Bleu_4": 0.0711980257594806, "METEOR": 0.1780432063540921, "ROUGE_L": 0.23843648208469054, "CIDEr": 1.859435853843133e-09, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.09523809523809523, "f": 0.10256410256410256, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a cat standing on the edge of a staircase, looking down at the floor. The cat has a curious expression on its face and its tail is curled up behind it. The background is a white wall with a window on the left side."}, "335851": {"image_id": 335851, "Bleu_1": 0.5999999998800002, "Bleu_2": 0.4472135954080309, "Bleu_3": 2.924017737592869e-06, "Bleu_4": 7.73055175524073e-09, "METEOR": 0.2691657733340005, "ROUGE_L": 0.5313588850174217, "CIDEr": 1.1240345274484307, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.08695652173913043, "f": 0.0784313725490196, "fn": 21.0, "numImages": 1.0, "fp": 26.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "Two horses graze in a green field surrounded by trees."}, "544065": {"image_id": 544065, "Bleu_1": 0.339622641503026, "Bleu_2": 0.16163173752903065, "Bleu_3": 0.08001308872460663, "Bleu_4": 1.006070177716116e-05, "METEOR": 0.22315663020475554, "ROUGE_L": 0.24811156304474144, "CIDEr": 2.315650829803413e-09, "SPICE": {"All": {"pr": 0.21875, "re": 0.4117647058823529, "f": 0.2857142857142857, "fn": 10.0, "numImages": 1.0, "fp": 25.0, "tp": 7.0}, "Relation": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3, "re": 0.6, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a group of children playing soccer on a field. One girl is wearing a yellow shirt and black shorts, while the other is wearing a black shirt and white shorts. They are both holding soccer balls and running towards the goal. There are several other children watching from the sidelines."}, "145567": {"image_id": 145567, "Bleu_1": 0.16513761467738405, "Bleu_2": 0.12969029210057853, "Bleu_3": 0.09806803420044803, "Bleu_4": 0.07187857353566632, "METEOR": 0.15930926122699993, "ROUGE_L": 0.15559098155317694, "CIDEr": 1.1150506949473973e-57, "SPICE": {"All": {"pr": 0.16216216216216217, "re": 0.3333333333333333, "f": 0.2181818181818182, "fn": 12.0, "numImages": 1.0, "fp": 31.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.8571428571428571, "f": 0.5217391304347825, "fn": 1.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}}, "caption": "A dog is swimming in the water next to a sailboat on the shore of a body of water. The dog is looking up at the sailboat with its head tilted to the side. The sailboat is white and has a red sail. The water is clear and calm. The sky is blue and cloudy.\n\nThe image is taken from a low angle, looking down at the dog and sailboat. The camera is positioned on the shore, facing the water. The lighting is natural, with the sun shining down on the scene. The colors are muted, with the green grass and blue water providing a calm and peaceful atmosphere."}, "559388": {"image_id": 559388, "Bleu_1": 0.3636363636280992, "Bleu_2": 0.26010243549896195, "Bleu_3": 0.14769184446990152, "Bleu_4": 0.0941502378538412, "METEOR": 0.2735990777829039, "ROUGE_L": 0.2787206266318538, "CIDEr": 1.123001862726875e-06, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.1875, "f": 0.26086956521739124, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.42857142857142855, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The man is lying on his back on a bed with his laptop on his stomach. He is holding a cat in his arms and another cat is sitting next to him on the bed. The man is smiling and looking at the camera."}, "169361": {"image_id": 169361, "Bleu_1": 0.4193548386961499, "Bleu_2": 0.23646136786155197, "Bleu_3": 0.12446315310421903, "Bleu_4": 1.6199107648103175e-05, "METEOR": 0.20045955641222452, "ROUGE_L": 0.3330300272975432, "CIDEr": 0.0013516992035488202, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "A small dog is standing on the grass, looking up at the camera with its tongue hanging out of its mouth. The dog is wearing a green collar around its neck."}, "549738": {"image_id": 549738, "Bleu_1": 0.22033898304711294, "Bleu_2": 0.16307248659580162, "Bleu_3": 0.11185856975273968, "Bleu_4": 0.07070578360988265, "METEOR": 0.22056470243462453, "ROUGE_L": 0.2625067240451856, "CIDEr": 4.9230758167482044e-15, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.2608695652173913, "f": 0.28571428571428575, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.45454545454545453, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a kite flying in the sky with a rainbow colored tail. The kite is made of lightweight materials and has a long tail that is shaped like a fish. The sky is clear and blue, with a few clouds scattered in the distance. The buildings in the background are made of stone and have steep roofs."}, "545407": {"image_id": 545407, "Bleu_1": 0.27906976743537054, "Bleu_2": 0.2156655464018017, "Bleu_3": 0.1783401917364648, "Bleu_4": 0.15432522609842, "METEOR": 0.24746250804590258, "ROUGE_L": 0.283344392833444, "CIDEr": 6.563067408408563e-07, "SPICE": {"All": {"pr": 0.029411764705882353, "re": 0.038461538461538464, "f": 0.03333333333333333, "fn": 25.0, "numImages": 1.0, "fp": 33.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.06666666666666667, "re": 0.125, "f": 0.08695652173913045, "fn": 7.0, "numImages": 1.0, "fp": 14.0, "tp": 1.0}}, "caption": "This is an image of a plane flying in the sky. It is a blue and white plane with a red tail. The plane is flying low to the ground and appears to be landing. There are no other objects in the image."}, "54204": {"image_id": 54204, "Bleu_1": 0.30952380951644, "Bleu_2": 0.1942853726806771, "Bleu_3": 9.808593569034828e-07, "Bleu_4": 2.217884382453587e-09, "METEOR": 0.22865176012448996, "ROUGE_L": 0.21631205673758863, "CIDEr": 1.632149479941945e-07, "SPICE": {"All": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 18.0, "numImages": 1.0, "fp": 25.0, "tp": 0.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}}, "caption": "This is an image of a horse and carriage on the side of the road. The horse is pulling a cart with some people in it. There are buildings in the background and some cars parked on the side of the road."}, "441323": {"image_id": 441323, "Bleu_1": 0.45454545452479345, "Bleu_2": 0.2548235957069542, "Bleu_3": 1.480754613698758e-06, "Bleu_4": 3.6155462435323534e-09, "METEOR": 0.23509289809642295, "ROUGE_L": 0.2791762013729977, "CIDEr": 0.15407413856894198, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.18181818181818182, "f": 0.16326530612244897, "fn": 18.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.36363636363636365, "f": 0.34782608695652173, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a red and white Chinese New Year's card with an orange and a duck figurine on a table."}, "465489": {"image_id": 465489, "Bleu_1": 0.3333333333247864, "Bleu_2": 0.16222142112654833, "Bleu_3": 0.08926301664901087, "Bleu_4": 1.1855723022764683e-05, "METEOR": 0.2174463480078686, "ROUGE_L": 0.2959112959112959, "CIDEr": 0.00014532084926776679, "SPICE": {"All": {"pr": 0.2, "re": 0.18181818181818182, "f": 0.1904761904761905, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a person standing on top of a snow covered mountain. They are wearing a backpack and have their skis on their feet. The sky is cloudy and there is a lot of snow on the ground."}, "24566": {"image_id": 24566, "Bleu_1": 0.6666666666296297, "Bleu_2": 0.485071250044925, "Bleu_3": 0.3086789594811046, "Bleu_4": 3.742031645854287e-05, "METEOR": 0.25556216691706435, "ROUGE_L": 0.5318883906327853, "CIDEr": 0.5159474935734103, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.07692307692307693, "f": 0.12121212121212123, "fn": 24.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "This is an image of a blue school bus parked in a field with trees in the background."}, "328301": {"image_id": 328301, "Bleu_1": 0.4999999999791667, "Bleu_2": 0.41702882809639563, "Bleu_3": 0.3619819441797855, "Bleu_4": 0.30830129953647895, "METEOR": 0.2218034914863203, "ROUGE_L": 0.43660531697341515, "CIDEr": 0.1766808391517311, "SPICE": {"All": {"pr": 0.375, "re": 0.24, "f": 0.2926829268292683, "fn": 19.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "Sure, here is a short caption for the image:\n\n\"A yellow car parked in front of a building with a boat in the background.\""}, "244181": {"image_id": 244181, "Bleu_1": 0.37777777776938276, "Bleu_2": 0.16049166880688226, "Bleu_3": 0.08429701120201874, "Bleu_4": 1.0928154087524093e-05, "METEOR": 0.17859582683833952, "ROUGE_L": 0.24646464646464644, "CIDEr": 2.490471642034131e-07, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.16129032258064516, "f": 0.20833333333333331, "fn": 26.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.07142857142857142, "f": 0.09090909090909091, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a table with two sandwiches on it. One of the sandwiches is a ham and cheese sandwich, while the other is a meatball sandwich. There are also two beers on the table, one of which is open and the other is closed."}, "43585": {"image_id": 43585, "Bleu_1": 0.36666666665444453, "Bleu_2": 0.2514326764768464, "Bleu_3": 0.16528691241294277, "Bleu_4": 0.11372027709677378, "METEOR": 0.3103990583538577, "ROUGE_L": 0.43963963963963953, "CIDEr": 0.001376518530963791, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.17647058823529413, "f": 0.21428571428571427, "fn": 14.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "A black and white dog is lying on its back with its paws in the air while a brown and white dog is standing on its back, biting its neck."}, "176730": {"image_id": 176730, "Bleu_1": 0.1690140845046618, "Bleu_2": 0.13898163681467207, "Bleu_3": 0.09434719715183576, "Bleu_4": 0.0592815463862682, "METEOR": 0.18483978988695837, "ROUGE_L": 0.22478120681713498, "CIDEr": 3.3784088808771293e-23, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.2222222222222222, "f": 0.2608695652173913, "fn": 21.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.07692307692307693, "f": 0.1, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a group of people standing in a swimming pool, some of them holding surfboards and others watching them. The pool is filled with water and there are several people in the water, including some children. The people in the pool are all wearing swimsuits and some of them are wearing life jackets. The image appears to be taken in a swimming pool at a gym or recreation center."}, "273246": {"image_id": 273246, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.1927248223279925, "Bleu_3": 0.09180747086790693, "Bleu_4": 1.1327499538368697e-05, "METEOR": 0.1660356362532351, "ROUGE_L": 0.2901307966706302, "CIDEr": 7.341815228788975e-09, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 21.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.2727272727272727, "f": 0.39999999999999997, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "A group of people are standing on the beach, looking out at the ocean. One person is holding a kite and another is holding a surfboard. There are several people in the background, walking along the beach. The sky is clear and blue, with a few clouds in the distance."}, "479562": {"image_id": 479562, "Bleu_1": 0.39999999998666674, "Bleu_2": 0.2626128657105405, "Bleu_3": 1.350489842713993e-06, "Bleu_4": 3.0904914793092257e-09, "METEOR": 0.2732017035001245, "ROUGE_L": 0.39757914338919925, "CIDEr": 0.03095999981471602, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.15, "f": 0.1764705882352941, "fn": 17.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The woman is standing outside, smiling and talking on her cell phone. She is wearing a black leather jacket and has long red hair. There are trees in the background."}, "114147": {"image_id": 114147, "Bleu_1": 0.24999999999375005, "Bleu_2": 0.17902871850532517, "Bleu_3": 0.13626814836267256, "Bleu_4": 0.1081441008020043, "METEOR": 0.17751885717255533, "ROUGE_L": 0.2691176470588235, "CIDEr": 1.0169547937010925e-06, "SPICE": {"All": {"pr": 0.2, "re": 0.13636363636363635, "f": 0.16216216216216214, "fn": 19.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "This is an image of a group of people riding motorcycles on the sidewalk. They are wearing helmets and are stopped at a red light. There are other people walking on the sidewalk and cars driving by in the background."}, "236123": {"image_id": 236123, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.14357265694226845, "Bleu_3": 7.887960518628795e-07, "Bleu_4": 1.8600626916589002e-09, "METEOR": 0.19282516777168696, "ROUGE_L": 0.2197406340057637, "CIDEr": 5.6540175490565975e-08, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.14285714285714285, "f": 0.21428571428571427, "fn": 18.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.25, "f": 0.36363636363636365, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "A black bear cub is standing in the middle of a forest, surrounded by trees and debris. The cub is looking up at something in the distance, possibly a bird or other animal. The trees are bare and there is snow on the ground."}, "278853": {"image_id": 278853, "Bleu_1": 0.3255813953412656, "Bleu_2": 0.23294541396842086, "Bleu_3": 0.10979304357192392, "Bleu_4": 1.3487023691913746e-05, "METEOR": 0.20904394397882078, "ROUGE_L": 0.21254355400696864, "CIDEr": 4.0494678012823804e-07, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.2, "f": 0.21276595744680854, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "This is an image of a person snowboarding down a snowy hill. The person is wearing a blue jacket and black pants, and has their arms raised in the air. The background is a mountain range with trees and snow on the ground."}, "353001": {"image_id": 353001, "Bleu_1": 0.333333333325926, "Bleu_2": 0.24618298195313262, "Bleu_3": 0.17797917821554635, "Bleu_4": 0.10763774116165369, "METEOR": 0.28358866761993345, "ROUGE_L": 0.38006230529595014, "CIDEr": 0.00012595691439326812, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.15789473684210525, "f": 0.1276595744680851, "fn": 16.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a group of people walking down a street with pink umbrellas. They are all wearing pink tutus and some of them are holding pink balloons. The street is lined with trees and there are people standing on the sidewalk watching the parade."}, "426542": {"image_id": 426542, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.15971914124669148, "Bleu_3": 0.1027737074612707, "Bleu_4": 0.0696982798311994, "METEOR": 0.2410896901296018, "ROUGE_L": 0.23091482649842268, "CIDEr": 1.071167376903041e-09, "SPICE": {"All": {"pr": 0.16, "re": 0.23529411764705882, "f": 0.19047619047619052, "fn": 13.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.6666666666666666, "f": 0.5333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows two baseball players standing on the field, one holding a bat and the other holding a glove. They are wearing uniforms with the numbers 1 and 2 on them. The background is a green field with a dirt infield and a white fence in the distance."}, "136212": {"image_id": 136212, "Bleu_1": 0.5862068965315101, "Bleu_2": 0.4575583087395897, "Bleu_3": 0.3141929045411871, "Bleu_4": 0.18584631011462543, "METEOR": 0.30271160089422794, "ROUGE_L": 0.3871260199456029, "CIDEr": 0.014012084531341907, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 9.0}, "Relation": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.6666666666666666, "f": 0.6153846153846153, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 8.0}}, "caption": "This image shows a hot dog on a bun with ketchup, mustard, and relish. There is also a cup of soda on the table next to the hot dog."}, "350111": {"image_id": 350111, "Bleu_1": 0.32727272726677686, "Bleu_2": 0.2806917861017441, "Bleu_3": 0.20738544025273947, "Bleu_4": 0.13609443289026635, "METEOR": 0.24992268777557214, "ROUGE_L": 0.3342465753424657, "CIDEr": 1.3222960695282773e-10, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.11904761904761904, "f": 0.15873015873015875, "fn": 37.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.05263157894736842, "f": 0.07407407407407407, "fn": 18.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.1875, "f": 0.23076923076923075, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of people flying kites on a beach with a clear blue sky in the background. The kites are flying high in the air and the people are standing on the sand, watching them. There are some trees and bushes in the foreground, and the ocean is visible in the distance."}, "53909": {"image_id": 53909, "Bleu_1": 0.5999999999200001, "Bleu_2": 0.292770021844827, "Bleu_3": 1.8751526124712048e-06, "Bleu_4": 4.841524712350714e-09, "METEOR": 0.1982859156275115, "ROUGE_L": 0.4535315985130111, "CIDEr": 0.24798185252200763, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.20833333333333334, "f": 0.2, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5555555555555556, "f": 0.5263157894736842, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "A hand is holding a smartphone with an image of a tree on the screen."}, "210299": {"image_id": 210299, "Bleu_1": 0.37209302324716065, "Bleu_2": 0.24902912254001586, "Bleu_3": 0.1446268093427292, "Bleu_4": 0.09325488826505739, "METEOR": 0.31490126102580973, "ROUGE_L": 0.3400696864111499, "CIDEr": 2.242032694608248e-06, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.125, "f": 0.1276595744680851, "fn": 21.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.2727272727272727, "f": 0.28571428571428564, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a young boy riding a bicycle on a concrete floor. The boy is wearing a helmet and has a big smile on his face as he rides the bike. The background is a concrete floor with some graffiti on it."}, "517318": {"image_id": 517318, "Bleu_1": 0.555555555432099, "Bleu_2": 0.5270462765739486, "Bleu_3": 0.49193407328629696, "Bleu_4": 0.44632361367485907, "METEOR": 0.3179771979400107, "ROUGE_L": 0.5213675213675214, "CIDEr": 2.0908463808341233, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.14285714285714285, "f": 0.16326530612244897, "fn": 24.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The woman is feeding a giraffe at the zoo."}, "36962": {"image_id": 36962, "Bleu_1": 0.6153846153372783, "Bleu_2": 0.4529108136215475, "Bleu_3": 0.3341085298955855, "Bleu_4": 0.24712442543084054, "METEOR": 0.3096007068663221, "ROUGE_L": 0.563944530046225, "CIDEr": 1.2285549767157615, "SPICE": {"All": {"pr": 0.12, "re": 0.0967741935483871, "f": 0.10714285714285714, "fn": 28.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 16.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The cat is sitting on top of the television, looking at the camera."}, "161854": {"image_id": 161854, "Bleu_1": 0.3333333333263889, "Bleu_2": 0.2526455763146363, "Bleu_3": 0.1907268589329514, "Bleu_4": 0.11143093224787655, "METEOR": 0.2558465667198252, "ROUGE_L": 0.29901960784313725, "CIDEr": 5.210888956466913e-08, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.08333333333333333, "f": 0.07692307692307691, "fn": 22.0, "numImages": 1.0, "fp": 26.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.07692307692307693, "re": 0.125, "f": 0.09523809523809525, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}}, "caption": "This is a bedroom with a blue wall and a white bed with a blue blanket on it. There is a window on the left side of the room with curtains open. There is also a desk with a lamp on it in the corner of the room."}, "101913": {"image_id": 101913, "Bleu_1": 0.423076923060651, "Bleu_2": 0.34418242031260665, "Bleu_3": 0.3093896579883273, "Bleu_4": 0.2832630234603657, "METEOR": 0.3616098782841653, "ROUGE_L": 0.45101663585951934, "CIDEr": 0.05791368157713986, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.21739130434782608, "f": 0.19230769230769232, "fn": 18.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.16666666666666666, "f": 0.1111111111111111, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A family sits on a bench in front of a train station, watching the train pass by.\""}, "334884": {"image_id": 334884, "Bleu_1": 0.37499999998437505, "Bleu_2": 0.2211629342229303, "Bleu_3": 0.13051707586308403, "Bleu_4": 1.8038302997832295e-05, "METEOR": 0.2260198445678303, "ROUGE_L": 0.38705583756345174, "CIDEr": 0.047482309644442625, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a bowl of vegetable soup with vegetables such as carrots, onions, and beans. There is also a spoon in the bowl."}, "560440": {"image_id": 560440, "Bleu_1": 0.17499999999562504, "Bleu_2": 0.09473309334073553, "Bleu_3": 6.181206892866832e-07, "Bleu_4": 1.5894780290442996e-09, "METEOR": 0.12221581988906717, "ROUGE_L": 0.13455882352941176, "CIDEr": 1.4252758616974293e-06, "SPICE": {"All": {"pr": 0.4444444444444444, "re": 0.11428571428571428, "f": 0.1818181818181818, "fn": 31.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.07142857142857142, "f": 0.11764705882352941, "fn": 13.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.23076923076923078, "f": 0.3157894736842105, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a street with a few trees on either side. There are no cars or people in the image, but there are some buildings in the background. The sky is blue and there are some clouds in it."}, "224222": {"image_id": 224222, "Bleu_1": 0.4594594594470417, "Bleu_2": 0.3195341955041846, "Bleu_3": 0.20607689301911084, "Bleu_4": 0.12666372159972075, "METEOR": 0.22386813167129377, "ROUGE_L": 0.3174721189591078, "CIDEr": 0.028699785771229922, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.13636363636363635, "f": 0.11764705882352941, "fn": 19.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.25, "f": 0.1904761904761905, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a group of people surfing on the ocean. One person is standing on the board, while the others are riding the waves. The sky is blue and there are palm trees in the background."}, "168093": {"image_id": 168093, "Bleu_1": 0.23188405796765385, "Bleu_2": 0.15450054281980155, "Bleu_3": 0.07089164796193918, "Bleu_4": 8.571568896129325e-06, "METEOR": 0.15920993946086937, "ROUGE_L": 0.21212121212121215, "CIDEr": 5.2276569381174325e-20, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.125, "f": 0.17391304347826086, "fn": 28.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.07142857142857142, "f": 0.11111111111111112, "fn": 13.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.23076923076923078, "f": 0.3157894736842105, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "This image shows a surfer riding a wave on a surfboard. The surfer is wearing a wetsuit and a helmet, and is standing on the board with their arms outstretched. The wave is large and white, with a lot of foam on top. The sky is blue and cloudy, with a few clouds visible in the background. The water is choppy and turbulent, with waves crashing against the shore."}, "152398": {"image_id": 152398, "Bleu_1": 0.19565217390879022, "Bleu_2": 0.06593804733812939, "Bleu_3": 4.6231696364506e-07, "Bleu_4": 1.2312259432484024e-09, "METEOR": 0.1938110168013426, "ROUGE_L": 0.2019867549668874, "CIDEr": 9.782301532034713e-09, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.2903225806451613, "f": 0.34615384615384615, "fn": 22.0, "numImages": 1.0, "fp": 12.0, "tp": 9.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5833333333333334, "re": 0.5833333333333334, "f": 0.5833333333333334, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 7.0}}, "caption": "This is a bedroom with a large bed and a red carpet on the floor. There is a green curtain on the window and a white dresser against one wall. The walls are painted a light color and there is a large mirror on one wall."}, "138838": {"image_id": 138838, "Bleu_1": 0.7647058823079586, "Bleu_2": 0.535504160439078, "Bleu_3": 0.38564280352678415, "Bleu_4": 0.2529920735774518, "METEOR": 0.34541838195455254, "ROUGE_L": 0.45963401506996776, "CIDEr": 1.1959639206062531, "SPICE": {"All": {"pr": 0.25, "re": 0.13793103448275862, "f": 0.17777777777777778, "fn": 25.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4444444444444444, "f": 0.5333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "A person is flying a kite on a beach with a clear blue sky in the background."}, "546826": {"image_id": 546826, "Bleu_1": 0.5333333333155555, "Bleu_2": 0.42884501392057667, "Bleu_3": 0.23595230888394805, "Bleu_4": 2.641053704974216e-05, "METEOR": 0.24158290293880086, "ROUGE_L": 0.32972972972972975, "CIDEr": 0.01130597108495562, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.45454545454545453, "f": 0.2631578947368421, "fn": 6.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.18181818181818182, "re": 0.5, "f": 0.26666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.6, "f": 0.33333333333333337, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a red scissors, a green marker, and a white sheet of paper. The scissors are lying on top of the paper, with the marker next to them."}, "373193": {"image_id": 373193, "Bleu_1": 0.36065573769900566, "Bleu_2": 0.20512557795372421, "Bleu_3": 8.934341348564664e-07, "Bleu_4": 1.872577960270234e-09, "METEOR": 0.20862763089446001, "ROUGE_L": 0.24676731922271183, "CIDEr": 1.8205582245439468e-13, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.125, "f": 0.14814814814814814, "fn": 14.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a woman sitting on the steps of a house, looking at a dog that is standing next to her. The woman is wearing a white shirt and jeans, and the dog is a white and brown mixed breed. The image appears to be taken in a residential area with a small yard and a fence surrounding the property."}, "268259": {"image_id": 268259, "Bleu_1": 0.16666666666468255, "Bleu_2": 0.04481107149428543, "Bleu_3": 2.9039263775167824e-07, "Bleu_4": 7.415115950320125e-10, "METEOR": 0.14092614512656843, "ROUGE_L": 0.19056544829740704, "CIDEr": 1.2821863035444545e-31, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.23809523809523808, "f": 0.20408163265306123, "fn": 16.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.14285714285714285, "f": 0.1, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a bicycle chain hanging from the rear wheel of a motorcycle. The chain is made of metal links and has a small sprocket on the end that is attached to the rear wheel. The chain is tightly wound around the wheel and appears to be in good condition. The motorcycle is parked on the side of the road, with its front tire facing the camera. There is a small amount of dirt and debris on the ground next to the motorcycle."}, "109539": {"image_id": 109539, "Bleu_1": 0.18333333333027782, "Bleu_2": 0.12464639250022254, "Bleu_3": 0.08121828408966404, "Bleu_4": 0.05536963281235316, "METEOR": 0.15644768777144832, "ROUGE_L": 0.17058165548098433, "CIDEr": 3.7628892017980414e-13, "SPICE": {"All": {"pr": 0.15, "re": 0.14285714285714285, "f": 0.14634146341463414, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of people standing under umbrellas in a city square. The people are dressed in various colors and styles, and they are all looking down at their feet. The umbrellas are open and provide shade for the people standing under them. The image is taken from a low angle, looking up at the people and umbrellas."}, "358685": {"image_id": 358685, "Bleu_1": 0.26785714285235973, "Bleu_2": 0.15604694598027796, "Bleu_3": 0.11059767924186374, "Bleu_4": 0.07107887461401326, "METEOR": 0.20756744947500458, "ROUGE_L": 0.2426136363636364, "CIDEr": 1.7550820022834423e-13, "SPICE": {"All": {"pr": 0.23333333333333334, "re": 0.2413793103448276, "f": 0.23728813559322037, "fn": 22.0, "numImages": 1.0, "fp": 23.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.6, "f": 0.5217391304347826, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image shows a zebra and its baby standing in a field of tall grass. The zebra has a brown and white striped pattern on its back, while the baby has a brown and white striped pattern on its back as well. They are both looking at each other with their heads tilted to the side."}, "21029": {"image_id": 21029, "Bleu_1": 0.34693877550312374, "Bleu_2": 0.170034010199895, "Bleu_3": 0.08504678729142533, "Bleu_4": 1.0753602435385096e-05, "METEOR": 0.2306048367921274, "ROUGE_L": 0.2576946288473144, "CIDEr": 4.87659839496729e-09, "SPICE": {"All": {"pr": 0.25, "re": 0.16, "f": 0.19512195121951217, "fn": 21.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a group of men playing baseball in a dirt field. One man is swinging a bat while another man is catching the ball. There are several other men standing around the field watching the game. The sky is cloudy and there are trees in the background."}, "367509": {"image_id": 367509, "Bleu_1": 0.25641025640368187, "Bleu_2": 0.08214400967955679, "Bleu_3": 5.670874342019592e-07, "Bleu_4": 1.500243980388443e-09, "METEOR": 0.12991452991452992, "ROUGE_L": 0.22246535375638216, "CIDEr": 1.0691402844817162e-06, "SPICE": {"All": {"pr": 0.08, "re": 0.11764705882352941, "f": 0.09523809523809526, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a group of animals, including a zebra, standing in a grassy area. The zebra is looking at the camera, while the other animals are looking away. The background is a clear blue sky with some clouds."}, "312263": {"image_id": 312263, "Bleu_1": 0.5142857142710204, "Bleu_2": 0.32539568671855057, "Bleu_3": 0.21272096745994748, "Bleu_4": 0.13169528608238576, "METEOR": 0.29225193579521863, "ROUGE_L": 0.3918779396581393, "CIDEr": 0.00577626848403499, "SPICE": {"All": {"pr": 0.25, "re": 0.34782608695652173, "f": 0.2909090909090909, "fn": 15.0, "numImages": 1.0, "fp": 24.0, "tp": 8.0}, "Relation": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.6, "f": 0.5217391304347826, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "This is an image of a tall building with many windows on each floor. The building has a clock on the front facade, and there are people walking on the sidewalk in front of it."}, "264753": {"image_id": 264753, "Bleu_1": 0.15068493150478515, "Bleu_2": 0.11205836704692944, "Bleu_3": 0.08910390561822273, "Bleu_4": 0.06705104400031281, "METEOR": 0.29080453633889547, "ROUGE_L": 0.2270823638901815, "CIDEr": 8.35689760147679e-26, "SPICE": {"All": {"pr": 0.6, "re": 0.10344827586206896, "f": 0.17647058823529413, "fn": 26.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Relation": {"pr": 0.5, "re": 0.1, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.25, "f": 0.36363636363636365, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "This is a black and white photograph of a train station with a large clock tower in the background. The train station has a long platform with several cars parked on it, and there are people standing on the platform waiting for the train to arrive. The clock tower is made of stone and has a large clock face on it. The sky is cloudy and there are some trees in the background."}, "278570": {"image_id": 278570, "Bleu_1": 0.15873015872763924, "Bleu_2": 0.07155646512237036, "Bleu_3": 4.37847264309999e-07, "Bleu_4": 1.0875623584120222e-09, "METEOR": 0.13457872036503554, "ROUGE_L": 0.17304964539007092, "CIDEr": 6.347729741697519e-16, "SPICE": {"All": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 18.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.3333333333333333, "f": 0.46153846153846156, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "This image shows a group of three red lanterns hanging from a wooden pole in the middle of a dirt path. The lanterns are made of metal and have a round shape with a handle on top. They are hung at different heights and are surrounded by trees and bushes. The sky is clear and blue, with some clouds visible in the distance."}, "463452": {"image_id": 463452, "Bleu_1": 0.21794871794592371, "Bleu_2": 0.15960741046037946, "Bleu_3": 0.10018543505768863, "Bleu_4": 0.060511528820104146, "METEOR": 0.2580113502894313, "ROUGE_L": 0.3287143956889915, "CIDEr": 3.888105172630507e-23, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 30.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.25, "f": 0.2727272727272727, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The man in the image is wearing a suit and tie, sitting at a desk with his hands folded in front of him. The background is a dark room with a window on the left side of the image.\n\nThe man in the image is wearing a suit and tie, sitting at a desk with his hands folded in front of him. The background is a dark room with a window on the left side of the image."}, "383046": {"image_id": 383046, "Bleu_1": 0.1935483870936525, "Bleu_2": 0.14903177731519934, "Bleu_3": 0.10355615621127776, "Bleu_4": 0.06586716003364178, "METEOR": 0.20492064570893043, "ROUGE_L": 0.18466195761856707, "CIDEr": 1.5296195272915736e-16, "SPICE": {"All": {"pr": 0.25, "re": 0.19230769230769232, "f": 0.2173913043478261, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is an image of a person snowboarding down a mountain. The person is wearing a red jacket and black pants, and is holding onto the snowboard with both hands. The snowboard is white and has a black stripe running down the middle. The person is standing on top of a large snowbank, and there are trees and mountains in the background."}, "291346": {"image_id": 291346, "Bleu_1": 0.2666666666607408, "Bleu_2": 0.1556997888288053, "Bleu_3": 0.10408285482696128, "Bleu_4": 0.07198169585141746, "METEOR": 0.24131166830188924, "ROUGE_L": 0.25902335456475584, "CIDEr": 1.4091772765908305e-08, "SPICE": {"All": {"pr": 0.24, "re": 0.21428571428571427, "f": 0.2264150943396226, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.45454545454545453, "f": 0.45454545454545453, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a group of men playing baseball on a field. One man is pitching the ball while another is catching it. The other men are standing on the sidelines watching the game. The field is green and there are trees in the background."}, "506540": {"image_id": 506540, "Bleu_1": 0.34210526314889206, "Bleu_2": 0.21501265303422734, "Bleu_3": 0.15676493616836654, "Bleu_4": 0.12180838504699394, "METEOR": 0.27831261349413844, "ROUGE_L": 0.3259541984732824, "CIDEr": 9.267147322173669e-06, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.2222222222222222, "f": 0.22857142857142856, "fn": 14.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The giraffe is standing in the grass, looking at the camera. It has a brown coat with white spots and long legs. The background is a zoo or wildlife park with trees and other animals in the distance."}, "533536": {"image_id": 533536, "Bleu_1": 0.8461538460236689, "Bleu_2": 0.7510676160808549, "Bleu_3": 0.6352994279150247, "Bleu_4": 0.5659119255720565, "METEOR": 0.43532835807932774, "ROUGE_L": 0.725231175693527, "CIDEr": 1.4605700456130384, "SPICE": {"All": {"pr": 0.4, "re": 0.23076923076923078, "f": 0.29268292682926833, "fn": 20.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.2857142857142857, "f": 0.4, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.6666666666666666, "re": 0.36363636363636365, "f": 0.4705882352941177, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "A cat is sitting in front of a television, looking at the screen."}, "168353": {"image_id": 168353, "Bleu_1": 0.9090909090082646, "Bleu_2": 0.6741998623988867, "Bleu_3": 0.46571647513349596, "Bleu_4": 5.9609942726317344e-05, "METEOR": 0.4064279764884334, "ROUGE_L": 0.5763779527559055, "CIDEr": 1.5240688116075969, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.22727272727272727, "f": 0.20833333333333331, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The bride and groom cutting their wedding cake at their reception."}, "241": {"image_id": 241, "Bleu_1": 0.30188679244713423, "Bleu_2": 0.152387863548989, "Bleu_3": 0.07693256188802164, "Bleu_4": 9.768775860825978e-06, "METEOR": 0.15580641336350531, "ROUGE_L": 0.2083096186681844, "CIDEr": 2.9086711971830588e-08, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.3157894736842105, "f": 0.2926829268292683, "fn": 13.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.15384615384615385, "re": 0.2, "f": 0.17391304347826086, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "This is a picture of a group of people sitting around a table with a white sheet on it. There are several people standing around the table, and one person is standing on top of the sheet. The room is filled with furniture and decorations, and there are several windows in the background."}, "182078": {"image_id": 182078, "Bleu_1": 0.29999999999000004, "Bleu_2": 0.17616606584843764, "Bleu_3": 0.10348931048234185, "Bleu_4": 1.4234121841688615e-05, "METEOR": 0.16554722271614686, "ROUGE_L": 0.24497991967871482, "CIDEr": 0.0017368250148896349, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 18.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a water fountain in the middle of a park. There is a bench nearby and some plants growing on the ground. The sky is clear and blue."}, "370337": {"image_id": 370337, "Bleu_1": 0.29411764705017307, "Bleu_2": 0.13351146745465192, "Bleu_3": 8.228027226970989e-07, "Bleu_4": 2.0588815727345863e-09, "METEOR": 0.19203513655927276, "ROUGE_L": 0.20783645655877342, "CIDEr": 0.00047502355741286205, "SPICE": {"All": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 20.0, "numImages": 1.0, "fp": 36.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.36363636363636365, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "This image shows a harbor with several boats docked at the pier. There are buildings in the background, including a large building with windows on the top floor. The sky is clear and blue."}, "26767": {"image_id": 26767, "Bleu_1": 0.2058823529381488, "Bleu_2": 0.12395303423735725, "Bleu_3": 0.061516289159189684, "Bleu_4": 7.735960758934913e-06, "METEOR": 0.16981659991956508, "ROUGE_L": 0.14805825242718448, "CIDEr": 1.0511236948573746e-21, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.20512820512820512, "f": 0.2461538461538462, "fn": 31.0, "numImages": 1.0, "fp": 18.0, "tp": 8.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.0625, "f": 0.08, "fn": 15.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.42857142857142855, "f": 0.4799999999999999, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "This is an image of a street with trees on both sides. There are no cars or people in the image. The street is lined with blue and white signs that read \"private road\" and \"no trespassing\". The trees are tall and green, with branches that stretch out towards the sky. The image is taken from a bird's eye view, looking down on the street and trees."}, "311746": {"image_id": 311746, "Bleu_1": 0.24137931034066593, "Bleu_2": 0.11271279531727188, "Bleu_3": 6.098918146146619e-07, "Bleu_4": 1.4251117838586347e-09, "METEOR": 0.11814210489031617, "ROUGE_L": 0.17192784667418262, "CIDEr": 2.4366456738047416e-14, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.1724137931034483, "f": 0.19230769230769232, "fn": 24.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a hummingbird perched on a pink flower. The bird is looking down and has its beak open as if it is about to take a drink. The flower is a type of rose with bright pink petals and a yellow center. The background is a garden with other flowers and plants growing in the foreground."}, "243569": {"image_id": 243569, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.17149858513911254, "Bleu_3": 0.12166026344082319, "Bleu_4": 0.07826205638192574, "METEOR": 0.2750140125305734, "ROUGE_L": 0.29847094801223245, "CIDEr": 3.933262279651683e-10, "SPICE": {"All": {"pr": 0.1875, "re": 0.17647058823529413, "f": 0.1818181818181818, "fn": 14.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a young woman sitting on a bed in a bedroom. She is using a laptop computer and has a teddy bear sitting next to her. There are several photos on the wall and a lamp on the nightstand. The room is well lit and appears to be tidy."}, "7207": {"image_id": 7207, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.19411635536098795, "Bleu_3": 0.1369612187156522, "Bleu_4": 0.08791866703176521, "METEOR": 0.17010787441702563, "ROUGE_L": 0.29249580436346195, "CIDEr": 0.007133352691757451, "SPICE": {"All": {"pr": 0.0975609756097561, "re": 0.26666666666666666, "f": 0.14285714285714285, "fn": 11.0, "numImages": 1.0, "fp": 37.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.5, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}}, "caption": "The image shows a group of men standing in front of a brick wall, each holding a carrot in their hand. They are all wearing black clothing and have long hair. The background is a dark, dimly lit room with a brick wall in the background."}, "573756": {"image_id": 573756, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.13187609467625871, "Bleu_3": 7.338824344329119e-07, "Bleu_4": 1.741216427287497e-09, "METEOR": 0.19268777476580393, "ROUGE_L": 0.24238410596026488, "CIDEr": 3.464428782632567e-08, "SPICE": {"All": {"pr": 0.4, "re": 0.15384615384615385, "f": 0.2222222222222222, "fn": 22.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.42857142857142855, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows two giraffes standing in a clearing surrounded by trees. They are both brown and have spots on their backs. One of the giraffes is eating leaves from a tree while the other stands nearby. The background is a mixture of green and brown."}, "513098": {"image_id": 513098, "Bleu_1": 0.25396825396422273, "Bleu_2": 0.19200614429185545, "Bleu_3": 0.13421059543538602, "Bleu_4": 1.4167795832880416e-05, "METEOR": 0.24148179398192243, "ROUGE_L": 0.25219638242894055, "CIDEr": 4.457520396266137e-18, "SPICE": {"All": {"pr": 0.375, "re": 0.24, "f": 0.2926829268292683, "fn": 19.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a group of four blue and yellow airplanes flying in formation in the sky. They are all flying in a line, with their wings spread out to the sides. The planes are flying low to the ground, with their engines roaring as they soar through the air. The sky is cloudy and there are some white clouds in the background."}, "132540": {"image_id": 132540, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.1799372899254913, "Bleu_3": 0.11289809419085711, "Bleu_4": 0.07562263205115649, "METEOR": 0.2137205952508036, "ROUGE_L": 0.24416277518345564, "CIDEr": 5.39907231687626e-09, "SPICE": {"All": {"pr": 0.06896551724137931, "re": 0.08695652173913043, "f": 0.07692307692307693, "fn": 21.0, "numImages": 1.0, "fp": 27.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "This is a living room with a couch, coffee table, and television. There are several pieces of artwork on the walls, including a painting of a woman in a black dress and a man in a suit. The room is well lit with lamps and overhead lighting."}, "309933": {"image_id": 309933, "Bleu_1": 0.3333333333247864, "Bleu_2": 0.18731716231147263, "Bleu_3": 9.82466623306346e-07, "Bleu_4": 2.265493021694376e-09, "METEOR": 0.18196955320202174, "ROUGE_L": 0.2347959969207082, "CIDEr": 2.7658132585777855e-05, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.21739130434782608, "f": 0.21739130434782608, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.625, "f": 0.5263157894736842, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "This image shows a kitchen with white cabinets and a stove. There is a microwave oven on the counter and a refrigerator in the background. The walls are painted a light color and there are plants on the windowsills."}, "68409": {"image_id": 68409, "Bleu_1": 0.35483870966597303, "Bleu_2": 0.326269233756791, "Bleu_3": 0.2637797288420401, "Bleu_4": 0.21058230202082015, "METEOR": 0.28476157964297977, "ROUGE_L": 0.37861322929597446, "CIDEr": 0.013791498374851234, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.21052631578947367, "f": 0.2, "fn": 15.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is a black and white photograph of a group of children sitting on a bench, wearing school uniforms. They are all looking at the camera with smiles on their faces."}, "72737": {"image_id": 72737, "Bleu_1": 0.2666666666607408, "Bleu_2": 0.1740776559517855, "Bleu_3": 0.12834519665251867, "Bleu_4": 0.10016820494780898, "METEOR": 0.19528065442549905, "ROUGE_L": 0.25258799171842644, "CIDEr": 9.654008765928723e-09, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.19047619047619047, "f": 0.1702127659574468, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.23076923076923078, "re": 0.375, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This is an image of a skateboarder performing a trick on a skateboard ramp. The skateboarder is wearing a black shirt and black pants, and has his arms extended as he jumps off the ramp. The background is a blurred image of trees and buildings."}, "339426": {"image_id": 339426, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.20084043275925678, "Bleu_3": 0.13804538956739063, "Bleu_4": 1.554938803660991e-05, "METEOR": 0.27078434785700556, "ROUGE_L": 0.28018372703412076, "CIDEr": 2.12072982662808e-08, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.16666666666666666, "f": 0.16, "fn": 20.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "This is an image of a baseball player hitting a ball on a field. The player is wearing a white jersey and black pants, and is holding a bat in his hand. The ball is flying through the air, and there are several people watching from the stands."}, "508101": {"image_id": 508101, "Bleu_1": 0.4210526315678671, "Bleu_2": 0.369537021466776, "Bleu_3": 0.24756607590438398, "Bleu_4": 0.17159666279833158, "METEOR": 0.2820615151342079, "ROUGE_L": 0.3116788321167883, "CIDEr": 0.00011117346928147097, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.16, "f": 0.18604651162790697, "fn": 21.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "A man is standing on a small boat in the ocean, holding a fishing rod. There is a large fish on the end of the line. The sky is cloudy and there are waves crashing against the shore."}, "25005": {"image_id": 25005, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.15182109665359528, "Bleu_3": 0.10007189813274586, "Bleu_4": 0.06869592482301583, "METEOR": 0.24974041028853977, "ROUGE_L": 0.2401574803149606, "CIDEr": 3.4746809581819633e-10, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.1875, "f": 0.23529411764705882, "fn": 26.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.2, "f": 0.30769230769230765, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "This is a man skiing down a snowy hill. He is wearing a black and orange suit with white gloves and goggles. He is holding onto a pair of skis with poles attached to them. The background is a winter landscape with trees and buildings in the distance."}, "345937": {"image_id": 345937, "Bleu_1": 0.34782608694896033, "Bleu_2": 0.24866794885861784, "Bleu_3": 0.17780705124344343, "Bleu_4": 0.12716046862985547, "METEOR": 0.27628308685865355, "ROUGE_L": 0.39109075770191504, "CIDEr": 1.4180837134377044e-06, "SPICE": {"All": {"pr": 0.08, "re": 0.07407407407407407, "f": 0.07692307692307691, "fn": 25.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.18181818181818182, "f": 0.1904761904761905, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "A young boy is standing in front of a fence, looking at a group of sheep grazing in the distance. The fence is made of wooden posts and has a white picket fence around it. The grass is green and there are trees in the background."}, "389419": {"image_id": 389419, "Bleu_1": 0.3999999999800001, "Bleu_2": 0.25131234496212107, "Bleu_3": 1.5195618441138907e-06, "Bleu_4": 3.790325913312514e-09, "METEOR": 0.28366366952196514, "ROUGE_L": 0.37014563106796117, "CIDEr": 0.15258029853544794, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.21052631578947367, "f": 0.23529411764705882, "fn": 15.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The man in the image is wearing a black suit and tie, and is pointing to something on the wall."}, "425964": {"image_id": 425964, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.18857036045053577, "Bleu_3": 0.1278888396607359, "Bleu_4": 0.08042331753470428, "METEOR": 0.23305103227588075, "ROUGE_L": 0.30619074177356387, "CIDEr": 1.9746856396570495e-10, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.16666666666666666, "f": 0.2325581395348837, "fn": 25.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.36363636363636365, "f": 0.4705882352941177, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image shows a man sitting at a table with a plate of food in front of him. He is wearing a gray shirt and jeans, and has a glass of milk in front of him. There are other people sitting at tables nearby, and the atmosphere appears to be casual and relaxed."}, "84866": {"image_id": 84866, "Bleu_1": 0.47368421050138515, "Bleu_2": 0.32444284224397485, "Bleu_3": 0.23135869341855983, "Bleu_4": 0.1667955161284029, "METEOR": 0.2796234279446681, "ROUGE_L": 0.3817271589486859, "CIDEr": 0.22223351555644086, "SPICE": {"All": {"pr": 0.05, "re": 0.06666666666666667, "f": 0.05714285714285715, "fn": 14.0, "numImages": 1.0, "fp": 19.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "Sure, here is a short caption for the image:\n\n\"A group of children playing tennis on a sunny day\""}, "25134": {"image_id": 25134, "Bleu_1": 0.2711864406733697, "Bleu_2": 0.15289912176646533, "Bleu_3": 0.07429821419893698, "Bleu_4": 9.250959395998023e-06, "METEOR": 0.21683274567812905, "ROUGE_L": 0.20760068065796938, "CIDEr": 1.1976313579613927e-12, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.13793103448275862, "f": 0.126984126984127, "fn": 25.0, "numImages": 1.0, "fp": 30.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.4444444444444444, "f": 0.32, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}}, "caption": "This is an image of a bus stop with several buses parked in front of it. The buses are white and have red and blue stripes on them. There are people standing on the sidewalk in front of the bus stop, looking at the buses. The sky is cloudy and there is a lot of fog in the air."}, "250260": {"image_id": 250260, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.24562537538976753, "Bleu_3": 0.18204642481324668, "Bleu_4": 0.13863341114193, "METEOR": 0.32549049410410985, "ROUGE_L": 0.37952488687782804, "CIDEr": 2.872155541396118e-10, "SPICE": {"All": {"pr": 0.2413793103448276, "re": 0.3333333333333333, "f": 0.28, "fn": 14.0, "numImages": 1.0, "fp": 22.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows two trains parked on a train platform. One of the trains is blue and yellow, while the other is blue and white. The trains are parked next to each other on the platform, with their engines facing each other. There are buildings and other structures visible in the background."}, "128699": {"image_id": 128699, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.1288070335219516, "Bleu_3": 6.923138992163507e-07, "Bleu_4": 1.6131630585021e-09, "METEOR": 0.12414860017626615, "ROUGE_L": 0.21580188679245285, "CIDEr": 1.5350283291240897e-11, "SPICE": {"All": {"pr": 0.038461538461538464, "re": 0.03571428571428571, "f": 0.03703703703703704, "fn": 27.0, "numImages": 1.0, "fp": 25.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.08333333333333333, "f": 0.08333333333333333, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "This is an image of a skateboarder jumping over a brick wall. The skateboarder is wearing a black shirt and jeans, and has a backpack on his back. The brick wall is painted with a mural of a city skyline. There are people watching the skateboarder from the side of the road."}, "383066": {"image_id": 383066, "Bleu_1": 0.1969696969667126, "Bleu_2": 0.14564381624866016, "Bleu_3": 0.08719228127993563, "Bleu_4": 0.056953890126771885, "METEOR": 0.19307987298524967, "ROUGE_L": 0.21631205673758866, "CIDEr": 9.521537610069222e-19, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 14.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "This image shows a woman in a blue and white uniform standing behind a counter at a market. She is holding a tray of food and looking at something on her phone. There are other people in the background, including a man in a white shirt and a woman in a red shirt. The image appears to be taken in a busy market or food court."}, "567812": {"image_id": 567812, "Bleu_1": 0.1960784313687044, "Bleu_2": 0.10846522890718008, "Bleu_3": 0.06215293828145826, "Bleu_4": 8.409805259069613e-06, "METEOR": 0.2405750960403015, "ROUGE_L": 0.2893689114781872, "CIDEr": 1.2183589579966034e-10, "SPICE": {"All": {"pr": 0.2, "re": 0.18181818181818182, "f": 0.1904761904761905, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The man is sitting on the bed with his arms around a teddy bear. He is wearing a black shirt and black pants. The teddy bear is sitting on his lap and he is holding it with one hand. The room is dimly lit and there are curtains on the windows."}, "477085": {"image_id": 477085, "Bleu_1": 0.6666666665185187, "Bleu_2": 0.40824829037030635, "Bleu_3": 2.8768479126408824e-06, "Bleu_4": 7.936880924121685e-09, "METEOR": 0.17472946830148467, "ROUGE_L": 0.4911433172302737, "CIDEr": 0.5572993808825601, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.17647058823529413, "f": 0.16666666666666669, "fn": 14.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "A group of sheep graze in a green field."}, "186412": {"image_id": 186412, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.22117152024581002, "Bleu_3": 0.17804731863811085, "Bleu_4": 0.14505210378846464, "METEOR": 0.25695850353507904, "ROUGE_L": 0.3028368794326241, "CIDEr": 5.014800258016376e-09, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.19047619047619047, "f": 0.18604651162790697, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "This image shows a group of people sitting in a garage with chairs and tables around them. There are several tools and equipment on the walls, including a tool bench, a workbench, and a shelf with various tools and supplies. The garage has a large window on one side that lets in natural light."}, "364567": {"image_id": 364567, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.14401064146758893, "Bleu_3": 0.0939614522123186, "Bleu_4": 0.06414506805775248, "METEOR": 0.15044713764482692, "ROUGE_L": 0.18373493975903615, "CIDEr": 7.610032741993882e-12, "SPICE": {"All": {"pr": 0.12, "re": 0.1875, "f": 0.14634146341463414, "fn": 13.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.4, "f": 0.23529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "This is an image of a horse jumping over a barrel in a competition. The horse is wearing a black and white striped saddle and bridle, and the rider is wearing a black and white striped helmet and jacket. The background is a green field with white fences and a blue sky."}, "402823": {"image_id": 402823, "Bleu_1": 0.8181818181074382, "Bleu_2": 0.7006490496784906, "Bleu_3": 0.6020134378481848, "Bleu_4": 0.4832697830390307, "METEOR": 0.32586199822889694, "ROUGE_L": 0.6539050535987749, "CIDEr": 1.9985660389248092, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.19230769230769232, "f": 0.1408450704225352, "fn": 21.0, "numImages": 1.0, "fp": 40.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 18.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.45454545454545453, "f": 0.41666666666666663, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "A woman riding a horse over a jump in a field."}, "375763": {"image_id": 375763, "Bleu_1": 0.5624999999648439, "Bleu_2": 0.433012701864254, "Bleu_3": 0.2992042402742815, "Bleu_4": 0.2130541361810694, "METEOR": 0.2564220811433084, "ROUGE_L": 0.5618421052631578, "CIDEr": 0.8011247920493437, "SPICE": {"All": {"pr": 0.12, "re": 0.15, "f": 0.1333333333333333, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.18181818181818182, "f": 0.18181818181818182, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "A flock of sheep grazing in a green field with a stone wall in the background."}, "328283": {"image_id": 328283, "Bleu_1": 0.27272727272107444, "Bleu_2": 0.21070705493664102, "Bleu_3": 0.10186765009058293, "Bleu_4": 1.2671594061541109e-05, "METEOR": 0.21464967389494805, "ROUGE_L": 0.2506849315068493, "CIDEr": 5.234570809643361e-08, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.2631578947368421, "f": 0.2127659574468085, "fn": 14.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.2, "f": 0.13333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a group of people skiing down a snowy slope. They are all wearing ski gear and helmets, and some of them are carrying skis on their backs. The snow is covered in trees and there are other skiers in the distance."}, "566264": {"image_id": 566264, "Bleu_1": 0.36842105262188374, "Bleu_2": 0.2822385621600037, "Bleu_3": 0.23678843319704615, "Bleu_4": 0.19736418685234536, "METEOR": 0.32367065287609165, "ROUGE_L": 0.3830455259026687, "CIDEr": 8.077064095588997e-05, "SPICE": {"All": {"pr": 0.15151515151515152, "re": 0.2631578947368421, "f": 0.19230769230769232, "fn": 14.0, "numImages": 1.0, "fp": 28.0, "tp": 5.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.1, "f": 0.08695652173913043, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.5, "f": 0.3478260869565218, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image shows a dog swimming in the ocean. The dog is swimming in the water and appears to be enjoying itself. The background of the image is a body of water with waves and a clear sky."}, "145208": {"image_id": 145208, "Bleu_1": 0.3863636363548554, "Bleu_2": 0.23218786590068996, "Bleu_3": 0.15674138067961096, "Bleu_4": 0.09844457464005989, "METEOR": 0.2131718120328228, "ROUGE_L": 0.214185393258427, "CIDEr": 1.5341196248104831e-06, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.10714285714285714, "f": 0.11111111111111112, "fn": 25.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2727272727272727, "f": 0.2608695652173913, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a group of people surfing on a large wave in the ocean. One person is standing on the board, while another person is sitting on the board and paddling. The waves are crashing against the shore and the sky is cloudy."}, "412621": {"image_id": 412621, "Bleu_1": 0.19999999999600004, "Bleu_2": 0.12777531299740644, "Bleu_3": 6.980462899277689e-07, "Bleu_4": 1.6401693914301652e-09, "METEOR": 0.17565642418731053, "ROUGE_L": 0.22732919254658387, "CIDEr": 2.3892030364304676e-10, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.15, "f": 0.16216216216216214, "fn": 17.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a person in a black and white jumpsuit jumping off a bridge into the air. The person is wearing a helmet and has their arms outstretched as they fly through the air. The background is a city skyline with tall buildings and a bridge in the distance."}, "289263": {"image_id": 289263, "Bleu_1": 0.41666666665509267, "Bleu_2": 0.28867513458667965, "Bleu_3": 0.16987257791700947, "Bleu_4": 1.9631974133116808e-05, "METEOR": 0.26225001052206104, "ROUGE_L": 0.33888888888888885, "CIDEr": 0.0001817384836565728, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.14814814814814814, "f": 0.14814814814814814, "fn": 23.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The woman is standing on the beach holding a surfboard. She is wearing a bikini and has her hair tied back in a ponytail. The sky is blue and there are waves crashing on the shore."}, "315491": {"image_id": 315491, "Bleu_1": 0.47826086954442354, "Bleu_2": 0.32969023668323344, "Bleu_3": 0.1729806903297508, "Bleu_4": 2.255489037161007e-05, "METEOR": 0.21302943346104847, "ROUGE_L": 0.4239791485664639, "CIDEr": 0.15996921443134948, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.23076923076923078, "f": 0.10909090909090909, "fn": 10.0, "numImages": 1.0, "fp": 39.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.1875, "re": 0.6, "f": 0.2857142857142857, "fn": 2.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}}, "caption": "The image shows a street with a red traffic light on the corner. The building in the background appears to be a church."}, "509037": {"image_id": 509037, "Bleu_1": 0.31914893616342244, "Bleu_2": 0.2498843395674313, "Bleu_3": 0.17705513173856344, "Bleu_4": 0.12603051731241743, "METEOR": 0.2754659400619546, "ROUGE_L": 0.27180140038192235, "CIDEr": 1.3498777520098114e-08, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.21428571428571427, "f": 0.24489795918367344, "fn": 22.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.5454545454545454, "f": 0.5714285714285713, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "This is an image of a group of people standing under an umbrella on a street at night. The people are dressed in casual clothing and are looking at something on a table in front of them. There are several buildings and cars visible in the background."}, "157019": {"image_id": 157019, "Bleu_1": 0.2666666666607408, "Bleu_2": 0.1740776559517855, "Bleu_3": 0.0889895891077732, "Bleu_4": 1.1381305436598616e-05, "METEOR": 0.2017367689964558, "ROUGE_L": 0.21048999309868874, "CIDEr": 8.052010744859648e-08, "SPICE": {"All": {"pr": 0.16, "re": 0.21052631578947367, "f": 0.1818181818181818, "fn": 15.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.375, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a city street with tall buildings on either side of the road. There are cars parked on the side of the road and pedestrians walking in the rain. The sky is overcast with clouds and there is a light drizzle of rain."}, "352290": {"image_id": 352290, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.25253813613284526, "Bleu_3": 0.18931078775968688, "Bleu_4": 0.1450348525506267, "METEOR": 0.2553781188982025, "ROUGE_L": 0.30329397141081416, "CIDEr": 6.779201119296373e-09, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.25, "f": 0.1904761904761905, "fn": 12.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a brown horse standing in a field with mountains in the background. The horse is looking up at the sky with its ears perked up. The sky is clear and blue with some white clouds. The grass is green and the mountains are covered in snow."}, "293768": {"image_id": 293768, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.16751484856166823, "Bleu_3": 0.10609125460399942, "Bleu_4": 1.2693173928949333e-05, "METEOR": 0.20335521829527547, "ROUGE_L": 0.23303196230739842, "CIDEr": 1.8335301544392163e-10, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.1, "f": 0.1081081081081081, "fn": 18.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.4, "f": 0.3076923076923077, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a young man performing a trick on a skateboard in a park. He is wearing a red hoodie and blue jeans, and has his arms outstretched as he jumps off the ramp. The sky is a bright pink color, and there are trees in the background."}, "14338": {"image_id": 14338, "Bleu_1": 0.11956521739000474, "Bleu_2": 0.0627830428010895, "Bleu_3": 3.5249048929160526e-07, "Bleu_4": 8.375544511813576e-10, "METEOR": 0.16046427081414258, "ROUGE_L": 0.15838278931750743, "CIDEr": 1.763125135216018e-41, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.13793103448275862, "f": 0.17391304347826086, "fn": 25.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a large boat in the middle of the ocean, with a group of people on the deck. The boat is surrounded by water and there are several sailboats in the distance. The sky is clear and blue, with a few clouds scattered about.\n\nThe boat appears to be moving through the water, with the waves crashing against its hull. The people on the deck are waving their arms and cheering as they look out at the water. The overall mood of the image is one of excitement and joy."}, "154230": {"image_id": 154230, "Bleu_1": 0.15238095237950114, "Bleu_2": 0.114833850351544, "Bleu_3": 0.07268999314638758, "Bleu_4": 7.833501447108926e-06, "METEOR": 0.17625835735828438, "ROUGE_L": 0.16153591525984773, "CIDEr": 4.946475934867366e-51, "SPICE": {"All": {"pr": 0.32142857142857145, "re": 0.2727272727272727, "f": 0.2950819672131148, "fn": 24.0, "numImages": 1.0, "fp": 19.0, "tp": 9.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5833333333333334, "f": 0.5384615384615384, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 7.0}}, "caption": "This is a black and white image of a desk with a laptop on it. There is a bookshelf behind the desk with books on it. There is also a chair in front of the desk with a pink cushion on it.\n\nThe desk has a black and white checkered pattern on it. The laptop has a black and white keyboard and a black and white screen. The bookshelf has books with black and white covers. The chair has a black and white cushion on it.\n\nThere is a small white bird sitting on top of the bookshelf. The bird is looking at the camera."}, "219458": {"image_id": 219458, "Bleu_1": 0.18518518518289895, "Bleu_2": 0.12729376930274755, "Bleu_3": 0.07430289455261192, "Bleu_4": 0.04788843546733435, "METEOR": 0.21022452670205252, "ROUGE_L": 0.24646464646464644, "CIDEr": 2.558026161182439e-29, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.13636363636363635, "f": 0.12244897959183673, "fn": 19.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This image shows a woman wearing a black and white striped dress, a black hat with a white feather on it, and a pair of black boots. She is standing in front of a window with a guitar case on the floor next to her. The woman appears to be talking on her phone while holding the guitar case with one hand. The background of the image is a dark room with a window on the left side of the image."}, "495183": {"image_id": 495183, "Bleu_1": 0.2142857142818878, "Bleu_2": 0.10811249552151898, "Bleu_3": 0.07564774850474067, "Bleu_4": 0.05345988714531165, "METEOR": 0.28267998236923336, "ROUGE_L": 0.21682464454976302, "CIDEr": 2.363791953244674e-14, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.2777777777777778, "f": 0.2777777777777778, "fn": 13.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.7142857142857143, "f": 0.588235294117647, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a woman riding a bicycle down a street with trees on either side. She is wearing a blue shirt and jeans, and has a helmet on her head. The bicycle has a basket on the front and a bell on the handlebars. The road is paved and there are no cars in sight."}, "58772": {"image_id": 58772, "Bleu_1": 0.2727272727190084, "Bleu_2": 0.09231861823165838, "Bleu_3": 6.502379296152039e-07, "Bleu_4": 1.7398984878177725e-09, "METEOR": 0.2284829157132408, "ROUGE_L": 0.21922731356693623, "CIDEr": 0.00035695146237400214, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 21.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.75, "re": 0.17647058823529413, "f": 0.2857142857142857, "fn": 14.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 0.2857142857142857, "f": 0.4, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a group of blue umbrellas lined up against a fence in a park. There are several trees and plants visible in the background, and the sky is clear and blue."}, "104486": {"image_id": 104486, "Bleu_1": 0.19230769230522685, "Bleu_2": 0.12241329578370261, "Bleu_3": 0.058203334066895686, "Bleu_4": 7.160536807055184e-06, "METEOR": 0.1493447120665123, "ROUGE_L": 0.18484848484848485, "CIDEr": 4.885667900446807e-24, "SPICE": {"All": {"pr": 0.1875, "re": 0.15, "f": 0.16666666666666663, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "This image shows a man carrying luggage through a hotel lobby. The man is wearing a suit and tie, and he is holding onto the handle of a large suitcase. There are other people in the background, some of whom are also carrying luggage. The door to the hotel is visible in the background, and there are windows on either side of it. The overall mood of the image is one of busy travelers arriving at a hotel."}, "190326": {"image_id": 190326, "Bleu_1": 0.27586206896076104, "Bleu_2": 0.19676758717389048, "Bleu_3": 0.1114079961993771, "Bleu_4": 0.07081032698954458, "METEOR": 0.23953658053580534, "ROUGE_L": 0.27001770607908715, "CIDEr": 5.185880965091629e-11, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.22727272727272727, "f": 0.25641025641025644, "fn": 17.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a cat sitting on the back of a motorcycle parked on the side of a narrow street lined with buildings. The cat is looking out of the side window of the motorcycle, while the driver is sitting in the front seat. The street is lined with parked cars and there are buildings in the background."}, "113828": {"image_id": 113828, "Bleu_1": 0.25396825396422273, "Bleu_2": 0.2122707793529746, "Bleu_3": 0.17292171917822072, "Bleu_4": 0.12680303825254177, "METEOR": 0.23218415257694724, "ROUGE_L": 0.24910668708524755, "CIDEr": 6.081361503974573e-17, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.17647058823529413, "f": 0.15, "fn": 14.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "Here is a short caption for the image:\n\n\"A group of red double decker buses are parked on the side of a city street. They are lined up in a row, with one in the front and the others behind it. The buses are old and have a vintage look to them. There are people walking down the street, looking at the buses.\""}, "148392": {"image_id": 148392, "Bleu_1": 0.24691358024386525, "Bleu_2": 0.1571348402617252, "Bleu_3": 0.09787678904295824, "Bleu_4": 1.0470951171416263e-05, "METEOR": 0.21090596102014544, "ROUGE_L": 0.17464212678936603, "CIDEr": 9.892147641000666e-29, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.2222222222222222, "f": 0.16666666666666669, "fn": 14.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.3, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "This image shows a tree that has been cut down and lying on the ground. There is a fire hydrant nearby, and a person in a yellow safety vest is standing next to the tree, looking at it. The tree appears to have been cut down by a chainsaw, and there are branches and leaves scattered around it. The person in the yellow safety vest is likely a park ranger or arborist who is assessing the damage caused by the storm."}, "221155": {"image_id": 221155, "Bleu_1": 0.3333333333247864, "Bleu_2": 0.1324532357030635, "Bleu_3": 7.797842756800693e-07, "Bleu_4": 1.905044960725107e-09, "METEOR": 0.15032084867385398, "ROUGE_L": 0.216773276474769, "CIDEr": 6.5595732655067025e-06, "SPICE": {"All": {"pr": 0.2, "re": 0.07407407407407407, "f": 0.10810810810810811, "fn": 25.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.16666666666666666, "f": 0.23529411764705882, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "This is an image of a small farm with several animals in the yard. There is a windmill in the background and a small house in the distance. The sky is cloudy and there are trees in the background."}, "469877": {"image_id": 469877, "Bleu_1": 0.1641791044751615, "Bleu_2": 0.07053456158479911, "Bleu_3": 4.245839065667784e-07, "Bleu_4": 1.0457494696030862e-09, "METEOR": 0.14468328858428847, "ROUGE_L": 0.17370669197911723, "CIDEr": 2.3663652495459285e-18, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.2857142857142857, "f": 0.24000000000000002, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.3333333333333333, "f": 0.18181818181818182, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.4166666666666667, "f": 0.3846153846153846, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a trash can on the side of a street with graffiti on the wall. The trash can is painted with the words \"stop\" and \"all ways\" in bold, colorful letters. The graffiti on the wall is also colorful and includes various tags and symbols. The image is taken from a high angle, looking down at the trash can and the graffiti on the wall."}, "494456": {"image_id": 494456, "Bleu_1": 0.5789473683905818, "Bleu_2": 0.4744957310725266, "Bleu_3": 0.29809079441887354, "Bleu_4": 3.587000421109487e-05, "METEOR": 0.30428811177584986, "ROUGE_L": 0.511377245508982, "CIDEr": 0.3318000140199762, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.16, "f": 0.18604651162790697, "fn": 21.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "Here is a short caption for the image:\n\n\"Two men standing on skis in front of a mountain range\""}, "553248": {"image_id": 553248, "Bleu_1": 0.3571428571343538, "Bleu_2": 0.26398183866786545, "Bleu_3": 0.19100703641258254, "Bleu_4": 0.13749229838123656, "METEOR": 0.3203708707485022, "ROUGE_L": 0.3551673944687045, "CIDEr": 2.3103426276237346e-06, "SPICE": {"All": {"pr": 0.30434782608695654, "re": 0.25925925925925924, "f": 0.27999999999999997, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a person holding a slice of pizza in their hand. The pizza appears to be topped with cheese, pepperoni, and other toppings. The person is wearing a white shirt and has a box of pizza slices next to them."}, "300233": {"image_id": 300233, "Bleu_1": 0.6666666666111113, "Bleu_2": 0.3481553118810641, "Bleu_3": 2.2971111883989787e-06, "Bleu_4": 6.057952803035667e-09, "METEOR": 0.16169603476850677, "ROUGE_L": 0.2932692307692307, "CIDEr": 0.41164517219722335, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.1, "f": 0.09523809523809525, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "Image of a kitchen with various ingredients and spices on the countertop."}, "316359": {"image_id": 316359, "Bleu_1": 0.19047619047316708, "Bleu_2": 0.09600307214592775, "Bleu_3": 5.326151009485259e-07, "Bleu_4": 1.2597149807623247e-09, "METEOR": 0.17764920651723293, "ROUGE_L": 0.19645732689210949, "CIDEr": 1.6217138094279598e-17, "SPICE": {"All": {"pr": 0.15151515151515152, "re": 0.21739130434782608, "f": 0.17857142857142858, "fn": 18.0, "numImages": 1.0, "fp": 28.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.16666666666666666, "f": 0.11764705882352942, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "Sure! Here is a short caption for the image:\n\nThis giraffe is lying down on the grass, looking up at the camera with its long neck stretched out. Its spots are visible on its brown fur, and its long eyelashes are visible as it blinks. The giraffe's long tongue can be seen hanging out of its mouth as it paws the ground."}, "389410": {"image_id": 389410, "Bleu_1": 0.6666666665777778, "Bleu_2": 0.5773502691112712, "Bleu_3": 0.42529037022415583, "Bleu_4": 0.2829559627926664, "METEOR": 0.23061110973906804, "ROUGE_L": 0.43416370106761565, "CIDEr": 1.3150554414584181, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.125, "f": 0.15789473684210525, "fn": 21.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "A dog is sitting on a windowsill looking out the window at the city below."}, "415856": {"image_id": 415856, "Bleu_1": 0.31481481480898493, "Bleu_2": 0.20391006635932993, "Bleu_3": 0.09281638782109244, "Bleu_4": 1.1189893497623519e-05, "METEOR": 0.22369659213214657, "ROUGE_L": 0.20962199312714777, "CIDEr": 2.5148593921012888e-12, "SPICE": {"All": {"pr": 0.1, "re": 0.10344827586206896, "f": 0.10169491525423728, "fn": 26.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.23076923076923078, "f": 0.24000000000000002, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a group of horses standing in a river, with one horse drinking from the water. There are two people standing on the bank of the river, one of them holding a bucket and the other looking at the horses. The sky is cloudy and there are some trees in the background."}, "494810": {"image_id": 494810, "Bleu_1": 0.45161290321123837, "Bleu_2": 0.27435163057536965, "Bleu_3": 0.17314728911420935, "Bleu_4": 0.11668694360280925, "METEOR": 0.1909202029898692, "ROUGE_L": 0.3224669603524229, "CIDEr": 0.0016308631959327997, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.20833333333333334, "f": 0.19607843137254902, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5555555555555556, "f": 0.4545454545454546, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "A person is holding a plate of food in their hand, with a hamburger and fries on the plate. There are also glasses of soda and a salad on the table."}, "13637": {"image_id": 13637, "Bleu_1": 0.4444444444320988, "Bleu_2": 0.35634832253985926, "Bleu_3": 0.24628814285114745, "Bleu_4": 0.17346491270276557, "METEOR": 0.28880600663340505, "ROUGE_L": 0.358612580834803, "CIDEr": 0.001190529729793373, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.16, "f": 0.1818181818181818, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A man is standing next to a fire hydrant, looking at something on the ground. The hydrant is painted yellow and has a red handle on it.\""}, "18295": {"image_id": 18295, "Bleu_1": 0.472222222209105, "Bleu_2": 0.30731814856777107, "Bleu_3": 0.22314431668767756, "Bleu_4": 0.16108992769219987, "METEOR": 0.2937418741720591, "ROUGE_L": 0.4080267558528428, "CIDEr": 0.001547488824046267, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.16666666666666666, "f": 0.13636363636363638, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This is an image of a train traveling down a railroad track. The train is blue and white and has a number on the side. There are trees and greenery on either side of the track."}, "303744": {"image_id": 303744, "Bleu_1": 0.22580645160926122, "Bleu_2": 0.16097271743377828, "Bleu_3": 0.09523452766146472, "Bleu_4": 1.0999750164157708e-05, "METEOR": 0.20225031432453733, "ROUGE_L": 0.25412884987353074, "CIDEr": 2.779806238129473e-16, "SPICE": {"All": {"pr": 0.24, "re": 0.2857142857142857, "f": 0.2608695652173913, "fn": 15.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a person standing on the shore of a lake, holding a kite. The sky is clear and blue, with a few clouds scattered about. The person is wearing a red shirt and jeans, and has a determined look on their face as they prepare to launch the kite. In the background, there is a wooden dock and some trees."}, "385236": {"image_id": 385236, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.15649215928402857, "Bleu_3": 7.990635300418294e-07, "Bleu_4": 1.8151458107416433e-09, "METEOR": 0.1912418954362444, "ROUGE_L": 0.18944099378881987, "CIDEr": 2.072889153835339e-09, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.25, "f": 0.2608695652173913, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a street with tall, colorful buildings on either side. In the center of the street is a large clock tower with a clock face on it. The clock face is white with black numbers and hands. The sky is blue and there are clouds in the background."}, "525971": {"image_id": 525971, "Bleu_1": 0.378378378368152, "Bleu_2": 0.22924343512884385, "Bleu_3": 0.1442730640873472, "Bleu_4": 0.09694361543381819, "METEOR": 0.2493887075920261, "ROUGE_L": 0.32323996971990915, "CIDEr": 2.207268242774073e-05, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.2916666666666667, "f": 0.2916666666666667, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.5, "f": 0.5217391304347826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "This is an image of a group of people gathered in a parking lot. They are all riding motorcycles and there are several cars parked nearby. The sky is clear and there are trees in the background."}, "84533": {"image_id": 84533, "Bleu_1": 0.45161290321123837, "Bleu_2": 0.17351520647985194, "Bleu_3": 1.0125714893868398e-06, "Bleu_4": 2.4676284196864047e-09, "METEOR": 0.294346102621196, "ROUGE_L": 0.3330300272975432, "CIDEr": 0.0008734203937062442, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.15789473684210525, "f": 0.16666666666666669, "fn": 16.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The woman is sitting on the back of a black motorcycle, wearing a leather jacket and sunglasses. She is parked in front of a white building with a garage door open."}, "162732": {"image_id": 162732, "Bleu_1": 0.27906976743537054, "Bleu_2": 0.23055616707626844, "Bleu_3": 0.17309181846231234, "Bleu_4": 0.12689657676966778, "METEOR": 0.33110286454459537, "ROUGE_L": 0.35803374908290536, "CIDEr": 1.641955873925887e-07, "SPICE": {"All": {"pr": 0.03333333333333333, "re": 0.045454545454545456, "f": 0.03846153846153846, "fn": 21.0, "numImages": 1.0, "fp": 29.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.1, "f": 0.0909090909090909, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The image shows a group of soccer players in a huddle on a field. They are wearing orange and blue jerseys and black shorts, and one player is holding a ball. There are two referees standing nearby, one with a whistle in hand."}, "556091": {"image_id": 556091, "Bleu_1": 0.6499999999675001, "Bleu_2": 0.41358509591303216, "Bleu_3": 0.26686753869549923, "Bleu_4": 0.18285615451974122, "METEOR": 0.2975044747483014, "ROUGE_L": 0.46923076923076923, "CIDEr": 0.47347859637513584, "SPICE": {"All": {"pr": 0.25, "re": 0.11538461538461539, "f": 0.15789473684210525, "fn": 23.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "A desk with a computer, keyboard, and headphones on it. There is also a monitor and speakers on the desk."}, "11494": {"image_id": 11494, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.21438189279304845, "Bleu_3": 0.1288187994554362, "Bleu_4": 0.08446409107172648, "METEOR": 0.22611289740905333, "ROUGE_L": 0.2742453436095055, "CIDEr": 7.905437353899445e-08, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.15789473684210525, "f": 0.16216216216216214, "fn": 16.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6, "f": 0.42857142857142855, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a group of people on a bus, waving and taking pictures. They are all wearing colorful clothing and hats, and some are holding signs that say \"LGBTQ+ Pride\" and \"Love is Love\". The bus is decorated with rainbow flags and balloons."}, "284954": {"image_id": 284954, "Bleu_1": 0.34615384614053263, "Bleu_2": 0.23533936215658835, "Bleu_3": 1.3214760629595458e-06, "Bleu_4": 3.164918395250227e-09, "METEOR": 0.21388193821895174, "ROUGE_L": 0.24158415841584158, "CIDEr": 0.046616475838788037, "SPICE": {"All": {"pr": 0.0625, "re": 0.1, "f": 0.07692307692307693, "fn": 18.0, "numImages": 1.0, "fp": 30.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A pair of bicycles parked on the sidewalk outside a business with a blue and white awning.\""}, "304063": {"image_id": 304063, "Bleu_1": 0.333333333325926, "Bleu_2": 0.19462473603600663, "Bleu_3": 0.09586112891273502, "Bleu_4": 1.203426530909924e-05, "METEOR": 0.17403707450162517, "ROUGE_L": 0.28754208754208754, "CIDEr": 9.698854538076918e-09, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.2, "f": 0.1923076923076923, "fn": 20.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.18181818181818182, "f": 0.1904761904761905, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is an image of a military aircraft flying in the sky. The plane is painted in a camouflage pattern and has a large propeller on the front. It is flying low to the ground and appears to be in the process of taking off."}, "205035": {"image_id": 205035, "Bleu_1": 0.26229508196291323, "Bleu_2": 0.19835388146890715, "Bleu_3": 0.08736613667841299, "Bleu_4": 1.0355005892559529e-05, "METEOR": 0.23622254078945334, "ROUGE_L": 0.28276065043043186, "CIDEr": 2.1963126757945378e-11, "SPICE": {"All": {"pr": 0.5, "re": 0.12, "f": 0.1935483870967742, "fn": 22.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.3333333333333333, "f": 0.46153846153846156, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "A man is sitting on a boat in the water, looking out at the horizon. The boat is covered in greenery and has a small dog sitting on the bow. The man is wearing a white shirt and black pants, and the dog is wearing a red collar. The sky is blue and there are trees and grass on the shore."}, "138784": {"image_id": 138784, "Bleu_1": 0.34883720929421314, "Bleu_2": 0.24112141107953186, "Bleu_3": 0.1123472808055299, "Bleu_4": 1.3721668601021086e-05, "METEOR": 0.19057178517669224, "ROUGE_L": 0.24881033310673015, "CIDEr": 2.0350221336267423e-07, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.13636363636363635, "f": 0.1818181818181818, "fn": 19.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.25, "f": 0.35294117647058826, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This is an image of a train on a railroad track. The train is red and has windows on the sides. There are people standing on the platform next to the train. The sky is cloudy and there are trees in the background."}, "529069": {"image_id": 529069, "Bleu_1": 0.35897435896515456, "Bleu_2": 0.21733262130578967, "Bleu_3": 0.13667613926528305, "Bleu_4": 1.6319013503559494e-05, "METEOR": 0.264875556345835, "ROUGE_L": 0.2897862232779097, "CIDEr": 4.109429647353711e-06, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.10526315789473684, "f": 0.15384615384615385, "fn": 17.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.18181818181818182, "f": 0.26666666666666666, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "This is a bathroom with a toilet, sink, and shower. The walls are painted white and the floor is made of wood. There is a light fixture above the sink and a window to the left of the toilet."}, "197245": {"image_id": 197245, "Bleu_1": 0.39393939392745647, "Bleu_2": 0.3328595117142288, "Bleu_3": 0.26144283928154666, "Bleu_4": 0.15622561745550437, "METEOR": 0.3182901001110564, "ROUGE_L": 0.36033755274261603, "CIDEr": 0.0010058375412868674, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.125, "f": 0.12000000000000001, "fn": 21.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.25, "f": 0.2608695652173913, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "A cat is laying on a couch next to a television with a remote control in its paw. The cat is looking up at the television with a curious expression on its face."}, "434066": {"image_id": 434066, "Bleu_1": 0.5333333332977779, "Bleu_2": 0.39036002915245993, "Bleu_3": 0.2271585618034379, "Bleu_4": 3.1437754723697544e-05, "METEOR": 0.2827642819582477, "ROUGE_L": 0.4979591836734694, "CIDEr": 0.7366075996602004, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.2692307692307692, "f": 0.2641509433962264, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5, "f": 0.4347826086956522, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows three zebras standing in a grassy field with mountains in the background."}, "511463": {"image_id": 511463, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.14869042853022912, "Bleu_3": 0.07777190244898266, "Bleu_4": 1.0056053706911773e-05, "METEOR": 0.2640898435876501, "ROUGE_L": 0.27354260089686094, "CIDEr": 7.894270790969335e-09, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.14285714285714285, "f": 0.16, "fn": 24.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3076923076923077, "f": 0.33333333333333337, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The woman is walking her dog on a leash through the woods. The dog is wearing a red collar and is pulling on the leash. The woman is smiling and looking down at the dog. The trees in the background are tall and green, with leaves on the ground."}, "320524": {"image_id": 320524, "Bleu_1": 0.45714285712979597, "Bleu_2": 0.16398401233340346, "Bleu_3": 0.09340347318658344, "Bleu_4": 1.2632368169557316e-05, "METEOR": 0.18613968879623474, "ROUGE_L": 0.3005296218746151, "CIDEr": 0.03308516848425891, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.125, "f": 0.12000000000000001, "fn": 21.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a baseball game in progress at a stadium. The field is filled with players in uniforms, and the crowd is cheering from the stands. The sky is pink and orange during sunset."}, "290231": {"image_id": 290231, "Bleu_1": 0.25641025640368187, "Bleu_2": 0.20121090914115636, "Bleu_3": 0.12983061254080153, "Bleu_4": 0.08829928855227857, "METEOR": 0.23020631974824124, "ROUGE_L": 0.2741573033707865, "CIDEr": 5.423057841778049e-06, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.1724137931034483, "f": 0.19230769230769232, "fn": 24.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3333333333333333, "f": 0.34782608695652173, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a person riding a motorcycle on a race track. The person is wearing a helmet and riding the bike with their hands on the handlebars. The background is a green field with trees in the distance."}, "317999": {"image_id": 317999, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.14869042853022912, "Bleu_3": 0.07777190244898266, "Bleu_4": 1.0056053706911773e-05, "METEOR": 0.21485214519119644, "ROUGE_L": 0.3010487353485503, "CIDEr": 1.1743434961889206e-07, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.13636363636363635, "f": 0.1818181818181818, "fn": 19.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a man sitting in bed with his daughter, holding a bottle of milk. The man is wearing glasses and has a beard. The child is wearing a onesie and has a pacifier in her mouth. The bed is covered in a blue and white striped blanket."}, "463670": {"image_id": 463670, "Bleu_1": 0.32608695651465036, "Bleu_2": 0.19034674690253633, "Bleu_3": 0.1180926166655855, "Bleu_4": 0.07866833262076792, "METEOR": 0.26760392941987704, "ROUGE_L": 0.26991150442477874, "CIDEr": 4.706766713699249e-08, "SPICE": {"All": {"pr": 0.08108108108108109, "re": 0.21428571428571427, "f": 0.11764705882352942, "fn": 11.0, "numImages": 1.0, "fp": 34.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.07692307692307693, "re": 0.14285714285714285, "f": 0.1, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.13333333333333333, "re": 0.6666666666666666, "f": 0.2222222222222222, "fn": 1.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}}, "caption": "This is a picture of a dog lying on a blue blanket. The dog is white and has spots on its fur. It is looking up at the camera with its tongue hanging out of its mouth. There is a toy in the dog's mouth."}, "255338": {"image_id": 255338, "Bleu_1": 0.25423728813128416, "Bleu_2": 0.17516794979677439, "Bleu_3": 8.134761278593369e-07, "Bleu_4": 1.7608063785579351e-09, "METEOR": 0.19791041060111103, "ROUGE_L": 0.2659400544959128, "CIDEr": 2.122393541929567e-15, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.16666666666666666, "f": 0.2285714285714286, "fn": 20.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.21428571428571427, "f": 0.3157894736842105, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This is an image of a skier in the snow. The skier is wearing blue and orange clothing and has a backpack on their back. They are holding a ski pole in one hand and the other hand is in the air as they ski down the mountain. The snow is falling around them and the sky is cloudy."}, "146315": {"image_id": 146315, "Bleu_1": 0.30508474575754096, "Bleu_2": 0.16217400875780294, "Bleu_3": 0.09735820273347665, "Bleu_4": 1.1330065075700408e-05, "METEOR": 0.20625600552724738, "ROUGE_L": 0.2197632527020072, "CIDEr": 3.892514805750856e-14, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.2, "f": 0.19607843137254902, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5, "f": 0.45454545454545453, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "A group of people are gathered around a table, looking at their phones. One man is holding a phone up to his ear, while another man is typing on his phone. There are several other people in the background, also looking at their phones. The room is well lit and there are several chairs and tables in the background."}, "306154": {"image_id": 306154, "Bleu_1": 0.3829787233961069, "Bleu_2": 0.27373457909672566, "Bleu_3": 0.20267753101829, "Bleu_4": 0.1543552297172121, "METEOR": 0.2478213564145103, "ROUGE_L": 0.2865531415149735, "CIDEr": 3.2535351503751136e-07, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.13043478260869565, "f": 0.1333333333333333, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a small pond with a green bench on the side and some plants growing around it. There is a small bird perched on the edge of the pond, looking out at the water. The sky is blue and there are trees in the background."}, "418959": {"image_id": 418959, "Bleu_1": 0.3255813953412656, "Bleu_2": 0.304997140658032, "Bleu_3": 0.26280435353228093, "Bleu_4": 0.1920833548570946, "METEOR": 0.24343884446063987, "ROUGE_L": 0.3400696864111499, "CIDEr": 8.88634062934394e-06, "SPICE": {"All": {"pr": 0.0625, "re": 0.1111111111111111, "f": 0.08, "fn": 16.0, "numImages": 1.0, "fp": 30.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.2857142857142857, "f": 0.19047619047619047, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "The image shows a bird sitting on top of a small puddle of water in the middle of a forest. The bird is looking down at its reflection in the water. The sky is cloudy and there are some trees in the background."}, "521819": {"image_id": 521819, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.21271781490162775, "Bleu_3": 0.16540015368980918, "Bleu_4": 0.12901292604257925, "METEOR": 0.31389989028239185, "ROUGE_L": 0.330722891566265, "CIDEr": 1.845797085819428e-07, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.09375, "f": 0.11764705882352941, "fn": 29.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.25, "f": 0.2727272727272727, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of people playing frisbee in a park. They are standing in a circle and throwing the frisbee around, laughing and having fun. The sky is clear and blue, with some clouds in the distance. The grass is green and lush, and there are trees in the background."}, "31151": {"image_id": 31151, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.10966267342231086, "Bleu_3": 6.441223689630493e-07, "Bleu_4": 1.5698679279588222e-09, "METEOR": 0.16423040980398776, "ROUGE_L": 0.15183571873055382, "CIDEr": 2.4476620570833423e-08, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 18.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.2222222222222222, "f": 0.3333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "This image shows a group of people skiing down a snowy slope. One person is sitting on a sled while the others are standing on skis. They are all wearing winter clothing, including hats, gloves, and goggles. The snow is covered with tracks from skiers and snowboards."}, "100974": {"image_id": 100974, "Bleu_1": 0.15384615384220912, "Bleu_2": 0.06362847629592486, "Bleu_3": 4.783000660880887e-07, "Bleu_4": 1.3203823351935062e-09, "METEOR": 0.12375690607734804, "ROUGE_L": 0.1931908155186065, "CIDEr": 8.250303522065264e-08, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 20.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.09090909090909091, "f": 0.14285714285714288, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a large airport with several planes parked on the tarmac. There are also several people standing around the airport, looking at the planes. The sky is clear and blue, with a few clouds in the distance."}, "16439": {"image_id": 16439, "Bleu_1": 0.7199999999712, "Bleu_2": 0.4898979485366315, "Bleu_3": 0.2753200250744422, "Bleu_4": 3.120848453597625e-05, "METEOR": 0.27805822088798526, "ROUGE_L": 0.44162895927601814, "CIDEr": 0.2612991089944694, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.1724137931034483, "f": 0.20833333333333334, "fn": 24.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4166666666666667, "f": 0.45454545454545453, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "This is a desk with a laptop on it and a lamp next to it. There is also a vase of flowers on the desk."}, "456578": {"image_id": 456578, "Bleu_1": 0.3809523809433107, "Bleu_2": 0.27263927062982823, "Bleu_3": 0.1773152254708225, "Bleu_4": 0.10934360033350278, "METEOR": 0.3082014195285535, "ROUGE_L": 0.3292847503373819, "CIDEr": 1.2242206850584606e-05, "SPICE": {"All": {"pr": 0.0967741935483871, "re": 0.2727272727272727, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 28.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.17647058823529413, "re": 0.6, "f": 0.2727272727272727, "fn": 2.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}}, "caption": "The woman is standing in front of a small pizza oven made out of wood. She is holding a plate of pizza in her hand and smiling at the camera. The background is a green field with trees and a blue sky."}, "267351": {"image_id": 267351, "Bleu_1": 0.4074074073923183, "Bleu_2": 0.30662207032435856, "Bleu_3": 0.19592909694603244, "Bleu_4": 2.3660362390767172e-05, "METEOR": 0.31344466478253824, "ROUGE_L": 0.41256038647342996, "CIDEr": 0.01636216693043742, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.18518518518518517, "f": 0.21739130434782608, "fn": 22.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a white clock tower with a blue sky in the background. The clock has a red hand pointing to the top of the hour."}, "249658": {"image_id": 249658, "Bleu_1": 0.3157894736759004, "Bleu_2": 0.18476851073338801, "Bleu_3": 9.824666233056464e-07, "Bleu_4": 2.2815045692245487e-09, "METEOR": 0.21687916923792333, "ROUGE_L": 0.27191679049034173, "CIDEr": 7.108218614224154e-06, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.24, "f": 0.2553191489361702, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5, "f": 0.4347826086956522, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "This is an image of a bus driving down a street in a city. The bus is orange and white, with the words \"City Bus\" written on the side. There are buildings and trees visible in the background."}, "472732": {"image_id": 472732, "Bleu_1": 0.39999999998666674, "Bleu_2": 0.23488808779791684, "Bleu_3": 0.1253683714769749, "Bleu_4": 1.6436148153953708e-05, "METEOR": 0.17644571363550304, "ROUGE_L": 0.3405103668261563, "CIDEr": 0.004626692839875475, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.2631578947368421, "f": 0.2631578947368421, "fn": 14.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a group of people herding cattle on a dirt road in the middle of a desert. The sky is cloudy and there are mountains in the background."}, "231991": {"image_id": 231991, "Bleu_1": 0.17999999999640004, "Bleu_2": 0.14846149778861856, "Bleu_3": 0.11126773075168087, "Bleu_4": 0.07357875901414347, "METEOR": 0.25949255449176306, "ROUGE_L": 0.26521739130434785, "CIDEr": 3.656089571800605e-10, "SPICE": {"All": {"pr": 0.22580645161290322, "re": 0.3333333333333333, "f": 0.2692307692307692, "fn": 14.0, "numImages": 1.0, "fp": 24.0, "tp": 7.0}, "Relation": {"pr": 0.07142857142857142, "re": 0.1111111111111111, "f": 0.08695652173913043, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.7142857142857143, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "This is a man sitting at a desk in a room. He is wearing a white shirt and black pants. There are several items on the desk, including a laptop, a cup of coffee, and a pen. The walls are painted blue and there is a window in the background."}, "433504": {"image_id": 433504, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.23783535599888, "Bleu_3": 0.17393278705640786, "Bleu_4": 0.1258146658036402, "METEOR": 0.2473889897725675, "ROUGE_L": 0.3609467455621302, "CIDEr": 9.149371039234969e-08, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.16666666666666666, "f": 0.12903225806451615, "fn": 20.0, "numImages": 1.0, "fp": 34.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.18181818181818182, "f": 0.16, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "This is a black and white image of a room with a table and chairs in it. There are shelves on the walls with various items on them. The floor is made of wood and there is a window on one side of the room."}, "530033": {"image_id": 530033, "Bleu_1": 0.23913043477741028, "Bleu_2": 0.1030922854689151, "Bleu_3": 0.062277793856498315, "Bleu_4": 8.65730664807734e-06, "METEOR": 0.20754999876516123, "ROUGE_L": 0.24830393487109906, "CIDEr": 4.3443017704001435e-09, "SPICE": {"All": {"pr": 0.32, "re": 0.2857142857142857, "f": 0.30188679245283023, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 8.0}, "Relation": {"pr": 0.125, "re": 0.06666666666666667, "f": 0.08695652173913045, "fn": 14.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5384615384615384, "re": 0.7, "f": 0.608695652173913, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 7.0}}, "caption": "This is a man standing in front of a bathroom sink. He is wearing a black coat and hat, and has his hands in his pockets. There are two toilets on the wall behind him, and a sign on the wall that reads \"Men's Restroom\"."}, "362352": {"image_id": 362352, "Bleu_1": 0.3333333333253969, "Bleu_2": 0.18033392692914046, "Bleu_3": 0.09333222718443626, "Bleu_4": 1.2015935000417904e-05, "METEOR": 0.19304526599913563, "ROUGE_L": 0.2531120331950207, "CIDEr": 4.7115561054997537e-07, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.23809523809523808, "f": 0.2631578947368421, "fn": 16.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "This is an image of a train on the tracks with people standing next to it. The train has a number 12 on the side and is pulling into a station. There are people standing on the platform looking at the train."}, "452179": {"image_id": 452179, "Bleu_1": 0.16666666666414143, "Bleu_2": 0.10127393670682042, "Bleu_3": 0.05431733704149795, "Bleu_4": 7.1018045397515604e-06, "METEOR": 0.20235322373560322, "ROUGE_L": 0.18208955223880596, "CIDEr": 1.01580810473184e-19, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.125, "f": 0.13793103448275862, "fn": 14.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Relation": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image shows a bedroom with two beds, one with blue and white striped sheets and the other with blue and white striped blankets. There is a large window on the left side of the room with curtains open to reveal a view of the ocean. The walls are painted a light blue color and there is a large painting on the wall above the beds."}, "540782": {"image_id": 540782, "Bleu_1": 0.7999999999466668, "Bleu_2": 0.5345224837879413, "Bleu_3": 0.28011059395359145, "Bleu_4": 3.678763249653386e-05, "METEOR": 0.3260257977556322, "ROUGE_L": 0.5520361990950226, "CIDEr": 1.1089339773912428, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.35714285714285715, "f": 0.24390243902439024, "fn": 9.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.8, "f": 0.47058823529411764, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "This is a garden with a bench in the middle surrounded by flowers and trees."}, "26393": {"image_id": 26393, "Bleu_1": 0.34042553190765057, "Bleu_2": 0.21072097723733796, "Bleu_3": 9.955605444507264e-07, "Bleu_4": 2.1761437901966275e-09, "METEOR": 0.20232630152576864, "ROUGE_L": 0.23843648208469054, "CIDEr": 1.37752800257742e-08, "SPICE": {"All": {"pr": 0.4444444444444444, "re": 0.2222222222222222, "f": 0.2962962962962963, "fn": 14.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.5714285714285714, "f": 0.6666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "This is an image of a train on a railroad track. The train is black and has two smokestacks on the front. There are people standing on the platform next to the train, looking at it. The sky is cloudy and there are trees in the background."}, "382728": {"image_id": 382728, "Bleu_1": 0.36363636362534446, "Bleu_2": 0.15075567228424214, "Bleu_3": 9.01699599018232e-07, "Bleu_4": 2.223392281759365e-09, "METEOR": 0.27301817080012547, "ROUGE_L": 0.21922731356693623, "CIDEr": 0.0002368005414632372, "SPICE": {"All": {"pr": 0.30434782608695654, "re": 0.4117647058823529, "f": 0.35, "fn": 10.0, "numImages": 1.0, "fp": 16.0, "tp": 7.0}, "Relation": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.8333333333333334, "f": 0.6666666666666667, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a train traveling down a railroad track with several cars loaded with coal. The train is moving at a slow pace and there are trees and buildings in the background."}, "519611": {"image_id": 519611, "Bleu_1": 0.17187499999731448, "Bleu_2": 0.1279415789277748, "Bleu_3": 0.10183503991877266, "Bleu_4": 0.08489278540777347, "METEOR": 0.2009586332963659, "ROUGE_L": 0.2476798143851508, "CIDEr": 7.36492056561e-17, "SPICE": {"All": {"pr": 0.3, "re": 0.10344827586206896, "f": 0.15384615384615385, "fn": 26.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.2727272727272727, "f": 0.37499999999999994, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows a polar bear standing on a rocky outcropping, looking out over a body of water. The bear is white and has a distinctive white fur pattern on its face and body. It appears to be standing on its hind legs, with its front paws resting on the rock. The background is a rocky cliff face with some vegetation growing on it."}, "250313": {"image_id": 250313, "Bleu_1": 0.39583333332508686, "Bleu_2": 0.2753141339220232, "Bleu_3": 0.225943095507441, "Bleu_4": 0.189207644235812, "METEOR": 0.3448442877766833, "ROUGE_L": 0.4022781774580335, "CIDEr": 2.704296065635779e-08, "SPICE": {"All": {"pr": 0.35, "re": 0.2916666666666667, "f": 0.31818181818181823, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5555555555555556, "f": 0.5555555555555556, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a group of young people playing tennis on a court. They are wearing tennis shoes and holding rackets. One person is serving the ball while the others watch and prepare to hit it back. The background is a green field with trees in the distance."}, "256223": {"image_id": 256223, "Bleu_1": 0.47999999998080006, "Bleu_2": 0.34641016149963044, "Bleu_3": 0.250144843590915, "Bleu_4": 0.16331948281263942, "METEOR": 0.35593920709245785, "ROUGE_L": 0.5193945127719962, "CIDEr": 0.07408924603560026, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.18181818181818182, "f": 0.16326530612244897, "fn": 18.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This image shows a plate of pancakes with syrup and butter on the side. There are also cups of coffee and tea on the table."}, "456199": {"image_id": 456199, "Bleu_1": 0.49999999997222233, "Bleu_2": 0.3429971702654019, "Bleu_3": 0.24499865250037733, "Bleu_4": 0.1769497514845518, "METEOR": 0.23915428163122796, "ROUGE_L": 0.4518518518518518, "CIDEr": 0.1352647444844625, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.10526315789473684, "f": 0.0851063829787234, "fn": 17.0, "numImages": 1.0, "fp": 26.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.125, "f": 0.1, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "Sure, here is a short caption for the image:\n\n\"A group of people skiing down a snowy slope\""}, "148358": {"image_id": 148358, "Bleu_1": 0.5714285713877553, "Bleu_2": 0.4193139346576645, "Bleu_3": 2.4469914284217973e-06, "Bleu_4": 6.041241049999893e-09, "METEOR": 0.2382420187039628, "ROUGE_L": 0.47805642633228845, "CIDEr": 0.7884852149201091, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.17391304347826086, "f": 0.15999999999999998, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "There are three zebras standing in a green field with trees in the background."}, "353807": {"image_id": 353807, "Bleu_1": 0.1911764705854239, "Bleu_2": 0.13084449146866245, "Bleu_3": 0.0803524239552018, "Bleu_4": 0.05315215750163827, "METEOR": 0.1806424143968315, "ROUGE_L": 0.20800857365549494, "CIDEr": 9.249468548770783e-19, "SPICE": {"All": {"pr": 0.04878048780487805, "re": 0.14285714285714285, "f": 0.07272727272727274, "fn": 12.0, "numImages": 1.0, "fp": 39.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 17.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.09523809523809523, "re": 0.3333333333333333, "f": 0.14814814814814814, "fn": 4.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}}, "caption": "The image shows a white horse pulling a carriage with people inside. The horse is wearing a harness and has a long mane and tail. The carriage is decorated with red and green streamers and has a sign on the side that reads \"Happy Holidays\". People are standing on the sidewalk, watching the horse and carriage pass by. There are buildings in the background with windows and balconies."}, "448365": {"image_id": 448365, "Bleu_1": 0.16666666666269844, "Bleu_2": 0.11043152607218519, "Bleu_3": 0.06730418227629331, "Bleu_4": 9.402977292158486e-06, "METEOR": 0.16614596939906975, "ROUGE_L": 0.22197962154294032, "CIDEr": 5.014628216588179e-08, "SPICE": {"All": {"pr": 0.375, "re": 0.15789473684210525, "f": 0.22222222222222218, "fn": 16.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.25, "f": 0.36363636363636365, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "The image shows a young boy skateboarding on a concrete skate park. He is wearing a white shirt and shorts, and has his arms outstretched as he jumps off the ramp. The sky is cloudy and there are trees in the background."}, "385535": {"image_id": 385535, "Bleu_1": 0.3999999999885715, "Bleu_2": 0.265684465654326, "Bleu_3": 0.16233648076075052, "Bleu_4": 1.9121616355363688e-05, "METEOR": 0.23489028451278116, "ROUGE_L": 0.2622527944969905, "CIDEr": 0.0010459130497771272, "SPICE": {"All": {"pr": 0.3125, "re": 0.15625, "f": 0.20833333333333334, "fn": 27.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.3076923076923077, "f": 0.42105263157894735, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "This is an image of a street sign with the words \"us 1st st\" written on it. The sign is on a green traffic light pole and there are cars driving by in the background."}, "104320": {"image_id": 104320, "Bleu_1": 0.32499999999187507, "Bleu_2": 0.25819888974062344, "Bleu_3": 0.15195618441550346, "Bleu_4": 1.7548433487955064e-05, "METEOR": 0.1877508212513794, "ROUGE_L": 0.2764350453172206, "CIDEr": 3.2220683580697775e-06, "SPICE": {"All": {"pr": 0.2, "re": 0.11538461538461539, "f": 0.14634146341463417, "fn": 23.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image is a black and white photograph of a cell phone with a keypad on the front. The keypad has several buttons with numbers and symbols on them. The phone is sitting on a table with a white background."}, "99581": {"image_id": 99581, "Bleu_1": 0.545454545355372, "Bleu_2": 0.40451991740255755, "Bleu_3": 0.3313007624084907, "Bleu_4": 0.2596535888827098, "METEOR": 0.233378895338336, "ROUGE_L": 0.5091819699499166, "CIDEr": 0.6106458037702196, "SPICE": {"All": {"pr": 0.75, "re": 0.17647058823529413, "f": 0.2857142857142857, "fn": 14.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.16666666666666666, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.25, "f": 0.36363636363636365, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "A hand holding a smartphone with an image on the screen."}, "64599": {"image_id": 64599, "Bleu_1": 0.3333333333253969, "Bleu_2": 0.2385593618010997, "Bleu_3": 0.17853812773870492, "Bleu_4": 0.10990870235704996, "METEOR": 0.2928448764117019, "ROUGE_L": 0.3191330343796711, "CIDEr": 8.096257846964507e-06, "SPICE": {"All": {"pr": 0.09375, "re": 0.09375, "f": 0.09375, "fn": 29.0, "numImages": 1.0, "fp": 29.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "There are several plates of food on a table, with different types of meat and vegetables on them. Some of the plates have forks and knives on them, while others have spoons. There is also a bottle of wine on the table."}, "144058": {"image_id": 144058, "Bleu_1": 0.5384615383786985, "Bleu_2": 0.29957234471059097, "Bleu_3": 0.2013122721652155, "Bleu_4": 3.005402808883257e-05, "METEOR": 0.17564421674031128, "ROUGE_L": 0.4093959731543623, "CIDEr": 0.768334279868827, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.2777777777777778, "f": 0.25641025641025644, "fn": 13.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.6666666666666666, "f": 0.5333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "A foggy day at the marina with many boats docked in the water."}, "20632": {"image_id": 20632, "Bleu_1": 0.3999999999885715, "Bleu_2": 0.30678599553005403, "Bleu_3": 0.20453114927632365, "Bleu_4": 2.2739562220150898e-05, "METEOR": 0.24236938453564086, "ROUGE_L": 0.39400028706760437, "CIDEr": 0.029126157000147625, "SPICE": {"All": {"pr": 0.0625, "re": 0.0625, "f": 0.0625, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image shows a suitcase with a stuffed animal inside. The suitcase is open and the stuffed animal is sitting on top of it. There are also some clothes and other items inside the suitcase."}, "502084": {"image_id": 502084, "Bleu_1": 0.22499999999437506, "Bleu_2": 0.20095923811203675, "Bleu_3": 0.1745021516446632, "Bleu_4": 0.15481575551498444, "METEOR": 0.2855630710675111, "ROUGE_L": 0.32250755287009064, "CIDEr": 3.198702731704467e-06, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.23529411764705882, "f": 0.26666666666666666, "fn": 13.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.42857142857142855, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows two polar bears playing in the snow. One of the bears is on its back, while the other is standing on its hind legs and pawing at its face. The bears are surrounded by snow and trees."}, "223959": {"image_id": 223959, "Bleu_1": 0.36734693876801333, "Bleu_2": 0.3154200309337761, "Bleu_3": 0.2766263590982406, "Bleu_4": 0.21901467404711264, "METEOR": 0.3400818159681011, "ROUGE_L": 0.35442220787604906, "CIDEr": 1.5338002598896528e-09, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.20833333333333334, "f": 0.23255813953488372, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a man standing on a tennis court, holding a tennis racket in his hand. He is wearing a white shirt and black shorts, and has a determined look on his face. The background of the image is a tennis court with a net in the center."}, "5247": {"image_id": 5247, "Bleu_1": 0.31818181817458685, "Bleu_2": 0.22758963106159172, "Bleu_3": 0.15466509142797644, "Bleu_4": 0.09746490477140814, "METEOR": 0.2566452917189024, "ROUGE_L": 0.2038770053475936, "CIDEr": 7.568365735161437e-08, "SPICE": {"All": {"pr": 0.14705882352941177, "re": 0.1724137931034483, "f": 0.15873015873015872, "fn": 24.0, "numImages": 1.0, "fp": 29.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.4166666666666667, "f": 0.4, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "An older man is walking with a pair of skis on his feet in the snow. He is wearing a black and white jacket and pants, and has a red scarf around his neck. The trees in the background are bare and snow covered."}, "543364": {"image_id": 543364, "Bleu_1": 0.46874999998535166, "Bleu_2": 0.3478041718090821, "Bleu_3": 0.2721694910356964, "Bleu_4": 0.19310235945030582, "METEOR": 0.26375512895699393, "ROUGE_L": 0.36810344827586206, "CIDEr": 0.001970384622667909, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.2777777777777778, "f": 0.28571428571428575, "fn": 13.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is a living room with a couch, coffee table, and TV. The walls are painted green and there are windows on one side of the room that let in natural light."}, "349021": {"image_id": 349021, "Bleu_1": 0.2647058823451558, "Bleu_2": 0.15512630699387414, "Bleu_3": 9.093693442749552e-07, "Bleu_4": 2.2192938453856764e-09, "METEOR": 0.15396693976198123, "ROUGE_L": 0.24478330658105937, "CIDEr": 0.00012299227727361812, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.24, "f": 0.23076923076923075, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a blue and yellow train on the tracks, with people standing next to it. There are buildings in the background, and trees and plants growing along the sides of the tracks."}, "238310": {"image_id": 238310, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.14458880781007946, "Bleu_3": 0.08055078690642642, "Bleu_4": 1.075935380376544e-05, "METEOR": 0.18842963224364007, "ROUGE_L": 0.2839851024208566, "CIDEr": 6.67230094056831e-06, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.3125, "f": 0.3448275862068966, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.6, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a group of people standing under an umbrella, taking pictures of a stage with a band playing on it. The people are all wearing colorful clothing and some are holding instruments. The stage is decorated with balloons and streamers."}, "334767": {"image_id": 334767, "Bleu_1": 0.26315789472991696, "Bleu_2": 0.16866980207552001, "Bleu_3": 0.09245364897036984, "Bleu_4": 1.2258181047033617e-05, "METEOR": 0.1415398821737706, "ROUGE_L": 0.19709208400646203, "CIDEr": 2.2185975522714802e-06, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.18518518518518517, "f": 0.18867924528301885, "fn": 22.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.1, "f": 0.09523809523809525, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is an image of a group of people skiing down a snowy hill. They are wearing ski gear and holding their skis in front of them. The sky is cloudy and there are trees in the background."}, "48910": {"image_id": 48910, "Bleu_1": 0.2666666666607408, "Bleu_2": 0.1556997888288053, "Bleu_3": 0.0826106166220859, "Bleu_4": 1.0763774116165367e-05, "METEOR": 0.2465633896595862, "ROUGE_L": 0.28754208754208754, "CIDEr": 7.362740634029842e-08, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.35714285714285715, "f": 0.2631578947368421, "fn": 9.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.6666666666666666, "f": 0.4705882352941177, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This is a kitchen with white cabinets and countertops. There is a stove, sink, and refrigerator in the kitchen. The floor is made of hardwood and there are no rugs. The walls are painted white and there are windows on either side of the room."}, "35313": {"image_id": 35313, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.29814239699327133, "Bleu_3": 0.2547747219616277, "Bleu_4": 0.22046656837155548, "METEOR": 0.3309837028186192, "ROUGE_L": 0.35260115606936415, "CIDEr": 1.6052061069289969e-07, "SPICE": {"All": {"pr": 0.6, "re": 0.13636363636363635, "f": 0.22222222222222218, "fn": 19.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.375, "f": 0.5454545454545454, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}}, "caption": "The woman is sitting on a bench in front of a building. She is wearing a black and white striped shirt and black pants. She has her arms crossed and is looking off to the side. There are cars parked in front of the building."}, "368602": {"image_id": 368602, "Bleu_1": 0.23913043477741028, "Bleu_2": 0.1030922854689151, "Bleu_3": 6.227779385649834e-07, "Bleu_4": 1.5395110158669013e-09, "METEOR": 0.17963182741017703, "ROUGE_L": 0.16968011126564672, "CIDEr": 1.2889497198304695e-09, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.16, "f": 0.18604651162790697, "fn": 21.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.36363636363636365, "f": 0.4210526315789474, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a person on a jet ski, riding on the water with a smile on their face. The person is wearing a life jacket and holding onto the handlebars of the jet ski. The water is choppy and there are waves in the background."}, "377832": {"image_id": 377832, "Bleu_1": 0.5217391304120984, "Bleu_2": 0.3079962013899118, "Bleu_3": 0.20827340015449858, "Bleu_4": 0.14578668354039617, "METEOR": 0.2239532834461445, "ROUGE_L": 0.4291457286432161, "CIDEr": 0.07581722249857037, "SPICE": {"All": {"pr": 0.5714285714285714, "re": 0.19047619047619047, "f": 0.2857142857142857, "fn": 17.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 1.0, "re": 0.1, "f": 0.18181818181818182, "fn": 9.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.3333333333333333, "f": 0.4444444444444444, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A group of people on bicycles ride down the street on a sunny day.\""}, "189939": {"image_id": 189939, "Bleu_1": 0.20338983050502735, "Bleu_2": 0.1776527256753781, "Bleu_3": 0.14921301815109392, "Bleu_4": 0.13123525835991323, "METEOR": 0.3109103675177977, "ROUGE_L": 0.29918256130790194, "CIDEr": 6.099397763493858e-15, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.24, "f": 0.2608695652173913, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.625, "f": 0.5882352941176471, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a black and white cat sitting in a sink. The cat is looking up at the camera with its eyes. The sink is made of white porcelain and has a faucet on the side. There is a towel hanging on the side of the sink. The cat appears to be enjoying the water in the sink."}, "552573": {"image_id": 552573, "Bleu_1": 0.2343749999963379, "Bleu_2": 0.16137430608943423, "Bleu_3": 0.09435589257348495, "Bleu_4": 0.06091781416114966, "METEOR": 0.17476033274307617, "ROUGE_L": 0.21013779527559054, "CIDEr": 3.464664732751523e-17, "SPICE": {"All": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 24.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.125, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A man is sitting on top of an inflatable raft in the middle of a river, surrounded by other people on rafts. The rafts are being pulled by a rope attached to a bicycle, which is being pedaled by a person on the shore. The image is taken from above, looking down on the scene.\""}, "139192": {"image_id": 139192, "Bleu_1": 0.21212121211478424, "Bleu_2": 0.18205477030800182, "Bleu_3": 0.14747595901295485, "Bleu_4": 0.10168586985130716, "METEOR": 0.21709158596988584, "ROUGE_L": 0.27403414195867026, "CIDEr": 0.00020962017512101279, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.18181818181818182, "f": 0.23529411764705885, "fn": 18.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.2727272727272727, "f": 0.37499999999999994, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows three elephants standing in a field with their trunks entwined. They are standing in a circle and looking at each other. The sky is clear and blue in the background."}, "214363": {"image_id": 214363, "Bleu_1": 0.10869565217155013, "Bleu_2": 0.04914731871721879, "Bleu_3": 3.800572259697493e-07, "Bleu_4": 1.0629666321559288e-09, "METEOR": 0.06973954314580035, "ROUGE_L": 0.12726008344923503, "CIDEr": 7.421831894033859e-09, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.09523809523809523, "f": 0.14285714285714285, "fn": 19.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.125, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}}, "caption": "The image shows a group of people walking across a bridge over a river. They are all wearing raincoats and carrying umbrellas. The bridge is made of steel and has a railing on either side. In the background, there are tall buildings and a city skyline."}, "56091": {"image_id": 56091, "Bleu_1": 0.39393939392745647, "Bleu_2": 0.3328595117142288, "Bleu_3": 0.29247321329063003, "Bleu_4": 0.24032516910194215, "METEOR": 0.292294174816216, "ROUGE_L": 0.4036393713813069, "CIDEr": 0.0008450250398508166, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.17857142857142858, "f": 0.1923076923076923, "fn": 23.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5555555555555556, "f": 0.5263157894736842, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "A woman in a pink shirt and black pants is standing on a tennis court holding a tennis racket. The court is made of red clay and there are trees in the background."}, "242073": {"image_id": 242073, "Bleu_1": 0.3846153846005918, "Bleu_2": 0.27735009810173394, "Bleu_3": 0.1857626796524052, "Bleu_4": 2.2976659662726714e-05, "METEOR": 0.2020723354569079, "ROUGE_L": 0.3131416837782341, "CIDEr": 0.023513648352330472, "SPICE": {"All": {"pr": 0.2, "re": 0.05, "f": 0.08000000000000002, "fn": 19.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}}, "caption": "This is a bathroom with a toilet and a sink. The walls are made of green tiles and there is a wooden barrel in the corner."}, "372087": {"image_id": 372087, "Bleu_1": 0.45238095237018144, "Bleu_2": 0.39302868178798567, "Bleu_3": 0.31378065245584824, "Bleu_4": 0.23725669008285571, "METEOR": 0.37518850683100896, "ROUGE_L": 0.39956331877729256, "CIDEr": 7.796490683533745e-06, "SPICE": {"All": {"pr": 0.12, "re": 0.1111111111111111, "f": 0.11538461538461538, "fn": 24.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a green and yellow train traveling on the tracks at a train station. There are people standing on the platform waiting to board the train. The train has a number on the side and is pulling into the station."}, "416862": {"image_id": 416862, "Bleu_1": 0.17948717948257728, "Bleu_2": 0.11903797917090887, "Bleu_3": 0.09149551111419987, "Bleu_4": 0.06791633087624536, "METEOR": 0.18029082863541862, "ROUGE_L": 0.2347959969207082, "CIDEr": 1.2720593826508255e-06, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.13043478260869565, "f": 0.12, "fn": 20.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.18181818181818182, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "This is a laboratory with several scientists working at their desks. There are several large windows on the walls that provide natural light. The room is well lit and has a lot of space for the scientists to work."}, "437651": {"image_id": 437651, "Bleu_1": 0.20289855072169713, "Bleu_2": 0.15450054281980155, "Bleu_3": 0.11253347655054148, "Bleu_4": 0.06816717842701753, "METEOR": 0.21339777840816737, "ROUGE_L": 0.19156572454015255, "CIDEr": 4.747696246433554e-19, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.15625, "f": 0.16666666666666666, "fn": 27.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.25, "f": 0.2608695652173913, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a group of people standing around a table filled with small cups of food. They are all wearing white shirts and black pants, and some of them have aprons on. The table is covered in a red and white checkered tablecloth, and there are several large pots of food on the table. The atmosphere is festive and cheerful, with balloons and streamers hanging from the ceiling."}, "218751": {"image_id": 218751, "Bleu_1": 0.3030303030211204, "Bleu_2": 0.19462473603439093, "Bleu_3": 0.10690830888031075, "Bleu_4": 1.420621166464532e-05, "METEOR": 0.26041408833070123, "ROUGE_L": 0.25738396624472576, "CIDEr": 0.0013952310097692707, "SPICE": {"All": {"pr": 0.08, "re": 0.125, "f": 0.09756097560975609, "fn": 14.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This is an image of a fire hydrant on the side of the road. The hydrant is red and has a small handle on top. There are trees and houses in the background."}, "103307": {"image_id": 103307, "Bleu_1": 0.5384615384201185, "Bleu_2": 0.36689969282327245, "Bleu_3": 2.304450251660214e-06, "Bleu_4": 5.914601686329329e-09, "METEOR": 0.2635428474238885, "ROUGE_L": 0.4975530179445351, "CIDEr": 0.7018716106897605, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.16666666666666666, "f": 0.19607843137254902, "fn": 25.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.38461538461538464, "f": 0.4347826086956522, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "A giraffe is standing on a rocky terrain, looking up at the sky."}, "418471": {"image_id": 418471, "Bleu_1": 0.2909090909038017, "Bleu_2": 0.20759971843926334, "Bleu_3": 0.13461691545954688, "Bleu_4": 1.4717155900954345e-05, "METEOR": 0.1704962052000793, "ROUGE_L": 0.26114211451723873, "CIDEr": 2.4044707190124094e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "This is a photo of a pizza restaurant with a large table and chairs in front of it. There are several pizzas on the table, and a man is standing behind the counter, looking at the menu. The walls are painted yellow and there are several posters on the wall advertising different types of pizza."}, "28978": {"image_id": 28978, "Bleu_1": 0.09677419354682625, "Bleu_2": 0.05632871717456784, "Bleu_3": 3.7534977255921687e-07, "Bleu_4": 9.73002855643511e-10, "METEOR": 0.14457918108427278, "ROUGE_L": 0.18807810894141827, "CIDEr": 3.663465117261213e-17, "SPICE": {"All": {"pr": 0.5, "re": 0.15384615384615385, "f": 0.23529411764705882, "fn": 22.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image shows a computer mouse, a keyboard, and a camera. The mouse has a black body with a white button on the top and a silver scroll wheel on the side. The keyboard has a black body with white keys and a silver scroll wheel on the side. The camera has a black body with a silver lens on the front."}, "491203": {"image_id": 491203, "Bleu_1": 0.4999999999833334, "Bleu_2": 0.22742941306595937, "Bleu_3": 1.227001451803117e-06, "Bleu_4": 2.8760263876588012e-09, "METEOR": 0.22419818245173126, "ROUGE_L": 0.26614310645724254, "CIDEr": 0.003574361176565695, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.125, "f": 0.16, "fn": 28.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.23076923076923078, "f": 0.2857142857142857, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is an image of a bathroom with a toilet, sink, and bathtub. The walls are painted pink and there is a window on the left side of the room."}, "309316": {"image_id": 309316, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.2102800206225174, "Bleu_3": 0.12345519976108324, "Bleu_4": 0.07997285160016328, "METEOR": 0.1930337513442434, "ROUGE_L": 0.24190350297422336, "CIDEr": 1.0061672529646314e-09, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.15789473684210525, "f": 0.21428571428571427, "fn": 16.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.1111111111111111, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image shows a firefighter standing in front of a red fire truck. The firefighter is wearing a helmet and a fire coat, and is holding a hose in one hand and a nozzle in the other. The truck has the words \"Bombo Fire Department\" written on the side."}, "333630": {"image_id": 333630, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.16568337391262167, "Bleu_3": 0.10386373237947197, "Bleu_4": 1.2360545409967114e-05, "METEOR": 0.17110555057516139, "ROUGE_L": 0.21997836278398844, "CIDEr": 6.38257489059095e-11, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.1875, "f": 0.21818181818181817, "fn": 26.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.38461538461538464, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a group of people in a room with a red carpet on the floor. There are several tables set up with drinks and snacks on them. One person is holding a microphone and another is playing a guitar. There are also several chairs set up around the room."}, "581886": {"image_id": 581886, "Bleu_1": 0.4074074073923183, "Bleu_2": 0.35405666968249755, "Bleu_3": 0.29267919501420286, "Bleu_4": 0.23660362390767173, "METEOR": 0.31019307238657323, "ROUGE_L": 0.41256038647342996, "CIDEr": 0.037130906755896184, "SPICE": {"All": {"pr": 0.2413793103448276, "re": 0.25925925925925924, "f": 0.25, "fn": 20.0, "numImages": 1.0, "fp": 22.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.45454545454545453, "f": 0.41666666666666663, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "Two people sit on the beach next to a group of surfboards. The sun is setting in the background, casting a warm orange glow over the scene."}, "363560": {"image_id": 363560, "Bleu_1": 0.3571428571343538, "Bleu_2": 0.13199091933393275, "Bleu_3": 7.580119263366549e-07, "Bleu_4": 1.828061815856166e-09, "METEOR": 0.21538447336276786, "ROUGE_L": 0.323321554770318, "CIDEr": 6.168288763509293e-05, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.16666666666666666, "f": 0.186046511627907, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a group of children playing tennis on a court. They are wearing white tennis outfits and holding rackets. The coach is standing at the net, watching them play. The background is a green field with trees in the distance."}, "324818": {"image_id": 324818, "Bleu_1": 0.6666666665777778, "Bleu_2": 0.5773502691112712, "Bleu_3": 0.5042374901047999, "Bleu_4": 0.42311785410129055, "METEOR": 0.26481603978178997, "ROUGE_L": 0.5538261997405965, "CIDEr": 0.9817652753148427, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.4, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.2, "re": 1.0, "f": 0.33333333333333337, "fn": 0.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "Two blue and yellow macaws perched on a wooden branch in a tropical jungle environment."}, "532043": {"image_id": 532043, "Bleu_1": 0.32608695651465036, "Bleu_2": 0.24077170616624616, "Bleu_3": 0.13812196235285776, "Bleu_4": 1.573366652415358e-05, "METEOR": 0.28636227062289193, "ROUGE_L": 0.32317880794701986, "CIDEr": 9.354766249204857e-09, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.125, "f": 0.15789473684210525, "fn": 21.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "The image shows a brown and white cow standing on a rocky road in front of a mountain range. The cow has a small horn on its forehead and is looking directly at the camera. The background is a green valley with mountains in the distance."}, "226567": {"image_id": 226567, "Bleu_1": 0.45454545452479345, "Bleu_2": 0.32897584746457503, "Bleu_3": 0.2532054772355419, "Bleu_4": 0.17096862608918384, "METEOR": 0.2228137727201015, "ROUGE_L": 0.3351648351648352, "CIDEr": 0.11173315019791194, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.17391304347826086, "f": 0.17391304347826086, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "Here is a caption for the image:\n\nA group of fire trucks are parked in a field with mountains in the background."}, "272727": {"image_id": 272727, "Bleu_1": 0.39999999998400004, "Bleu_2": 0.3872983346049271, "Bleu_3": 0.37366676313170866, "Bleu_4": 0.34537865577212, "METEOR": 0.4372948678896549, "ROUGE_L": 0.5573604060913705, "CIDEr": 0.06516429308031997, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.1111111111111111, "f": 0.09999999999999999, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2857142857142857, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a horse grazing in a green field with trees in the background. The sky is clear and blue with fluffy white clouds."}, "555900": {"image_id": 555900, "Bleu_1": 0.378378378368152, "Bleu_2": 0.20504156173746327, "Bleu_3": 0.10630130250063007, "Bleu_4": 1.3709897573198736e-05, "METEOR": 0.1862899384942831, "ROUGE_L": 0.2783799201369082, "CIDEr": 0.02779535688112842, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 14.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A sleek and modern kitchen with a stainless steel oven and a blender on the counter. There are several muffins on the counter and a coffee maker nearby.\""}, "41212": {"image_id": 41212, "Bleu_1": 0.6666666666296297, "Bleu_2": 0.485071250044925, "Bleu_3": 0.3086789594811046, "Bleu_4": 3.742031645854287e-05, "METEOR": 0.36187095607751935, "ROUGE_L": 0.6024691358024692, "CIDEr": 0.7106942326544905, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.23809523809523808, "f": 0.2631578947368421, "fn": 16.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4, "f": 0.47058823529411764, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a soccer player in red and black uniform kicking a ball on a grass field."}, "247880": {"image_id": 247880, "Bleu_1": 0.3809523809433107, "Bleu_2": 0.28917761562015887, "Bleu_3": 0.18441526604132946, "Bleu_4": 0.1126111776817302, "METEOR": 0.23144210981057284, "ROUGE_L": 0.2663755458515284, "CIDEr": 4.7525470801333643e-07, "SPICE": {"All": {"pr": 0.3, "re": 0.36, "f": 0.3272727272727273, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 9.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.14285714285714285, "f": 0.10526315789473685, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a group of surfboards lying on the sand next to the ocean. The sky is clear and blue, with a few clouds in the distance. The beach is empty except for the surfboards and some trash on the ground."}, "220528": {"image_id": 220528, "Bleu_1": 0.4999999999833334, "Bleu_2": 0.3474041668780458, "Bleu_3": 0.23471693384611736, "Bleu_4": 2.6306760830615268e-05, "METEOR": 0.3339489150084867, "ROUGE_L": 0.4543761638733706, "CIDEr": 0.005402488733301046, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.18181818181818182, "f": 0.2285714285714286, "fn": 18.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a stuffed animal wearing a green shirt with the words \"Brasil\" written on it. The animal is sitting on a desk in front of a computer monitor."}, "98674": {"image_id": 98674, "Bleu_1": 0.49999999998076927, "Bleu_2": 0.28284271246352294, "Bleu_3": 0.14938015821259065, "Bleu_4": 1.9511368321629798e-05, "METEOR": 0.22028926945423036, "ROUGE_L": 0.30198019801980197, "CIDEr": 0.037910057506679605, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 12.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.6, "f": 0.4615384615384615, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a black bird perched on a branch with an apple in its beak. The bird is surrounded by snow covered trees and branches."}, "513611": {"image_id": 513611, "Bleu_1": 0.34042553190765057, "Bleu_2": 0.19236105428737107, "Bleu_3": 0.0936858341260546, "Bleu_4": 1.1692093421349074e-05, "METEOR": 0.2004581263959451, "ROUGE_L": 0.3122511659651917, "CIDEr": 0.04070396218410975, "SPICE": {"All": {"pr": 0.15, "re": 0.125, "f": 0.13636363636363635, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.25, "f": 0.2727272727272727, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of cows grazing in a green field. The cows are brown and black, and they are standing in a line, looking at the camera. There is a fence in the background, and trees in the distance. The sky is clear and blue."}, "327005": {"image_id": 327005, "Bleu_1": 0.3399999999932, "Bleu_2": 0.2634155559173319, "Bleu_3": 0.20546173445629382, "Bleu_4": 0.16483094398882964, "METEOR": 0.30108562520269216, "ROUGE_L": 0.3100381194409149, "CIDEr": 9.918906732631587e-10, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.17647058823529413, "f": 0.21428571428571427, "fn": 14.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a man standing on a surfboard in the water, holding a fishing rod and reel. The man is wearing a white shirt and shorts, and has a fishing hat on his head. The water is calm and clear, with boats and fishing nets visible in the background."}, "50434": {"image_id": 50434, "Bleu_1": 0.2615384615344379, "Bleu_2": 0.09040507133354568, "Bleu_3": 5.062305444419554e-07, "Bleu_4": 1.2027166877249277e-09, "METEOR": 0.1359627411607818, "ROUGE_L": 0.15091538842157345, "CIDEr": 1.2587318690836564e-18, "SPICE": {"All": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.45454545454545453, "f": 0.45454545454545453, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a baseball game in progress on a field. There are two players on the field, one pitching and the other catching. The pitcher is wearing a white jersey with red sleeves and pants, while the catcher is wearing a black jersey with white sleeves and pants. The field is made of grass and there are spectators in the stands watching the game."}, "64152": {"image_id": 64152, "Bleu_1": 0.4999999999791667, "Bleu_2": 0.32969023668385783, "Bleu_3": 0.245642541542721, "Bleu_4": 0.19383418022593038, "METEOR": 0.2857842822813337, "ROUGE_L": 0.38125000000000003, "CIDEr": 0.11520592929355435, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.25, "f": 0.27027027027027023, "fn": 15.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "This is a kitchen with a refrigerator, sink, and cabinets. The refrigerator is open and there is a bowl of fruit on the counter."}, "360610": {"image_id": 360610, "Bleu_1": 0.2222222222191358, "Bleu_2": 0.1582375544236339, "Bleu_3": 0.08943695954056846, "Bleu_4": 1.0090797649061763e-05, "METEOR": 0.21095821035686302, "ROUGE_L": 0.22344322344322343, "CIDEr": 9.675676120788743e-24, "SPICE": {"All": {"pr": 0.4117647058823529, "re": 0.19444444444444445, "f": 0.2641509433962264, "fn": 29.0, "numImages": 1.0, "fp": 10.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.15384615384615385, "f": 0.2666666666666667, "fn": 11.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.3333333333333333, "f": 0.43478260869565216, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image shows a group of people playing on the beach. There are two people in the foreground, one is throwing a frisbee and the other is watching. In the background, there are several people standing on the sand, some of them are also playing frisbee. The sky is clear and blue, with a few clouds scattered across it. The ocean is visible in the distance, with waves crashing against the shore."}, "514518": {"image_id": 514518, "Bleu_1": 0.30769230768441824, "Bleu_2": 0.1272569525918497, "Bleu_3": 0.0759254028064691, "Bleu_4": 1.0500614219604798e-05, "METEOR": 0.21538207419026167, "ROUGE_L": 0.24148851939825808, "CIDEr": 4.949339338384994e-06, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.16666666666666666, "f": 0.14634146341463414, "fn": 15.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is an image of a skier on a snowy slope. The skier is wearing a helmet and has their skis on their feet. The sun is shining down on the slope and there are trees in the background."}, "353108": {"image_id": 353108, "Bleu_1": 0.714285714234694, "Bleu_2": 0.5741692517206252, "Bleu_3": 0.4789823780673032, "Bleu_4": 0.3759663529163807, "METEOR": 0.2454611814730183, "ROUGE_L": 0.5313588850174217, "CIDEr": 0.9442353126208379, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.18181818181818182, "f": 0.17777777777777776, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "A group of sheep standing in a field with a mountain in the background."}, "66556": {"image_id": 66556, "Bleu_1": 0.32608695651465036, "Bleu_2": 0.25537695922201126, "Bleu_3": 0.20718294352928657, "Bleu_4": 0.16959513235152923, "METEOR": 0.28307043677251414, "ROUGE_L": 0.3855878634639696, "CIDEr": 1.9060104677998016e-07, "SPICE": {"All": {"pr": 0.043478260869565216, "re": 0.047619047619047616, "f": 0.04545454545454545, "fn": 20.0, "numImages": 1.0, "fp": 22.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a cat sitting on top of a wooden chair in a garden. The cat is white and has blue eyes. The chair is old and has a wooden seat and backrest. There are leaves on the ground and a tree in the background."}, "146126": {"image_id": 146126, "Bleu_1": 0.4473684210408588, "Bleu_2": 0.29092485085203773, "Bleu_3": 0.19177565064778895, "Bleu_4": 0.11914562164868793, "METEOR": 0.2804665905452186, "ROUGE_L": 0.3830455259026687, "CIDEr": 0.0009315861510079918, "SPICE": {"All": {"pr": 0.2, "re": 0.2608695652173913, "f": 0.22641509433962265, "fn": 17.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a table with a plate of food, a drink, and a remote control. The food appears to be french fries and a soda can. The remote control is on the table next to the food."}, "229653": {"image_id": 229653, "Bleu_1": 0.24999999999375005, "Bleu_2": 0.19611613513321832, "Bleu_3": 0.1448065155642414, "Bleu_4": 0.11318741601733968, "METEOR": 0.31260979365760583, "ROUGE_L": 0.33152173913043476, "CIDEr": 2.2154287252179546e-06, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.07692307692307693, "f": 0.1142857142857143, "fn": 24.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}}, "caption": "A woman is sitting on a bed with a laptop in front of her. She is wearing a green shirt and has a serious expression on her face. The room is dimly lit and there are lamps on the nightstand."}, "193911": {"image_id": 193911, "Bleu_1": 0.37499999998437505, "Bleu_2": 0.2211629342229303, "Bleu_3": 1.3051707586308407e-06, "Bleu_4": 3.2077142813088536e-09, "METEOR": 0.18440848563143272, "ROUGE_L": 0.33008658008658004, "CIDEr": 0.028021418329174097, "SPICE": {"All": {"pr": 0.3548387096774194, "re": 0.36666666666666664, "f": 0.36065573770491804, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 11.0}, "Relation": {"pr": 0.1, "re": 0.07692307692307693, "f": 0.08695652173913043, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.6363636363636364, "f": 0.56, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 7.0}}, "caption": "Sure, here is a short caption for the image:\n\n\"Two brown cows standing in a barn with their heads down and their tails up.\""}, "124684": {"image_id": 124684, "Bleu_1": 0.17647058823183395, "Bleu_2": 0.10289915108346752, "Bleu_3": 6.000800213279683e-07, "Bleu_4": 1.456620999046851e-09, "METEOR": 0.17391589986025283, "ROUGE_L": 0.22584228063680117, "CIDEr": 2.1185803952450498e-10, "SPICE": {"All": {"pr": 0.23333333333333334, "re": 0.25925925925925924, "f": 0.2456140350877193, "fn": 20.0, "numImages": 1.0, "fp": 23.0, "tp": 7.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.18181818181818182, "f": 0.19999999999999998, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.29411764705882354, "re": 0.5555555555555556, "f": 0.3846153846153846, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}}, "caption": "The image shows a woman playing frisbee on a beach. She is wearing a white shirt and shorts, and has a frisbee in her hand. There are several other people in the background, some of whom are also playing frisbee. The sky is blue and there are some clouds in it."}, "331386": {"image_id": 331386, "Bleu_1": 0.3181818181673554, "Bleu_2": 0.1740776559475969, "Bleu_3": 0.11485555942497074, "Bleu_4": 1.6804500805879955e-05, "METEOR": 0.24590190343643578, "ROUGE_L": 0.2612419700214133, "CIDEr": 0.12156198899848225, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.058823529411764705, "f": 0.0816326530612245, "fn": 32.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.18181818181818182, "f": 0.23529411764705885, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A busy street scene with several buses and people walking on the sidewalk.\""}, "508586": {"image_id": 508586, "Bleu_1": 0.36842105262188374, "Bleu_2": 0.19957280121567952, "Bleu_3": 0.10342687475822786, "Bleu_4": 1.3333925991412677e-05, "METEOR": 0.23030846330070245, "ROUGE_L": 0.28728414442700156, "CIDEr": 8.460456747083494e-06, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.16666666666666666, "f": 0.13636363636363638, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.25, "f": 0.24000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a herd of zebras grazing in a grassy field. The zebras are standing in a line, with their heads down and their stripes visible. In the background, there is a large, open sky with clouds."}, "363673": {"image_id": 363673, "Bleu_1": 0.3235294117551904, "Bleu_2": 0.22140372137841335, "Bleu_3": 0.1662571646020208, "Bleu_4": 0.1312207007570676, "METEOR": 0.291444613703376, "ROUGE_L": 0.36003372681281615, "CIDEr": 0.001418535668914663, "SPICE": {"All": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a woman playing tennis on a court. She is wearing a white tennis dress and has a racket in her hand. There are other people watching her play from the sidelines."}, "445953": {"image_id": 445953, "Bleu_1": 0.1728395061707057, "Bleu_2": 0.10393492740909611, "Bleu_3": 0.06490955715452294, "Bleu_4": 0.04327208623802408, "METEOR": 0.21439180884849135, "ROUGE_L": 0.15345911949685534, "CIDEr": 7.58505644073151e-31, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.15151515151515152, "f": 0.14705882352941174, "fn": 28.0, "numImages": 1.0, "fp": 30.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.23529411764705882, "re": 0.2857142857142857, "f": 0.2580645161290323, "fn": 10.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}}, "caption": "The image shows a man sitting on the steps of a building, wearing a red robe and holding a phone to his ear. He appears to be talking on the phone, looking down at the ground. The building behind him is made of stone and has a large archway with a sign that reads \"city hall\" in the center. There are other buildings in the background, some of which have windows and doors open. The image is in black and white."}, "435257": {"image_id": 435257, "Bleu_1": 0.27027027026296574, "Bleu_2": 0.19374606456772306, "Bleu_3": 0.1289662020068933, "Bleu_4": 0.08912246776433805, "METEOR": 0.2231602482509893, "ROUGE_L": 0.332295719844358, "CIDEr": 3.080583511947747e-05, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.13043478260869565, "f": 0.14634146341463414, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "This is an image of a couple standing on the sidewalk in front of a building. The man is wearing a hat and the woman is wearing a scarf. There is a clock tower in the background."}, "436617": {"image_id": 436617, "Bleu_1": 0.29999999999250004, "Bleu_2": 0.27735009810559197, "Bleu_3": 0.2530002863269082, "Bleu_4": 0.22637483203467934, "METEOR": 0.3382914357130623, "ROUGE_L": 0.4619394177812746, "CIDEr": 2.6565144566288167e-05, "SPICE": {"All": {"pr": 0.2, "re": 0.06896551724137931, "f": 0.10256410256410257, "fn": 27.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2, "f": 0.26666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a group of people sitting at a table in a restaurant. They are all wearing casual clothing and are engaged in conversation. There are candles on the table and a mirror hanging on the wall behind them."}, "309160": {"image_id": 309160, "Bleu_1": 0.26829268292028563, "Bleu_2": 0.2006088294094673, "Bleu_3": 1.0105205741245248e-06, "Bleu_4": 2.2827742812602696e-09, "METEOR": 0.17153532167021213, "ROUGE_L": 0.2588767859668977, "CIDEr": 1.3483767409502134e-06, "SPICE": {"All": {"pr": 0.13157894736842105, "re": 0.35714285714285715, "f": 0.1923076923076923, "fn": 9.0, "numImages": 1.0, "fp": 33.0, "tp": 5.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.14285714285714285, "f": 0.1, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.6666666666666666, "f": 0.36363636363636365, "fn": 2.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}}, "caption": "The image shows a cat sitting on the steps of a brick building. The cat has a curious expression on its face and is looking up at something. The background is a brick wall with a window on the left side."}, "100430": {"image_id": 100430, "Bleu_1": 0.305555555547068, "Bleu_2": 0.16183471873797783, "Bleu_3": 9.166878867586852e-07, "Bleu_4": 2.1980503399202124e-09, "METEOR": 0.12024622630273629, "ROUGE_L": 0.22897897897897898, "CIDEr": 5.002441020182301e-05, "SPICE": {"All": {"pr": 0.1875, "re": 0.24, "f": 0.21052631578947367, "fn": 19.0, "numImages": 1.0, "fp": 26.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5, "f": 0.36363636363636365, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "This image shows a room with a blue desk and chair, a white wall with a painting on it, and a wooden floor. The room has a large window with a view of the city outside."}, "302038": {"image_id": 302038, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.19999999999595922, "Bleu_3": 0.13572088082697478, "Bleu_4": 1.5186599421783195e-05, "METEOR": 0.23447430411901393, "ROUGE_L": 0.26521739130434785, "CIDEr": 5.346797693127817e-10, "SPICE": {"All": {"pr": 0.2, "re": 0.19230769230769232, "f": 0.19607843137254902, "fn": 21.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5, "f": 0.4347826086956522, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "This is a dining room with a large wooden table and chairs. There is a fireplace in the corner of the room with a wood burning stove. The walls are made of stone and there is a large window on one side of the room that lets in natural light."}, "287667": {"image_id": 287667, "Bleu_1": 0.4705882352802769, "Bleu_2": 0.358248860405223, "Bleu_3": 0.22914671579622262, "Bleu_4": 0.14036046697224608, "METEOR": 0.3075016552287821, "ROUGE_L": 0.3024793388429752, "CIDEr": 0.0052262947581741504, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.21739130434782608, "f": 0.21739130434782608, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "This is an image of a carrot and a knife on a wooden cutting board. The carrot has a face made out of cheese and the knife has a handle shaped like a beak."}, "154431": {"image_id": 154431, "Bleu_1": 0.3207547169750801, "Bleu_2": 0.26048408657499267, "Bleu_3": 0.17458921120504992, "Bleu_4": 0.10157119243203651, "METEOR": 0.20852992066220907, "ROUGE_L": 0.2896142433234421, "CIDEr": 6.99165943149455e-10, "SPICE": {"All": {"pr": 0.3684210526315789, "re": 0.2916666666666667, "f": 0.32558139534883723, "fn": 17.0, "numImages": 1.0, "fp": 12.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5555555555555556, "f": 0.5263157894736842, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "This is a living room with a large window that looks out onto a garden. There is a television on a shelf in front of the window, and a wooden statue on a pedestal in the corner of the room. The walls are painted white and there is a rug on the floor."}, "39726": {"image_id": 39726, "Bleu_1": 0.2727272727190084, "Bleu_2": 0.18463723646331667, "Bleu_3": 0.14886732381578285, "Bleu_4": 0.12178021069024866, "METEOR": 0.19405238978346892, "ROUGE_L": 0.30886075949367087, "CIDEr": 0.0001326897063421235, "SPICE": {"All": {"pr": 0.1, "re": 0.09523809523809523, "f": 0.0975609756097561, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This image shows a close up of a cinnamon roll with cream cheese frosting on top. The roll is cut in half and there is a fork on the side of the plate."}, "85007": {"image_id": 85007, "Bleu_1": 0.25714285713551027, "Bleu_2": 0.1229880092500526, "Bleu_3": 0.07710286831404463, "Bleu_4": 1.0939951744794564e-05, "METEOR": 0.2627996568632128, "ROUGE_L": 0.2469635627530364, "CIDEr": 7.103134588484727e-05, "SPICE": {"All": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.42857142857142855, "f": 0.6, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.625, "re": 0.8333333333333334, "f": 0.7142857142857143, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image shows two people playing frisbee in a grassy field. One person is throwing the frisbee while the other person is catching it. The sky is cloudy and there are trees in the background."}, "412873": {"image_id": 412873, "Bleu_1": 0.5238095237845806, "Bleu_2": 0.4281744192679387, "Bleu_3": 0.33794752877070244, "Bleu_4": 0.25590356076152615, "METEOR": 0.29024173501771766, "ROUGE_L": 0.4959349593495934, "CIDEr": 0.07699711096393984, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.16666666666666666, "f": 0.2105263157894737, "fn": 20.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "A black and white image of a herd of cows grazing in a field with a few trees in the background."}, "471566": {"image_id": 471566, "Bleu_1": 0.9999999999166668, "Bleu_2": 0.7977240351479671, "Bleu_3": 0.6337555593509505, "Bleu_4": 0.4876836638215391, "METEOR": 0.23530525222774654, "ROUGE_L": 0.6777777777777778, "CIDEr": 1.012037071625072, "SPICE": {"All": {"pr": 0.125, "re": 0.06451612903225806, "f": 0.0851063829787234, "fn": 29.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.08333333333333333, "f": 0.1111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "A horse standing in a field with a fence in the background."}, "10534": {"image_id": 10534, "Bleu_1": 0.13793103448117322, "Bleu_2": 0.08955024394535527, "Bleu_3": 4.552376857897442e-07, "Bleu_4": 1.029458475943369e-09, "METEOR": 0.17011086955841562, "ROUGE_L": 0.17294451194815716, "CIDEr": 3.4006947768840994e-32, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.08333333333333333, "f": 0.09756097560975609, "fn": 22.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image shows a woman sitting on a bench in front of a building with a sign that reads, \"Welcome to the park.\" The woman is wearing a black shirt and jeans, and her hair is tied back in a ponytail. She is looking down at her phone, which is on her lap. The bench is made of wood and has a backrest. The building behind her has a large window with white curtains. There are plants and flowers in pots on either side of the bench."}, "15567": {"image_id": 15567, "Bleu_1": 0.4493981746973232, "Bleu_2": 0.3078084890009808, "Bleu_3": 0.17421473584478553, "Bleu_4": 2.3662970827341347e-05, "METEOR": 0.22347118691102946, "ROUGE_L": 0.29221556886227545, "CIDEr": 0.7527501288683625, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.13793103448275862, "f": 0.18181818181818182, "fn": 25.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "This is an old rocking chair with a cat sitting on it. The cat is looking at the camera."}, "88250": {"image_id": 88250, "Bleu_1": 0.6999999998600002, "Bleu_2": 0.3944053187922357, "Bleu_3": 2.689047742804065e-06, "Bleu_4": 7.259795289559491e-09, "METEOR": 0.21898895680106617, "ROUGE_L": 0.42508710801393734, "CIDEr": 1.2479171705384773, "SPICE": {"All": {"pr": 0.1, "re": 0.08333333333333333, "f": 0.0909090909090909, "fn": 22.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.15384615384615385, "f": 0.18181818181818185, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "Two elephants are standing in the dirt, their trunks entwined."}, "58937": {"image_id": 58937, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.19296124624292718, "Bleu_3": 0.1344109151128908, "Bleu_4": 0.0857082790640443, "METEOR": 0.2465659792381944, "ROUGE_L": 0.32562277580071175, "CIDEr": 1.4204370041012792e-07, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.1111111111111111, "f": 0.10714285714285715, "fn": 24.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2727272727272727, "f": 0.2608695652173913, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a table set with several bottles of wine, glasses, and plates of food. There are also two people sitting at the table, one of whom is holding a glass of wine. The background is a dark brown color with some lighting coming from the windows."}, "112110": {"image_id": 112110, "Bleu_1": 0.20930232557652792, "Bleu_2": 0.12227087188800603, "Bleu_3": 0.09001137287152322, "Bleu_4": 0.06534434987611225, "METEOR": 0.16120197233178715, "ROUGE_L": 0.21254355400696864, "CIDEr": 2.1458582274880444e-07, "SPICE": {"All": {"pr": 0.2647058823529412, "re": 0.2903225806451613, "f": 0.27692307692307694, "fn": 22.0, "numImages": 1.0, "fp": 25.0, "tp": 9.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.07692307692307693, "f": 0.08333333333333334, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.47058823529411764, "re": 0.5333333333333333, "f": 0.5, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 8.0}}, "caption": "The image shows a person standing on the sidewalk, holding a laptop in their hands. They are wearing a pair of sneakers and have their arms stretched out to the side. The background is a dark blue color with streetlights in the distance."}, "380142": {"image_id": 380142, "Bleu_1": 0.41666666665509267, "Bleu_2": 0.28867513458667965, "Bleu_3": 0.16987257791700947, "Bleu_4": 0.11039870350119563, "METEOR": 0.2126915007149501, "ROUGE_L": 0.3567251461988304, "CIDEr": 0.0004941735421606912, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.09523809523809523, "f": 0.1, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows two horses grazing in a green field. One horse is lying down on its side while the other is standing nearby, looking at it. The sky is blue and cloudy in the background."}, "77282": {"image_id": 77282, "Bleu_1": 0.7777777776049386, "Bleu_2": 0.6236095643194133, "Bleu_3": 0.38157141409384626, "Bleu_4": 5.51625153137941e-05, "METEOR": 0.2887675538674008, "ROUGE_L": 0.6256410256410255, "CIDEr": 1.7192116701966418, "SPICE": {"All": {"pr": 0.35, "re": 0.3888888888888889, "f": 0.36842105263157887, "fn": 11.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "A vase filled with flowers sits on a windowsill."}, "186038": {"image_id": 186038, "Bleu_1": 0.3437499999892579, "Bleu_2": 0.18239004641192846, "Bleu_3": 1.0350476356783778e-06, "Bleu_4": 2.486684880432591e-09, "METEOR": 0.2126009898030817, "ROUGE_L": 0.2629310344827586, "CIDEr": 0.0005883087104977011, "SPICE": {"All": {"pr": 0.16216216216216217, "re": 0.21428571428571427, "f": 0.1846153846153846, "fn": 22.0, "numImages": 1.0, "fp": 31.0, "tp": 6.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.16666666666666666, "f": 0.11764705882352942, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.1111111111111111, "f": 0.09999999999999999, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.3076923076923077, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image shows a woman holding a toothbrush in her mouth, with a red light shining behind her. She is wearing a red shirt and has a serious expression on her face."}, "448974": {"image_id": 448974, "Bleu_1": 0.3157894736759004, "Bleu_2": 0.26130213377863615, "Bleu_3": 0.21166601750481703, "Bleu_4": 0.16885023000536672, "METEOR": 0.3372858286278551, "ROUGE_L": 0.41908396946564885, "CIDEr": 4.185964992199104e-05, "SPICE": {"All": {"pr": 0.058823529411764705, "re": 0.10526315789473684, "f": 0.07547169811320754, "fn": 17.0, "numImages": 1.0, "fp": 32.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.13333333333333333, "re": 0.3333333333333333, "f": 0.19047619047619044, "fn": 4.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}}, "caption": "A person is holding a cell phone in their hand. The phone has a small screen and a keypad on the front. The person is standing in a room with a bed and a dresser in the background."}, "457766": {"image_id": 457766, "Bleu_1": 0.14062499999780276, "Bleu_2": 0.09449111825081868, "Bleu_3": 0.05241594611405221, "Bleu_4": 6.9705189659283325e-06, "METEOR": 0.18319772954179578, "ROUGE_L": 0.15561224489795916, "CIDEr": 2.5560900883821085e-18, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.09523809523809523, "f": 0.08888888888888889, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "A dump truck is driving down the street in the snow. The truck has a yellow and black body with a large bucket on the back. There are two men standing next to the truck, one is wearing a hard hat and the other is wearing a yellow jacket. The scene is set in a small town with houses and trees in the background."}, "131611": {"image_id": 131611, "Bleu_1": 0.3829787233961069, "Bleu_2": 0.24141120717629194, "Bleu_3": 0.10900191148347908, "Bleu_4": 1.3098224091468965e-05, "METEOR": 0.18882505492409377, "ROUGE_L": 0.34837235865219873, "CIDEr": 0.024245637789215534, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.19047619047619047, "f": 0.19047619047619047, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of elephants standing in a small pond surrounded by trees and rocks. The elephants are standing on the shore of the pond, looking out at the camera. The water is calm and clear, reflecting the green trees and rocks in the background."}, "434187": {"image_id": 434187, "Bleu_1": 0.27272727272314046, "Bleu_2": 0.1832114449629405, "Bleu_3": 0.10160577837039446, "Bleu_4": 0.06387834682203493, "METEOR": 0.23515552939626858, "ROUGE_L": 0.17579250720461098, "CIDEr": 2.2540877945776458e-18, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.25, "f": 0.1702127659574468, "fn": 12.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.375, "f": 0.2727272727272727, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a group of people standing in front of a wooden fence, looking at something on their phones. One person is holding a baby, while another person is holding a camera. There are several people in the background, including a man in a pirate costume and a woman in a pink dress. The image appears to be taken in a park or outdoor area."}, "526446": {"image_id": 526446, "Bleu_1": 0.5384615384408284, "Bleu_2": 0.35948681369506397, "Bleu_3": 0.2208317739180072, "Bleu_4": 2.615858282472591e-05, "METEOR": 0.24992268777557214, "ROUGE_L": 0.38193202146690514, "CIDEr": 0.052247309371375, "SPICE": {"All": {"pr": 0.875, "re": 0.21212121212121213, "f": 0.3414634146341463, "fn": 26.0, "numImages": 1.0, "fp": 1.0, "tp": 7.0}, "Relation": {"pr": 0.6666666666666666, "re": 0.2, "f": 0.30769230769230765, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.09090909090909091, "f": 0.16666666666666669, "fn": 10.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 4.0}}, "caption": "The image shows a baseball player in the middle of a game, holding a bat and wearing a helmet. The crowd is cheering in the background."}, "345356": {"image_id": 345356, "Bleu_1": 0.37096774192950055, "Bleu_2": 0.2205708664749214, "Bleu_3": 0.1594550767100615, "Bleu_4": 0.12875993774316236, "METEOR": 0.21331484071763848, "ROUGE_L": 0.24621594349142278, "CIDEr": 5.087475192595353e-14, "SPICE": {"All": {"pr": 0.03333333333333333, "re": 0.038461538461538464, "f": 0.03571428571428572, "fn": 25.0, "numImages": 1.0, "fp": 29.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.1111111111111111, "f": 0.10526315789473685, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows two men sitting at a table in a restaurant, both of them holding cell phones and looking at their screens. The table is set with white tablecloths and has a vase of flowers in the center. The walls are painted a light blue color and there are windows on the side of the room that let in natural light."}, "506574": {"image_id": 506574, "Bleu_1": 0.14545454545190087, "Bleu_2": 0.08989331499344942, "Bleu_3": 5.342275830329977e-07, "Bleu_4": 1.3085607656499974e-09, "METEOR": 0.2107754474454198, "ROUGE_L": 0.18340348767288037, "CIDEr": 3.094912488511353e-14, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.19230769230769232, "f": 0.2439024390243902, "fn": 21.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.5555555555555556, "f": 0.5882352941176471, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA giraffe is eating leaves from a tree in a zoo enclosure. The giraffe has a long neck and spotted fur. The leaves are green and hanging from the branches of the tree. The giraffe is standing on the ground and looking up at the leaves."}, "486910": {"image_id": 486910, "Bleu_1": 0.1846153846125444, "Bleu_2": 0.05370861555212476, "Bleu_3": 3.5775231712004667e-07, "Bleu_4": 9.270196054838439e-10, "METEOR": 0.09178933013533043, "ROUGE_L": 0.14827418570734077, "CIDEr": 1.6490992255554278e-19, "SPICE": {"All": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 14.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a foal nursing from its mother in a green pasture. The foal is brown and black, while the mother is black and white. The foal is standing on its hind legs and nursing from its mother's udder. The mother is standing next to the foal, looking down at it. The background is a green pasture with some trees in the distance."}, "98443": {"image_id": 98443, "Bleu_1": 0.36585365852766216, "Bleu_2": 0.25303041366748835, "Bleu_3": 0.1701377556473561, "Bleu_4": 1.8973813415884158e-05, "METEOR": 0.23844774052330026, "ROUGE_L": 0.26425992779783397, "CIDEr": 1.5954517472823519e-06, "SPICE": {"All": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 12.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.6, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a tall building with a clock tower in the center. The building is made of brick and has a large clock face on the front. There are palm trees in the foreground and tall buildings in the background."}, "292926": {"image_id": 292926, "Bleu_1": 0.21276595744228163, "Bleu_2": 0.09618052714368557, "Bleu_3": 0.05901837724618784, "Bleu_4": 8.267558544502552e-06, "METEOR": 0.2031183261936631, "ROUGE_L": 0.24416277518345564, "CIDEr": 9.503008016731243e-10, "SPICE": {"All": {"pr": 0.28, "re": 0.30434782608695654, "f": 0.2916666666666667, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a small plant growing out of a mug on a windowsill. The mug is blue and has a white handle. The plant is a small, brown tree with green leaves. The window is open and there is a view of the outside through it."}, "27530": {"image_id": 27530, "Bleu_1": 0.5384615384408284, "Bleu_2": 0.4150996173139321, "Bleu_3": 0.19291432368783407, "Bleu_4": 2.363694785201641e-05, "METEOR": 0.23885828373272414, "ROUGE_L": 0.3382624768946396, "CIDEr": 0.08031055834372593, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.12244897959183673, "f": 0.16, "fn": 43.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 20.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.07692307692307693, "f": 0.10526315789473684, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.3125, "f": 0.35714285714285715, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A car with a large backpack on top of it, parked on the side of the road.\""}, "331289": {"image_id": 331289, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.15070298814247132, "Bleu_3": 0.10942600553008858, "Bleu_4": 0.07119473298475835, "METEOR": 0.1835096533141051, "ROUGE_L": 0.25326215895610915, "CIDEr": 2.989019772542963e-11, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.18181818181818182, "f": 0.19999999999999998, "fn": 18.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a group of people riding bicycles on a street with tall buildings on either side. The people are wearing helmets and some are holding bags or other items. There are also cars and motorcycles driving on the road. The sky is blue and there are trees and greenery in the background."}, "27874": {"image_id": 27874, "Bleu_1": 0.5714285713877553, "Bleu_2": 0.29649972664244745, "Bleu_3": 0.19421783838169637, "Bleu_4": 2.856726515501468e-05, "METEOR": 0.26490872995656806, "ROUGE_L": 0.45252225519287836, "CIDEr": 0.8632859518430012, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.12, "f": 0.15384615384615383, "fn": 22.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.1111111111111111, "f": 0.19999999999999998, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "A train is parked at a train station with passengers getting on and off."}, "99416": {"image_id": 99416, "Bleu_1": 0.34482758619500603, "Bleu_2": 0.15694120513807777, "Bleu_3": 9.69847388558379e-07, "Bleu_4": 2.4337962273104214e-09, "METEOR": 0.19552748248664362, "ROUGE_L": 0.32649420160570913, "CIDEr": 0.005468527636461416, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.35, "f": 0.29787234042553196, "fn": 13.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6666666666666666, "f": 0.5714285714285715, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows two men standing next to each other, one wearing a suit and the other wearing a tie. They are both smiling and looking at each other."}, "206831": {"image_id": 206831, "Bleu_1": 0.3571428571343538, "Bleu_2": 0.26398183866786545, "Bleu_3": 0.2057560926437255, "Bleu_4": 0.16088986597188545, "METEOR": 0.2454611814730183, "ROUGE_L": 0.35328185328185324, "CIDEr": 8.998491799984034e-06, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.2, "f": 0.25641025641025644, "fn": 20.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.36363636363636365, "f": 0.4444444444444444, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a brown and white dog sitting in the grass with its mouth open, chewing on a bone. The dog is wearing a collar and tag around its neck. The background is a wooden fence with greenery growing on it."}, "171382": {"image_id": 171382, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.27439773622258, "Bleu_3": 0.20968727356426176, "Bleu_4": 0.16648830933698916, "METEOR": 0.289090455323286, "ROUGE_L": 0.42841707185305244, "CIDEr": 1.917920636862702e-08, "SPICE": {"All": {"pr": 0.12, "re": 0.14285714285714285, "f": 0.13043478260869565, "fn": 18.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.375, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a man in a black and white striped shirt and jeans standing on a skateboard, doing a trick in the middle of a busy street. There are several people walking by, looking at him in amazement. The sky is clear and blue, with some clouds in the distance."}, "113159": {"image_id": 113159, "Bleu_1": 0.31818181817458685, "Bleu_2": 0.17204158993311794, "Bleu_3": 0.11211985653831963, "Bleu_4": 1.3616513966805827e-05, "METEOR": 0.20100022362194236, "ROUGE_L": 0.20890410958904113, "CIDEr": 3.321080674799239e-07, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.14285714285714285, "f": 0.17543859649122806, "fn": 30.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.25, "f": 0.3, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The woman in the image is wearing a white tennis outfit and holding a tennis racket. She is standing on a tennis court with several tennis balls at her feet. The sun is setting in the background, casting a warm glow over the scene."}, "367569": {"image_id": 367569, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.25043516133286925, "Bleu_3": 0.1986553232654495, "Bleu_4": 0.14160105937297243, "METEOR": 0.31013350739263157, "ROUGE_L": 0.3647234678624813, "CIDEr": 5.563929990741914e-07, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.23809523809523808, "f": 0.2631578947368421, "fn": 16.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is a living room with a fireplace, a couch, and a coffee table. There are two windows on the wall opposite the fireplace, and a piano in the corner. The walls are painted white and the floor is made of hardwood."}, "412151": {"image_id": 412151, "Bleu_1": 0.22580645160926122, "Bleu_2": 0.14903177731519934, "Bleu_3": 0.10355615621127776, "Bleu_4": 0.07832969535702965, "METEOR": 0.21517088877893084, "ROUGE_L": 0.24621594349142278, "CIDEr": 5.89089444752953e-16, "SPICE": {"All": {"pr": 0.3125, "re": 0.2, "f": 0.24390243902439027, "fn": 20.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA man is working on his bicycle in a bike shop. He is wearing a blue shirt and jeans, and has a tool belt around his waist. There are several bicycles on the walls and shelves in the background, and a large window in the background shows a view of the city outside."}, "383406": {"image_id": 383406, "Bleu_1": 0.26229508196291323, "Bleu_2": 0.14784425418847072, "Bleu_3": 0.07182114038796941, "Bleu_4": 8.939891008573484e-06, "METEOR": 0.17195462300459705, "ROUGE_L": 0.24936126724578436, "CIDEr": 2.2709771280643494e-11, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.22727272727272727, "f": 0.20833333333333331, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a group of cats sleeping on top of a computer desk. The cats are all different colors and sizes, and they are all curled up together in a pile. There are some toys and other objects scattered around the desk, including a mouse and a keyboard. The overall mood of the image is one of relaxation and contentment."}, "301102": {"image_id": 301102, "Bleu_1": 0.17499999999781252, "Bleu_2": 0.13312219569589415, "Bleu_3": 0.08800537519261438, "Bleu_4": 9.699720447935918e-06, "METEOR": 0.17364377608550532, "ROUGE_L": 0.1560368349249659, "CIDEr": 2.2905867947998532e-30, "SPICE": {"All": {"pr": 0.04, "re": 0.043478260869565216, "f": 0.041666666666666664, "fn": 22.0, "numImages": 1.0, "fp": 24.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.1, "f": 0.09523809523809525, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "A pair of tennis rackets on a table\n\nThe image shows two tennis rackets on a table. One of the rackets is pink and the other is white. The pink racket has a black handle and the white racket has a black handle with white accents. The rackets are lying on their sides on the table, with the pink one on the left and the white one on the right. There is a small amount of space between the rackets."}, "499268": {"image_id": 499268, "Bleu_1": 0.30188679244713423, "Bleu_2": 0.18663625434394554, "Bleu_3": 0.12701286121266542, "Bleu_4": 0.08000981634230918, "METEOR": 0.26968296332736486, "ROUGE_L": 0.28355607205113303, "CIDEr": 1.545032900637762e-10, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.18518518518518517, "f": 0.22222222222222224, "fn": 22.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.45454545454545453, "f": 0.47619047619047616, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The woman is sitting on a bench in the park, looking at her phone. She is wearing black pants and a white shirt, and has her hair tied back in a ponytail. The bench is made of wood and has a metal frame. The trees in the background are green and have leaves."}, "201220": {"image_id": 201220, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.16624095289858323, "Bleu_3": 0.12082769166967569, "Bleu_4": 0.07869287296538219, "METEOR": 0.23323794266049241, "ROUGE_L": 0.26940063091482647, "CIDEr": 2.82178807484717e-10, "SPICE": {"All": {"pr": 0.3103448275862069, "re": 0.4090909090909091, "f": 0.35294117647058826, "fn": 13.0, "numImages": 1.0, "fp": 20.0, "tp": 9.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.8571428571428571, "f": 0.5714285714285714, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}}, "caption": "This image shows a bride and groom sitting in the back seat of a car. The bride is wearing a white wedding dress and the groom is wearing a black tuxedo. They are both smiling and looking at each other. The car is a white limousine with tinted windows."}, "24157": {"image_id": 24157, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.1624659147420524, "Bleu_3": 0.10182666119201575, "Bleu_4": 1.2115660853589845e-05, "METEOR": 0.22482322739405564, "ROUGE_L": 0.30049261083743845, "CIDEr": 5.519987714298516e-12, "SPICE": {"All": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.3333333333333333, "f": 0.4444444444444444, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "The image shows a group of people skiing down a snowy mountain slope. They are wearing snow gear and carrying skis on their backs. The sky is clear and blue, with a few clouds in the distance. The mountains in the background are covered in snow and have a rugged, rocky appearance."}, "356478": {"image_id": 356478, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.2102800206225174, "Bleu_3": 0.14132092548377867, "Bleu_4": 0.08850450893277763, "METEOR": 0.28358866761993345, "ROUGE_L": 0.28222075346992725, "CIDEr": 3.432504646678679e-10, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.17391304347826086, "f": 0.2352941176470588, "fn": 38.0, "numImages": 1.0, "fp": 14.0, "tp": 8.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.08333333333333333, "f": 0.1111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 16.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6363636363636364, "re": 0.3888888888888889, "f": 0.4827586206896552, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 7.0}}, "caption": "This is an image of a baby elephant walking on the dirt path. The elephant is small and has a trunk that is curled up. The elephant is walking towards the camera with its ears up and its tail down. There are trees in the background of the image."}, "384010": {"image_id": 384010, "Bleu_1": 0.7499999999375001, "Bleu_2": 0.4522670168272435, "Bleu_3": 0.3445666782598466, "Bleu_4": 0.25965358890901935, "METEOR": 0.24613184043879158, "ROUGE_L": 0.46212121212121204, "CIDEr": 0.9598201195855995, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.15789473684210525, "f": 0.15, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is a bowl of food with broccoli and fish on it."}, "184746": {"image_id": 184746, "Bleu_1": 0.31147540983095945, "Bleu_2": 0.21615113109550282, "Bleu_3": 0.1468614014499306, "Bleu_4": 0.11313684574728082, "METEOR": 0.19532408245043748, "ROUGE_L": 0.24936126724578436, "CIDEr": 1.0264574008273998e-13, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.08333333333333333, "f": 0.0930232558139535, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a person sitting at a table with a plate of food in front of them. There is a glass of water on the table and a fork and knife on the plate. The person is wearing a black hoodie and has their hands on the table. The background is a wooden wall with a window in the background."}, "280810": {"image_id": 280810, "Bleu_1": 0.692307692254438, "Bleu_2": 0.537086155486539, "Bleu_3": 0.37431888793482826, "Bleu_4": 4.785543920673609e-05, "METEOR": 0.3666246852422277, "ROUGE_L": 0.657935285053929, "CIDEr": 1.528484664456537, "SPICE": {"All": {"pr": 0.24, "re": 0.2727272727272727, "f": 0.2553191489361702, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.625, "f": 0.5263157894736842, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "This is a plate of food that includes a meat pie and broccoli."}, "402528": {"image_id": 402528, "Bleu_1": 0.37499999998437505, "Bleu_2": 0.18057877962096616, "Bleu_3": 1.1401716778849578e-06, "Bleu_4": 2.8984970515985937e-09, "METEOR": 0.22145156727971688, "ROUGE_L": 0.24497991967871482, "CIDEr": 0.08160299844962866, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.13636363636363635, "f": 0.1395348837209302, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.375, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a sandwich with lettuce, tomato, and ham on a plate. There is also a glass of orange juice on the table."}, "57403": {"image_id": 57403, "Bleu_1": 0.42499999998937504, "Bleu_2": 0.25570415597190493, "Bleu_3": 0.1509757946419843, "Bleu_4": 0.0982041999961109, "METEOR": 0.23425945110673435, "ROUGE_L": 0.34078212290502796, "CIDEr": 9.772265460113354e-06, "SPICE": {"All": {"pr": 0.18421052631578946, "re": 0.30434782608695654, "f": 0.22950819672131145, "fn": 16.0, "numImages": 1.0, "fp": 31.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.2727272727272727, "f": 0.18749999999999997, "fn": 8.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}}, "caption": "This is a black and white image of a desk with a computer, keyboard, mouse, and cup of coffee on it. The desk is in front of a window with blinds open, and there are two lamps on the desk."}, "156928": {"image_id": 156928, "Bleu_1": 0.5848076807365695, "Bleu_2": 0.44401909271299045, "Bleu_3": 0.3657155988043964, "Bleu_4": 0.31632090284112546, "METEOR": 0.43431531815758084, "ROUGE_L": 0.6742522756827047, "CIDEr": 0.16957083519783278, "SPICE": {"All": {"pr": 0.6666666666666666, "re": 0.17391304347826086, "f": 0.27586206896551724, "fn": 19.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.1111111111111111, "f": 0.19999999999999998, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.14285714285714285, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.75, "re": 0.42857142857142855, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image shows a white pickup truck parked in front of a house with a sign that reads \"Karaoke\" on it. There is also a statue of a horse on the porch of the house."}, "2261": {"image_id": 2261, "Bleu_1": 0.43589743588625907, "Bleu_2": 0.2623469285652076, "Bleu_3": 0.17737422037230524, "Bleu_4": 0.13269353023735384, "METEOR": 0.1885000761468359, "ROUGE_L": 0.2669584245076586, "CIDEr": 4.94904353118408e-05, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.14814814814814814, "f": 0.15686274509803924, "fn": 23.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.07692307692307693, "f": 0.09523809523809525, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "This is an image of a person surfing on a wave in the ocean. The person is wearing a wetsuit and holding onto the board as they ride the wave. The water is blue and the sky is cloudy."}, "416101": {"image_id": 416101, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.19999999999595922, "Bleu_3": 0.14938015821552278, "Bleu_4": 0.09176883572497656, "METEOR": 0.31166432070484656, "ROUGE_L": 0.2594167679222357, "CIDEr": 4.222580586884243e-10, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.1875, "f": 0.13636363636363635, "fn": 13.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.5, "f": 0.3157894736842105, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a man in a white shirt and black pants holding a tennis racket and standing on a tennis court. He is looking down at the ball in his hand and appears to be ready to hit it. The background is a white court with lines and nets."}, "34080": {"image_id": 34080, "Bleu_1": 0.6999999998600002, "Bleu_2": 0.6236095643341374, "Bleu_3": 0.5793377740249008, "Bleu_4": 0.5372849657937071, "METEOR": 0.36339386936543017, "ROUGE_L": 0.7000000000000001, "CIDEr": 3.3543980642792413, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.14285714285714285, "f": 0.14545454545454545, "fn": 24.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "A small pair of scissors sitting on a wooden table."}, "178084": {"image_id": 178084, "Bleu_1": 0.4210526315678671, "Bleu_2": 0.3017257145538383, "Bleu_3": 0.17165272987504965, "Bleu_4": 0.10964050440666685, "METEOR": 0.25975130110185995, "ROUGE_L": 0.3658170914542728, "CIDEr": 5.410284432519779e-05, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.08695652173913043, "f": 0.08163265306122448, "fn": 21.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "This is an image of a motorcycle parked in a garage. The motorcycle is black and has a sleek design. There are several other motorcycles parked nearby, and the garage appears to be well organized and well maintained."}, "133999": {"image_id": 133999, "Bleu_1": 0.22727272726756204, "Bleu_2": 0.12592155012443357, "Bleu_3": 0.07227425284747027, "Bleu_4": 9.795841373567018e-06, "METEOR": 0.17875847590237356, "ROUGE_L": 0.18047337278106512, "CIDEr": 9.129481867123891e-08, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.2, "f": 0.14634146341463417, "fn": 12.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is an image of a city street with several buses parked on the side of the road. The buildings on either side of the street are tall and modern, with large windows and balconies. There are also several pedestrians walking on the sidewalk."}, "280911": {"image_id": 280911, "Bleu_1": 0.3928571428431123, "Bleu_2": 0.20892772350173638, "Bleu_3": 0.11885193737704458, "Bleu_4": 1.6097917483901073e-05, "METEOR": 0.2633292356599742, "ROUGE_L": 0.2978515625, "CIDEr": 0.0051180744668195815, "SPICE": {"All": {"pr": 0.46153846153846156, "re": 0.3, "f": 0.3636363636363637, "fn": 14.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.8333333333333334, "re": 0.625, "f": 0.7142857142857143, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 5.0}}, "caption": "The image shows two elephants standing in a green field with trees in the background. They are both looking down and appear to be grazing on the grass."}, "409496": {"image_id": 409496, "Bleu_1": 0.34146341462581803, "Bleu_2": 0.22631728213415833, "Bleu_3": 0.10951079799876592, "Bleu_4": 1.3634738359895023e-05, "METEOR": 0.2722984434553055, "ROUGE_L": 0.2713120830244626, "CIDEr": 3.586405284032479e-07, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.17391304347826086, "f": 0.1951219512195122, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The man is standing in front of a wooden fence, holding a large surfboard. He is wearing a white shirt and shorts, and has a friendly smile on his face. The background is a green field with trees in the distance."}, "467437": {"image_id": 467437, "Bleu_1": 0.1481481481463192, "Bleu_2": 0.060858061944262444, "Bleu_3": 3.605811738200387e-07, "Bleu_4": 8.80498530434062e-10, "METEOR": 0.16294263977179177, "ROUGE_L": 0.17903563941299788, "CIDEr": 7.563658366766418e-31, "SPICE": {"All": {"pr": 0.06896551724137931, "re": 0.06451612903225806, "f": 0.06666666666666667, "fn": 29.0, "numImages": 1.0, "fp": 27.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.13333333333333333, "re": 0.18181818181818182, "f": 0.15384615384615383, "fn": 9.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}}, "caption": "The image shows a man and a woman lying in bed together, both of them are sleeping. The man is wearing a white shirt and pants, while the woman is wearing a blue nightgown. The bed is made of wood and has a white sheet on it. There is a window on the wall behind the bed, with curtains open to let in natural light. The room is decorated with a few pieces of furniture, including a dresser and a nightstand."}, "293964": {"image_id": 293964, "Bleu_1": 0.34146341462581803, "Bleu_2": 0.2771809306010938, "Bleu_3": 0.22779163936673777, "Bleu_4": 0.19858659849333718, "METEOR": 0.34156756283710626, "ROUGE_L": 0.3617494440326167, "CIDEr": 8.507645226429963e-07, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.23076923076923078, "f": 0.2790697674418605, "fn": 20.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.08333333333333333, "f": 0.11764705882352941, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.36363636363636365, "f": 0.4444444444444444, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "This is a black and white image of a restaurant with a long counter and several tables. There are several people standing behind the counter, preparing food. The lighting in the image is dim, and the atmosphere is quiet and peaceful."}, "436426": {"image_id": 436426, "Bleu_1": 0.36111111110108035, "Bleu_2": 0.3368858315300131, "Bleu_3": 0.2858873057147094, "Bleu_4": 0.23069207037172892, "METEOR": 0.268754814048806, "ROUGE_L": 0.37654320987654316, "CIDEr": 0.00015701250332649707, "SPICE": {"All": {"pr": 0.5, "re": 0.15, "f": 0.23076923076923075, "fn": 17.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}}, "caption": "A cell phone is sitting on top of a table next to a vase. The phone has a black case and is turned off. There is a book lying on the table next to the phone."}, "80213": {"image_id": 80213, "Bleu_1": 0.6923076922011837, "Bleu_2": 0.4803844613398166, "Bleu_3": 0.2758005147163744, "Bleu_4": 3.805803001048077e-05, "METEOR": 0.3096184922551231, "ROUGE_L": 0.5150784077201447, "CIDEr": 1.6439145580158008, "SPICE": {"All": {"pr": 0.5625, "re": 0.3333333333333333, "f": 0.4186046511627907, "fn": 18.0, "numImages": 1.0, "fp": 7.0, "tp": 9.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8571428571428571, "re": 0.5, "f": 0.631578947368421, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 6.0}}, "caption": "The cat is sitting on top of the couch wearing a black hat."}, "167583": {"image_id": 167583, "Bleu_1": 0.4999999999750001, "Bleu_2": 0.32444284224487613, "Bleu_3": 0.18016397830290895, "Bleu_4": 2.4218026051569858e-05, "METEOR": 0.2689742109894843, "ROUGE_L": 0.40848214285714285, "CIDEr": 0.19796942217281457, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.17857142857142858, "f": 0.22222222222222224, "fn": 23.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.45454545454545453, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A colorful display of fresh fruits and vegetables in a market\""}, "547227": {"image_id": 547227, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.23957871187003724, "Bleu_3": 0.15416056119190602, "Bleu_4": 1.679927363038273e-05, "METEOR": 0.2201136001803434, "ROUGE_L": 0.28110599078341014, "CIDEr": 1.1574723694164004e-09, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.2857142857142857, "f": 0.2727272727272727, "fn": 15.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is an image of a street with a clock tower in the center. The clock tower has a large clock face on it and is surrounded by buildings with windows and doors. There are cars parked along the side of the street and people walking on the sidewalk."}, "223374": {"image_id": 223374, "Bleu_1": 0.35294117646020773, "Bleu_2": 0.3102526139877483, "Bleu_3": 0.20819360802658496, "Bleu_4": 0.13062013259021196, "METEOR": 0.3022996936550822, "ROUGE_L": 0.4520378756689996, "CIDEr": 0.0003497740356675706, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.17647058823529413, "f": 0.17142857142857143, "fn": 14.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is a black and white image of a microwave oven with a plate of food on top of it. There are several toy cars and trucks on the counter next to the microwave."}, "106901": {"image_id": 106901, "Bleu_1": 0.6071428571211734, "Bleu_2": 0.4241393401714729, "Bleu_3": 0.2748242215724415, "Bleu_4": 0.20186626686264555, "METEOR": 0.2760628865802841, "ROUGE_L": 0.4452554744525547, "CIDEr": 0.0095946553779862, "SPICE": {"All": {"pr": 0.1388888888888889, "re": 0.13513513513513514, "f": 0.136986301369863, "fn": 32.0, "numImages": 1.0, "fp": 31.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.29411764705882354, "re": 0.38461538461538464, "f": 0.33333333333333337, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}}, "caption": "This is a small, white building with a blue door and a bench in front of it. There are no windows or other details visible on the building."}, "420852": {"image_id": 420852, "Bleu_1": 0.2903225806357961, "Bleu_2": 0.19674775072873343, "Bleu_3": 0.11010503638215555, "Bleu_4": 1.4776306152176402e-05, "METEOR": 0.17218334479138217, "ROUGE_L": 0.24537409493161708, "CIDEr": 0.002218907946436549, "SPICE": {"All": {"pr": 0.4444444444444444, "re": 0.25, "f": 0.32, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.5714285714285714, "f": 0.6666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "This is an image of a street with a power line in the foreground and a building in the background. The sky is blue and there are clouds in the sky."}, "215151": {"image_id": 215151, "Bleu_1": 0.3888888888780865, "Bleu_2": 0.18257418582991147, "Bleu_3": 0.0993420862130566, "Bleu_4": 1.3128692369069765e-05, "METEOR": 0.2129370782509162, "ROUGE_L": 0.31213450292397665, "CIDEr": 0.00017152004216207018, "SPICE": {"All": {"pr": 0.4375, "re": 0.1590909090909091, "f": 0.23333333333333334, "fn": 37.0, "numImages": 1.0, "fp": 9.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.047619047619047616, "f": 0.07142857142857142, "fn": 20.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.2857142857142857, "f": 0.4444444444444445, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5714285714285714, "re": 0.25, "f": 0.34782608695652173, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a group of people standing on a skateboard ramp, with one person jumping over the railing while another person watches. The background is a city street with buildings and cars in the distance."}, "549568": {"image_id": 549568, "Bleu_1": 0.32432432431555885, "Bleu_2": 0.189831599145298, "Bleu_3": 0.10097712220824674, "Bleu_4": 1.3191601177260918e-05, "METEOR": 0.2636978924613325, "ROUGE_L": 0.27706283118849356, "CIDEr": 2.8985257406547206e-05, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.23529411764705882, "f": 0.21052631578947367, "fn": 13.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.6666666666666666, "f": 0.36363636363636365, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a street with several parked cars and a pedestrian crossing. There are buildings on either side of the street, and a few people are walking on the sidewalk. The sky is clear and blue."}, "124940": {"image_id": 124940, "Bleu_1": 0.6297017414153193, "Bleu_2": 0.4882583110666058, "Bleu_3": 0.371323010438372, "Bleu_4": 0.2750918124632971, "METEOR": 0.3140962751881377, "ROUGE_L": 0.52876280535855, "CIDEr": 0.3981797938887813, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.13333333333333333, "f": 0.18181818181818182, "fn": 26.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image shows a piece of toast with peanut butter and jelly on it. There is also a knife on the cutting board next to the toast."}, "372428": {"image_id": 372428, "Bleu_1": 0.48717948716699544, "Bleu_2": 0.2773500981054095, "Bleu_3": 0.16080330592584718, "Bleu_4": 1.8435104536393853e-05, "METEOR": 0.25877956735086294, "ROUGE_L": 0.24148851939825808, "CIDEr": 5.03958922303396e-05, "SPICE": {"All": {"pr": 0.3125, "re": 0.21739130434782608, "f": 0.2564102564102564, "fn": 18.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.16666666666666666, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a group of cows standing in a field next to a river. They are all wearing white sunglasses and looking at the camera. In the background, there are several white chairs set up on the grass."}, "79356": {"image_id": 79356, "Bleu_1": 0.1839080459748976, "Bleu_2": 0.1667334803241343, "Bleu_3": 0.14843702280001286, "Bleu_4": 0.13284932483117814, "METEOR": 0.288824650645808, "ROUGE_L": 0.2609879424348503, "CIDEr": 5.781116496038117e-33, "SPICE": {"All": {"pr": 0.4, "re": 0.125, "f": 0.19047619047619047, "fn": 14.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.2857142857142857, "f": 0.4, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "The image shows a group of people riding on the back of an elephant. The elephant is standing in the middle of a forest, surrounded by trees and a lake in the background. The people are sitting on the elephant's back, with one person holding onto the elephant's ears and another person holding onto the elephant's tail. The elephant is wearing a saddle and has a harness around its body. The people are all smiling and looking happy as they ride on the elephant."}, "13465": {"image_id": 13465, "Bleu_1": 0.1739130434744802, "Bleu_2": 0.06216698721465449, "Bleu_3": 4.44517628108609e-07, "Bleu_4": 1.1955001291193746e-09, "METEOR": 0.12996684805352432, "ROUGE_L": 0.17428571428571427, "CIDEr": 2.68617958646462e-05, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.18181818181818182, "f": 0.24242424242424246, "fn": 18.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image shows a skateboarder jumping off a staircase in front of a building. The skateboarder is wearing a red shirt and black pants, and the building has a blue and white awning on top. The sky is cloudy and there are trees in the background."}, "558213": {"image_id": 558213, "Bleu_1": 0.32499999999187507, "Bleu_2": 0.24152294576370853, "Bleu_3": 0.1663737545180078, "Bleu_4": 0.1056241390458418, "METEOR": 0.24071313162872826, "ROUGE_L": 0.32250755287009064, "CIDEr": 2.6374691480612566e-06, "SPICE": {"All": {"pr": 0.14705882352941177, "re": 0.2, "f": 0.16949152542372883, "fn": 20.0, "numImages": 1.0, "fp": 29.0, "tp": 5.0}, "Relation": {"pr": 0.07142857142857142, "re": 0.1111111111111111, "f": 0.08695652173913043, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.36363636363636365, "f": 0.2962962962962963, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}}, "caption": "The image shows a man standing on top of a skateboard, wearing a black shirt and jeans, and holding a piece of paper in his hand. The background is a fenced in area with a large building in the distance."}, "517296": {"image_id": 517296, "Bleu_1": 0.26785714285235973, "Bleu_2": 0.120873444601629, "Bleu_3": 6.467791518167733e-07, "Bleu_4": 1.5031351890910523e-09, "METEOR": 0.17547517776614793, "ROUGE_L": 0.2401574803149606, "CIDEr": 1.2514660001734826e-13, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.35294117647058826, "f": 0.34285714285714286, "fn": 11.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA group of people are standing in front of a bus stop on a city street. The bus stop has a sign that reads \"Bus Stop\" and there are several people waiting for the bus to arrive. The sky is cloudy and there are some trees nearby."}, "134722": {"image_id": 134722, "Bleu_1": 0.27027027026296574, "Bleu_2": 0.19374606456772306, "Bleu_3": 0.1289662020068933, "Bleu_4": 0.08912246776433805, "METEOR": 0.25644214016890726, "ROUGE_L": 0.332295719844358, "CIDEr": 3.123167800507476e-05, "SPICE": {"All": {"pr": 0.25, "re": 0.3125, "f": 0.2777777777777778, "fn": 11.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "A train is pulling into a station with a brick building in the background. The train is white and has a blue stripe on the side. There are people standing on the platform looking at the train."}, "414661": {"image_id": 414661, "Bleu_1": 0.33333333332407417, "Bleu_2": 0.13801311186458243, "Bleu_3": 0.08243669901955125, "Bleu_4": 1.1414633188359127e-05, "METEOR": 0.2014722735669895, "ROUGE_L": 0.2839851024208566, "CIDEr": 4.2650802728027434e-05, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.17391304347826086, "f": 0.1904761904761905, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a group of people skateboarding on a concrete ramp in a park. One person is doing a trick on the ramp while the others watch. There are trees and houses in the background."}, "167353": {"image_id": 167353, "Bleu_1": 0.3170731707239739, "Bleu_2": 0.21808478994970526, "Bleu_3": 0.10683872974718221, "Bleu_4": 1.3384453330858416e-05, "METEOR": 0.2679930937668944, "ROUGE_L": 0.30049261083743845, "CIDEr": 9.455595228817258e-07, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.10344827586206896, "f": 0.15789473684210528, "fn": 26.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.23076923076923078, "f": 0.3529411764705882, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "This is a large, ornate clock hanging on the wall of a room. It has a large face with Roman numerals and hands that are pointing to the time. The clock is surrounded by intricate carvings and has a wooden frame."}, "260150": {"image_id": 260150, "Bleu_1": 0.41666666665509267, "Bleu_2": 0.3273268353447663, "Bleu_3": 0.21144715867028854, "Bleu_4": 0.1300986845270742, "METEOR": 0.35074894294674, "ROUGE_L": 0.37654320987654316, "CIDEr": 0.02246899903541565, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.18181818181818182, "f": 0.17391304347826086, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.2727272727272727, "f": 0.3157894736842105, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a person holding a plate with pancakes on it. The person is wearing a white shirt and has a fork in their hand. There is a window in the background with trees outside."}, "541991": {"image_id": 541991, "Bleu_1": 0.40624999998730477, "Bleu_2": 0.2559769394774182, "Bleu_3": 0.18712589684530032, "Bleu_4": 0.1226029504479948, "METEOR": 0.23959916130686862, "ROUGE_L": 0.32562277580071175, "CIDEr": 0.003156943745124183, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.30434782608695654, "f": 0.31818181818181823, "fn": 16.0, "numImages": 1.0, "fp": 14.0, "tp": 7.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.5555555555555556, "f": 0.5882352941176471, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image shows a sheep standing on a grassy hillside, looking out over a valley with mountains in the background. The sky is cloudy and there are some clouds in the distance."}, "439132": {"image_id": 439132, "Bleu_1": 0.305555555547068, "Bleu_2": 0.2472066162295572, "Bleu_3": 0.19300434438611871, "Bleu_4": 0.15989214998480095, "METEOR": 0.3425874534325951, "ROUGE_L": 0.39869281045751637, "CIDEr": 5.749186915521949e-05, "SPICE": {"All": {"pr": 0.043478260869565216, "re": 0.05263157894736842, "f": 0.04761904761904762, "fn": 18.0, "numImages": 1.0, "fp": 22.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.125, "f": 0.10526315789473685, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows a black cat sitting in a flower pot on a windowsill. The cat is looking up at the camera with its eyes. The background is a greenhouse with plants and flowers growing inside."}, "256713": {"image_id": 256713, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.1624659147420524, "Bleu_3": 0.11656242933815306, "Bleu_4": 0.07539975290832036, "METEOR": 0.2778386189560819, "ROUGE_L": 0.3380541871921182, "CIDEr": 1.5807107304591297e-10, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.22727272727272727, "f": 0.23255813953488372, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "This is a bathroom with a white bathtub, a white sink, and a white toilet. There is a large mirror on the wall above the sink and a window with curtains in the background. The floor is made of hardwood and there are two wooden chairs in the corner of the room."}, "149832": {"image_id": 149832, "Bleu_1": 0.9090909090082646, "Bleu_2": 0.5222329678172442, "Bleu_3": 0.3117659538504856, "Bleu_4": 4.4116293588517445e-05, "METEOR": 0.3044066648555698, "ROUGE_L": 0.5897518530454399, "CIDEr": 1.9549233868320854, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.21052631578947367, "f": 0.1904761904761905, "fn": 15.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.6666666666666666, "f": 0.4705882352941177, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "A field of cows grazing on green grass in the countryside."}, "285212": {"image_id": 285212, "Bleu_1": 0.25714285713918367, "Bleu_2": 0.17266633891820174, "Bleu_3": 0.12990488546029308, "Bleu_4": 0.09953612427684536, "METEOR": 0.23748639542366182, "ROUGE_L": 0.23127962085308057, "CIDEr": 1.902397722928336e-17, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.23529411764705882, "f": 0.26666666666666666, "fn": 13.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "A small dog is sitting on the floor next to a woman who is wearing sneakers and has a laptop on her lap. The dog is looking up at the woman with its ears perked up. There are several other people in the background, some of whom are sitting at tables and others who are standing. The room appears to be a classroom or office with wooden chairs and tables."}, "120747": {"image_id": 120747, "Bleu_1": 0.5333333333155555, "Bleu_2": 0.3835706411753012, "Bleu_3": 0.25073674295394976, "Bleu_4": 0.18485450667838474, "METEOR": 0.38076947284664964, "ROUGE_L": 0.4959349593495934, "CIDEr": 0.0507545791675436, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.36363636363636365, "f": 0.32, "fn": 14.0, "numImages": 1.0, "fp": 20.0, "tp": 8.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5555555555555556, "f": 0.4545454545454546, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "This is a living room with a couch, coffee table, and TV. There are two people sitting on the couch watching TV. The room has hardwood floors and a fireplace."}, "327314": {"image_id": 327314, "Bleu_1": 0.26315789472991696, "Bleu_2": 0.16866980207552001, "Bleu_3": 0.13334123550086785, "Bleu_4": 0.10788569011232613, "METEOR": 0.2376773116363106, "ROUGE_L": 0.39725036179450074, "CIDEr": 2.5322796065483687e-05, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.2, "f": 0.21739130434782608, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.08333333333333333, "f": 0.0909090909090909, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a gray scooter parked on the sidewalk in front of a building with a sign that reads \"Fashion Show\" in French. There are people walking by on the sidewalk and a few bicycles parked nearby."}, "431236": {"image_id": 431236, "Bleu_1": 0.6999999998600002, "Bleu_2": 0.6236095643341374, "Bleu_3": 0.364959928246606, "Bleu_4": 5.133450479273673e-05, "METEOR": 0.22968393476142077, "ROUGE_L": 0.5313588850174217, "CIDEr": 0.6777404457013058, "SPICE": {"All": {"pr": 0.16, "re": 0.12903225806451613, "f": 0.14285714285714285, "fn": 27.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "A small kitchen with white appliances and a white sink."}, "186991": {"image_id": 186991, "Bleu_1": 0.3571428571343538, "Bleu_2": 0.26398183866786545, "Bleu_3": 0.19100703641258254, "Bleu_4": 0.13749229838123656, "METEOR": 0.3237138711389214, "ROUGE_L": 0.3551673944687045, "CIDEr": 1.069245909908316e-06, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.18181818181818182, "f": 0.21621621621621623, "fn": 18.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a zebra standing in a field with other zebras in the background. The zebra is eating grass from the ground and looks healthy and happy. The trees in the background are tall and green, providing shade for the zebras."}, "170974": {"image_id": 170974, "Bleu_1": 0.35294117646020773, "Bleu_2": 0.3102526139877483, "Bleu_3": 0.26230750920625656, "Bleu_4": 0.2196760025101482, "METEOR": 0.3450391150579131, "ROUGE_L": 0.36371379897785344, "CIDEr": 0.0006422253663382936, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 15.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "This is an image of a group of people standing around a table with a video game console on it. They are all looking at the screen and have their hands on their hips."}, "453622": {"image_id": 453622, "Bleu_1": 0.35135135134185547, "Bleu_2": 0.3124061420526953, "Bleu_3": 0.2406838939215381, "Bleu_4": 0.18728192138265748, "METEOR": 0.3292286973867957, "ROUGE_L": 0.39071257005604487, "CIDEr": 9.445692252231055e-05, "SPICE": {"All": {"pr": 0.5, "re": 0.1111111111111111, "f": 0.1818181818181818, "fn": 24.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.3, "f": 0.4285714285714285, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "This is a living room with a couch, coffee table, and chairs. There is a ceiling fan in the room and a window on the wall. The walls are painted white and there is a hardwood floor."}, "116068": {"image_id": 116068, "Bleu_1": 0.2647058823490484, "Bleu_2": 0.17778265528115397, "Bleu_3": 0.09857231259143596, "Bleu_4": 1.1017622045922306e-05, "METEOR": 0.16238558549314164, "ROUGE_L": 0.19695571955719554, "CIDEr": 4.1015450588075514e-15, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.19047619047619047, "f": 0.23529411764705882, "fn": 17.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a group of people standing on the beach, holding kites. One person is holding a kite and another person is holding a stick to help launch it. The kite is made of colorful fabric and has a long tail. The people are standing in front of the water, which is calm and clear. The sky is blue and there are some clouds in the distance."}, "324139": {"image_id": 324139, "Bleu_1": 0.8181818181074382, "Bleu_2": 0.7006490496784906, "Bleu_3": 0.546965507537804, "Bleu_4": 0.37817904272487507, "METEOR": 0.3122237775579143, "ROUGE_L": 0.6902404526166903, "CIDEr": 1.6902346473433794, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.20833333333333334, "f": 0.1818181818181818, "fn": 19.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.4444444444444444, "f": 0.33333333333333337, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "A group of seagulls perched on a bench in a park."}, "410576": {"image_id": 410576, "Bleu_1": 0.4193548386961499, "Bleu_2": 0.23646136786155197, "Bleu_3": 1.2446315310421905e-06, "Bleu_4": 2.8806539591625907e-09, "METEOR": 0.1872725947879308, "ROUGE_L": 0.3464432770126366, "CIDEr": 0.03420970024757054, "SPICE": {"All": {"pr": 0.2, "re": 0.13793103448275862, "f": 0.16326530612244897, "fn": 25.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is an image of a room with a desk, chair, and computer in the center. The walls are painted red and there are some books and papers on the desk."}, "201463": {"image_id": 201463, "Bleu_1": 0.49999999998611117, "Bleu_2": 0.33806170188188195, "Bleu_3": 0.21604526952247782, "Bleu_4": 0.15723078586343264, "METEOR": 0.30063125581824685, "ROUGE_L": 0.4121621621621622, "CIDEr": 0.00020813805227173866, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.1935483870967742, "f": 0.22641509433962262, "fn": 25.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.5, "re": 0.3076923076923077, "f": 0.380952380952381, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows two men standing in a bathroom, one with a toothbrush in his mouth and the other with a toothbrush in his hand. They are both wearing white robes and looking at each other."}, "12670": {"image_id": 12670, "Bleu_1": 0.22413793103061835, "Bleu_2": 0.1659087424695837, "Bleu_3": 0.12527666086006603, "Bleu_4": 0.10176355452480418, "METEOR": 0.17244074895214515, "ROUGE_L": 0.2406989853438557, "CIDEr": 1.210700315705694e-13, "SPICE": {"All": {"pr": 0.25, "re": 0.5555555555555556, "f": 0.3448275862068966, "fn": 8.0, "numImages": 1.0, "fp": 30.0, "tp": 10.0}, "Relation": {"pr": 0.07142857142857142, "re": 0.3333333333333333, "f": 0.11764705882352941, "fn": 2.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.23076923076923078, "re": 0.42857142857142855, "f": 0.3, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.75, "f": 0.5714285714285714, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image shows a large crowd of people standing on a street. They are all wearing different colored t-shirts and hoodies, and some of them are holding signs and banners. There are also several police officers standing on the street, directing traffic and controlling the crowd. The atmosphere is lively and festive, with people chatting and taking pictures."}, "410023": {"image_id": 410023, "Bleu_1": 0.18032786884950286, "Bleu_2": 0.10964423342383232, "Bleu_3": 0.05884458799865846, "Bleu_4": 7.698797497340994e-06, "METEOR": 0.16428262048585554, "ROUGE_L": 0.16495402920497565, "CIDEr": 2.1017314003674724e-15, "SPICE": {"All": {"pr": 0.5714285714285714, "re": 0.19047619047619047, "f": 0.2857142857142857, "fn": 17.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.375, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image shows a group of teddy bears sitting in a room with a table and chairs. The bears are wearing different outfits and accessories, such as hats and scarves. There is a vase of flowers on the table and a small tablecloth on the table. The bears are looking at each other and seem to be enjoying their time together."}, "71301": {"image_id": 71301, "Bleu_1": 0.3809523809433107, "Bleu_2": 0.23611253443469188, "Bleu_3": 0.1407351877211811, "Bleu_4": 0.09194664155137737, "METEOR": 0.22530209528356368, "ROUGE_L": 0.25957446808510637, "CIDEr": 9.59787612525005e-06, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 12.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.6666666666666666, "f": 0.5333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A group of people are standing on a snowy slope, watching as someone jumps off a ramp and lands on the ground below. The crowd is cheering and taking photos of the event.\""}, "435533": {"image_id": 435533, "Bleu_1": 0.1538461538431953, "Bleu_2": 0.10984700727408482, "Bleu_3": 0.07844142656278796, "Bleu_4": 0.05602219133569573, "METEOR": 0.17059630786511626, "ROUGE_L": 0.23047858942065497, "CIDEr": 1.2990921610651373e-11, "SPICE": {"All": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 24.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "A bathroom with a toilet, sink, and shower\n\nThe bathroom has a toilet, sink, and shower. The toilet is on the left side of the room and the sink is on the right side. The shower is in the back of the room. There is a hose attached to the shower head."}, "546378": {"image_id": 546378, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.23262966005988533, "Bleu_3": 0.18184270686072843, "Bleu_4": 0.12857787545454705, "METEOR": 0.25955717886185437, "ROUGE_L": 0.29067392784206936, "CIDEr": 5.232574874711644e-09, "SPICE": {"All": {"pr": 0.09375, "re": 0.15, "f": 0.11538461538461538, "fn": 17.0, "numImages": 1.0, "fp": 29.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}}, "caption": "This is a picture of a cat sitting on top of a bookshelf. The cat is gray and has a white collar around its neck. It is looking up at the camera with its eyes closed. There are several books on the shelf next to the cat."}, "518203": {"image_id": 518203, "Bleu_1": 0.5555555555349795, "Bleu_2": 0.38674623406228154, "Bleu_3": 0.31042788609877586, "Bleu_4": 0.24728515686141225, "METEOR": 0.31886256431988924, "ROUGE_L": 0.3986928104575163, "CIDEr": 0.04583336077241913, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.1875, "f": 0.16216216216216214, "fn": 13.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a red and white airplane taking off from a runway in the distance. The plane is surrounded by buildings and trees in the background."}, "121016": {"image_id": 121016, "Bleu_1": 0.5429024507129954, "Bleu_2": 0.4046555949795809, "Bleu_3": 0.26457606599748784, "Bleu_4": 3.933517112506113e-05, "METEOR": 0.25867829462890474, "ROUGE_L": 0.5366568914956013, "CIDEr": 1.3743896458193174, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.22580645161290322, "f": 0.2692307692307692, "fn": 24.0, "numImages": 1.0, "fp": 14.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.13333333333333333, "f": 0.2222222222222222, "fn": 13.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.625, "f": 0.5555555555555556, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "This is a pan with broccoli and beef in it."}, "381031": {"image_id": 381031, "Bleu_1": 0.5428571428416327, "Bleu_2": 0.39957961101257494, "Bleu_3": 0.26848347708282555, "Bleu_4": 0.1568197214685799, "METEOR": 0.2785213637892876, "ROUGE_L": 0.32670237184391737, "CIDEr": 0.002837527283492792, "SPICE": {"All": {"pr": 0.46153846153846156, "re": 0.21428571428571427, "f": 0.2926829268292683, "fn": 22.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}, "Relation": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.07692307692307693, "f": 0.125, "fn": 12.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.2, "f": 0.33333333333333337, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "This image shows a table with a bowl of fruit and a glass of juice. There are also several other items on the table, including a jar of peanut butter and a plate of bread."}, "381630": {"image_id": 381630, "Bleu_1": 0.22727272726756204, "Bleu_2": 0.14540168172223333, "Bleu_3": 7.954810829018741e-07, "Bleu_4": 1.871873206790386e-09, "METEOR": 0.18404146631860863, "ROUGE_L": 0.23890339425587467, "CIDEr": 4.254671036493121e-08, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.175, "f": 0.21875, "fn": 33.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.11764705882352941, "f": 0.2, "fn": 15.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.4166666666666667, "f": 0.43478260869565216, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "This is an image of a train on a track, with buildings in the background. The train is traveling through a tunnel, with the sun shining through the windows. There are people standing on the platform, looking at the train as it passes by."}, "241837": {"image_id": 241837, "Bleu_1": 0.30952380951644, "Bleu_2": 0.26066118020872475, "Bleu_3": 0.20402696809840276, "Bleu_4": 0.14446313293436042, "METEOR": 0.3225345833918702, "ROUGE_L": 0.3551673944687045, "CIDEr": 9.990533847105471e-07, "SPICE": {"All": {"pr": 0.1, "re": 0.09090909090909091, "f": 0.09523809523809525, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a man standing next to a dog on a skateboard in a park. The man is wearing a blue shirt and jeans, and the dog is wearing a red collar. The park has trees and grass in the background."}, "91495": {"image_id": 91495, "Bleu_1": 0.18867924527945892, "Bleu_2": 0.10433283794475068, "Bleu_3": 5.976183926619197e-07, "Bleu_4": 1.4373928004601428e-09, "METEOR": 0.16251328955083102, "ROUGE_L": 0.17183098591549298, "CIDEr": 8.260796286144367e-11, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.1, "f": 0.10169491525423728, "fn": 27.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2727272727272727, "f": 0.23076923076923075, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "The image shows a baseball player sliding into home plate while another player is tagging him out. The player on the left is wearing a white jersey and pants, while the player on the right is wearing a black jersey and pants. The background is a dark green field with a dirt infield."}, "132024": {"image_id": 132024, "Bleu_1": 0.3333333333247864, "Bleu_2": 0.22941573386460196, "Bleu_3": 0.14169620653049472, "Bleu_4": 1.6766524290532757e-05, "METEOR": 0.2391278798835691, "ROUGE_L": 0.2683677958644963, "CIDEr": 3.9785439382021e-05, "SPICE": {"All": {"pr": 0.5, "re": 0.15384615384615385, "f": 0.23529411764705882, "fn": 22.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.23076923076923078, "f": 0.3529411764705882, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image shows a person skiing down a snowy slope with mountains in the background. The person is wearing a red and white suit and holding skis. The sky is blue and there are some clouds in the background."}, "356400": {"image_id": 356400, "Bleu_1": 0.1538461538441815, "Bleu_2": 0.0999500374674876, "Bleu_3": 0.08071187576015698, "Bleu_4": 0.06119208672953315, "METEOR": 0.20552699485492512, "ROUGE_L": 0.18777484608619172, "CIDEr": 6.68593461967427e-30, "SPICE": {"All": {"pr": 0.125, "re": 0.07692307692307693, "f": 0.09523809523809525, "fn": 24.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "This is a kitchen with a large island in the center of the room. The walls are made of stone and there is a large window above the sink. The cabinets are made of wood and the countertops are made of granite. There is a large stove in the corner of the room and a refrigerator on the wall. The floor is made of tile and there is a large wooden table in the center of the room."}, "146112": {"image_id": 146112, "Bleu_1": 0.26027397259917434, "Bleu_2": 0.17005684428565496, "Bleu_3": 0.10690968397939424, "Bleu_4": 1.1494452087472036e-05, "METEOR": 0.18811041773271286, "ROUGE_L": 0.2630341042728342, "CIDEr": 1.0350174098946773e-15, "SPICE": {"All": {"pr": 0.12, "re": 0.2, "f": 0.15, "fn": 12.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a man standing on a stage in front of a group of people. He is wearing a black shirt and pants, and has a microphone in his hand. There are several bicycles parked on the stage behind him. The room is filled with tables and chairs, and there are several people sitting at them. The walls are painted a light blue color, and there are several posters on the walls."}, "413810": {"image_id": 413810, "Bleu_1": 0.5698222021537606, "Bleu_2": 0.3631918160063906, "Bleu_3": 2.230954526496004e-06, "Bleu_4": 5.662604394362829e-09, "METEOR": 0.20760470263747868, "ROUGE_L": 0.39804241435562804, "CIDEr": 0.3442202729446681, "SPICE": {"All": {"pr": 0.0625, "re": 0.08695652173913043, "f": 0.07272727272727272, "fn": 21.0, "numImages": 1.0, "fp": 30.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "A person skiing down a snowy mountain slope with trees in the background."}, "534444": {"image_id": 534444, "Bleu_1": 0.4074074073923183, "Bleu_2": 0.30662207032435856, "Bleu_3": 0.22428282780473585, "Bleu_4": 0.14724623770370476, "METEOR": 0.2887675538674008, "ROUGE_L": 0.31671858774662515, "CIDEr": 0.009912281256296387, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.10256410256410256, "f": 0.14814814814814814, "fn": 35.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 16.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3076923076923077, "f": 0.3636363636363637, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "Sure, here is a short caption for the image:\n\n\"A group of people are flying kites on a beach with a clear blue sky in the background.\""}, "527164": {"image_id": 527164, "Bleu_1": 0.20967741935145687, "Bleu_2": 0.10154803902700668, "Bleu_3": 0.05559861127421401, "Bleu_4": 7.346575651576122e-06, "METEOR": 0.18967702828508826, "ROUGE_L": 0.19162303664921465, "CIDEr": 1.833502415774525e-17, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 20.0, "numImages": 1.0, "fp": 32.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "The image shows a street sign with the words \"Juice Theory\" written on it. The sign is red and white, with the words in black letters. There are also some other signs on the street, including one that says \"Stop\" and another that says \"Go\". The image appears to be taken from a distance, with the street and buildings in the background."}, "193717": {"image_id": 193717, "Bleu_1": 0.3947368420948754, "Bleu_2": 0.230960638416735, "Bleu_3": 0.1436374916873903, "Bleu_4": 0.09592545068229469, "METEOR": 0.21650186771743976, "ROUGE_L": 0.2936726272352132, "CIDEr": 0.00014442718821694667, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.1, "f": 0.16216216216216217, "fn": 27.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.2727272727272727, "f": 0.39999999999999997, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "This is an image of a red fire hydrant on the side of a city street. The hydrant is made of metal and has a large handle on top. There are no people or vehicles in the image."}, "456768": {"image_id": 456768, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.1748949264355777, "Bleu_3": 0.10767861130247747, "Bleu_4": 1.2699504465465572e-05, "METEOR": 0.22294300336128944, "ROUGE_L": 0.2893689114781872, "CIDEr": 7.289747502599804e-10, "SPICE": {"All": {"pr": 0.2, "re": 0.18181818181818182, "f": 0.1904761904761905, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a stop sign on a pole in the middle of a city street. The sign is red and white, with the words \"stop\" written in bold black letters. There are trees and buildings visible in the background, and a few cars parked along the side of the road."}, "278350": {"image_id": 278350, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.17864740024886272, "Bleu_3": 0.12767884383539146, "Bleu_4": 0.08246811684519831, "METEOR": 0.2032350390174619, "ROUGE_L": 0.29901960784313725, "CIDEr": 2.1443755398038975e-08, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.375, "f": 0.2857142857142857, "fn": 10.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.5, "f": 0.36363636363636365, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.6666666666666666, "f": 0.4705882352941177, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a man standing in the water, looking out at the sky. He is wearing a red shirt and has his arms stretched out to the side. There is a large body of water in the background, with buildings and trees visible on the other side."}, "251250": {"image_id": 251250, "Bleu_1": 0.6111111110771605, "Bleu_2": 0.3791976393079946, "Bleu_3": 0.26194719623255935, "Bleu_4": 0.18605335291625483, "METEOR": 0.19410742782578647, "ROUGE_L": 0.3765432098765432, "CIDEr": 0.1686046692960128, "SPICE": {"All": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1111111111111111, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "A group of people stand on their surfboards in the water, with a large ship in the background."}, "428357": {"image_id": 428357, "Bleu_1": 0.30952380951644, "Bleu_2": 0.12287685874511865, "Bleu_3": 0.07227033533137166, "Bleu_4": 9.918680490802729e-06, "METEOR": 0.24177279860816764, "ROUGE_L": 0.25957446808510637, "CIDEr": 5.294017931283874e-07, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.05555555555555555, "f": 0.06779661016949153, "fn": 34.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.18181818181818182, "f": 0.18181818181818182, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "This is an image of a group of airplanes parked on a runway. The planes are all different sizes and colors, with some having propellers and others having jet engines. There are also several people standing around the planes, looking at them."}, "76873": {"image_id": 76873, "Bleu_1": 0.30952380951644, "Bleu_2": 0.17377412013914983, "Bleu_3": 0.09105491676695633, "Bleu_4": 1.1795365411101286e-05, "METEOR": 0.1667834775124078, "ROUGE_L": 0.2469635627530364, "CIDEr": 1.6095686730162698e-06, "SPICE": {"All": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 18.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}}, "caption": "The image shows a man sitting in the driver's seat of a truck, wearing a pair of boots and a hat. The truck is parked on the side of the road, with a sign in the background that reads \"Safety First.\""}, "518375": {"image_id": 518375, "Bleu_1": 0.2424242424205693, "Bleu_2": 0.1365577483976988, "Bleu_3": 0.06629552898300543, "Bleu_4": 8.246659114166758e-06, "METEOR": 0.19159081333706635, "ROUGE_L": 0.23672903672903675, "CIDEr": 1.135449951290418e-13, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.07142857142857142, "f": 0.08163265306122448, "fn": 26.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image shows a table set with a white plate on it, containing a slice of pizza topped with cheese and herbs. There are two glasses of wine on the table, one red and one white. A woman is sitting at the table, holding a fork in one hand and a knife in the other. Another woman is standing behind her, pouring wine into a glass."}, "191474": {"image_id": 191474, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.24671758189216153, "Bleu_3": 0.1905340106122511, "Bleu_4": 0.14821514446378253, "METEOR": 0.2807937724831323, "ROUGE_L": 0.34702907711757275, "CIDEr": 1.1604342738944305e-07, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.3125, "f": 0.3448275862068966, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5714285714285714, "f": 0.6153846153846153, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "This is an image of a yellow taxi driving down the street. The taxi is stopped at a red light, and there are other cars and pedestrians in the background. The sky is clear and blue, and there are trees and buildings visible in the distance."}, "261471": {"image_id": 261471, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.16803361008003348, "Bleu_3": 0.1200160042655936, "Bleu_4": 0.09212480089236007, "METEOR": 0.2278483793159831, "ROUGE_L": 0.23416506717850286, "CIDEr": 2.3365416257775345e-09, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.6, "f": 0.3870967741935483, "fn": 4.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.3333333333333333, "f": 0.16666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 1.0, "f": 0.4615384615384615, "fn": 0.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is an image of a city street with tall buildings on either side. There are people walking on the sidewalk and cars driving down the street. The buildings are made of brick and have windows on the upper floors. There are also street signs and traffic lights on the street."}, "87581": {"image_id": 87581, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.1403458930502932, "Bleu_3": 0.077086262053372, "Bleu_4": 1.021928280144888e-05, "METEOR": 0.15621659431184873, "ROUGE_L": 0.24646464646464644, "CIDEr": 5.461867416325322e-08, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 16.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.5555555555555556, "f": 0.5882352941176471, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image shows a herd of zebras grazing in a dry, grassy area. The zebras are standing in a line, with their heads down and their ears up, as they eat the grass. In the background, there are trees and a small body of water."}, "376310": {"image_id": 376310, "Bleu_1": 0.34782608694139894, "Bleu_2": 0.3079962013899118, "Bleu_3": 0.23841352750186381, "Bleu_4": 0.1613394868072289, "METEOR": 0.2934511550664233, "ROUGE_L": 0.4711334234408186, "CIDEr": 0.3634186360836289, "SPICE": {"All": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 21.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "This is a purple bathroom with two sinks and a mirror on the wall. There are also two lights hanging from the ceiling."}, "451856": {"image_id": 451856, "Bleu_1": 0.36666666665444453, "Bleu_2": 0.2514326764768464, "Bleu_3": 0.16528691241294277, "Bleu_4": 0.11372027709677378, "METEOR": 0.28517591762526895, "ROUGE_L": 0.4543761638733706, "CIDEr": 0.0009315295019757385, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.2608695652173913, "f": 0.23076923076923075, "fn": 17.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.25, "f": 0.14285714285714288, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5555555555555556, "f": 0.4545454545454546, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "Here is a short caption for the image:\n\n\"A group of people are standing outside a restaurant holding up signs with numbers on them. They are smiling and having fun.\""}, "81512": {"image_id": 81512, "Bleu_1": 0.3170731707239739, "Bleu_2": 0.23555849565513073, "Bleu_3": 0.16221265425974885, "Bleu_4": 0.12242641935912445, "METEOR": 0.29816144184990134, "ROUGE_L": 0.3165307635285397, "CIDEr": 1.106080838111387e-06, "SPICE": {"All": {"pr": 0.07894736842105263, "re": 0.16666666666666666, "f": 0.10714285714285714, "fn": 15.0, "numImages": 1.0, "fp": 35.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.17647058823529413, "re": 0.375, "f": 0.24, "fn": 5.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}}, "caption": "This is a display case filled with various ceramic vases and other decorative items. The vases are of different shapes and sizes, with some having floral designs on them. The display case is made of glass and has a mirrored surface."}, "268641": {"image_id": 268641, "Bleu_1": 0.4444444444279836, "Bleu_2": 0.2614881801743744, "Bleu_3": 0.17619680839487792, "Bleu_4": 0.12286996020485069, "METEOR": 0.26228588630739935, "ROUGE_L": 0.3783448520290626, "CIDEr": 0.07187698072434329, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.2857142857142857, "f": 0.24489795918367344, "fn": 15.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "This is an old fire hydrant on the side of a brick building. It has a red handle on top and is surrounded by other fire hydrants."}, "103837": {"image_id": 103837, "Bleu_1": 0.19999999999600004, "Bleu_2": 0.0903507902886997, "Bleu_3": 5.540397074769196e-07, "Bleu_4": 1.3792125616624927e-09, "METEOR": 0.2064458618128219, "ROUGE_L": 0.19830949284785435, "CIDEr": 2.246304869280173e-10, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.2631578947368421, "f": 0.23255813953488372, "fn": 14.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a horse racing on a dirt track. The horse is wearing a blue and white jockey's cap and is ridden by a jockey in a blue and white uniform. The track is surrounded by tall trees and there are people in the stands watching the race."}, "84060": {"image_id": 84060, "Bleu_1": 0.21212121211799817, "Bleu_2": 0.08078865345212301, "Bleu_3": 4.6720439734350565e-07, "Bleu_4": 1.1279635194063212e-09, "METEOR": 0.13055553464831132, "ROUGE_L": 0.19823584029712163, "CIDEr": 4.5204658310820275e-18, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.16666666666666666, "f": 0.21621621621621623, "fn": 20.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a young girl sitting on the ground, being helped by an adult to put on her hair. The adult is holding a comb and smiling at the girl. The girl is wearing a pink shirt and has a look of concentration on her face as she gets her hair done. The background is a rocky terrain with trees and bushes in the distance."}, "110972": {"image_id": 110972, "Bleu_1": 0.3333333333232324, "Bleu_2": 0.22821773228679554, "Bleu_3": 0.1497806431282426, "Bleu_4": 1.829411709689116e-05, "METEOR": 0.28364421193260997, "ROUGE_L": 0.37162750217580504, "CIDEr": 0.0005389853559287321, "SPICE": {"All": {"pr": 0.10810810810810811, "re": 0.12903225806451613, "f": 0.11764705882352941, "fn": 27.0, "numImages": 1.0, "fp": 33.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.08333333333333333, "f": 0.1111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.1875, "re": 0.3, "f": 0.23076923076923075, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}}, "caption": "The image shows a black bear standing on the grass, looking at something in its paws. The bear is standing in front of some trees and there are some leaves on the ground."}, "16451": {"image_id": 16451, "Bleu_1": 0.32432432431555885, "Bleu_2": 0.2324952774812677, "Bleu_3": 0.11558994996382839, "Bleu_4": 1.4598906514772134e-05, "METEOR": 0.20718156666015694, "ROUGE_L": 0.24419535628502803, "CIDEr": 1.719243192197622e-05, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.08, "f": 0.0851063829787234, "fn": 23.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2, "f": 0.1904761904761905, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "This is a beach scene with several surfboards and umbrellas on the sand. There are also some chairs and tables set up on the beach. The sky is blue and there are some clouds in the distance."}, "525762": {"image_id": 525762, "Bleu_1": 0.30952380951644, "Bleu_2": 0.2128289624210096, "Bleu_3": 0.1503283554093226, "Bleu_4": 0.11488730100868012, "METEOR": 0.29772949284345207, "ROUGE_L": 0.38812301166489926, "CIDEr": 3.917799574101495e-06, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.13636363636363635, "f": 0.12244897959183673, "fn": 19.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a young boy playing tennis on a court with a net in the background. He is wearing white tennis shoes and holding a racket. The sun is shining down on the court, casting a warm glow over the scene."}, "557321": {"image_id": 557321, "Bleu_1": 0.2027027026999635, "Bleu_2": 0.14904360038636366, "Bleu_3": 0.09745522791454049, "Bleu_4": 0.07145732721539282, "METEOR": 0.20482521703981768, "ROUGE_L": 0.24057843996494305, "CIDEr": 2.4488379262591724e-19, "SPICE": {"All": {"pr": 0.25, "re": 0.17391304347826086, "f": 0.20512820512820512, "fn": 19.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a person sitting at a desk with a computer, mouse, and keyboard in front of them. The person is wearing a black shirt and jeans, and has a laptop open on the desk. There are several cables and wires connected to the computer, and a monitor is mounted on the wall behind it. The room appears to be a home office or study area, with a window visible in the background."}, "172094": {"image_id": 172094, "Bleu_1": 0.4999999999000002, "Bleu_2": 0.23570226034706615, "Bleu_3": 1.907857070517686e-06, "Bleu_4": 5.612222323072491e-09, "METEOR": 0.23693874629632286, "ROUGE_L": 0.31881533101045295, "CIDEr": 0.8765895935477599, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.13043478260869565, "f": 0.14634146341463414, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "How to remove frizz from hair using a blow dryer."}, "570448": {"image_id": 570448, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.10942520359115704, "Bleu_3": 0.06169095833758949, "Bleu_4": 8.277965966610606e-06, "METEOR": 0.14458859662403908, "ROUGE_L": 0.2083096186681844, "CIDEr": 3.3837660186198924e-09, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.46153846153846156, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.7142857142857143, "f": 0.588235294117647, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a small boat floating in the water next to a rocky shoreline. The sky is cloudy and there are no people in the image. The water is calm and there are no waves. The rocky shoreline is covered in greenery and there are no buildings or structures in the image."}, "342397": {"image_id": 342397, "Bleu_1": 0.28947368420290864, "Bleu_2": 0.08845119041795683, "Bleu_3": 6.012221254053181e-07, "Bleu_4": 1.578553134101312e-09, "METEOR": 0.13946117274167988, "ROUGE_L": 0.18625954198473282, "CIDEr": 2.8952571097077335e-06, "SPICE": {"All": {"pr": 0.12, "re": 0.13043478260869565, "f": 0.12499999999999997, "fn": 20.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This image shows a person skiing down a snowy slope. The person is wearing a helmet and goggles, and is holding onto a ski pole. The background is a winter landscape with trees and mountains in the distance."}, "69842": {"image_id": 69842, "Bleu_1": 0.3333333333247864, "Bleu_2": 0.18731716231147263, "Bleu_3": 0.09824666233063457, "Bleu_4": 1.2739803480291042e-05, "METEOR": 0.23536597798111067, "ROUGE_L": 0.24148851939825808, "CIDEr": 5.9760904202075e-06, "SPICE": {"All": {"pr": 0.2, "re": 0.16, "f": 0.17777777777777778, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is an image of a train with red and white stripes on the side. The train has a large window on the front and a door on the side. There are people standing outside the train, looking in."}, "199989": {"image_id": 199989, "Bleu_1": 0.357142857117347, "Bleu_2": 0.16574838602065456, "Bleu_3": 1.3179708049006483e-06, "Bleu_4": 3.7982292265213524e-09, "METEOR": 0.09890817335887275, "ROUGE_L": 0.2577464788732394, "CIDEr": 0.17279021718132737, "SPICE": {"All": {"pr": 0.13157894736842105, "re": 0.16129032258064516, "f": 0.14492753623188406, "fn": 26.0, "numImages": 1.0, "fp": 33.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 10.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}}, "caption": "Here is a short caption for the image:\n\n\"Skiing in the mountains with friends\""}, "290768": {"image_id": 290768, "Bleu_1": 0.36842105262188374, "Bleu_2": 0.2640100002346085, "Bleu_3": 0.15703245364319998, "Bleu_4": 1.823790929218847e-05, "METEOR": 0.24090753280558752, "ROUGE_L": 0.28728414442700156, "CIDEr": 1.3912976760601209e-05, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.2857142857142857, "f": 0.24000000000000002, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.35714285714285715, "re": 0.5555555555555556, "f": 0.43478260869565216, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "This is a kitchen with black and white checkered flooring and a white countertop. There is a stove, sink, and refrigerator in the kitchen. The walls are white and there are windows on one side of the room."}, "38714": {"image_id": 38714, "Bleu_1": 0.512195121938727, "Bleu_2": 0.32006096979354487, "Bleu_3": 0.23593386214161544, "Bleu_4": 0.16214527868787693, "METEOR": 0.2643762243817187, "ROUGE_L": 0.3302716813303684, "CIDEr": 0.036344379902730074, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.09090909090909091, "f": 0.11538461538461539, "fn": 30.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.25, "f": 0.2727272727272727, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of people standing on the beach with kite surfing boards. The sky is clear and blue with a few clouds in the distance. The water is calm and there are several kites flying in the air."}, "551215": {"image_id": 551215, "Bleu_1": 0.5135135134996348, "Bleu_2": 0.2925501419943171, "Bleu_3": 1.3472375969184147e-06, "Bleu_4": 2.91214782247913e-09, "METEOR": 0.2636978924613325, "ROUGE_L": 0.32323996971990915, "CIDEr": 0.0001146784673284324, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 24.0, "numImages": 1.0, "fp": 16.0, "tp": 8.0}, "Relation": {"pr": 0.1, "re": 0.09090909090909091, "f": 0.09523809523809525, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.5, "f": 0.5217391304347826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The woman in white is playing tennis on a green court. She is wearing a white shirt and shorts, and has a white racket in her hand. She is running towards the net to hit the ball."}, "48636": {"image_id": 48636, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.2303502213753046, "Bleu_3": 0.1768080407355261, "Bleu_4": 0.13705104707463134, "METEOR": 0.3302488429012665, "ROUGE_L": 0.34099378881987574, "CIDEr": 3.870685886466069e-10, "SPICE": {"All": {"pr": 0.46153846153846156, "re": 0.16216216216216217, "f": 0.24, "fn": 31.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.125, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.35714285714285715, "f": 0.45454545454545453, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image shows a baseball player in a red and white uniform swinging a bat at a ball on a baseball field. The player is wearing a helmet and gloves, and the ball is flying through the air. The background of the image is a blue sky with some clouds."}, "189427": {"image_id": 189427, "Bleu_1": 0.5185185184993142, "Bleu_2": 0.315776977798527, "Bleu_3": 0.22872522208884816, "Bleu_4": 0.17770114737548345, "METEOR": 0.25744879101643126, "ROUGE_L": 0.42657342657342656, "CIDEr": 0.2414656430110953, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.26666666666666666, "f": 0.21621621621621623, "fn": 11.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.1, "re": 0.2, "f": 0.13333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2222222222222222, "re": 0.5, "f": 0.30769230769230765, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "This is an image of a sign that reads, \"Stop, Don't Feed the Wildlife.\" The sign is sitting on the ground next to a trash can."}, "444755": {"image_id": 444755, "Bleu_1": 0.30769230768441824, "Bleu_2": 0.20121090914115636, "Bleu_3": 1.0304662546247208e-06, "Bleu_4": 2.3480087200537226e-09, "METEOR": 0.26324087704978777, "ROUGE_L": 0.33808392715756136, "CIDEr": 1.84292186615287e-06, "SPICE": {"All": {"pr": 0.125, "re": 0.15384615384615385, "f": 0.13793103448275862, "fn": 11.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "This is a man sitting in an armchair, wearing glasses and a suit, holding a small dog in his lap. The dog is wearing a red bow tie. There are books and other objects on shelves behind the man."}, "211498": {"image_id": 211498, "Bleu_1": 0.8333333331944446, "Bleu_2": 0.6154574547917563, "Bleu_3": 0.48436465299109077, "Bleu_4": 0.3352113418479386, "METEOR": 0.3415445263265626, "ROUGE_L": 0.5865384615384615, "CIDEr": 1.7248024537883109, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.2222222222222222, "f": 0.17391304347826086, "fn": 14.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This is a plate of food with broccoli and cheese on it."}, "554900": {"image_id": 554900, "Bleu_1": 0.29411764705017307, "Bleu_2": 0.16351748503705, "Bleu_3": 9.418739954830287e-07, "Bleu_4": 2.278527011349529e-09, "METEOR": 0.23167886352823483, "ROUGE_L": 0.21441124780316342, "CIDEr": 0.00010813224722055852, "SPICE": {"All": {"pr": 0.1875, "re": 0.13636363636363635, "f": 0.15789473684210525, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "This is a bathroom with a toilet and sink. The walls are white and the floor is gray. There is a man standing in front of the toilet, wearing a black shirt and pants."}, "56684": {"image_id": 56684, "Bleu_1": 0.22580645160561919, "Bleu_2": 0.15026857675445401, "Bleu_3": 0.11591050055045549, "Bleu_4": 1.535686541265103e-05, "METEOR": 0.24254648188765768, "ROUGE_L": 0.26872246696035246, "CIDEr": 0.0004048658265446691, "SPICE": {"All": {"pr": 0.375, "re": 0.24, "f": 0.2926829268292683, "fn": 19.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a doughnut sitting on a red tablecloth. The doughnut has a glaze on it and appears to be freshly baked. There is a fork next to the doughnut."}, "575051": {"image_id": 575051, "Bleu_1": 0.35483870966597303, "Bleu_2": 0.26639771382432886, "Bleu_3": 0.19435456595137918, "Bleu_4": 2.262854099257572e-05, "METEOR": 0.33791630076322154, "ROUGE_L": 0.4260945490831982, "CIDEr": 0.0055859965871628055, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.05263157894736842, "f": 0.06451612903225808, "fn": 18.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}}, "caption": "The image shows a baseball player in the middle of a game, holding a bat and wearing a helmet. The other players on the field are watching him from the sidelines."}, "137294": {"image_id": 137294, "Bleu_1": 0.19277108433502685, "Bleu_2": 0.11876532024389455, "Bleu_3": 5.584248760236415e-07, "Bleu_4": 1.2146497653223633e-09, "METEOR": 0.1392989650217204, "ROUGE_L": 0.1982460665462987, "CIDEr": 2.011143474161054e-26, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.09523809523809523, "f": 0.08888888888888889, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "This image shows a man in a white shirt and black pants standing in front of a large metal box with a sign on it that reads \"Egg Hatcher\". The man is holding a small egg in his hand and appears to be examining it. There are several other eggs in the box, and the man is likely checking them for quality or inspecting them for any defects. The background of the image is a green grassy field with trees in the distance."}, "168953": {"image_id": 168953, "Bleu_1": 0.6086956521474481, "Bleu_2": 0.5260036519575005, "Bleu_3": 0.42917705119894006, "Bleu_4": 0.32998954723738916, "METEOR": 0.4148996114112808, "ROUGE_L": 0.5162460329454436, "CIDEr": 0.29051829829128945, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.2, "f": 0.17647058823529413, "fn": 12.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The man is sitting at a table with several cell phones in front of him. He is smiling and looking at the camera."}, "552752": {"image_id": 552752, "Bleu_1": 0.1739130434757404, "Bleu_2": 0.1238760208504916, "Bleu_3": 0.08824165570931415, "Bleu_4": 1.0101113530808207e-05, "METEOR": 0.16950745408760742, "ROUGE_L": 0.22624014835419562, "CIDEr": 4.501122670278478e-21, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.09090909090909091, "f": 0.07692307692307691, "fn": 20.0, "numImages": 1.0, "fp": 28.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2222222222222222, "f": 0.18181818181818185, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a man standing on the platform of a train car, looking out at the tracks in front of him. The train car is old and has a wooden body with brass fittings. The man is wearing a white shirt and black pants, and he is standing with his hands on his hips. The image is taken in a dimly lit room with wooden floors and walls."}, "61418": {"image_id": 61418, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.16578342426777695, "Bleu_3": 0.08681823924888467, "Bleu_4": 1.1239895308238822e-05, "METEOR": 0.18557708759920352, "ROUGE_L": 0.25318206972883234, "CIDEr": 1.0882931354617834e-07, "SPICE": {"All": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 18.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.1111111111111111, "f": 0.19999999999999998, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}}, "caption": "This is a black and white photograph of a group of children playing tic tac toe on a wooden board on the deck of a ship. The children are sitting in chairs around the board, and there is a large ship in the background."}, "367905": {"image_id": 367905, "Bleu_1": 0.25641025640368187, "Bleu_2": 0.1642880193591135, "Bleu_3": 9.001951896101368e-07, "Bleu_4": 2.121665383933931e-09, "METEOR": 0.1974144356604638, "ROUGE_L": 0.22846441947565538, "CIDEr": 5.6091580905055015e-06, "SPICE": {"All": {"pr": 0.45, "re": 0.4090909090909091, "f": 0.4285714285714286, "fn": 13.0, "numImages": 1.0, "fp": 11.0, "tp": 9.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.75, "re": 0.8571428571428571, "f": 0.7999999999999999, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 6.0}}, "caption": "The image shows a surfer riding a wave on a surfboard. The surfer is lying on the board and appears to be in the air as they ride the wave. The water is green and the sky is blue."}, "159500": {"image_id": 159500, "Bleu_1": 0.16981132075151303, "Bleu_2": 0.09897882079639587, "Bleu_3": 0.057699421416016236, "Bleu_4": 7.872924608075425e-06, "METEOR": 0.14314567842965334, "ROUGE_L": 0.14796846573681016, "CIDEr": 9.846765118840063e-13, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.29411764705882354, "f": 0.22727272727272727, "fn": 12.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5555555555555556, "f": 0.4761904761904762, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "This is a bathroom with red walls and white tiles on the floor. There are two toilets in the room, one on the left and one on the right. The toilets have white seats and red handles. There is also a sink in the corner of the room with a mirror above it."}, "415768": {"image_id": 415768, "Bleu_1": 0.5937499999814454, "Bleu_2": 0.3914406806169766, "Bleu_3": 0.273373796503649, "Bleu_4": 0.16291765998499427, "METEOR": 0.3805158517225722, "ROUGE_L": 0.3570234113712374, "CIDEr": 0.0035671153263759194, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.1111111111111111, "f": 0.15, "fn": 24.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is an image of a pot filled with vegetables, including carrots and onions, being cooked on a stove. The pot has a wooden spoon in it and the vegetables are steaming."}, "521141": {"image_id": 521141, "Bleu_1": 0.5263157894459835, "Bleu_2": 0.38235955643025316, "Bleu_3": 2.048794150967711e-06, "Bleu_4": 4.814971806817797e-09, "METEOR": 0.20686976934950518, "ROUGE_L": 0.29221556886227545, "CIDEr": 0.20162948556337795, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.23333333333333334, "f": 0.2592592592592593, "fn": 23.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 14.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "This is an image of a street with people walking on it. There are tall buildings in the background."}, "210654": {"image_id": 210654, "Bleu_1": 0.4090909090723141, "Bleu_2": 0.2791452631065508, "Bleu_3": 1.573536579103672e-06, "Bleu_4": 3.784157746578089e-09, "METEOR": 0.2330792624926765, "ROUGE_L": 0.3351648351648352, "CIDEr": 0.15977050077317298, "SPICE": {"All": {"pr": 0.25, "re": 0.21739130434782608, "f": 0.23255813953488372, "fn": 18.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.15384615384615385, "f": 0.2222222222222222, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6, "f": 0.42857142857142855, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a skateboard with two shoes on it, one black and one white, sitting on the side of the road."}, "52664": {"image_id": 52664, "Bleu_1": 0.3793103448145066, "Bleu_2": 0.20159462811746034, "Bleu_3": 0.11460354422397828, "Bleu_4": 1.551155008995511e-05, "METEOR": 0.24989297510186637, "ROUGE_L": 0.29075309818875117, "CIDEr": 0.002822509202837712, "SPICE": {"All": {"pr": 0.022727272727272728, "re": 0.03225806451612903, "f": 0.02666666666666667, "fn": 30.0, "numImages": 1.0, "fp": 43.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.0625, "re": 0.0625, "f": 0.0625, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 1.0}}, "caption": "This image shows a pizza on a wooden cutting board with fresh basil leaves and tomatoes on top. The pizza appears to be cooked and ready to be served."}, "306139": {"image_id": 306139, "Bleu_1": 0.34146341462581803, "Bleu_2": 0.2613286875248416, "Bleu_3": 0.2190215959975318, "Bleu_4": 0.1928243190797223, "METEOR": 0.32087652567952707, "ROUGE_L": 0.39638989169675093, "CIDEr": 4.485914845209788e-06, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.15625, "f": 0.16666666666666666, "fn": 27.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.07142857142857142, "f": 0.08695652173913043, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a group of people sitting at a table in a large, open room. They are all using laptops and looking at them intently. There are several chairs around the table, and the room has a modern, minimalist aesthetic."}, "487222": {"image_id": 487222, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.22247460415230486, "Bleu_3": 0.10480069030260979, "Bleu_4": 1.2866510680665704e-05, "METEOR": 0.251819261692165, "ROUGE_L": 0.28754208754208754, "CIDEr": 4.3906582209377164e-08, "SPICE": {"All": {"pr": 0.1891891891891892, "re": 0.30434782608695654, "f": 0.23333333333333334, "fn": 16.0, "numImages": 1.0, "fp": 30.0, "tp": 7.0}, "Relation": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}}, "caption": "The image shows a large airplane flying over a garden with trees and flowers. The plane is white with a red tail and wings, and it is flying low over the garden. The sky is clear and blue, with a few clouds in the distance."}, "331049": {"image_id": 331049, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.23783535599888, "Bleu_3": 0.10957078983962544, "Bleu_4": 1.3303281214014741e-05, "METEOR": 0.2941500452780937, "ROUGE_L": 0.3233929754804506, "CIDEr": 6.540500813393752e-08, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.20833333333333334, "f": 0.2, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.18181818181818182, "re": 0.2, "f": 0.1904761904761905, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a black horse standing on top of a hill with trees in the background. The horse is looking out into the distance with its head tilted to one side. The sky is clear and blue with a few clouds scattered across it."}, "107558": {"image_id": 107558, "Bleu_1": 0.27586206896076104, "Bleu_2": 0.17040572913395824, "Bleu_3": 0.08033906732368051, "Bleu_4": 9.85381528236167e-06, "METEOR": 0.2412389310788975, "ROUGE_L": 0.2456846950517837, "CIDEr": 4.043955255532851e-14, "SPICE": {"All": {"pr": 0.4166666666666667, "re": 0.22727272727272727, "f": 0.29411764705882354, "fn": 17.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.4444444444444444, "f": 0.5714285714285714, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The image shows a person riding a skateboard on a ramp in a skate park. The person is wearing a black helmet and is standing on the board with their arms outstretched. The ramp is made of wood and has a green surface. There are other skaters in the background, some of whom are also riding on boards."}, "528714": {"image_id": 528714, "Bleu_1": 0.333333333325926, "Bleu_2": 0.23028309323074364, "Bleu_3": 0.1948658043741257, "Bleu_4": 0.17227882631406896, "METEOR": 0.3482030633555363, "ROUGE_L": 0.3696969696969697, "CIDEr": 5.16993819309271e-08, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.28, "f": 0.29787234042553196, "fn": 18.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "This image shows a group of people playing tennis on a court at night. The players are wearing white shirts and white shorts, and they are holding rackets in their hands. The court is made of green grass and there are trees in the background."}, "316806": {"image_id": 316806, "Bleu_1": 0.4999999999833334, "Bleu_2": 0.4734320764579462, "Bleu_3": 0.4161021363949723, "Bleu_4": 0.3696864460431678, "METEOR": 0.36610116033100676, "ROUGE_L": 0.5951219512195122, "CIDEr": 0.06915830660420294, "SPICE": {"All": {"pr": 0.041666666666666664, "re": 0.08333333333333333, "f": 0.05555555555555555, "fn": 11.0, "numImages": 1.0, "fp": 23.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a sign on a pole in the middle of a field with trees and a body of water in the background. The sign reads, \"No Fishing Allowed\"."}, "446473": {"image_id": 446473, "Bleu_1": 0.3333333333247864, "Bleu_2": 0.1324532357030635, "Bleu_3": 0.07797842756800691, "Bleu_4": 1.0712855077613533e-05, "METEOR": 0.1873353365778649, "ROUGE_L": 0.28870858688302903, "CIDEr": 0.00041060260282687163, "SPICE": {"All": {"pr": 0.15625, "re": 0.23809523809523808, "f": 0.18867924528301888, "fn": 16.0, "numImages": 1.0, "fp": 27.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5714285714285714, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "This is an image of a skier in mid-air, performing a trick on a snowboard. The skier is wearing a red and black outfit with a helmet and goggles. The background is a blue sky with fluffy white clouds."}, "364126": {"image_id": 364126, "Bleu_1": 0.27586206896076104, "Bleu_2": 0.2199928503447174, "Bleu_3": 0.15120391375656378, "Bleu_4": 0.10588613616169155, "METEOR": 0.19238240586760136, "ROUGE_L": 0.2105868814729574, "CIDEr": 3.24241890631111e-15, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.15789473684210525, "f": 0.18749999999999997, "fn": 16.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a surfer riding a wave on a surfboard in the ocean. The surfer is wearing a wetsuit and standing on the board, with his arms outstretched to balance himself. The wave is large and white, with a lot of foam on top. The sky is blue and cloudy, with some clouds visible in the distance."}, "83331": {"image_id": 83331, "Bleu_1": 0.714285714234694, "Bleu_2": 0.4688072309037214, "Bleu_3": 0.2635941609801295, "Bleu_4": 3.5921434200531924e-05, "METEOR": 0.18793560473009527, "ROUGE_L": 0.3824451410658307, "CIDEr": 0.6568747966641277, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.09090909090909091, "f": 0.07692307692307691, "fn": 20.0, "numImages": 1.0, "fp": 28.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.25, "f": 0.1904761904761905, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "This is an old traffic light with three red and green lights on it."}, "347768": {"image_id": 347768, "Bleu_1": 0.3499999999912501, "Bleu_2": 0.18946618668147105, "Bleu_3": 0.09812054324169892, "Bleu_4": 1.2640653505172758e-05, "METEOR": 0.22286704279742028, "ROUGE_L": 0.23036253776435048, "CIDEr": 5.432743079022523e-06, "SPICE": {"All": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 24.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 1.0, "re": 0.125, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.25, "f": 0.375, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "This image shows a group of cars driving down a city street. The cars are parked on the side of the road and there are other vehicles parked in the distance. There are buildings and trees visible in the background."}, "491017": {"image_id": 491017, "Bleu_1": 0.18965517241052324, "Bleu_2": 0.14129296641606834, "Bleu_3": 0.1125566132145619, "Bleu_4": 0.08485844890318373, "METEOR": 0.1779759872768623, "ROUGE_L": 0.20631341600901915, "CIDEr": 1.0968654284218606e-13, "SPICE": {"All": {"pr": 0.3, "re": 0.0967741935483871, "f": 0.14634146341463414, "fn": 28.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a group of men in leather outfits standing on the sidewalk. They are wearing leather harnesses, chaps, and boots, and are holding umbrellas. The men are dressed in different colors and patterns, and they are all smiling and looking at something in the distance. There are buildings and cars in the background of the image."}, "525077": {"image_id": 525077, "Bleu_1": 0.27272727272107444, "Bleu_2": 0.15927956195690762, "Bleu_3": 0.08453247893683392, "Bleu_4": 1.1017212838732253e-05, "METEOR": 0.1891968259613107, "ROUGE_L": 0.24465240641711228, "CIDEr": 5.6751436203140997e-08, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.375, "f": 0.27906976744186046, "fn": 10.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is an image of a white and red airplane flying in the sky. The plane is taking off from the ground and is flying towards the left side of the image. The sky is cloudy and there are some clouds in the background."}, "29306": {"image_id": 29306, "Bleu_1": 0.29999999999250004, "Bleu_2": 0.12403473458606788, "Bleu_3": 7.397773249928141e-07, "Bleu_4": 1.8187597339048352e-09, "METEOR": 0.20635650016907198, "ROUGE_L": 0.27199762187871585, "CIDEr": 1.9411727490873213e-06, "SPICE": {"All": {"pr": 0.28, "re": 0.21875, "f": 0.2456140350877193, "fn": 25.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.6, "f": 0.5217391304347826, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "A brown and white dog is standing on the beach, looking out at the ocean. The dog is wearing a black collar with a tag that reads \"Buddy\". The sky is cloudy and there are waves crashing on the shore."}, "81303": {"image_id": 81303, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.15534712747310678, "Bleu_3": 0.0988300045102394, "Bleu_4": 0.06662198853445316, "METEOR": 0.23633830649401083, "ROUGE_L": 0.2167219327333018, "CIDEr": 2.891334391042329e-11, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.05, "f": 0.0625, "fn": 19.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}}, "caption": "This is an image of a person skiing down a snowy slope. The person is wearing a black and white jacket, black pants, and black ski boots. They are holding a pair of skis and are in the process of turning. The background is a snowy mountain with trees in the distance."}, "297520": {"image_id": 297520, "Bleu_1": 0.19565217390879022, "Bleu_2": 0.13187609467625871, "Bleu_3": 0.07338824344329116, "Bleu_4": 9.791579531640564e-06, "METEOR": 0.1939551723328244, "ROUGE_L": 0.2378476735118274, "CIDEr": 1.427919343869846e-08, "SPICE": {"All": {"pr": 0.5, "re": 0.15384615384615385, "f": 0.23529411764705882, "fn": 22.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 4.0}}, "caption": "This image shows a barbecue grill with several sausages and hot dogs on it. The grill is made of metal and has a lid that is open, revealing the food inside. There is a table next to the grill with a plate of food on it."}, "300341": {"image_id": 300341, "Bleu_1": 0.1911764705854239, "Bleu_2": 0.0925210271983966, "Bleu_3": 0.05061885517561792, "Bleu_4": 6.683529970233257e-06, "METEOR": 0.170640222736641, "ROUGE_L": 0.14805825242718448, "CIDEr": 1.9093870061456025e-21, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.19047619047619047, "f": 0.17777777777777778, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a group of men playing video games in a living room. They are all wearing casual clothing and are gathered around a large screen displaying the game. One man is holding a controller and another is standing next to him, watching the game. The room is well lit and there are several other objects in the room, such as a couch and a coffee table."}, "357": {"image_id": 357, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.14686261420159358, "Bleu_3": 0.0958411776672495, "Bleu_4": 0.06544158309931196, "METEOR": 0.19153201998138225, "ROUGE_L": 0.2501464557703574, "CIDEr": 1.731098973426524e-09, "SPICE": {"All": {"pr": 0.3, "re": 0.2727272727272727, "f": 0.28571428571428564, "fn": 16.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a baseball game in progress on a green field. There are several players on the field, including a pitcher throwing a ball to a batter, and a catcher catching a ball thrown by the pitcher. The crowd is seated in the stands behind the field, watching the game."}, "188718": {"image_id": 188718, "Bleu_1": 0.5833333332361111, "Bleu_2": 0.32566947358395304, "Bleu_3": 2.197107811108781e-06, "Bleu_4": 5.859059369098998e-09, "METEOR": 0.24754334920116453, "ROUGE_L": 0.3112244897959184, "CIDEr": 0.7679284289957756, "SPICE": {"All": {"pr": 0.1875, "re": 0.1111111111111111, "f": 0.13953488372093023, "fn": 24.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "Two zebras graze in a field with a fence in the background."}, "554749": {"image_id": 554749, "Bleu_1": 0.28205128204405006, "Bleu_2": 0.22794037622152502, "Bleu_3": 0.19148595889172806, "Bleu_4": 0.15552757085793464, "METEOR": 0.2992616685725947, "ROUGE_L": 0.3756735950731332, "CIDEr": 4.729481429915851e-06, "SPICE": {"All": {"pr": 0.125, "re": 0.15789473684210525, "f": 0.13953488372093023, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is a bathroom with a large walk in shower, a double sink, and a toilet. The walls are beige and the floors are white tile. There is a large window with blinds and a mirror on the wall."}, "439709": {"image_id": 439709, "Bleu_1": 0.4814814814636489, "Bleu_2": 0.33333333332075027, "Bleu_3": 0.23712622029020833, "Bleu_4": 0.1535259783805314, "METEOR": 0.26842461560315395, "ROUGE_L": 0.3948220064724919, "CIDEr": 0.038145401231784434, "SPICE": {"All": {"pr": 0.15151515151515152, "re": 0.17857142857142858, "f": 0.16393442622950818, "fn": 23.0, "numImages": 1.0, "fp": 28.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.1111111111111111, "f": 0.10526315789473685, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "This is a group of three ceramic plates with birds on them. The plates are painted with different colors and designs, including red cardinals perched on branches."}, "122354": {"image_id": 122354, "Bleu_1": 0.4090909090723141, "Bleu_2": 4.41367414731835e-09, "Bleu_3": 9.912659293961434e-12, "Bleu_4": 4.758326453740933e-13, "METEOR": 0.17817371937639198, "ROUGE_L": 0.20938215102974828, "CIDEr": 0.04296569082886664, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.25, "f": 0.22857142857142856, "fn": 12.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a street with cars parked on the side of the road. There are trees and buildings in the background."}, "184400": {"image_id": 184400, "Bleu_1": 0.38095238093424044, "Bleu_2": 0.19518001458018006, "Bleu_3": 1.260972737339982e-06, "Bleu_4": 3.2487115055976186e-09, "METEOR": 0.2210636259800092, "ROUGE_L": 0.43109540636042404, "CIDEr": 0.08996279406509969, "SPICE": {"All": {"pr": 0.38095238095238093, "re": 0.22857142857142856, "f": 0.2857142857142857, "fn": 27.0, "numImages": 1.0, "fp": 13.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.7, "re": 0.4666666666666667, "f": 0.56, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 7.0}}, "caption": "The image shows a blue and yellow train traveling on a track next to a building with windows and a roof."}, "196430": {"image_id": 196430, "Bleu_1": 0.3499999999912501, "Bleu_2": 0.26794565081604904, "Bleu_3": 0.17829685970436746, "Bleu_4": 1.978369188299523e-05, "METEOR": 0.31016910385797947, "ROUGE_L": 0.34078212290502796, "CIDEr": 1.0660903818088452e-05, "SPICE": {"All": {"pr": 0.125, "re": 0.13636363636363635, "f": 0.13043478260869565, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "This is an image of a young boy playing baseball in a park. He is wearing a blue shirt and white pants, and has a bat in his hand. The background is a green field with trees in the distance."}, "501116": {"image_id": 501116, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.20447945297237122, "Bleu_3": 0.10148763200900297, "Bleu_4": 1.279510009626945e-05, "METEOR": 0.15243722883540275, "ROUGE_L": 0.22197962154294032, "CIDEr": 2.892909243285858e-07, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.18518518518518517, "f": 0.17543859649122806, "fn": 22.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.25, "f": 0.14285714285714288, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.07692307692307693, "f": 0.09090909090909093, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a street with a red light at the intersection. There are trees on both sides of the street and a house on the left side. The sky is cloudy and there are no cars or people in the scene."}, "460967": {"image_id": 460967, "Bleu_1": 0.3829787233961069, "Bleu_2": 0.24141120717629194, "Bleu_3": 0.13733380275681295, "Bleu_4": 1.5576501283474943e-05, "METEOR": 0.21734066273053373, "ROUGE_L": 0.2948640483383686, "CIDEr": 1.6638863362236457e-07, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.13333333333333333, "f": 0.13559322033898305, "fn": 26.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3333333333333333, "f": 0.34782608695652173, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This is an image of a red and yellow bus parked in front of a tall building. The bus has the words \"City Bus\" written on the side in white letters. The building has large windows and a flat roof. There are no people in the image."}, "107216": {"image_id": 107216, "Bleu_1": 0.4242424242295685, "Bleu_2": 0.32566947362944193, "Bleu_3": 0.2173224313183697, "Bleu_4": 0.1360028792323118, "METEOR": 0.30791043143799907, "ROUGE_L": 0.38822593476531425, "CIDEr": 0.004824352234028097, "SPICE": {"All": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.08333333333333333, "f": 0.1111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "This image shows a red and white boat docked at a pier on a body of water. The reflection of the boat in the water creates an interesting pattern of colors and shapes."}, "172935": {"image_id": 172935, "Bleu_1": 0.11538461538239647, "Bleu_2": 0.04756514941452576, "Bleu_3": 3.563438288459303e-07, "Bleu_4": 9.80286251174814e-10, "METEOR": 0.12531784877557736, "ROUGE_L": 0.15024630541871922, "CIDEr": 2.2020725584752522e-11, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.17647058823529413, "f": 0.23076923076923078, "fn": 14.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "This is an old black and white photograph of a man jumping off a cliff into the water below. The man is wearing a pair of sunglasses and a hat, and he is holding onto a surfboard as he jumps. The water is choppy and there are several boats in the background."}, "277032": {"image_id": 277032, "Bleu_1": 0.4242424242295685, "Bleu_2": 0.282038037400203, "Bleu_3": 0.19745053261647894, "Bleu_4": 2.2506782730688327e-05, "METEOR": 0.2687082425191655, "ROUGE_L": 0.30886075949367087, "CIDEr": 0.0018041668929942509, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.2, "f": 0.2631578947368421, "fn": 20.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.375, "f": 0.4615384615384615, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This is a man standing in the snow with skis and poles. He is wearing a black jacket and pants, and has a backpack on his back. There are mountains in the background."}, "475613": {"image_id": 475613, "Bleu_1": 0.37142857141795926, "Bleu_2": 0.209039419701316, "Bleu_3": 0.1583754635438043, "Bleu_4": 0.1055549075428401, "METEOR": 0.23330197119423826, "ROUGE_L": 0.3918779396581393, "CIDEr": 0.0002883681114154918, "SPICE": {"All": {"pr": 0.47368421052631576, "re": 0.3, "f": 0.3673469387755102, "fn": 21.0, "numImages": 1.0, "fp": 10.0, "tp": 9.0}, "Relation": {"pr": 0.375, "re": 0.21428571428571427, "f": 0.2727272727272727, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.5454545454545454, "f": 0.5714285714285713, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The image shows a person holding a pizza in their hands, with the toppings visible on the surface of the pizza. The person is standing in a field, with trees and grass in the background."}, "551288": {"image_id": 551288, "Bleu_1": 0.28070175438104034, "Bleu_2": 0.2452557357896452, "Bleu_3": 0.21430849609306035, "Bleu_4": 0.17374951565120048, "METEOR": 0.31899033791188547, "ROUGE_L": 0.3613354873451804, "CIDEr": 5.697785770330883e-13, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.24, "f": 0.2553191489361702, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2, "f": 0.26666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a woman sitting at a table with two plates of food in front of her. One plate has a piece of chicken on it, while the other has a salad with lettuce, tomatoes, and olives. There are also two glasses of wine on the table. The woman is smiling and looking at the camera."}, "169438": {"image_id": 169438, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.16751484856166823, "Bleu_3": 0.13366660488533524, "Bleu_4": 0.10094509680842466, "METEOR": 0.29934067762480665, "ROUGE_L": 0.27566171723692706, "CIDEr": 7.614027416030228e-10, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2727272727272727, "f": 0.24489795918367346, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5555555555555556, "f": 0.4761904761904762, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA group of children are sitting in front of a television playing a video game. One child is holding a controller and another is watching the screen. The room is dimly lit and there are some toys on the floor."}, "468965": {"image_id": 468965, "Bleu_1": 0.23214285713871177, "Bleu_2": 0.12993504870706918, "Bleu_3": 0.06787131897112117, "Bleu_4": 8.763866421088602e-06, "METEOR": 0.21076789432258874, "ROUGE_L": 0.2883403361344538, "CIDEr": 2.06520116241628e-12, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.22727272727272727, "f": 0.21739130434782608, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "Sure, here is a short caption for the image:\n\nThe image shows a group of children playing soccer in the middle of a small town. They are wearing school uniforms and are holding signs with the names of different countries on them. The buildings in the background are made of wood and have a traditional style."}, "568559": {"image_id": 568559, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.19794866371815809, "Bleu_3": 0.1483569743355745, "Bleu_4": 0.10857104303325285, "METEOR": 0.285400247317328, "ROUGE_L": 0.2776332899869961, "CIDEr": 2.437874140826221e-10, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.17391304347826086, "f": 0.1904761904761905, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a black cat sitting on top of a wooden desk. The cat is looking directly at the camera with its eyes. The desk has a laptop and other office supplies on it. There is a lamp on the desk, and the room appears to be well lit."}, "503392": {"image_id": 503392, "Bleu_1": 0.1249999999982639, "Bleu_2": 0.05933908290886273, "Bleu_3": 3.6914291720661185e-07, "Bleu_4": 9.240248103016933e-10, "METEOR": 0.14291668856253875, "ROUGE_L": 0.13664874551971326, "CIDEr": 2.3049156374442525e-23, "SPICE": {"All": {"pr": 0.5555555555555556, "re": 0.2, "f": 0.29411764705882354, "fn": 20.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 1.0, "re": 0.14285714285714285, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.4, "f": 0.5333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The image shows a woman standing on a horse in a circus ring. The woman is wearing a black and white striped shirt and pants, and has a red scarf tied around her neck. The horse is white with a brown mane and tail, and is wearing a red and white striped saddle. The ring is surrounded by a wooden fence, and there are several people in the stands watching the performance."}, "317310": {"image_id": 317310, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.18650096164396338, "Bleu_3": 0.13335528843258257, "Bleu_4": 0.08617684067542819, "METEOR": 0.2764160876665574, "ROUGE_L": 0.377008652657602, "CIDEr": 1.6813186861258686e-07, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.17647058823529413, "f": 0.13636363636363638, "fn": 14.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.375, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a toy bear sitting in a bathtub filled with water. The bear is wearing a red and white striped bathrobe and has its paws on the edge of the bathtub. There is a rubber ducky floating in the water next to the bear."}, "244925": {"image_id": 244925, "Bleu_1": 0.378378378368152, "Bleu_2": 0.2899725574592808, "Bleu_3": 0.13393124865178632, "Bleu_4": 1.6303907740006476e-05, "METEOR": 0.2443589019325094, "ROUGE_L": 0.416382252559727, "CIDEr": 0.0005545431733321398, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.3125, "f": 0.25, "fn": 11.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.25, "f": 0.13333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.75, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a person wearing a backpack and holding a camera. The person is standing near a body of water, possibly a lake or river. The sky is cloudy and there are trees in the background."}, "14821": {"image_id": 14821, "Bleu_1": 0.5909090908822315, "Bleu_2": 0.37509017673027106, "Bleu_3": 0.19160806943285094, "Bleu_4": 2.4667318767602415e-05, "METEOR": 0.25269872903246415, "ROUGE_L": 0.3489702517162472, "CIDEr": 0.20224537414204774, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.1, "f": 0.1142857142857143, "fn": 18.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a backpack on a chair with various items inside, including a banana, an orange, and a bag of chips."}, "28903": {"image_id": 28903, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.25253813613284526, "Bleu_3": 0.17574056770956026, "Bleu_4": 0.123943015938953, "METEOR": 0.2743694693820304, "ROUGE_L": 0.3078864353312303, "CIDEr": 2.8819180908625197e-09, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.08333333333333333, "f": 0.10344827586206896, "fn": 33.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.21428571428571427, "f": 0.23999999999999996, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a cat sitting on top of a toilet in a bathroom. The cat is looking directly at the camera with its eyes. The toilet is white and has a seat cover on it. There is a sink in the background with a towel hanging over it."}, "204804": {"image_id": 204804, "Bleu_1": 0.20338983050502735, "Bleu_2": 0.14505284310643746, "Bleu_3": 0.09037934933366287, "Bleu_4": 1.0715313974803593e-05, "METEOR": 0.1294086711631142, "ROUGE_L": 0.2667379263434069, "CIDEr": 1.0772322083952611e-12, "SPICE": {"All": {"pr": 0.08108108108108109, "re": 0.14285714285714285, "f": 0.10344827586206896, "fn": 18.0, "numImages": 1.0, "fp": 34.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.3, "f": 0.21428571428571427, "fn": 7.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}}, "caption": "This is a bathroom with a large mirror on the wall. There is a sink in the corner of the room and a toilet in the opposite corner. The floor is made of white tiles and there are two chairs in front of the sink. The walls are made of wood and there is a skylight in the ceiling."}, "377486": {"image_id": 377486, "Bleu_1": 0.3124999999951172, "Bleu_2": 0.1725163898328716, "Bleu_3": 0.0986505875624193, "Bleu_4": 0.06298574903813266, "METEOR": 0.20652678785705625, "ROUGE_L": 0.3019413731036256, "CIDEr": 0.001979231208841736, "SPICE": {"All": {"pr": 0.25, "re": 0.2631578947368421, "f": 0.25641025641025644, "fn": 14.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.6666666666666666, "f": 0.5333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a man riding a horse in a rodeo arena. The man is wearing a cowboy hat and holding onto the reins of the horse as it gallops around the arena. There are other riders in the arena, some of whom are also riding horses. The arena is surrounded by a fence and there are spectators in the stands watching the rodeo."}, "488522": {"image_id": 488522, "Bleu_1": 0.5416666666440973, "Bleu_2": 0.43405736612273677, "Bleu_3": 0.3247709612094161, "Bleu_4": 0.2009685362352922, "METEOR": 0.35631574788692394, "ROUGE_L": 0.5187074829931972, "CIDEr": 0.2573106143563201, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.35, "f": 0.31818181818181823, "fn": 13.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6666666666666666, "f": 0.5714285714285715, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a chocolate cake with a knife cutting into it. There are also some chocolate chips on the side of the cake."}, "223751": {"image_id": 223751, "Bleu_1": 0.255813953482423, "Bleu_2": 0.13517553494737666, "Bleu_3": 0.07638430164587322, "Bleu_4": 1.0273965107862501e-05, "METEOR": 0.17905220565569674, "ROUGE_L": 0.26852531181217903, "CIDEr": 3.223811591378072e-07, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.2, "f": 0.19607843137254902, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.09090909090909091, "f": 0.09090909090909091, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "This image shows a group of people surfing on a wave in the ocean. The surfers are wearing wetsuits and standing on their surfboards, paddling through the water. The sun is setting in the background, casting a warm orange glow over the scene."}, "237011": {"image_id": 237011, "Bleu_1": 0.35294117646020773, "Bleu_2": 0.253320198544886, "Bleu_3": 0.15888145887773164, "Bleu_4": 1.8965508470168648e-05, "METEOR": 0.22358965822610335, "ROUGE_L": 0.3426966292134831, "CIDEr": 0.00030144588748091597, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.25, "f": 0.1702127659574468, "fn": 12.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "This is an image of a pizza with toppings such as sausage, mushrooms, and onions on top of a white sauce. There are two glasses of wine on the table next to the pizza."}, "431140": {"image_id": 431140, "Bleu_1": 0.45161290321123837, "Bleu_2": 0.27435163057536965, "Bleu_3": 0.17314728911420935, "Bleu_4": 0.11668694360280925, "METEOR": 0.3184240976403382, "ROUGE_L": 0.46073612276705433, "CIDEr": 0.008129063222273112, "SPICE": {"All": {"pr": 0.375, "re": 0.2608695652173913, "f": 0.30769230769230765, "fn": 17.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.5555555555555556, "f": 0.6250000000000001, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "This is a bathroom with a toilet, sink, and mirror. The walls are painted white and the floor is made of tile. There is a window in the background with blinds."}, "494393": {"image_id": 494393, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.19782182158264086, "Bleu_3": 0.11460186406839476, "Bleu_4": 0.07370572412364096, "METEOR": 0.19780792986489992, "ROUGE_L": 0.2798165137614679, "CIDEr": 7.476149575901743e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.17391304347826086, "f": 0.20512820512820512, "fn": 19.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.16666666666666666, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a street scene with a car parked on the side of the road. The building on the left has a sign that reads \"Bistro\" and the building on the right has a sign that reads \"Cafe\". There are people walking down the sidewalk and a few cars parked on the street."}, "179392": {"image_id": 179392, "Bleu_1": 0.31481481480898493, "Bleu_2": 0.21798903029455755, "Bleu_3": 0.12226401225946745, "Bleu_4": 1.375882791025065e-05, "METEOR": 0.28480809771886795, "ROUGE_L": 0.2853801169590643, "CIDEr": 2.8994501643471834e-12, "SPICE": {"All": {"pr": 0.25, "re": 0.15789473684210525, "f": 0.1935483870967742, "fn": 16.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.4, "f": 0.3076923076923077, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a black and white cat sitting on top of a wooden desk. The cat has a collar around its neck and is looking up at the camera with its eyes. The desk has a computer monitor, keyboard, and mouse on it. There are also some books and papers on the desk."}, "187565": {"image_id": 187565, "Bleu_1": 0.17333333333102224, "Bleu_2": 0.12804841426568395, "Bleu_3": 0.060786692916430934, "Bleu_4": 7.473486651460866e-06, "METEOR": 0.1604452107901632, "ROUGE_L": 0.18952507767421217, "CIDEr": 4.533212330890647e-26, "SPICE": {"All": {"pr": 0.4666666666666667, "re": 0.2916666666666667, "f": 0.35897435897435903, "fn": 17.0, "numImages": 1.0, "fp": 8.0, "tp": 7.0}, "Relation": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.8, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a vase with red roses sitting on a table in front of a red wall. The table is made of wood and has a smooth surface. The vase is made of metal and has a round shape with a handle on the side. The roses are arranged in a bouquet and are placed in the vase. The wall behind the table is red and has a pattern of red and white stripes."}, "405740": {"image_id": 405740, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.19296124624292718, "Bleu_3": 0.09319532338930898, "Bleu_4": 1.1580903993958116e-05, "METEOR": 0.2455145583669317, "ROUGE_L": 0.28638497652582157, "CIDEr": 2.639324572142811e-08, "SPICE": {"All": {"pr": 0.23333333333333334, "re": 0.25, "f": 0.2413793103448276, "fn": 21.0, "numImages": 1.0, "fp": 23.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}}, "caption": "The man in the image is sitting at a desk with a laptop in front of him. He is wearing glasses and has a drink in his hand. The room is dimly lit and there are several other objects on the desk, including a pen and a notebook."}, "484614": {"image_id": 484614, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.12950478164521437, "Bleu_3": 6.857872734978661e-07, "Bleu_4": 1.5858040477395045e-09, "METEOR": 0.20487538354049561, "ROUGE_L": 0.2445589919816724, "CIDEr": 1.584075564396592e-12, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.21052631578947367, "f": 0.1951219512195122, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a man standing on the beach holding a surfboard. He is wearing black shorts and a white shirt, and his hair is tied back in a ponytail. The background is a rocky beach with trees and bushes growing on it. There are several surfboards lying on the sand next to him."}, "384242": {"image_id": 384242, "Bleu_1": 0.19999999999733334, "Bleu_2": 0.1273429079916933, "Bleu_3": 0.06056321041025165, "Bleu_4": 7.4528699401716725e-06, "METEOR": 0.15486579477375517, "ROUGE_L": 0.1611624834874505, "CIDEr": 3.8102877733016256e-25, "SPICE": {"All": {"pr": 0.041666666666666664, "re": 0.038461538461538464, "f": 0.04, "fn": 25.0, "numImages": 1.0, "fp": 23.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a person standing on a surfboard in the ocean, with a windsurfer in the background. The person is wearing a wetsuit and holding onto the surfboard as they paddle through the water. The sky is clear and blue, with a few clouds scattered across it. The waves are crashing against the shore, creating a white foamy surface. The beach is sandy and there are some rocks and shells scattered along the shoreline."}, "393971": {"image_id": 393971, "Bleu_1": 0.3499999999912501, "Bleu_2": 0.26794565081604904, "Bleu_3": 0.155756653561564, "Bleu_4": 1.787658362427431e-05, "METEOR": 0.2907554464483721, "ROUGE_L": 0.3043044469783352, "CIDEr": 2.461774305253127e-05, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.12, "f": 0.15384615384615383, "fn": 22.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "A cat is sitting on a desk in front of a laptop computer. The laptop has a photo of a woman on the screen. There are several other objects on the desk, including a cup of coffee and a pen."}, "418623": {"image_id": 418623, "Bleu_1": 0.33333333332098775, "Bleu_2": 0.19611613513078086, "Bleu_3": 0.11544156732198758, "Bleu_4": 1.591178311035633e-05, "METEOR": 0.17519029533763267, "ROUGE_L": 0.34173669467787116, "CIDEr": 0.01550919461466567, "SPICE": {"All": {"pr": 0.4444444444444444, "re": 0.2857142857142857, "f": 0.34782608695652173, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.5, "f": 0.5454545454545454, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows a room with a bed, a desk, and a bookshelf. There are several suitcases on the floor and a guitar hanging on the wall."}, "161635": {"image_id": 161635, "Bleu_1": 0.21249999999734373, "Bleu_2": 0.16400833569223994, "Bleu_3": 0.10113919633938576, "Bleu_4": 0.06054341896495835, "METEOR": 0.19778769903869226, "ROUGE_L": 0.18093220338983051, "CIDEr": 2.3893310070921825e-30, "SPICE": {"All": {"pr": 0.16, "re": 0.13793103448275862, "f": 0.14814814814814817, "fn": 25.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is an image of a surfer riding a wave on a surfboard in the ocean. The surfer is wearing a wetsuit and standing on the board, with his arms outstretched to balance himself. The wave is large and white, with a lot of foam on top. There are other surfers in the background, also riding waves. The sky is blue and cloudy, with some white clouds visible. The water is clear and blue, with some white foam on top."}, "308194": {"image_id": 308194, "Bleu_1": 0.423240862374767, "Bleu_2": 0.3609410201956994, "Bleu_3": 0.28044004082583596, "Bleu_4": 3.795104906811203e-05, "METEOR": 0.4043557340594044, "ROUGE_L": 0.44202898550724634, "CIDEr": 0.9837863981078756, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.2222222222222222, "f": 0.21621621621621623, "fn": 14.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "A couple walks through a park holding umbrellas on a sunny day."}, "449338": {"image_id": 449338, "Bleu_1": 0.5833333332847223, "Bleu_2": 0.32566947361109216, "Bleu_3": 2.1971078112918733e-06, "Bleu_4": 5.859059369587253e-09, "METEOR": 0.3205009345182055, "ROUGE_L": 0.5187074829931972, "CIDEr": 0.9749783982674984, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.10344827586206896, "f": 0.0967741935483871, "fn": 26.0, "numImages": 1.0, "fp": 30.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2727272727272727, "f": 0.23076923076923075, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "A pair of ducks swimming in a body of water at sunset."}, "56592": {"image_id": 56592, "Bleu_1": 0.382352941165225, "Bleu_2": 0.28478969316957436, "Bleu_3": 0.13634300208924155, "Bleu_4": 1.690963431814651e-05, "METEOR": 0.24567793858443376, "ROUGE_L": 0.3024793388429752, "CIDEr": 0.00022213034096192657, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.3333333333333333, "f": 0.22857142857142854, "fn": 8.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.6, "f": 0.35294117647058826, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a man holding a tennis racket and preparing to hit the ball. He is wearing a white shirt and black shorts, and his hair is cut short. The background is black."}, "506945": {"image_id": 506945, "Bleu_1": 0.45454545452479345, "Bleu_2": 0.36037498506145293, "Bleu_3": 0.29615092273975135, "Bleu_4": 0.2530618805525521, "METEOR": 0.4314343094876418, "ROUGE_L": 0.5583524027459954, "CIDEr": 0.25496509034047116, "SPICE": {"All": {"pr": 0.15, "re": 0.13043478260869565, "f": 0.13953488372093023, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a man holding a cell phone in his hand, looking at it with a serious expression on his face."}, "364745": {"image_id": 364745, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.2258769757216551, "Bleu_3": 0.18675222022958107, "Bleu_4": 0.1542676522468039, "METEOR": 0.2799840377492014, "ROUGE_L": 0.3614049936521372, "CIDEr": 4.4177793523286027e-08, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 21.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a man sitting on a couch with his two children. The man is holding a baby in his arms and the other child is sitting on the couch next to him. The room appears to be a living room with a large window in the background."}, "311846": {"image_id": 311846, "Bleu_1": 0.43333333331888896, "Bleu_2": 0.3234156785660397, "Bleu_3": 0.22378370217722007, "Bleu_4": 2.5382266503583618e-05, "METEOR": 0.28607609373522136, "ROUGE_L": 0.3726003490401396, "CIDEr": 0.011536166607426939, "SPICE": {"All": {"pr": 0.037037037037037035, "re": 0.043478260869565216, "f": 0.039999999999999994, "fn": 22.0, "numImages": 1.0, "fp": 26.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.1111111111111111, "f": 0.09999999999999999, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows a table with three cakes on it. The cakes are decorated with flowers and other decorations. There are also several other tables nearby with cakes on them."}, "124766": {"image_id": 124766, "Bleu_1": 0.36956521738327036, "Bleu_2": 0.28657565120073264, "Bleu_3": 0.22373076962696106, "Bleu_4": 0.17965618424902763, "METEOR": 0.2651075692041284, "ROUGE_L": 0.40568319226118504, "CIDEr": 1.138014404096469e-06, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.23809523809523808, "f": 0.22727272727272724, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is a man wearing a blue shirt and a black hat. He is sitting in the driver's seat of a car with his hands on the steering wheel. The car is parked in front of a building with a sign that reads \"City Hall.\""}, "466921": {"image_id": 466921, "Bleu_1": 0.26829268292028563, "Bleu_2": 0.11582156166137168, "Bleu_3": 7.006558330325156e-07, "Bleu_4": 1.7345333611892186e-09, "METEOR": 0.1851067816135189, "ROUGE_L": 0.18583396801218582, "CIDEr": 2.429728802116008e-07, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.21052631578947367, "f": 0.1951219512195122, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is an image of a narrow street with buildings on either side. There are several bicycles parked on the sidewalk, and a person is walking down the street. The sky is clear and there are some trees in the background."}, "163138": {"image_id": 163138, "Bleu_1": 0.23880597014568944, "Bleu_2": 0.10418645221255786, "Bleu_3": 5.506847470461125e-07, "Bleu_4": 1.2709611986492497e-09, "METEOR": 0.18054655968685118, "ROUGE_L": 0.17672621921776918, "CIDEr": 2.949215590147138e-20, "SPICE": {"All": {"pr": 0.25, "re": 0.13636363636363635, "f": 0.1764705882352941, "fn": 19.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "This is a display case filled with various ceramic vases and other decorative items. The vases are arranged on shelves and in baskets, and they are all different shapes and sizes. Some of them have floral designs, while others have geometric patterns. The display case is made of glass and has a mirrored backdrop, reflecting the vases and making them appear more numerous than they actually are."}, "482436": {"image_id": 482436, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.18516401995076925, "Bleu_3": 0.08939035350783202, "Bleu_4": 1.1103081472064331e-05, "METEOR": 0.21993967102477965, "ROUGE_L": 0.23252858958068615, "CIDEr": 8.628059880149759e-09, "SPICE": {"All": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 24.0, "numImages": 1.0, "fp": 28.0, "tp": 4.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.125, "f": 0.1, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1875, "re": 0.3333333333333333, "f": 0.24000000000000005, "fn": 6.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}}, "caption": "This image shows a man standing in front of a window at night. He is wearing a black shirt and pants, and has a cigarette in his hand. There are other people in the background, but they are not visible. The window is open, and there is a streetlight outside."}, "469424": {"image_id": 469424, "Bleu_1": 0.23913043477741028, "Bleu_2": 0.192868005722087, "Bleu_3": 0.11913313386236632, "Bleu_4": 0.07918762373166545, "METEOR": 0.24740346935178245, "ROUGE_L": 0.28968792401628224, "CIDEr": 1.0256172124049634e-08, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.17857142857142858, "f": 0.1851851851851852, "fn": 23.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.45454545454545453, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a orange cat sitting on top of a bench in a park. The cat is looking up at the camera with its eyes closed. The bench is made of metal and has a wooden seat. There are plants and trees in the background."}, "547744": {"image_id": 547744, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.1956151991049542, "Bleu_3": 0.14822533542491692, "Bleu_4": 0.10908370302144317, "METEOR": 0.26126591585958087, "ROUGE_L": 0.26341764342998153, "CIDEr": 7.827256673123933e-10, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.13636363636363635, "f": 0.13636363636363635, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a purple and white bus driving down a street with buildings on either side. The bus has the words \"Southbound\" written on the side in white letters. There are people standing on the sidewalk and in the street, looking at the bus as it passes by."}, "268941": {"image_id": 268941, "Bleu_1": 0.29999999999500004, "Bleu_2": 0.1886616557167528, "Bleu_3": 0.13489621379916564, "Bleu_4": 0.08100859619094931, "METEOR": 0.24185805672016478, "ROUGE_L": 0.17058165548098433, "CIDEr": 1.687475746954002e-15, "SPICE": {"All": {"pr": 0.12195121951219512, "re": 0.19230769230769232, "f": 0.1492537313432836, "fn": 21.0, "numImages": 1.0, "fp": 36.0, "tp": 5.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.1111111111111111, "f": 0.09999999999999999, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.4444444444444444, "f": 0.32, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}}, "caption": "This is an image of a large white yacht docked at a marina in a small town. The yacht has a large deck with several windows and a large cabin on the top deck. There are several people standing on the deck, looking out at the water. In the background, there are several small boats and buildings along the shore."}, "388085": {"image_id": 388085, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.22086305214437038, "Bleu_3": 0.1540881120701569, "Bleu_4": 0.098414864488791, "METEOR": 0.23729396113367138, "ROUGE_L": 0.2663755458515284, "CIDEr": 2.493736285607836e-07, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.19230769230769232, "f": 0.2439024390243902, "fn": 21.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1111111111111111, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.5, "f": 0.6153846153846154, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "A group of people are walking down the street on a rainy day. They are carrying umbrellas and wearing raincoats. The buildings on either side of the street are tall and white. There are cars parked on the side of the street."}, "359149": {"image_id": 359149, "Bleu_1": 0.8181818181074382, "Bleu_2": 0.6396021490057785, "Bleu_3": 0.35688292771587565, "Bleu_4": 4.882270447860348e-05, "METEOR": 0.23947982818092256, "ROUGE_L": 0.4073455759599332, "CIDEr": 1.1094974466120349, "SPICE": {"All": {"pr": 0.16, "re": 0.1111111111111111, "f": 0.13114754098360656, "fn": 32.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3076923076923077, "f": 0.33333333333333337, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "Two people walking across a bridge with umbrellas in the rain."}, "567308": {"image_id": 567308, "Bleu_1": 0.3863636363548554, "Bleu_2": 0.2681074537606562, "Bleu_3": 0.11961606057428292, "Bleu_4": 1.4293749188232824e-05, "METEOR": 0.2691050633573829, "ROUGE_L": 0.2924657534246575, "CIDEr": 2.8599478107927086e-07, "SPICE": {"All": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image shows a man playing tennis on a green court with a net in the background. He is wearing a yellow shirt and white shorts, and is holding a racket in his right hand. There are several people watching him from the sidelines."}, "304657": {"image_id": 304657, "Bleu_1": 0.26190476189852613, "Bleu_2": 0.11303027047441294, "Bleu_3": 6.83559800121601e-07, "Bleu_4": 1.6916722834125866e-09, "METEOR": 0.12869755651860262, "ROUGE_L": 0.22197962154294032, "CIDEr": 3.209680270226244e-07, "SPICE": {"All": {"pr": 0.2, "re": 0.07142857142857142, "f": 0.10526315789473682, "fn": 26.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.16666666666666666, "f": 0.23529411764705882, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a large, modern hotel with a swimming pool and lounge chairs on the patio. The building is white with blue accents and has a large, open lobby with a high ceiling. There are several palm trees in the background."}, "269280": {"image_id": 269280, "Bleu_1": 0.33333333332407417, "Bleu_2": 0.09759000729210383, "Bleu_3": 6.543005137221079e-07, "Bleu_4": 1.7068857826300114e-09, "METEOR": 0.2534783936829498, "ROUGE_L": 0.2824074074074074, "CIDEr": 9.098899893820695e-05, "SPICE": {"All": {"pr": 0.3125, "re": 0.2631578947368421, "f": 0.2857142857142857, "fn": 14.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The man is sitting on a bench, wearing a white shirt and a black hat. He is holding a pen and paper, and appears to be writing something. There are plants and trees in the background."}, "245026": {"image_id": 245026, "Bleu_1": 0.222222222217284, "Bleu_2": 0.1421338109005459, "Bleu_3": 7.773956660946081e-07, "Bleu_4": 1.8288128464905184e-09, "METEOR": 0.25086996709893794, "ROUGE_L": 0.25902335456475584, "CIDEr": 1.1166602955729968e-08, "SPICE": {"All": {"pr": 0.32142857142857145, "re": 0.32142857142857145, "f": 0.32142857142857145, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 9.0}, "Relation": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.875, "f": 0.6363636363636364, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 7.0}}, "caption": "The image shows a woman standing in front of a table with a cake on it. The cake has a rainbow design on it and the woman is holding a fork in her hand. There is a chandelier hanging from the ceiling above the table."}, "409725": {"image_id": 409725, "Bleu_1": 0.2105263157857803, "Bleu_2": 0.1371021242743437, "Bleu_3": 0.08808836678271832, "Bleu_4": 0.059647257268019734, "METEOR": 0.20074661444835587, "ROUGE_L": 0.24247586598523563, "CIDEr": 1.695007321401709e-14, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.19047619047619047, "f": 0.18604651162790697, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a group of people standing on a bridge over a river, holding kites. The sky is clear and blue, with a few clouds in the distance. The buildings in the background are tall and modern, with many windows and balconies. There are people walking and biking on the bridge, and some are holding kites."}, "448555": {"image_id": 448555, "Bleu_1": 0.3928571428431123, "Bleu_2": 0.1705887719001811, "Bleu_3": 1.0382673068864815e-06, "Bleu_4": 2.5867048784784203e-09, "METEOR": 0.2793212611703829, "ROUGE_L": 0.28773584905660377, "CIDEr": 0.011382619785288085, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "This is a kitchen with stainless steel appliances and a refrigerator. The walls are painted white and there is a window on the left side of the room."}, "512938": {"image_id": 512938, "Bleu_1": 0.3255813953412656, "Bleu_2": 0.2641352718914714, "Bleu_3": 0.17218556197008944, "Bleu_4": 0.10628758794786379, "METEOR": 0.28734815606030517, "ROUGE_L": 0.29756097560975614, "CIDEr": 0.008737244619853875, "SPICE": {"All": {"pr": 0.21875, "re": 0.3181818181818182, "f": 0.25925925925925924, "fn": 15.0, "numImages": 1.0, "fp": 25.0, "tp": 7.0}, "Relation": {"pr": 0.15384615384615385, "re": 0.2, "f": 0.17391304347826086, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.5, "f": 0.41666666666666663, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "This is a picture of a sheep and its lamb standing in a field. The sheep has a thick, fluffy coat and the lamb is suckling on its mother's teats. The grass in the background is green and the sky is blue."}, "124983": {"image_id": 124983, "Bleu_1": 0.29999999999250004, "Bleu_2": 0.12403473458606788, "Bleu_3": 7.397773249928141e-07, "Bleu_4": 1.8187597339048352e-09, "METEOR": 0.19234853572572333, "ROUGE_L": 0.21298882681564243, "CIDEr": 4.617881182863239e-06, "SPICE": {"All": {"pr": 0.075, "re": 0.15789473684210525, "f": 0.10169491525423728, "fn": 16.0, "numImages": 1.0, "fp": 37.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.3333333333333333, "f": 0.15384615384615383, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.2857142857142857, "f": 0.17391304347826086, "fn": 5.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}}, "caption": "The image shows a street sign with the words \"fouth and third\" written on it. The sign is attached to a pole in the middle of the street. The sky is clear and blue, with some clouds in the distance."}, "74789": {"image_id": 74789, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.15291943545714587, "Bleu_3": 0.09983569293155374, "Bleu_4": 1.2127601540611025e-05, "METEOR": 0.19450471405022948, "ROUGE_L": 0.24190350297422336, "CIDEr": 6.275094001686906e-11, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.16, "f": 0.1818181818181818, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is an image of a train station with tracks leading up to it. There are several cars parked on the platform, and people are standing on the platform looking at the train. The train is parked on the tracks, and there are trees and buildings in the background."}, "519758": {"image_id": 519758, "Bleu_1": 0.24390243901844147, "Bleu_2": 0.17460757393808263, "Bleu_3": 0.09211998312650962, "Bleu_4": 1.1976212357708837e-05, "METEOR": 0.2718459957506747, "ROUGE_L": 0.26703633445206476, "CIDEr": 4.987361492766902e-06, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.13636363636363635, "f": 0.15384615384615383, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a tall clock tower with a white clock face on the front. The clock face has Roman numerals and hands, and the tower is made of brick. The sky is blue and there are clouds in the background."}, "442306": {"image_id": 442306, "Bleu_1": 0.45098039214802005, "Bleu_2": 0.35535124848369415, "Bleu_3": 0.2344390062716755, "Bleu_4": 0.12800062627278813, "METEOR": 0.3525145069506178, "ROUGE_L": 0.391653290529695, "CIDEr": 2.6859553482602654e-07, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 12.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2857142857142857, "f": 0.2105263157894737, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a young girl standing on a rock in the middle of a forest, holding an umbrella. She is wearing rain boots and a raincoat, and has a big smile on her face. The background is made up of trees and foliage, with the sun shining through the clouds."}, "565582": {"image_id": 565582, "Bleu_1": 0.19230769230399414, "Bleu_2": 0.13730875909260604, "Bleu_3": 0.10419556764481888, "Bleu_4": 0.08243191945354035, "METEOR": 0.1835049610382546, "ROUGE_L": 0.22241127856101123, "CIDEr": 1.908082337486416e-11, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.24, "f": 0.22222222222222224, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "This is a living room with a blue couch, a pink armchair, and a wooden coffee table. There is a fireplace in the corner of the room with a vase of flowers on top of it. The walls are painted a warm yellow color and there are several paintings on the walls."}, "485916": {"image_id": 485916, "Bleu_1": 0.339622641503026, "Bleu_2": 0.2138186907385403, "Bleu_3": 0.13906381417319805, "Bleu_4": 0.10184169067891133, "METEOR": 0.23729396113367138, "ROUGE_L": 0.28103661044837513, "CIDEr": 1.144004669312382e-10, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.42857142857142855, "f": 0.2, "fn": 4.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.6666666666666666, "f": 0.30769230769230765, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This is a bathroom with a sink, toilet, and mirror. The sink is made of white porcelain and has two faucets. The toilet is red and has a seat and lid. The mirror is framed in wood and has a round mirror hanging above it. There is a red rug on the floor."}, "345434": {"image_id": 345434, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.20966962740242623, "Bleu_3": 0.1441827180568874, "Bleu_4": 0.0913729807004326, "METEOR": 0.19785884931857556, "ROUGE_L": 0.3084702907711757, "CIDEr": 1.6788460618050347e-08, "SPICE": {"All": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 16.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "A group of people are sitting on the grassy bank of a river, looking out at the water. There is a large boat in the distance, and a few trees in the background. The sky is clear and blue, with a few clouds scattered across it."}, "495612": {"image_id": 495612, "Bleu_1": 0.5517241379120095, "Bleu_2": 0.3713906763410685, "Bleu_3": 0.27339217086735623, "Bleu_4": 0.16743498907547102, "METEOR": 0.33993332648338576, "ROUGE_L": 0.5113160100586757, "CIDEr": 0.014775128058074925, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a street sign with the words \"Walking Man\" written on it. The sign is attached to a utility pole and there are buildings in the background."}, "17953": {"image_id": 17953, "Bleu_1": 0.21999999999560005, "Bleu_2": 0.09476070829395405, "Bleu_3": 5.719241732016864e-07, "Bleu_4": 1.412470464555783e-09, "METEOR": 0.15076064955159743, "ROUGE_L": 0.1937738246505718, "CIDEr": 1.4162664838360766e-11, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.21739130434782608, "f": 0.21739130434782608, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.6666666666666666, "f": 0.5714285714285715, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is an image of a kitchen with various food items on the countertop. There are several pots and pans on the stove, as well as a blender and other kitchen appliances. The image appears to be taken in a home or apartment, with a wooden floor and white walls."}, "464857": {"image_id": 464857, "Bleu_1": 0.339622641503026, "Bleu_2": 0.2555622163811263, "Bleu_3": 0.21718893759224345, "Bleu_4": 0.18725075919606604, "METEOR": 0.26148717421798906, "ROUGE_L": 0.33351558228540185, "CIDEr": 3.237927433051116e-10, "SPICE": {"All": {"pr": 0.06451612903225806, "re": 0.09090909090909091, "f": 0.07547169811320754, "fn": 20.0, "numImages": 1.0, "fp": 29.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.13333333333333333, "re": 0.2222222222222222, "f": 0.16666666666666669, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}}, "caption": "The image shows a group of people in a room, with some sitting at tables and others standing around. There is a man in a suit and tie standing in the center of the room, holding a glass of wine. The room appears to be dimly lit, with only a few lights on."}, "20395": {"image_id": 20395, "Bleu_1": 0.36111111110108035, "Bleu_2": 0.17593288763229242, "Bleu_3": 0.0969181349729333, "Bleu_4": 1.288769653445438e-05, "METEOR": 0.23683091145402213, "ROUGE_L": 0.29383429672447015, "CIDEr": 8.411417255754951e-05, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.15789473684210525, "f": 0.16216216216216214, "fn": 16.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a harbor at night with many boats docked in the water. The sky is full of stars and the moon is visible in the background. There are buildings and trees in the background."}, "115924": {"image_id": 115924, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.23783535599888, "Bleu_3": 0.1580284245644431, "Bleu_4": 1.750810269276388e-05, "METEOR": 0.235444298613429, "ROUGE_L": 0.25902335456475584, "CIDEr": 3.2395911096697264e-08, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.19230769230769232, "f": 0.20408163265306123, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5555555555555556, "f": 0.4545454545454546, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a surfer riding a wave on a surfboard. The surfer is wearing a yellow shirt and has his arms outstretched as he jumps off the wave. The wave is large and white, with foam on top. The sky is blue and cloudy."}, "437497": {"image_id": 437497, "Bleu_1": 0.28787878787442606, "Bleu_2": 0.16301357787808698, "Bleu_3": 0.10759603807947313, "Bleu_4": 0.06668253054944054, "METEOR": 0.209834654264183, "ROUGE_L": 0.21243781094527364, "CIDEr": 1.479832202392251e-19, "SPICE": {"All": {"pr": 0.17142857142857143, "re": 0.3, "f": 0.21818181818181817, "fn": 14.0, "numImages": 1.0, "fp": 29.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4444444444444444, "f": 0.34782608695652173, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "This is an image of a young boy playing baseball. He is wearing a green and white jersey and red gloves, and is holding a bat in his right hand. He is standing on the plate, ready to swing at the ball that is being thrown by the pitcher on the mound. The background of the image is a green field with trees in the distance."}, "403104": {"image_id": 403104, "Bleu_1": 0.378378378368152, "Bleu_2": 0.25112360116008, "Bleu_3": 0.12168461497444134, "Bleu_4": 1.5172495765202357e-05, "METEOR": 0.17878070210589797, "ROUGE_L": 0.23735408560311286, "CIDEr": 4.2964699814475375e-05, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.21212121212121213, "f": 0.2456140350877193, "fn": 26.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5833333333333334, "re": 0.4666666666666667, "f": 0.5185185185185186, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 7.0}}, "caption": "This is an image of a street with a sign that reads \"Roman Avenue\" and a house in the background. The house has been damaged by a tornado and there are trees and debris scattered around it."}, "184139": {"image_id": 184139, "Bleu_1": 0.4399999999824001, "Bleu_2": 0.35823642098878333, "Bleu_3": 0.28155108805655055, "Bleu_4": 0.23487811399113218, "METEOR": 0.36619615284795815, "ROUGE_L": 0.5142255005268704, "CIDEr": 0.07457562847113706, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.2777777777777778, "f": 0.2272727272727273, "fn": 13.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5, "f": 0.45454545454545453, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "This is a bedroom with a large bed, a desk, and a chair. The walls are painted green and there are curtains on the windows."}, "281179": {"image_id": 281179, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.1814970425910117, "Bleu_3": 0.12634404006922517, "Bleu_4": 0.08051110007483202, "METEOR": 0.23632078015841373, "ROUGE_L": 0.2799770510613884, "CIDEr": 5.540330824602977e-10, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.3181818181818182, "f": 0.3255813953488372, "fn": 15.0, "numImages": 1.0, "fp": 14.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.625, "f": 0.5555555555555556, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "This is a nighttime image of a city street with a Christmas tree in the foreground. The street is empty and there are no cars or people in sight. The tree is decorated with lights and ornaments, and there is a reflection of the tree in the puddle on the sidewalk."}, "470350": {"image_id": 470350, "Bleu_1": 0.37209302324716065, "Bleu_2": 0.24902912254001586, "Bleu_3": 0.1655563685096674, "Bleu_4": 0.12273033502643034, "METEOR": 0.22955401589503374, "ROUGE_L": 0.36158861885002963, "CIDEr": 2.5941672205194632e-05, "SPICE": {"All": {"pr": 0.5454545454545454, "re": 0.3157894736842105, "f": 0.39999999999999997, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.5555555555555556, "f": 0.7142857142857143, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 5.0}}, "caption": "The image shows a man playing tennis on a court. He is wearing a black shirt and shorts, and has a tennis racket in his hand. The court is made of blue and white tiles, and there are spectators seated in the stands."}, "162902": {"image_id": 162902, "Bleu_1": 0.4999999999772728, "Bleu_2": 0.3450327796551204, "Bleu_3": 0.26137897927488973, "Bleu_4": 0.20821983208129713, "METEOR": 0.3053596012928108, "ROUGE_L": 0.4692307692307692, "CIDEr": 0.15540244062528233, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.12, "f": 0.11538461538461538, "fn": 22.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.18181818181818182, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "Sure, here is a short caption for the image:\n\n\"A group of people standing on a snowy slope with skis and snowboards\""}, "425727": {"image_id": 425727, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.23063280200236536, "Bleu_3": 0.10496103543446568, "Bleu_4": 1.2660998324356513e-05, "METEOR": 0.2882306629932022, "ROUGE_L": 0.28018372703412076, "CIDEr": 8.159806376357075e-09, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.16666666666666666, "f": 0.186046511627907, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a person flying a kite in a park on a sunny day. The person is standing on the grass and holding the kite with both hands, while the kite flies in the sky. The sky is cloudy and there are some trees in the background."}, "347506": {"image_id": 347506, "Bleu_1": 0.3863636363548554, "Bleu_2": 0.3143838566112782, "Bleu_3": 0.24169860555098002, "Bleu_4": 0.17928334978912372, "METEOR": 0.28481047414497884, "ROUGE_L": 0.33190827827438785, "CIDEr": 5.637013519732383e-07, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.25, "f": 0.23255813953488372, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a group of people standing in front of a bus stop on a sidewalk. The bus is parked in front of them, and there are trees and buildings in the background. The sky is blue and there are clouds in it."}, "48133": {"image_id": 48133, "Bleu_1": 0.27272727272107444, "Bleu_2": 0.13794014695833945, "Bleu_3": 0.07680285411963501, "Bleu_4": 1.0252671801486271e-05, "METEOR": 0.18227773115475604, "ROUGE_L": 0.23341836734693874, "CIDEr": 1.0344472886203686e-06, "SPICE": {"All": {"pr": 0.05, "re": 0.05, "f": 0.05000000000000001, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "This is an image of a ski resort with a large mountain in the background. There are several people on the slopes, some of them skiing and others snowboarding. The resort has a lodge in the foreground with a sign that reads \"ski resort\"."}, "373486": {"image_id": 373486, "Bleu_1": 0.17999999999640004, "Bleu_2": 0.06060915267190813, "Bleu_3": 4.245658537601285e-07, "Bleu_4": 1.129625096611556e-09, "METEOR": 0.10431187066020438, "ROUGE_L": 0.19830949284785435, "CIDEr": 7.507202187111234e-12, "SPICE": {"All": {"pr": 0.1935483870967742, "re": 0.2857142857142857, "f": 0.23076923076923075, "fn": 15.0, "numImages": 1.0, "fp": 25.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5555555555555556, "f": 0.4545454545454546, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "This image shows a skateboarder jumping over a set of stairs. The skateboarder is wearing a purple shirt and black pants, and has a black helmet on their head. The stairs are made of concrete and have a smooth surface. The background is a blurred image of trees and buildings."}, "279388": {"image_id": 279388, "Bleu_1": 0.32432432431555885, "Bleu_2": 0.189831599145298, "Bleu_3": 1.0097712220824676e-06, "Bleu_4": 2.3458352758968296e-09, "METEOR": 0.2315252316967738, "ROUGE_L": 0.3017312448474856, "CIDEr": 8.076301215181539e-05, "SPICE": {"All": {"pr": 0.06896551724137931, "re": 0.08333333333333333, "f": 0.07547169811320754, "fn": 22.0, "numImages": 1.0, "fp": 27.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.2222222222222222, "f": 0.17391304347826086, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "The image shows a giraffe eating leaves from a tree. The giraffe has a long neck and spotted fur, and its eyes are looking up towards the sky. The background is a blue sky with some clouds."}, "90374": {"image_id": 90374, "Bleu_1": 0.4634146341350387, "Bleu_2": 0.2847763349922257, "Bleu_3": 0.18408630482539004, "Bleu_4": 2.012890781837401e-05, "METEOR": 0.27806705083317446, "ROUGE_L": 0.27875095201827876, "CIDEr": 2.124148316268122e-06, "SPICE": {"All": {"pr": 0.16, "re": 0.13333333333333333, "f": 0.14545454545454545, "fn": 26.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3076923076923077, "f": 0.33333333333333337, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a woman in black and white tennis outfit playing tennis on a court. She is holding a tennis racket and swinging it to hit the ball. The background is a green grass field with trees in the distance."}, "519491": {"image_id": 519491, "Bleu_1": 0.4838709677263268, "Bleu_2": 0.33601075250510387, "Bleu_3": 0.26900444252673095, "Bleu_4": 0.22963869978186033, "METEOR": 0.38650432795603146, "ROUGE_L": 0.48370044052863437, "CIDEr": 0.02596332586011038, "SPICE": {"All": {"pr": 0.05263157894736842, "re": 0.05555555555555555, "f": 0.05405405405405406, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image shows a large clock tower with a statue of an angel on top. The clock has four faces and is surrounded by buildings. The sky is clear and blue."}, "460972": {"image_id": 460972, "Bleu_1": 0.5714285713877553, "Bleu_2": 0.46880723090372134, "Bleu_3": 0.3321078320482429, "Bleu_4": 4.2718025132374636e-05, "METEOR": 0.25440373202518574, "ROUGE_L": 0.5545454545454546, "CIDEr": 0.8509833910107036, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.3125, "f": 0.22222222222222224, "fn": 11.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.625, "f": 0.45454545454545453, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "A group of ducks swimming in a pond surrounded by tall grass and trees."}, "32901": {"image_id": 32901, "Bleu_1": 0.11607142857039224, "Bleu_2": 0.06467421574846623, "Bleu_3": 0.042367537015155644, "Bleu_4": 5.139469447741035e-06, "METEOR": 0.13905695264922138, "ROUGE_L": 0.135126582278481, "CIDEr": 1.3627039686263157e-63, "SPICE": {"All": {"pr": 0.2, "re": 0.2631578947368421, "f": 0.22727272727272727, "fn": 14.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.6, "f": 0.37499999999999994, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "Here are the captions for the image:\n\n1. A group of men in suits and ties standing in a room with tables and chairs.\n2. A group of men in suits and ties standing in a room with tables and chairs, looking at something on a table.\n3. A group of men in suits and ties standing in a room with tables and chairs, talking to each other.\n4. A group of men in suits and ties standing in a room with tables and chairs, looking at something on a table.\n5. A group of men in suits and ties standing in a room with tables and chairs, smiling at each other."}, "9395": {"image_id": 9395, "Bleu_1": 0.20967741935145687, "Bleu_2": 0.17588636300376279, "Bleu_3": 0.11564977189564374, "Bleu_4": 0.07155592208032009, "METEOR": 0.2518630813142024, "ROUGE_L": 0.2323177366702938, "CIDEr": 4.134139405042973e-17, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 14.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.375, "f": 0.42857142857142855, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a baseball player pitching a ball on a green field. The player is wearing a white jersey with the number 24 on the back and a black cap with the letters \"SF\" on it. The ball is flying through the air as the player throws it. The background is a clear blue sky with some clouds in the distance."}, "16606": {"image_id": 16606, "Bleu_1": 0.652173913015123, "Bleu_2": 0.5710402406947687, "Bleu_3": 0.4266070671172512, "Bleu_4": 0.2968390508306839, "METEOR": 0.41059780354229525, "ROUGE_L": 0.4846077457795432, "CIDEr": 0.2688361024596043, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2692307692307692, "f": 0.2978723404255319, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image is a book with a mouse on top of it. The book has a picture of a tree on the cover."}, "478586": {"image_id": 478586, "Bleu_1": 0.5999999999700001, "Bleu_2": 0.35540932663721736, "Bleu_3": 0.1914527954016162, "Bleu_4": 2.5347437072286464e-05, "METEOR": 0.3074988116990698, "ROUGE_L": 0.3546511627906977, "CIDEr": 0.3022478945624621, "SPICE": {"All": {"pr": 0.2, "re": 0.13043478260869565, "f": 0.15789473684210528, "fn": 20.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "A white swan is standing in the water next to a black cat. The cat is looking at the swan."}, "190664": {"image_id": 190664, "Bleu_1": 0.41666666665509267, "Bleu_2": 0.308606699915489, "Bleu_3": 0.2237676280726019, "Bleu_4": 0.13574363002742867, "METEOR": 0.29992826180594717, "ROUGE_L": 0.33888888888888885, "CIDEr": 0.00015689633203833683, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.18181818181818182, "f": 0.17391304347826086, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is an image of a fire hydrant on the side of a city street. It is made of orange metal and has a large handle on top. There are no other objects in the image."}, "255479": {"image_id": 255479, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.09157370929741424, "Bleu_3": 0.05443097196884579, "Bleu_4": 7.498804358364543e-06, "METEOR": 0.1493762208276805, "ROUGE_L": 0.14896214896214896, "CIDEr": 1.3291276811012156e-12, "SPICE": {"All": {"pr": 0.35, "re": 0.3181818181818182, "f": 0.3333333333333333, "fn": 15.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5555555555555556, "f": 0.5263157894736842, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a person standing on the beach holding a surfboard. The person is wearing a black wetsuit and has a surfboard under their arm. The sky is clear and blue, with a few clouds in the distance. The beach is lined with palm trees and there are people walking along the shore."}, "68852": {"image_id": 68852, "Bleu_1": 0.2295081967175491, "Bleu_2": 0.1636336037715597, "Bleu_3": 0.1219881532441201, "Bleu_4": 0.09843772265092689, "METEOR": 0.25766187339314756, "ROUGE_L": 0.31043256997455465, "CIDEr": 1.9816974411124226e-14, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.12, "f": 0.10344827586206896, "fn": 22.0, "numImages": 1.0, "fp": 30.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.375, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a blue car parked on the side of the road with surfboards on top of it. There are people standing on the sidewalk looking at the car. The car has a surfboard on top of it and there are surfboards on the ground next to it. The sky is blue and there are palm trees in the background."}, "438432": {"image_id": 438432, "Bleu_1": 0.36363636362534446, "Bleu_2": 0.2383656473040621, "Bleu_3": 0.17650172911257067, "Bleu_4": 0.1383690338387529, "METEOR": 0.30261161262378045, "ROUGE_L": 0.36033755274261603, "CIDEr": 0.0008590556917034031, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.3333333333333333, "f": 0.27272727272727276, "fn": 12.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.25, "f": 0.15384615384615383, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.625, "f": 0.5555555555555556, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "This is a photograph of a group of young women in white shirts and black skirts, sitting on the ground and holding cricket bats. They are all smiling and looking at the camera."}, "581632": {"image_id": 581632, "Bleu_1": 0.4651162790589508, "Bleu_2": 0.2353104026619684, "Bleu_3": 0.11053491096485213, "Bleu_4": 1.3555314602460314e-05, "METEOR": 0.22876252368905547, "ROUGE_L": 0.25003415767181314, "CIDEr": 8.292251505717704e-06, "SPICE": {"All": {"pr": 0.30303030303030304, "re": 0.35714285714285715, "f": 0.32786885245901637, "fn": 18.0, "numImages": 1.0, "fp": 23.0, "tp": 10.0}, "Relation": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.125, "f": 0.10526315789473685, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6363636363636364, "f": 0.56, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 7.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A group of people standing at a bar in a dimly lit room. There are several bottles of alcohol on the shelves behind them, and a clock hanging on the wall above their heads.\""}, "121849": {"image_id": 121849, "Bleu_1": 0.2535211267569926, "Bleu_2": 0.18054244221157284, "Bleu_3": 0.13317616761572848, "Bleu_4": 0.09129566483266331, "METEOR": 0.20085977903698315, "ROUGE_L": 0.19999999999999998, "CIDEr": 5.640600586821541e-23, "SPICE": {"All": {"pr": 0.7142857142857143, "re": 0.22727272727272727, "f": 0.3448275862068965, "fn": 17.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 1.0, "re": 0.2, "f": 0.33333333333333337, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.375, "f": 0.5454545454545454, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}}, "caption": "The image shows a young boy sitting on the toilet in a bathroom. He is wearing a gray shirt and blue jeans, and has his hands on his hips. The toilet is white and has a seat cover on it. There is a sink in the background with a faucet and a mirror above it. The floor is made of tile and there is a rug in front of the toilet."}, "391375": {"image_id": 391375, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.22918388364562542, "Bleu_3": 0.20448709776883991, "Bleu_4": 0.18694976490600204, "METEOR": 0.28750525514015157, "ROUGE_L": 0.3588235294117647, "CIDEr": 1.9630934184535234e-07, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.09523809523809523, "f": 0.125, "fn": 19.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a woman sitting on a bench in front of an old stone archway. She is wearing a black coat and has her hands folded in her lap. The archway is covered in moss and vines, giving it a mysterious and ancient appearance."}, "337160": {"image_id": 337160, "Bleu_1": 0.4827586206730084, "Bleu_2": 0.18569533817053427, "Bleu_3": 1.0849575490867782e-06, "Bleu_4": 2.647379627419493e-09, "METEOR": 0.19991359569885706, "ROUGE_L": 0.29075309818875117, "CIDEr": 0.02661899768994105, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.4444444444444444, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.6, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a baseball player in the middle of a game, holding a bat and running towards home plate. The crowd is cheering and watching from the stands."}, "376773": {"image_id": 376773, "Bleu_1": 0.30434782607372407, "Bleu_2": 0.20372033840756823, "Bleu_3": 0.12549213105395926, "Bleu_4": 1.7729842263868143e-05, "METEOR": 0.131372869834205, "ROUGE_L": 0.2423038728897716, "CIDEr": 0.016867756425638324, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.14285714285714285, "f": 0.15, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A group of children playing tennis on a sunny day at an outdoor court.\""}, "93435": {"image_id": 93435, "Bleu_1": 0.7999999998400004, "Bleu_2": 0.6666666665296299, "Bleu_3": 0.5503212080324162, "Bleu_4": 0.3928146508141954, "METEOR": 0.3033502192537088, "ROUGE_L": 0.6609907120743034, "CIDEr": 1.2650888015420128, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.21739130434782608, "f": 0.25, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "Two men sitting at a table outside, enjoying their meals."}, "215579": {"image_id": 215579, "Bleu_1": 0.8571428570816327, "Bleu_2": 0.7262730391486911, "Bleu_3": 0.6034799806556997, "Bleu_4": 0.37596635291638075, "METEOR": 0.3054431913360709, "ROUGE_L": 0.49061662198391426, "CIDEr": 1.3248714198361977, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.23076923076923078, "f": 0.17647058823529413, "fn": 10.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "A cat is sitting on top of a television set, looking at the screen."}, "350851": {"image_id": 350851, "Bleu_1": 0.6190476190181406, "Bleu_2": 0.4309458036646331, "Bleu_3": 0.3083691961453375, "Bleu_4": 0.23891455817181373, "METEOR": 0.3060453150080505, "ROUGE_L": 0.543026706231454, "CIDEr": 0.35352617520010854, "SPICE": {"All": {"pr": 0.17142857142857143, "re": 0.2857142857142857, "f": 0.21428571428571427, "fn": 15.0, "numImages": 1.0, "fp": 29.0, "tp": 6.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.16666666666666666, "f": 0.10526315789473684, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5714285714285714, "f": 0.34782608695652173, "fn": 3.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}}, "caption": "The image shows a black and white cat sitting on top of a refrigerator with various food items and drinks inside."}, "380414": {"image_id": 380414, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.19973386548003494, "Bleu_3": 0.13753786517106545, "Bleu_4": 0.10369816700415074, "METEOR": 0.21837279742422613, "ROUGE_L": 0.2635802469135803, "CIDEr": 1.3566418565052673e-08, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.625, "f": 0.3448275862068965, "fn": 3.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.3333333333333333, "f": 0.15384615384615383, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is an image of two people skateboarding in a parking lot. One person is standing on the sidewalk and the other is on the ground, holding onto the skateboard. The building in the background is a large, modern office building with large windows and a flat roof."}, "332058": {"image_id": 332058, "Bleu_1": 0.2666666666607408, "Bleu_2": 0.1740776559517855, "Bleu_3": 0.11211985653837894, "Bleu_4": 1.3534729403222222e-05, "METEOR": 0.2331625852410396, "ROUGE_L": 0.24646464646464644, "CIDEr": 9.68229406810632e-09, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.18181818181818182, "f": 0.16326530612244897, "fn": 18.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a man walking on the beach with a surfboard under his arm. He is wearing a black and white wetsuit and sunglasses, and his hair is blowing in the wind. The ocean is calm and there are waves breaking on the shore."}, "531896": {"image_id": 531896, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.11215443081631235, "Bleu_3": 6.230790884875896e-07, "Bleu_4": 1.475756952410161e-09, "METEOR": 0.19153801271921755, "ROUGE_L": 0.2445589919816724, "CIDEr": 9.073086820174648e-12, "SPICE": {"All": {"pr": 0.15, "re": 0.12, "f": 0.1333333333333333, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a man carrying a child in a stroller while walking through an airport terminal. The man is wearing a backpack and has a suitcase in his hand. The child is sitting in the stroller and looking around. There are other people in the background, some of whom are also carrying luggage."}, "160703": {"image_id": 160703, "Bleu_1": 0.29629629628532245, "Bleu_2": 0.10675210253269501, "Bleu_3": 7.69610448813251e-07, "Bleu_4": 2.0876149875064654e-09, "METEOR": 0.16595119357820434, "ROUGE_L": 0.28478057889822594, "CIDEr": 0.005582542164833076, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.15384615384615385, "f": 0.1, "fn": 11.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.4, "f": 0.23529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "There are two plates of pizza on the table, one with pepperoni and the other with sausage. There are also two glasses of wine on the table."}, "13985": {"image_id": 13985, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.13453455879664997, "Bleu_3": 0.07126876576918602, "Bleu_4": 9.2709749646976e-06, "METEOR": 0.2076874219032617, "ROUGE_L": 0.22048192771084338, "CIDEr": 1.6160566841713167e-11, "SPICE": {"All": {"pr": 0.125, "re": 0.21052631578947367, "f": 0.1568627450980392, "fn": 15.0, "numImages": 1.0, "fp": 28.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.5, "f": 0.3, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The man is sitting at a table with a laptop in front of him. He is wearing a blue shirt and tie, and has his hair slicked back. There is a bookshelf behind him with several books on it. The room appears to be a bedroom, with a bed in the background."}, "47511": {"image_id": 47511, "Bleu_1": 0.30188679244713423, "Bleu_2": 0.18663625434394554, "Bleu_3": 0.12701286121266542, "Bleu_4": 0.09514824286433504, "METEOR": 0.2139035097709657, "ROUGE_L": 0.2943699731903485, "CIDEr": 2.1560823738270057e-07, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.12, "f": 0.13953488372093023, "fn": 22.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a group of people sitting at a table with laptops and papers in front of them. One woman is writing on a whiteboard while another woman looks on. There are several posters on the walls with words written on them. The room appears to be a classroom or meeting space."}, "262425": {"image_id": 262425, "Bleu_1": 0.3999999999800001, "Bleu_2": 0.14509525001455675, "Bleu_3": 1.053605336689408e-06, "Bleu_4": 2.8800248891848133e-09, "METEOR": 0.15390140282326978, "ROUGE_L": 0.3096446700507614, "CIDEr": 0.016148616549727636, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.2692307692307692, "f": 0.2916666666666667, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.5454545454545454, "f": 0.5714285714285713, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "Sure, here is a short caption for the image:\n\n\"A marina filled with sailboats and yachts on a sunny day\""}, "349402": {"image_id": 349402, "Bleu_1": 0.19444444444174383, "Bleu_2": 0.14801767859355835, "Bleu_3": 0.10777789808402706, "Bleu_4": 1.1606065294167229e-05, "METEOR": 0.22299175333873061, "ROUGE_L": 0.19768518518518519, "CIDEr": 2.5044034129792875e-24, "SPICE": {"All": {"pr": 0.4, "re": 0.2727272727272727, "f": 0.3243243243243243, "fn": 16.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.625, "f": 0.6666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "This image shows a bunch of bananas hanging from a wooden rack in a room. The bananas are yellow and ripe, and they are arranged in a neat row on the rack. There is a wooden floor beneath the rack, and the walls are made of wood as well. The lighting in the room is dim, and there is a window on one side of the room that lets in natural light."}, "11987": {"image_id": 11987, "Bleu_1": 0.41463414633135043, "Bleu_2": 0.26937144541723856, "Bleu_3": 0.15496115116589365, "Bleu_4": 0.09947666715459964, "METEOR": 0.28548836681588463, "ROUGE_L": 0.4191130543410369, "CIDEr": 6.144001074522431e-05, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.16666666666666666, "f": 0.19512195121951217, "fn": 20.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is a bedroom with a striped tent ceiling and a wooden floor. There is a bed with a white sheet and pillows, a table with chairs, and a fireplace with a mantle. The walls are painted with a striped pattern."}, "292209": {"image_id": 292209, "Bleu_1": 0.2027027026999635, "Bleu_2": 0.14904360038636366, "Bleu_3": 0.08513498329256622, "Bleu_4": 0.05429582721953822, "METEOR": 0.19661991788578614, "ROUGE_L": 0.19641214351425942, "CIDEr": 3.1192811567911904e-25, "SPICE": {"All": {"pr": 0.4166666666666667, "re": 0.15151515151515152, "f": 0.2222222222222222, "fn": 28.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.0625, "f": 0.10526315789473684, "fn": 15.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.6, "re": 0.3333333333333333, "f": 0.42857142857142855, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This is an image of a blue and white truck parked in a parking lot. The truck has a large tank on the back of it and a hose attached to the side of it. There are two men standing next to the truck, one of them is holding a wrench and the other is holding a hose. The truck is parked in front of a building with a sign that reads \"Fuel Station\"."}, "92134": {"image_id": 92134, "Bleu_1": 0.29824561402985533, "Bleu_2": 0.2307772635281109, "Bleu_3": 0.16917302609003057, "Bleu_4": 1.7304135150777453e-05, "METEOR": 0.33008582924392676, "ROUGE_L": 0.35446381405176963, "CIDEr": 1.8903377865558777e-12, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.07407407407407407, "f": 0.08333333333333333, "fn": 25.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a beach with lounge chairs and umbrellas on the sand. In the background, there is a cruise ship docked at the pier. The sky is clear and blue, with a few clouds scattered about. The water is calm and clear, with a few boats in the distance. The overall atmosphere is relaxing and peaceful."}, "43098": {"image_id": 43098, "Bleu_1": 0.32727272726677686, "Bleu_2": 0.25819888974242317, "Bleu_3": 0.19615288823180035, "Bleu_4": 0.14445264825736923, "METEOR": 0.3144802961712286, "ROUGE_L": 0.38821657586423025, "CIDEr": 1.6935229518738885e-10, "SPICE": {"All": {"pr": 0.6363636363636364, "re": 0.22580645161290322, "f": 0.3333333333333333, "fn": 24.0, "numImages": 1.0, "fp": 4.0, "tp": 7.0}, "Relation": {"pr": 0.6666666666666666, "re": 0.14285714285714285, "f": 0.23529411764705882, "fn": 12.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.2, "f": 0.33333333333333337, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.3333333333333333, "f": 0.4210526315789474, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a man walking down the sidewalk with a blue suitcase in front of him. The suitcase has the words \"Image Content\" written on it. The man is wearing a black jacket and jeans, and he is carrying a black backpack. The building in the background has a red awning over the door."}, "476735": {"image_id": 476735, "Bleu_1": 0.20454545454080583, "Bleu_2": 0.09753841331211074, "Bleu_3": 6.095846571183441e-07, "Bleu_4": 1.5331320282613667e-09, "METEOR": 0.1590507538107259, "ROUGE_L": 0.2197406340057637, "CIDEr": 1.594094114554743e-08, "SPICE": {"All": {"pr": 0.3684210526315789, "re": 0.4666666666666667, "f": 0.4117647058823529, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 7.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.6, "f": 0.4615384615384615, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a person riding a jet ski on a lake. The person is wearing a life jacket and has their arms outstretched as they jump off the back of the boat. The water is calm and there are trees in the background."}, "263359": {"image_id": 263359, "Bleu_1": 0.27692307691881657, "Bleu_2": 0.14708710135135747, "Bleu_3": 0.10099734594769044, "Bleu_4": 0.07592626695215311, "METEOR": 0.23882684254956382, "ROUGE_L": 0.23396298782241826, "CIDEr": 4.681448155646161e-17, "SPICE": {"All": {"pr": 0.2, "re": 0.18181818181818182, "f": 0.1904761904761905, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a group of people riding horses along a dirt path in the mountains. The horses are brown and white, and the riders are wearing blue shirts and jeans. The sky is clear and blue, with some clouds in the distance. The grass is green and the trees are tall and lush. The riders are smiling and appear to be enjoying their ride."}, "39068": {"image_id": 39068, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.1403458930502932, "Bleu_3": 7.708626205337203e-07, "Bleu_4": 1.817274019118142e-09, "METEOR": 0.17918885450586958, "ROUGE_L": 0.17268223637650387, "CIDEr": 1.8053222978686687e-08, "SPICE": {"All": {"pr": 0.6, "re": 0.16666666666666666, "f": 0.2608695652173913, "fn": 15.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.42857142857142855, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "This is an image of a street with a tree growing out of the sidewalk. The tree is surrounded by buildings on either side, and there are cars parked along the street. The sky is clear and blue, with a few clouds scattered across it."}, "439427": {"image_id": 439427, "Bleu_1": 0.20454545454080583, "Bleu_2": 0.13794014695833945, "Bleu_3": 0.07680285411963501, "Bleu_4": 1.025267180148627e-05, "METEOR": 0.2041859943384005, "ROUGE_L": 0.25702247191011235, "CIDEr": 1.815423907795215e-08, "SPICE": {"All": {"pr": 0.1875, "re": 0.13636363636363635, "f": 0.15789473684210525, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is an image of a person snowboarding down a hill in the snow. The person is wearing a black and white jacket and pants, and has their arms outstretched to balance themselves. There are trees in the background, and the sky is cloudy."}, "177420": {"image_id": 177420, "Bleu_1": 0.47826086954442354, "Bleu_2": 0.39009474878540096, "Bleu_3": 0.24380931992651245, "Bleu_4": 2.917630083954008e-05, "METEOR": 0.25703687877786957, "ROUGE_L": 0.407119021134594, "CIDEr": 0.1149195672699857, "SPICE": {"All": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 15.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is a bathroom with a green wall and a white sink. There is a mirror on the wall and a wooden floor."}, "82994": {"image_id": 82994, "Bleu_1": 0.35897435896515456, "Bleu_2": 0.3073547405967436, "Bleu_3": 0.27335227853056604, "Bleu_4": 0.2510388336878763, "METEOR": 0.4213054869911078, "ROUGE_L": 0.45692883895131076, "CIDEr": 5.789882516046798e-05, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.125, "f": 0.13953488372093023, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a group of people standing in front of an airplane. They are all wearing military uniforms and are smiling for the camera. The airplane has the words \"US Air Force\" written on the side of it."}, "548780": {"image_id": 548780, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.18898223650071672, "Bleu_3": 0.15604075333783501, "Bleu_4": 0.13481992110749652, "METEOR": 0.26739020737850533, "ROUGE_L": 0.31504196255648803, "CIDEr": 3.7454926212424296e-09, "SPICE": {"All": {"pr": 0.25, "re": 0.2413793103448276, "f": 0.24561403508771928, "fn": 22.0, "numImages": 1.0, "fp": 21.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.16666666666666666, "f": 0.2105263157894737, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows two women sitting on a bench in a city square. They are both wearing sunglasses and one of them is holding a bird on her lap. The bird is perched on the other woman's lap. The scene is surrounded by buildings and people walking by."}, "78381": {"image_id": 78381, "Bleu_1": 0.3829787233961069, "Bleu_2": 0.24141120717629194, "Bleu_3": 0.15720795999973383, "Bleu_4": 1.7238232342610575e-05, "METEOR": 0.2239164880102366, "ROUGE_L": 0.22775357809583074, "CIDEr": 1.8569568611190093e-05, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.38461538461538464, "f": 0.2325581395348837, "fn": 8.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.5, "f": 0.22222222222222224, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.8, "f": 0.47058823529411764, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "This is an image of a baseball game in progress. There are several players on the field, including one who is sliding into home plate while another player is catching the ball. The crowd is cheering and there are people standing on the sidelines watching the game."}, "335658": {"image_id": 335658, "Bleu_1": 0.6874999999570314, "Bleu_2": 0.6055300707803913, "Bleu_3": 0.47141253750235657, "Bleu_4": 0.2996160046293989, "METEOR": 0.4336893699634929, "ROUGE_L": 0.5319767441860466, "CIDEr": 1.1847797602535701, "SPICE": {"All": {"pr": 0.3, "re": 0.17647058823529413, "f": 0.22222222222222224, "fn": 14.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "A white mouse sitting on a wooden desk next to a keyboard and a computer monitor."}, "101022": {"image_id": 101022, "Bleu_1": 0.38095238093424044, "Bleu_2": 4.364357804506826e-09, "Bleu_3": 1.0008347248783542e-11, "Bleu_4": 4.857956790434755e-13, "METEOR": 0.19326404716305584, "ROUGE_L": 0.33116178067318125, "CIDEr": 0.07777168179422601, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.13636363636363635, "f": 0.11999999999999998, "fn": 19.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a road sign with the number 60 written on it. The sign is surrounded by snow and trees."}, "147482": {"image_id": 147482, "Bleu_1": 0.2142857142818878, "Bleu_2": 0.13957263155725563, "Bleu_3": 0.07118725684669193, "Bleu_4": 9.083071358441841e-06, "METEOR": 0.19513247747151907, "ROUGE_L": 0.21229698375870068, "CIDEr": 1.4161487006272685e-14, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.10714285714285714, "f": 0.10714285714285714, "fn": 25.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.375, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a group of people flying kites on a sunny day at the beach. The kites are colorful and have different shapes, such as fish, birds, and other creatures. The people are standing on the sand, watching the kites fly in the sky. There are also other people in the background, enjoying the festival."}, "530836": {"image_id": 530836, "Bleu_1": 0.3809523809433107, "Bleu_2": 0.23611253443469188, "Bleu_3": 0.11170159251877247, "Bleu_4": 1.3749229838123656e-05, "METEOR": 0.23985368195041543, "ROUGE_L": 0.3092522179974651, "CIDEr": 8.269001797255068e-06, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.04, "f": 0.052631578947368425, "fn": 24.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "This is an image of a kitchen with white appliances and a black and white checkered floor. There is a stove, refrigerator, and sink in the kitchen. The walls are painted a light green color and there are curtains on the windows."}, "376284": {"image_id": 376284, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.14280110945625535, "Bleu_3": 0.09406593130377755, "Bleu_4": 1.1475297679846863e-05, "METEOR": 0.16269569157303673, "ROUGE_L": 0.22889305816135083, "CIDEr": 9.253562434315374e-11, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.35714285714285715, "f": 0.3174603174603175, "fn": 18.0, "numImages": 1.0, "fp": 25.0, "tp": 10.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.4666666666666667, "re": 0.6363636363636364, "f": 0.5384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 7.0}}, "caption": "This is an image of a fire hydrant on the side of the road. It is made of metal and has a handle on top. There are several other fire hydrants in the background, also made of metal. The image is taken from a low angle, looking down at the hydrants."}, "134346": {"image_id": 134346, "Bleu_1": 0.14563106795975117, "Bleu_2": 0.10687396570611038, "Bleu_3": 0.06974524060623692, "Bleu_4": 7.63195731325573e-06, "METEOR": 0.15495374756067198, "ROUGE_L": 0.16425445977785255, "CIDEr": 9.56581769715867e-53, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.4444444444444444, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 1.0, "f": 0.6153846153846153, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "Sure, here is a short caption for the image:\n\nThe two bears are standing on the edge of a small pond, looking out at the water. They appear to be enjoying the view and the cool breeze on their fur. The pond is surrounded by rocks and trees, and there is a small bridge leading over it. The bears are standing on the edge of the pond, looking out at the water. They appear to be enjoying the view and the cool breeze on their fur. The pond is surrounded by rocks and trees, and there is a small bridge leading over it."}, "571215": {"image_id": 571215, "Bleu_1": 0.3255813953412656, "Bleu_2": 0.17609018126098094, "Bleu_3": 0.09110918073501856, "Bleu_4": 1.1726181398583003e-05, "METEOR": 0.20834871406392666, "ROUGE_L": 0.40203714799281004, "CIDEr": 8.813980290554015e-06, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.16, "f": 0.17391304347826086, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This image shows a graffiti mural of a person running on a sidewalk. The person is wearing a black and white striped shirt and has a red hat on their head. The mural is painted on a concrete wall in a dark color."}, "104313": {"image_id": 104313, "Bleu_1": 0.3124999999902345, "Bleu_2": 0.17390208590454106, "Bleu_3": 1.0026809779444285e-06, "Bleu_4": 2.4281336212346506e-09, "METEOR": 0.28409746172946754, "ROUGE_L": 0.2970779220779221, "CIDEr": 0.0022745763653247517, "SPICE": {"All": {"pr": 0.30434782608695654, "re": 0.23333333333333334, "f": 0.26415094339622636, "fn": 23.0, "numImages": 1.0, "fp": 16.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.18181818181818182, "f": 0.26666666666666666, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a box filled with various types of donuts, including chocolate frosted, sprinkled, and glazed. There are also cups of coffee and tea on the table next to the box."}, "82678": {"image_id": 82678, "Bleu_1": 0.28571428570918367, "Bleu_2": 0.14414999402869194, "Bleu_3": 7.273528851712344e-07, "Bleu_4": 1.641496295683848e-09, "METEOR": 0.16071643319201656, "ROUGE_L": 0.21229698375870068, "CIDEr": 1.8455908740902666e-12, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 18.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}}, "caption": "This is a view of the ocean from a bench on the beach. The water is calm and clear, with a few boats in the distance. The sky is blue and cloudy, with a few white clouds floating in it. The bench is made of metal and has a sign that reads, \"Welcome to the beach.\""}, "127781": {"image_id": 127781, "Bleu_1": 0.27906976743537054, "Bleu_2": 0.2577696311071676, "Bleu_3": 0.23492174066127405, "Bleu_4": 0.21824882776467988, "METEOR": 0.44315601467946353, "ROUGE_L": 0.4250871080139373, "CIDEr": 3.334415665483118e-07, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.19230769230769232, "f": 0.23255813953488372, "fn": 21.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a black cat sitting under an umbrella on the floor. The cat is looking up at the umbrella with its eyes. The umbrella is open and has a handle on the side. There is a white wall in the background."}, "235791": {"image_id": 235791, "Bleu_1": 0.2166666666630556, "Bleu_2": 0.12119928026283562, "Bleu_3": 0.07971389456746727, "Bleu_4": 9.709163330925734e-06, "METEOR": 0.2109097271933115, "ROUGE_L": 0.22521097046413502, "CIDEr": 1.6447814219124355e-15, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.26666666666666666, "f": 0.163265306122449, "fn": 11.0, "numImages": 1.0, "fp": 30.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.14285714285714285, "re": 0.5, "f": 0.22222222222222224, "fn": 2.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "This is a photograph of a boat floating on a river surrounded by buildings on either side. The boat is white and has red and white stripes on it. There are several other boats in the background, some of which are also white and have red and white stripes. The sky is blue and there are some clouds in it."}, "281448": {"image_id": 281448, "Bleu_1": 0.4166666666319445, "Bleu_2": 0.19462473602342495, "Bleu_3": 1.5588297692668627e-06, "Bleu_4": 4.5293761703575315e-09, "METEOR": 0.2587371485048883, "ROUGE_L": 0.4149659863945578, "CIDEr": 0.5072599622325511, "SPICE": {"All": {"pr": 0.16, "re": 0.2222222222222222, "f": 0.18604651162790697, "fn": 14.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "A white sheep and a black sheep graze in a green field."}, "291589": {"image_id": 291589, "Bleu_1": 0.3225806451508845, "Bleu_2": 0.20739033893928357, "Bleu_3": 1.1404064937195537e-06, "Bleu_4": 2.697772065383126e-09, "METEOR": 0.1973571148368296, "ROUGE_L": 0.3451899757477768, "CIDEr": 0.0034229891330360657, "SPICE": {"All": {"pr": 0.5, "re": 0.3125, "f": 0.38461538461538464, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.75, "re": 0.6, "f": 0.6666666666666665, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image shows a dining table with several vases of flowers on it. The walls are painted a light green color and there is a white lamp hanging from the ceiling."}, "161567": {"image_id": 161567, "Bleu_1": 0.36956521738327036, "Bleu_2": 0.3005630786494515, "Bleu_3": 0.24313018181836488, "Bleu_4": 0.1779476905229679, "METEOR": 0.3218444215812708, "ROUGE_L": 0.32317880794701986, "CIDEr": 1.4770389941647812e-07, "SPICE": {"All": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 28.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.23076923076923078, "f": 0.2857142857142857, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a man and a woman standing in a kitchen, both wearing jeans and white shirts. The man is holding a spatula and the woman is holding a frying pan. They are both smiling at each other as they stand next to a stove."}, "85556": {"image_id": 85556, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.18857036045053577, "Bleu_3": 0.11172119198541168, "Bleu_4": 1.2922875770638225e-05, "METEOR": 0.25721920694032163, "ROUGE_L": 0.24811156304474144, "CIDEr": 1.4126160592518049e-11, "SPICE": {"All": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 12.0, "numImages": 1.0, "fp": 12.0, "tp": 8.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6666666666666666, "f": 0.5714285714285715, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a plate of pizza on a table with a beer glass next to it. The pizza has cheese, pepperoni, and other toppings on it. There is a white napkin on the table and a red and white checkered tablecloth. The background is a wooden deck with chairs and umbrellas nearby."}, "183204": {"image_id": 183204, "Bleu_1": 0.35483870966597303, "Bleu_2": 0.21751282250452736, "Bleu_3": 0.11772189470040113, "Bleu_4": 1.5536508417020945e-05, "METEOR": 0.17445015350475787, "ROUGE_L": 0.26872246696035246, "CIDEr": 0.0018733042485830657, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.19047619047619047, "f": 0.16666666666666666, "fn": 17.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A collection of items laid out on a red carpet, including clothing, gear, and other supplies for a camping or outdoor adventure.\""}, "264787": {"image_id": 264787, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.20782052056698208, "Bleu_3": 0.14674773886538112, "Bleu_4": 0.0942786957423983, "METEOR": 0.2995364530843389, "ROUGE_L": 0.34882058613295214, "CIDEr": 1.1185567986136018e-07, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.14285714285714285, "f": 0.19047619047619047, "fn": 24.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.2727272727272727, "f": 0.3529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a cat hiding under a blanket. The cat has its head peeking out from under the blanket, looking curiously at the camera. The background is a blue and white striped blanket with a small white pillow on top of it."}, "251140": {"image_id": 251140, "Bleu_1": 0.4999999999750001, "Bleu_2": 0.28097574346008974, "Bleu_3": 0.16368983753038932, "Bleu_4": 2.253741272145215e-05, "METEOR": 0.26501895833657013, "ROUGE_L": 0.33701657458563533, "CIDEr": 0.07625089344790473, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.19230769230769232, "f": 0.19230769230769232, "fn": 21.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The book is titled \"the ten-speed bicycle\" and shows a group of people working on a bicycle in a garage."}, "5644": {"image_id": 5644, "Bleu_1": 0.14893617020959712, "Bleu_2": 0.09855571262853866, "Bleu_3": 5.998606361814997e-07, "Bleu_4": 1.4882455879058203e-09, "METEOR": 0.11904539863484748, "ROUGE_L": 0.23404527433175598, "CIDEr": 4.254605637916772e-10, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.16666666666666666, "f": 0.09523809523809522, "fn": 10.0, "numImages": 1.0, "fp": 28.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2857142857142857, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a person skateboarding on a ramp in front of a park. The person is wearing a red hoodie and blue jeans, and has a red helmet on their head. The sun is setting in the background, casting a warm orange glow over the scene."}, "246535": {"image_id": 246535, "Bleu_1": 0.37777777776938276, "Bleu_2": 0.22696949467458388, "Bleu_3": 0.10620757885664733, "Bleu_4": 1.2995838594729719e-05, "METEOR": 0.2859188047642841, "ROUGE_L": 0.24063116370808676, "CIDEr": 4.247466742217166e-08, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.10526315789473684, "f": 0.1, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The man is holding a tennis racket and swinging it at the ball on the court. He is wearing white shorts and a white shirt with a red stripe on the sleeve. The background is a green tennis court with a net in the center."}, "102555": {"image_id": 102555, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.13736056394607243, "Bleu_3": 0.07178791139239354, "Bleu_4": 9.274617069102212e-06, "METEOR": 0.24531391302279779, "ROUGE_L": 0.25894481503941785, "CIDEr": 4.966376199163016e-12, "SPICE": {"All": {"pr": 0.1875, "re": 0.0967741935483871, "f": 0.12765957446808507, "fn": 28.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.16666666666666666, "f": 0.2105263157894737, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The man is kneeling down next to a small dog, both of them are smiling. The man is wearing a hat and has a backpack on his back. The dog is wearing a collar and is looking up at the man. The background is a wooden floor with some chairs and tables nearby."}, "80328": {"image_id": 80328, "Bleu_1": 0.44999999997750006, "Bleu_2": 0.266556994977913, "Bleu_3": 0.1580408005034111, "Bleu_4": 2.1951524425427533e-05, "METEOR": 0.2275841544219835, "ROUGE_L": 0.4117911791179118, "CIDEr": 0.13325196962127803, "SPICE": {"All": {"pr": 0.16, "re": 0.17391304347826086, "f": 0.16666666666666666, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a herd of zebras grazing in a green field with a group of wildebeest in the background."}, "366493": {"image_id": 366493, "Bleu_1": 0.22580645160926122, "Bleu_2": 0.13604677703436896, "Bleu_3": 6.756810749922659e-07, "Bleu_4": 1.5121445668009706e-09, "METEOR": 0.1738871151793346, "ROUGE_L": 0.20788704965920152, "CIDEr": 1.0856993427305866e-14, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.17391304347826086, "f": 0.1702127659574468, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a plate of sliced apples with a knife on top. The apples are cut into thin slices and are arranged in a neat pattern on the plate. The knife is placed on top of the apples, with its blade facing upwards. The plate is on a white surface, and there is a fork on the side of the plate."}, "455624": {"image_id": 455624, "Bleu_1": 0.3333333333263889, "Bleu_2": 0.1883108942847125, "Bleu_3": 9.169191011404368e-07, "Bleu_4": 2.034441173199727e-09, "METEOR": 0.17146873881686564, "ROUGE_L": 0.27371794871794874, "CIDEr": 1.9484252256099133e-08, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.07142857142857142, "f": 0.0975609756097561, "fn": 26.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a motorcycle racing down a dirt track in the middle of a field. The rider is wearing a helmet and is leaning forward on the bike, with his arms outstretched. The background is a grassy field with hay bales and people watching from the sidelines."}, "2142": {"image_id": 2142, "Bleu_1": 0.5238095237845806, "Bleu_2": 0.4577377081947216, "Bleu_3": 0.4044613344206799, "Bleu_4": 0.368198599768179, "METEOR": 0.42771513399513755, "ROUGE_L": 0.574793875147232, "CIDEr": 0.31122652111944527, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.12, "f": 0.13953488372093023, "fn": 22.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA man sitting on a bench surrounded by pigeons in a park."}, "137538": {"image_id": 137538, "Bleu_1": 0.1964285714250638, "Bleu_2": 0.13363062095380426, "Bleu_3": 6.91522111125961e-07, "Bleu_4": 1.5804675591263229e-09, "METEOR": 0.17643353836296546, "ROUGE_L": 0.21682464454976302, "CIDEr": 1.8029072450613874e-14, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.13793103448275862, "f": 0.126984126984127, "fn": 25.0, "numImages": 1.0, "fp": 30.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a white pelican standing on a rock in the middle of a pond. The pelican is looking down at a smaller bird, possibly a heron, that is standing on the other side of the rock. The pond is surrounded by trees and greenery, and there are other birds flying in the sky above."}, "114891": {"image_id": 114891, "Bleu_1": 0.32432432431555885, "Bleu_2": 0.13423121103912666, "Bleu_3": 8.014559500904618e-07, "Bleu_4": 1.9726044742773524e-09, "METEOR": 0.2625146950574286, "ROUGE_L": 0.32323996971990915, "CIDEr": 0.0001388671463960843, "SPICE": {"All": {"pr": 0.4444444444444444, "re": 0.2857142857142857, "f": 0.34782608695652173, "fn": 20.0, "numImages": 1.0, "fp": 10.0, "tp": 8.0}, "Relation": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.625, "re": 0.5555555555555556, "f": 0.5882352941176471, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "This is a small brown dog sitting in a large, fluffy pillow. The dog is wearing a blue collar and has its paws on the pillow. There is a banana on the floor next to the dog."}, "15953": {"image_id": 15953, "Bleu_1": 0.4102564102458909, "Bleu_2": 0.27490643727245323, "Bleu_3": 0.12687888836700859, "Bleu_4": 1.5433570088200913e-05, "METEOR": 0.31048613968801825, "ROUGE_L": 0.3198501872659176, "CIDEr": 8.438808161839056e-06, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.17647058823529413, "f": 0.15384615384615383, "fn": 14.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a plate with a cupcake topped with whipped cream and sprinkled with cinnamon. There are several apples on the table, including one that has been bitten into. The background is a red and white checkered tablecloth."}, "566155": {"image_id": 566155, "Bleu_1": 0.4583333333142362, "Bleu_2": 0.2823298512746205, "Bleu_3": 0.1935115854658825, "Bleu_4": 0.13629358171800737, "METEOR": 0.21579584260444845, "ROUGE_L": 0.3546511627906977, "CIDEr": 0.06637525690815066, "SPICE": {"All": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 21.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3, "f": 0.24, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "This is a bathroom with a toilet, sink, and shower. The walls are painted white and there is a blue bucket in the corner."}, "137321": {"image_id": 137321, "Bleu_1": 0.255813953482423, "Bleu_2": 0.19116707482361836, "Bleu_3": 0.12125252078651538, "Bleu_4": 0.08170583718657062, "METEOR": 0.2714432765735724, "ROUGE_L": 0.33174711080897346, "CIDEr": 5.556897933314396e-07, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.15384615384615385, "f": 0.14814814814814817, "fn": 22.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3076923076923077, "f": 0.32, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "This is a black and white image of a bedroom with a bed, nightstand, and chair. The bed has a quilt on it and there are some books on the nightstand. The chair is empty and there is a window in the background."}, "166259": {"image_id": 166259, "Bleu_1": 0.222222222217284, "Bleu_2": 0.12309149097656633, "Bleu_3": 0.07063108368194851, "Bleu_4": 9.57049894254339e-06, "METEOR": 0.22936369595787579, "ROUGE_L": 0.2053872053872054, "CIDEr": 1.970452243881656e-08, "SPICE": {"All": {"pr": 0.3, "re": 0.11538461538461539, "f": 0.16666666666666669, "fn": 23.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.2727272727272727, "f": 0.37499999999999994, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "Four ducks walking on a wooden walkway\n\nThe image shows four ducks walking on a wooden walkway. They are all facing the same direction and appear to be in a line. The walkway is surrounded by greenery and there are some buildings in the background."}, "56669": {"image_id": 56669, "Bleu_1": 0.382352941165225, "Bleu_2": 0.18643861801326042, "Bleu_3": 1.0279545754105056e-06, "Bleu_4": 2.4329882944987743e-09, "METEOR": 0.24241621413539502, "ROUGE_L": 0.28549141965678626, "CIDEr": 0.00037124704690499053, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.34782608695652173, "f": 0.3137254901960784, "fn": 15.0, "numImages": 1.0, "fp": 20.0, "tp": 8.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.125, "f": 0.10526315789473685, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5, "f": 0.4347826086956522, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a man playing frisbee in a park. He is standing in front of a metal pole with a frisbee in his hand, and there are trees and grass in the background."}, "4979": {"image_id": 4979, "Bleu_1": 0.24137931034066593, "Bleu_2": 0.18405922400671818, "Bleu_3": 0.08457507315944857, "Bleu_4": 1.0240970478949073e-05, "METEOR": 0.227712660438032, "ROUGE_L": 0.2660850599781897, "CIDEr": 1.2695629067838887e-13, "SPICE": {"All": {"pr": 0.25, "re": 0.24, "f": 0.24489795918367346, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3076923076923077, "f": 0.34782608695652173, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is an image of a red chair with a white horse on it. The horse is standing on the seat of the chair and looks like it is about to jump off. The chair is made of metal and has a red and white striped pattern on it. There are buildings in the background of the image."}, "197350": {"image_id": 197350, "Bleu_1": 0.39999999999, "Bleu_2": 0.33588764909534785, "Bleu_3": 0.2611671647800347, "Bleu_4": 0.20948527325149155, "METEOR": 0.31515987826986785, "ROUGE_L": 0.40234518138512276, "CIDEr": 5.33756232095227e-06, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.2, "f": 0.20833333333333331, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a woman in a red dress playing tennis on a court. She is holding a tennis racket and appears to be preparing to hit the ball. The background is a blue sky with some clouds in it."}, "7888": {"image_id": 7888, "Bleu_1": 0.2777777777700618, "Bleu_2": 0.1259881576661928, "Bleu_3": 7.757590387941911e-07, "Bleu_4": 1.939396682572253e-09, "METEOR": 0.16210942215323984, "ROUGE_L": 0.24918300653594777, "CIDEr": 4.38015954784498e-05, "SPICE": {"All": {"pr": 0.625, "re": 0.22727272727272727, "f": 0.3333333333333333, "fn": 17.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}}, "caption": "This is an image of a clock tower in the middle of a field. The clock has two hands and is surrounded by grass. The sky is cloudy and there are no people in the image."}, "248457": {"image_id": 248457, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.19026059765810296, "Bleu_3": 0.17176786449592008, "Bleu_4": 0.1578320617906604, "METEOR": 0.3577077546220242, "ROUGE_L": 0.3380541871921182, "CIDEr": 1.5075492929308603e-11, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.2, "f": 0.25641025641025644, "fn": 20.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1111111111111111, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4, "f": 0.47058823529411764, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a person sitting on the ground with an umbrella over their head. The person is wearing a black shirt and pants, and has a backpack on their back. The umbrella is black and has a white handle. The background is a dirt road with some trees in the distance."}, "61735": {"image_id": 61735, "Bleu_1": 0.12857142856959186, "Bleu_2": 0.09652341781177916, "Bleu_3": 0.051552787958869445, "Bleu_4": 6.724661326588284e-06, "METEOR": 0.23516432216123884, "ROUGE_L": 0.17958783120706576, "CIDEr": 3.290457883418e-23, "SPICE": {"All": {"pr": 0.09375, "re": 0.15, "f": 0.11538461538461538, "fn": 17.0, "numImages": 1.0, "fp": 29.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.08333333333333333, "re": 0.2, "f": 0.11764705882352941, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Size": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "This is an image of a dog sitting on a desk in front of a computer. The dog is looking up at the camera with its tongue hanging out of its mouth. The desk has a computer on it with a monitor and keyboard. There is a lamp on the desk next to the computer. The room is dimly lit and there are some books and papers on the desk."}, "9236": {"image_id": 9236, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.13197176106186115, "Bleu_3": 0.088065799309334, "Bleu_4": 0.0607943136593165, "METEOR": 0.2118073429478997, "ROUGE_L": 0.24707788450410828, "CIDEr": 1.6842959902610313e-11, "SPICE": {"All": {"pr": 0.5, "re": 0.38461538461538464, "f": 0.4347826086956522, "fn": 16.0, "numImages": 1.0, "fp": 10.0, "tp": 10.0}, "Relation": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5714285714285714, "re": 0.4, "f": 0.47058823529411764, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}, "Size": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.625, "re": 0.625, "f": 0.625, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "This image shows a kitchen with a refrigerator, stove, and sink. There is also a table with chairs in the corner of the room. The walls are painted white and there are wooden cabinets above the countertops. The floor is made of hardwood and there is a door leading out of the room."}, "228335": {"image_id": 228335, "Bleu_1": 0.3157894736759004, "Bleu_2": 0.18476851073338801, "Bleu_3": 9.824666233056464e-07, "Bleu_4": 2.2815045692245487e-09, "METEOR": 0.2469638896257273, "ROUGE_L": 0.295638126009693, "CIDEr": 9.832016761033643e-06, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.25, "f": 0.2608695652173913, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.4, "re": 0.2, "f": 0.26666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is a kitchen with a stove, refrigerator, and sink. There are several pots and pans on the countertops, as well as a microwave oven. The walls are painted white and there are several windows in the room."}, "451449": {"image_id": 451449, "Bleu_1": 0.2166666666630556, "Bleu_2": 0.17140166589755992, "Bleu_3": 7.971389456746732e-07, "Bleu_4": 1.7265605240090155e-09, "METEOR": 0.19624006744147376, "ROUGE_L": 0.22521097046413502, "CIDEr": 6.460740540868609e-16, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 14.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a dog lying on top of a pile of books on a bed. The dog is wearing a collar and appears to be sleeping. There are several books and other items on the bed, including a lamp, a vase, and a small table. The room appears to be a bedroom, with a window visible in the background."}, "254033": {"image_id": 254033, "Bleu_1": 0.18840579709871877, "Bleu_2": 0.11770032894399912, "Bleu_3": 0.05913258301516445, "Bleu_4": 7.4814220226521244e-06, "METEOR": 0.17645443358324292, "ROUGE_L": 0.1818181818181818, "CIDEr": 3.983948360241929e-22, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.20833333333333334, "f": 0.20833333333333334, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows two zebras standing in a clearing surrounded by trees. They are both black and white with distinctive stripes on their backs. One of the zebras is standing in the foreground, looking directly at the camera, while the other is standing in the background, looking away. The trees in the background are tall and green, providing a contrast to the black and white stripes of the zebras."}, "515555": {"image_id": 515555, "Bleu_1": 0.2181818181778513, "Bleu_2": 0.16817499303341832, "Bleu_3": 0.12875644765560088, "Bleu_4": 0.08004346926940502, "METEOR": 0.21998362264207352, "ROUGE_L": 0.27555053642010163, "CIDEr": 9.872160967568256e-13, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.07407407407407407, "f": 0.11764705882352941, "fn": 25.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "This image shows a large, ornate building with a clock tower in the center. The building has a lot of intricate details, including carvings and arches. The clock tower is tall and slender, with a large clock face on the front. The sky is cloudy and gray, with a few birds flying in the air."}, "69213": {"image_id": 69213, "Bleu_1": 0.47058823526643606, "Bleu_2": 0.2425356250216204, "Bleu_3": 0.1576957321539479, "Bleu_4": 2.300556723830808e-05, "METEOR": 0.21626241690308226, "ROUGE_L": 0.35589264877479576, "CIDEr": 0.6483407867558453, "SPICE": {"All": {"pr": 0.125, "re": 0.11538461538461539, "f": 0.12000000000000001, "fn": 23.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "Two men in hats and suits stand on the sidewalk, looking at something in front of them."}, "579362": {"image_id": 579362, "Bleu_1": 0.17117117116962907, "Bleu_2": 0.13083240086770287, "Bleu_3": 0.10320499601445364, "Bleu_4": 0.08446214435819425, "METEOR": 0.21735137561309223, "ROUGE_L": 0.20870917573872474, "CIDEr": 4.1317796744287085e-54, "SPICE": {"All": {"pr": 0.08163265306122448, "re": 0.23529411764705882, "f": 0.12121212121212122, "fn": 13.0, "numImages": 1.0, "fp": 45.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 17.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.21052631578947367, "re": 0.6666666666666666, "f": 0.32, "fn": 2.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}}, "caption": "A man sits on a bench on the beach, looking out at the ocean. The sky is clear and blue, with a few clouds scattered in it. The sand is white and the water is clear and blue.\n\nThe man is wearing a white shirt and blue shorts, and has his arms crossed over his chest. He looks out at the ocean, lost in thought.\n\nIn the background, people are walking along the beach, enjoying the sun and the water. Some are playing games, while others are simply relaxing.\n\nThe overall mood of the image is peaceful and serene, with the man lost in thought and the people enjoying the beach."}, "244496": {"image_id": 244496, "Bleu_1": 0.3749999999882814, "Bleu_2": 0.26940795303160764, "Bleu_3": 0.13424553701132266, "Bleu_4": 1.6995165295471083e-05, "METEOR": 0.23732328341130698, "ROUGE_L": 0.39610389610389607, "CIDEr": 0.004308663158679243, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.1, "f": 0.0909090909090909, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.45454545454545453, "f": 0.43478260869565216, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "A man is standing in front of a door wearing a red shirt and black pants. He has a red tie around his neck and is holding a cigarette in his hand."}, "121041": {"image_id": 121041, "Bleu_1": 0.22033898304711294, "Bleu_2": 0.15097578581028312, "Bleu_3": 7.367382993796893e-07, "Bleu_4": 1.6346994958840727e-09, "METEOR": 0.20199776084670107, "ROUGE_L": 0.17300056721497448, "CIDEr": 3.528056626820971e-16, "SPICE": {"All": {"pr": 0.1282051282051282, "re": 0.15625, "f": 0.14084507042253522, "fn": 27.0, "numImages": 1.0, "fp": 34.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 16.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.25, "f": 0.14285714285714288, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.23529411764705882, "re": 0.3333333333333333, "f": 0.27586206896551724, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}}, "caption": "This is an image of a black bird swimming in the ocean. The bird is swimming in the water with its head tucked under its wing. The bird's feathers are ruffled and it appears to be swimming in the water with ease. The background of the image is a blue ocean with white waves crashing against the shore."}, "27235": {"image_id": 27235, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.23260756692519305, "Bleu_3": 0.1700663264201955, "Bleu_4": 0.10341811892391474, "METEOR": 0.29276300216298107, "ROUGE_L": 0.32099229468145085, "CIDEr": 1.0398017635553099e-07, "SPICE": {"All": {"pr": 0.1875, "re": 0.13636363636363635, "f": 0.15789473684210525, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a child's bedroom with a teddy bear sitting on the bed. The walls are painted blue and there is a tree sticker on one wall. The floor is covered in a blue carpet and there is a green plant on the windowsill."}, "229599": {"image_id": 229599, "Bleu_1": 0.7857142856581634, "Bleu_2": 0.6953534953135371, "Bleu_3": 0.586228166010131, "Bleu_4": 0.4374811430871823, "METEOR": 0.3459991554700024, "ROUGE_L": 0.6224489795918368, "CIDEr": 1.6867787360540887, "SPICE": {"All": {"pr": 0.06521739130434782, "re": 0.13043478260869565, "f": 0.08695652173913045, "fn": 20.0, "numImages": 1.0, "fp": 43.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 16.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.13636363636363635, "re": 0.3333333333333333, "f": 0.1935483870967742, "fn": 6.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}}, "caption": "The image shows a clear glass bowl filled with oranges on a wooden surface."}, "435312": {"image_id": 435312, "Bleu_1": 0.2692307692204142, "Bleu_2": 0.1467598771353111, "Bleu_3": 9.645716184391707e-07, "Bleu_4": 2.4993029414165316e-09, "METEOR": 0.19281051745887393, "ROUGE_L": 0.21143847487001732, "CIDEr": 0.0027602556982337673, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.13043478260869565, "f": 0.13636363636363635, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.25, "f": 0.2727272727272727, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is an image of a woman standing at an intersection, looking at her phone. The streetlights are yellow and there are buildings in the background."}, "41257": {"image_id": 41257, "Bleu_1": 0.37499999998437505, "Bleu_2": 0.2553769592167526, "Bleu_3": 0.1809909720898928, "Bleu_4": 2.3050898625539613e-05, "METEOR": 0.2100465584786718, "ROUGE_L": 0.30348258706467657, "CIDEr": 0.03686927991746305, "SPICE": {"All": {"pr": 0.21212121212121213, "re": 0.23333333333333334, "f": 0.22222222222222224, "fn": 23.0, "numImages": 1.0, "fp": 26.0, "tp": 7.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.07142857142857142, "f": 0.07407407407407408, "fn": 13.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.5555555555555556, "f": 0.43478260869565216, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a white ferret sleeping in a bed with a grey background. The ferret is curled up and has its eyes closed."}, "502419": {"image_id": 502419, "Bleu_1": 0.2142857142806123, "Bleu_2": 0.07229440390503974, "Bleu_3": 5.074381600450152e-07, "Bleu_4": 1.3529171154640911e-09, "METEOR": 0.17293307735221336, "ROUGE_L": 0.22197962154294032, "CIDEr": 1.674959300750283e-07, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.3181818181818182, "f": 0.30434782608695654, "fn": 15.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows two elephants standing next to each other in a zoo enclosure. One of the elephants is looking directly at the camera while the other is looking away. The enclosure has a wooden fence and some trees in the background."}, "382309": {"image_id": 382309, "Bleu_1": 0.4583333333142362, "Bleu_2": 0.24450482345050376, "Bleu_3": 0.13954600049383722, "Bleu_4": 1.896632645996694e-05, "METEOR": 0.2295600689775153, "ROUGE_L": 0.3546511627906977, "CIDEr": 0.06951136057302149, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.2727272727272727, "f": 0.2790697674418604, "fn": 16.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a pizza with meat and cheese on top of it. There is a beer can on the table next to it."}, "24601": {"image_id": 24601, "Bleu_1": 0.39999999999, "Bleu_2": 0.33588764909534785, "Bleu_3": 0.22815053318240427, "Bleu_4": 0.13384917078518666, "METEOR": 0.3578392525613723, "ROUGE_L": 0.3588235294117647, "CIDEr": 9.750061063498297e-05, "SPICE": {"All": {"pr": 0.2, "re": 0.08823529411764706, "f": 0.12244897959183675, "fn": 31.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a woman in a white tennis outfit standing on a tennis court, holding a tennis racket and ready to hit the ball. The background is a green grass field with trees and buildings visible in the distance."}, "9527": {"image_id": 9527, "Bleu_1": 0.41666666664930563, "Bleu_2": 0.19034674689861678, "Bleu_3": 1.1809261666306976e-06, "Bleu_4": 2.9758582163943454e-09, "METEOR": 0.2524978136068765, "ROUGE_L": 0.27477477477477474, "CIDEr": 0.0396422906853643, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.23076923076923078, "f": 0.1714285714285714, "fn": 10.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.4, "f": 0.23529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "This is a cluttered office space with a desk, chair, and computer. There are papers and other office supplies on the desk and floor."}, "548538": {"image_id": 548538, "Bleu_1": 0.24999999999652778, "Bleu_2": 0.21395010606691334, "Bleu_3": 0.1577221689990124, "Bleu_4": 0.12280676204602445, "METEOR": 0.21457792838254874, "ROUGE_L": 0.2732974910394265, "CIDEr": 2.848186049828666e-21, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.17647058823529413, "f": 0.1935483870967742, "fn": 14.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a group of people standing on the side of a train track in the middle of a forest. The train is an old, wooden train with green and brown paint and a large, metal engine at the front. The people are dressed in casual clothing and are looking out at the scenery around them. The trees are tall and green, and there are rocks and moss on the ground."}, "284623": {"image_id": 284623, "Bleu_1": 0.23188405796765385, "Bleu_2": 0.18466346893592037, "Bleu_3": 0.14508175784614852, "Bleu_4": 0.10854352878142433, "METEOR": 0.27326148686398194, "ROUGE_L": 0.2633093525179856, "CIDEr": 6.741762622628338e-22, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.19047619047619047, "f": 0.17777777777777778, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This is a black cat sitting on the edge of a bathroom sink. The cat has green eyes and is looking directly at the camera. The sink is made of white porcelain and has a faucet on the right side. There is a towel hanging on the left side of the sink. The cat appears to be looking directly at the camera with an angry expression on its face."}, "376236": {"image_id": 376236, "Bleu_1": 0.17187499999731448, "Bleu_2": 0.13819269959596528, "Bleu_3": 0.08508823255530318, "Bleu_4": 1.0024660377689843e-05, "METEOR": 0.23394205437453794, "ROUGE_L": 0.2205578512396694, "CIDEr": 2.012772620794748e-18, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.19047619047619047, "f": 0.16, "fn": 17.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a young boy feeding a giraffe at a zoo. The giraffe is standing on its hind legs and reaching its long neck to eat from the boy's hand. The boy is wearing a green shirt and blue pants, and the giraffe is wearing a yellow and brown patterned blanket. The background is a wooden fence and a green grassy area."}, "308678": {"image_id": 308678, "Bleu_1": 0.2419354838670656, "Bleu_2": 0.15426254515919732, "Bleu_3": 0.09256921411827357, "Bleu_4": 1.0768046681574556e-05, "METEOR": 0.18849588738859213, "ROUGE_L": 0.2264050901378579, "CIDEr": 7.272583496124071e-17, "SPICE": {"All": {"pr": 0.15151515151515152, "re": 0.2631578947368421, "f": 0.19230769230769232, "fn": 14.0, "numImages": 1.0, "fp": 28.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.1, "re": 0.1111111111111111, "f": 0.10526315789473685, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a group of people in a small boat, surrounded by a large ship. The people are wearing life jackets and are standing on the boat, looking at something in the water. The ship is a large, white vessel with a red and blue stripe on the side. There are other boats in the background, also surrounded by the ship."}, "293625": {"image_id": 293625, "Bleu_1": 0.26829268292028563, "Bleu_2": 0.14185186364132965, "Bleu_3": 8.020507112003898e-07, "Bleu_4": 1.9195767099451357e-09, "METEOR": 0.1579168525090354, "ROUGE_L": 0.27926749509483323, "CIDEr": 2.487888343393805e-06, "SPICE": {"All": {"pr": 0.4, "re": 0.3, "f": 0.34285714285714286, "fn": 14.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image shows two women sitting on a couch, one holding a microphone and the other holding a camera. They are both smiling and looking at each other. The room is dimly lit and there are some plants on the windowsill."}, "313420": {"image_id": 313420, "Bleu_1": 0.24999999999609374, "Bleu_2": 0.1992047682192617, "Bleu_3": 0.13680099421543584, "Bleu_4": 1.4313125573717594e-05, "METEOR": 0.21919759465601668, "ROUGE_L": 0.2139278557114228, "CIDEr": 2.192781100047234e-18, "SPICE": {"All": {"pr": 0.4, "re": 0.42857142857142855, "f": 0.4137931034482759, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.8, "f": 0.5714285714285714, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a stuffed bear sitting on a shelf in a store. The bear is wearing a black and white striped shirt and has a tag on its neck that reads, \"Bear\". The shelf is made of wood and has a few other stuffed animals on it. There is a small table next to the shelf with a vase of flowers on it."}, "398884": {"image_id": 398884, "Bleu_1": 0.6190476190181406, "Bleu_2": 0.4654746681029118, "Bleu_3": 0.35729984742113635, "Bleu_4": 0.22436571656700707, "METEOR": 0.27022057878330696, "ROUGE_L": 0.4005252790544977, "CIDEr": 0.23759343028384483, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.14285714285714285, "f": 0.16326530612244897, "fn": 24.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is an image of a green truck parked on a grassy field. There are other trucks and cars parked nearby."}, "24021": {"image_id": 24021, "Bleu_1": 0.20289855072169713, "Bleu_2": 0.14452202432557354, "Bleu_3": 0.10763439819965812, "Bleu_4": 0.06592912794913229, "METEOR": 0.15487383244920822, "ROUGE_L": 0.19156572454015255, "CIDEr": 3.5412011057324706e-19, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.23809523809523808, "f": 0.25, "fn": 16.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "This is a group photo of a large group of people standing in front of a brick building. They are all wearing suits and ties, and some of them are holding hats. The building appears to be an old school or church.\n\nThe caption for this image could be: \"A group of men standing in front of an old school or church, wearing suits and ties and holding hats.\""}, "245701": {"image_id": 245701, "Bleu_1": 0.5151515151359045, "Bleu_2": 0.31079078024446555, "Bleu_3": 0.18402133843647953, "Bleu_4": 2.1348670051455563e-05, "METEOR": 0.2986820220716332, "ROUGE_L": 0.36033755274261603, "CIDEr": 0.001618374500044445, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.20833333333333334, "f": 0.18867924528301888, "fn": 19.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5555555555555556, "f": 0.4761904761904762, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a man playing tennis on a court. He is wearing a red shirt and white shorts, and has a tennis racket in his hand. The crowd is watching him play."}, "284991": {"image_id": 284991, "Bleu_1": 0.19999999999500007, "Bleu_2": 0.14322297480426013, "Bleu_3": 0.0814230302502716, "Bleu_4": 1.0990311827446426e-05, "METEOR": 0.20959717936931294, "ROUGE_L": 0.2764350453172206, "CIDEr": 1.2793528790812582e-06, "SPICE": {"All": {"pr": 0.4, "re": 0.08695652173913043, "f": 0.14285714285714285, "fn": 21.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.25, "f": 0.36363636363636365, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "The man in the image is drinking from a red plastic cup while sitting on a train. The train windows are open, and there are trees and fields visible outside. The man is wearing a blue shirt and white pants."}, "238488": {"image_id": 238488, "Bleu_1": 0.26229508196291323, "Bleu_2": 0.17493168065037046, "Bleu_3": 0.10122900631831826, "Bleu_4": 0.06503119460141625, "METEOR": 0.21743270195645517, "ROUGE_L": 0.23093564088696594, "CIDEr": 5.3230517942022045e-15, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.16129032258064516, "f": 0.19999999999999998, "fn": 26.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a woman sitting at a desk in front of a large screen displaying a video call. She is wearing a headset and typing on her laptop. There are several other people in the room, some of them also on video calls. The room is dimly lit and there are several computers and monitors set up around the room."}, "330455": {"image_id": 330455, "Bleu_1": 0.3499999999912501, "Bleu_2": 0.09473309334073557, "Bleu_3": 6.181206892866834e-07, "Bleu_4": 1.5894780290442998e-09, "METEOR": 0.16379166955965066, "ROUGE_L": 0.17941176470588235, "CIDEr": 2.4540563131535772e-05, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.09523809523809523, "f": 0.1111111111111111, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a busy street with cars driving by at night. There are several buses parked on the side of the road, and people walking on the sidewalk. The buildings in the background are lit up with neon lights."}, "130984": {"image_id": 130984, "Bleu_1": 0.45161290321123837, "Bleu_2": 0.30053715350890803, "Bleu_3": 0.249721603324861, "Bleu_4": 0.21717887342109382, "METEOR": 0.3039916543815362, "ROUGE_L": 0.37033824804856896, "CIDEr": 0.0029143436068200866, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.2, "f": 0.1702127659574468, "fn": 16.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is an image of two blue and yellow trains parked on a train track. The trains are parked next to each other and have their engines facing the same direction."}, "534428": {"image_id": 534428, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.20516007603198386, "Bleu_3": 0.09779674410658105, "Bleu_4": 1.2074805060760116e-05, "METEOR": 0.21113809415357213, "ROUGE_L": 0.22775357809583074, "CIDEr": 4.0735119516203996e-08, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.08333333333333333, "f": 0.09523809523809525, "fn": 22.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "This is an image of a busy street with people walking in the rain. There are several cars parked on the side of the road and people are walking in the crosswalk. The sky is cloudy and there are umbrellas being held by some of the people."}, "367429": {"image_id": 367429, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.06838765055261399, "Bleu_3": 4.633962375070945e-07, "Bleu_4": 1.2127601540611027e-09, "METEOR": 0.11748696797168603, "ROUGE_L": 0.19690122659780504, "CIDEr": 3.05481461753313e-08, "SPICE": {"All": {"pr": 0.1, "re": 0.23076923076923078, "f": 0.13953488372093023, "fn": 10.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.13333333333333333, "re": 0.4, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}}, "caption": "The image shows a group of people walking down the street with their luggage. They are all wearing blue shirts and jeans, and one person is carrying a large suitcase. There are several cars parked on the side of the road, and a tree is visible in the background."}, "260106": {"image_id": 260106, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.17978662998615724, "Bleu_3": 9.092474869081761e-07, "Bleu_4": 2.056834079241225e-09, "METEOR": 0.21243578383507267, "ROUGE_L": 0.26804770872567485, "CIDEr": 6.1240777552205016e-06, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.13043478260869565, "f": 0.12, "fn": 20.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a horse jumping over a bar at an equestrian competition. The horse is wearing a blue and white saddle and bridle, and the rider is wearing a white shirt and pants. The background is a green field with trees in the distance."}, "566941": {"image_id": 566941, "Bleu_1": 0.2545454545408265, "Bleu_2": 0.20597146021399534, "Bleu_3": 0.16871867607116212, "Bleu_4": 0.14659327058139618, "METEOR": 0.3293479396350974, "ROUGE_L": 0.2934455802766085, "CIDEr": 2.2734420826215925e-12, "SPICE": {"All": {"pr": 0.0625, "re": 0.10526315789473684, "f": 0.0784313725490196, "fn": 17.0, "numImages": 1.0, "fp": 30.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.13333333333333333, "re": 0.2, "f": 0.16, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}}, "caption": "The image shows a group of people standing around an elephant in the wild. The elephant is standing on its hind legs and appears to be interacting with the people. The people are standing around the elephant, looking at it with curiosity and wonder. The background is a dense forest with tall trees and underbrush."}, "555009": {"image_id": 555009, "Bleu_1": 0.3749999999882814, "Bleu_2": 0.21997067252504504, "Bleu_3": 0.14775633223339277, "Bleu_4": 1.8262493612884185e-05, "METEOR": 0.26035991206082437, "ROUGE_L": 0.3406190172303765, "CIDEr": 0.003840899042358069, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.16666666666666666, "f": 0.1923076923076923, "fn": 25.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3333333333333333, "f": 0.380952380952381, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "This is an image of a desk with a computer, headphones, and other office supplies. The computer has a monitor and keyboard, and there are papers and other items on the desk."}, "299492": {"image_id": 299492, "Bleu_1": 0.2968749999953613, "Bleu_2": 0.21707836343480114, "Bleu_3": 0.14486621941181507, "Bleu_4": 0.09991953056360228, "METEOR": 0.21643942283087392, "ROUGE_L": 0.24897959183673468, "CIDEr": 4.5047602081418146e-18, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.15384615384615385, "f": 0.21621621621621623, "fn": 22.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2727272727272727, "f": 0.3529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a bridge over a river with train tracks running along the side. The bridge is made of steel and has a large sign on it that reads, \"Welcome to the Bridge\". In the background, there are trees and buildings on the other side of the river. The sky is cloudy and there is a reflection of the bridge in the water."}, "16064": {"image_id": 16064, "Bleu_1": 0.21951219511659734, "Bleu_2": 0.1656472891081792, "Bleu_3": 0.11205846904084894, "Bleu_4": 1.387195318328694e-05, "METEOR": 0.15534634885814896, "ROUGE_L": 0.18583396801218582, "CIDEr": 1.2867800821374362e-06, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.15384615384615385, "f": 0.14035087719298245, "fn": 22.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.07142857142857142, "re": 0.16666666666666666, "f": 0.1, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.25, "f": 0.2608695652173913, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is an image of a group of people playing frisbee in a park. They are all wearing different colored shirts and pants, and some of them are holding frisbees. The grass is green and there are trees in the background."}, "386553": {"image_id": 386553, "Bleu_1": 0.4827586206730084, "Bleu_2": 0.34740416687763226, "Bleu_3": 0.2075449127632402, "Bleu_4": 2.421534899165543e-05, "METEOR": 0.25367435122673254, "ROUGE_L": 0.3871260199456029, "CIDEr": 0.006176266957396521, "SPICE": {"All": {"pr": 0.05555555555555555, "re": 0.03571428571428571, "f": 0.043478260869565216, "fn": 27.0, "numImages": 1.0, "fp": 17.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.08333333333333333, "f": 0.09523809523809525, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "There is a plate with a piece of toast on it. The toast has banana slices on top of it. There is also a banana peel on the plate."}, "530384": {"image_id": 530384, "Bleu_1": 0.7333333332844446, "Bleu_2": 0.4577377081854579, "Bleu_3": 0.3182536122341727, "Bleu_4": 4.048411918358003e-05, "METEOR": 0.2314148671731944, "ROUGE_L": 0.4979591836734694, "CIDEr": 0.7256597692857382, "SPICE": {"All": {"pr": 0.0967741935483871, "re": 0.11538461538461539, "f": 0.10526315789473684, "fn": 23.0, "numImages": 1.0, "fp": 28.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This is a kitchen with wooden floors, a refrigerator, and a dining table with chairs."}, "75412": {"image_id": 75412, "Bleu_1": 0.27272727272107444, "Bleu_2": 0.13794014695833945, "Bleu_3": 0.07680285411963501, "Bleu_4": 1.0252671801486271e-05, "METEOR": 0.16433229412708428, "ROUGE_L": 0.20265780730897012, "CIDEr": 1.3682571794353948e-07, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.16666666666666666, "f": 0.14814814814814814, "fn": 20.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}}, "caption": "This is a small room with a wooden door and a window on the left side. There is a bookshelf on the wall with several books on it. The room is dimly lit by a lamp on the table in front of the window."}, "417339": {"image_id": 417339, "Bleu_1": 0.21276595744228163, "Bleu_2": 0.16658955971162087, "Bleu_3": 0.13511835401219335, "Bleu_4": 0.11388142795948562, "METEOR": 0.26393993549451317, "ROUGE_L": 0.3076091850517784, "CIDEr": 2.1011662069208555e-08, "SPICE": {"All": {"pr": 0.125, "re": 0.15, "f": 0.13636363636363635, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "This is a picture of a man and a boy standing on a snowy slope with skis and snowboards. The man is wearing a black jacket and pants, while the boy is wearing a red jacket and pants. They are both smiling and looking at the camera."}, "547258": {"image_id": 547258, "Bleu_1": 0.3207547169750801, "Bleu_2": 0.1756183353427233, "Bleu_3": 8.456484271609978e-07, "Bleu_4": 1.8648756700531404e-09, "METEOR": 0.18085789350011494, "ROUGE_L": 0.2507339988256019, "CIDEr": 0.002141987878599557, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.19047619047619047, "f": 0.19047619047619047, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a young girl standing on a carpeted floor, wearing a pink dress and white sandals. She is jumping up and down with her arms outstretched, as if she is trying to fly. The room appears to be a living room with a couch, coffee table, and television in the background."}, "210520": {"image_id": 210520, "Bleu_1": 0.305555555547068, "Bleu_2": 0.16183471873797783, "Bleu_3": 9.166878867586852e-07, "Bleu_4": 2.1980503399202124e-09, "METEOR": 0.20457478856598835, "ROUGE_L": 0.2824074074074074, "CIDEr": 5.4237678485799623e-05, "SPICE": {"All": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 15.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.25, "f": 0.36363636363636365, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "This image shows a table set with plates, glasses, and utensils. There are several dishes on the table, including a salad, grilled chicken, and corn on the cob. The table is surrounded by flowers and candles."}, "404608": {"image_id": 404608, "Bleu_1": 0.3437499999892579, "Bleu_2": 0.23546453742246556, "Bleu_3": 0.12271846683908968, "Bleu_4": 1.5888501567858706e-05, "METEOR": 0.25188014140207693, "ROUGE_L": 0.3060200668896321, "CIDEr": 0.0014850672496721051, "SPICE": {"All": {"pr": 0.24, "re": 0.2608695652173913, "f": 0.24999999999999994, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "This is a bathroom with a toilet and sink in the corner. The walls are white and the floor is tiled. There is a window on the left side of the room."}, "133087": {"image_id": 133087, "Bleu_1": 0.26190476189852613, "Bleu_2": 0.07992447073180702, "Bleu_3": 5.425417728981009e-07, "Bleu_4": 1.4225211589057101e-09, "METEOR": 0.14050170333823445, "ROUGE_L": 0.18236173393124064, "CIDEr": 3.291662081623187e-07, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.2692307692307692, "f": 0.2916666666666667, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "This is a nighttime image of a city street with tall buildings on either side. There are streetlights on the sidewalk and a few people walking down the street. The sky is dark and there are some stars visible in the sky."}, "560819": {"image_id": 560819, "Bleu_1": 0.4285714285591838, "Bleu_2": 0.3368165348445391, "Bleu_3": 0.25807600297633954, "Bleu_4": 0.18104257674113108, "METEOR": 0.3387783896090854, "ROUGE_L": 0.4799370574350904, "CIDEr": 0.00027858618808815317, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.14814814814814814, "f": 0.1818181818181818, "fn": 23.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a man in white tennis attire holding a tennis racket and waving his arm in the air while standing on a tennis court. The crowd in the background is cheering and clapping."}, "358572": {"image_id": 358572, "Bleu_1": 0.33333333332407417, "Bleu_2": 0.169030850940941, "Bleu_3": 9.436646347676264e-07, "Bleu_4": 2.2463880215974342e-09, "METEOR": 0.23495575582692504, "ROUGE_L": 0.2053872053872054, "CIDEr": 8.90543528995382e-05, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.17391304347826086, "f": 0.17391304347826086, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The woman in the image is playing tennis on a court. She is wearing an orange and white dress and has a racket in her hand. The other players on the court are watching her play."}, "67164": {"image_id": 67164, "Bleu_1": 0.41666666665509267, "Bleu_2": 0.345032779661456, "Bleu_3": 0.2759292130984703, "Bleu_4": 0.22463880215974344, "METEOR": 0.3724100176562653, "ROUGE_L": 0.470679012345679, "CIDEr": 0.00019187519455668813, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.14285714285714285, "f": 0.14035087719298248, "fn": 24.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.25, "f": 0.27586206896551724, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a white cat sitting in the back seat of a car, looking out the window. The car is parked in front of a building with a sign that reads \"Pet Grooming\" on it."}, "482777": {"image_id": 482777, "Bleu_1": 0.29999999999250004, "Bleu_2": 0.15191090505870355, "Bleu_3": 0.10669435290940495, "Bleu_4": 0.07569298710692891, "METEOR": 0.2798956100127958, "ROUGE_L": 0.28416149068322977, "CIDEr": 5.904664083375812e-07, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.42105263157894735, "f": 0.326530612244898, "fn": 11.0, "numImages": 1.0, "fp": 22.0, "tp": 8.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.2, "f": 0.11764705882352941, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.5, "f": 0.22222222222222224, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.5, "f": 0.5217391304347826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "This is an image of a large military aircraft flying in the sky. The plane is white and has a black tail with a red stripe on it. The sky is cloudy and there are some clouds in the background."}, "151516": {"image_id": 151516, "Bleu_1": 0.32499999999187507, "Bleu_2": 0.20412414522676303, "Bleu_3": 0.10311813598199678, "Bleu_4": 1.312051431427763e-05, "METEOR": 0.2283043996878957, "ROUGE_L": 0.25558659217877094, "CIDEr": 1.1562572639140091e-05, "SPICE": {"All": {"pr": 0.25, "re": 0.1875, "f": 0.21428571428571427, "fn": 13.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a bird flying over the water with its wings spread wide. The bird is a brown and white color with a red beak and legs. The background is a clear blue sky with some clouds in it."}, "121692": {"image_id": 121692, "Bleu_1": 0.2499999999583334, "Bleu_2": 4.7673129454153526e-09, "Bleu_3": 1.3147679469348974e-11, "Bleu_4": 7.088856800987232e-13, "METEOR": 0.1995297023586442, "ROUGE_L": 0.3112244897959184, "CIDEr": 0.46004709453490644, "SPICE": {"All": {"pr": 0.46153846153846156, "re": 0.25, "f": 0.32432432432432434, "fn": 18.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}, "Relation": {"pr": 0.4, "re": 0.18181818181818182, "f": 0.25000000000000006, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.3333333333333333, "f": 0.42857142857142855, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The giraffe is standing on the ground, looking up at the rocks."}, "407943": {"image_id": 407943, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.13453455879664997, "Bleu_3": 0.10278734680694784, "Bleu_4": 0.08159493877948074, "METEOR": 0.23443909792506773, "ROUGE_L": 0.25722891566265055, "CIDEr": 2.76666399315676e-11, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.5454545454545454, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.6666666666666666, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 1.0, "f": 0.8, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.36363636363636365, "re": 0.8, "f": 0.5000000000000001, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a person standing in front of a large white umbrella. The person is wearing a black shirt and pants, and has a black hat on their head. The umbrella is open and has a silver handle. The background is a dark room with a few lights on the walls."}, "401935": {"image_id": 401935, "Bleu_1": 0.7499999999375001, "Bleu_2": 0.5838742080702745, "Bleu_3": 0.40852897028427665, "Bleu_4": 5.246341022356036e-05, "METEOR": 0.2732017035001245, "ROUGE_L": 0.6135057471264368, "CIDEr": 1.1168174415142127, "SPICE": {"All": {"pr": 0.38095238095238093, "re": 0.32, "f": 0.34782608695652173, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 8.0}, "Relation": {"pr": 0.4, "re": 0.18181818181818182, "f": 0.25000000000000006, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.75, "f": 0.6, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "A red and yellow train traveling down the tracks at high speed."}, "492805": {"image_id": 492805, "Bleu_1": 0.43589743588625907, "Bleu_2": 0.30293213965638827, "Bleu_3": 0.17054526207704587, "Bleu_4": 1.926655731967689e-05, "METEOR": 0.2705385696409631, "ROUGE_L": 0.2741573033707865, "CIDEr": 1.3432290027989763e-05, "SPICE": {"All": {"pr": 0.05555555555555555, "re": 0.05555555555555555, "f": 0.05555555555555555, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "A train is traveling on the tracks next to a bridge over a river. The train has a blue and yellow caboose and is pulling a red and white container car. There are trees and buildings in the background."}, "166165": {"image_id": 166165, "Bleu_1": 0.3902439024295063, "Bleu_2": 0.22086305214423887, "Bleu_3": 0.10774418588231362, "Bleu_4": 1.3469438255990046e-05, "METEOR": 0.26790986002014106, "ROUGE_L": 0.26425992779783397, "CIDEr": 6.76966558808047e-06, "SPICE": {"All": {"pr": 0.1875, "re": 0.10714285714285714, "f": 0.13636363636363635, "fn": 25.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.18181818181818182, "f": 0.19999999999999998, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a woman playing tennis on a court. She is wearing a white shirt and white shorts, and has a racket in her hand. The image is taken from above, showing the woman's body and the tennis court."}, "314649": {"image_id": 314649, "Bleu_1": 0.17460317460040317, "Bleu_2": 0.12998877417942564, "Bleu_3": 0.08213040272867694, "Bleu_4": 0.055123927354419074, "METEOR": 0.18205193072107995, "ROUGE_L": 0.27566171723692706, "CIDEr": 7.355947647656022e-15, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.3, "f": 0.25531914893617025, "fn": 14.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.7142857142857143, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a river with a bridge in the background. There is a white boat on the water, and a train on the tracks. The sky is clear and blue.\n\nThe image is of a river with a bridge in the background. There is a white boat on the water, and a train on the tracks. The sky is clear and blue."}, "446260": {"image_id": 446260, "Bleu_1": 0.32499999999187507, "Bleu_2": 0.20412414522676303, "Bleu_3": 0.12992071014963966, "Bleu_4": 0.08774216743977534, "METEOR": 0.23293076563075943, "ROUGE_L": 0.2764350453172206, "CIDEr": 1.4418209414204881e-05, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.16666666666666666, "f": 0.14814814814814814, "fn": 20.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The man in the image is wearing a white shirt with black and yellow stripes, a black tie, and a pair of sunglasses. He is standing in front of a window with his arms crossed and looking at something outside."}, "188852": {"image_id": 188852, "Bleu_1": 0.18965517241052324, "Bleu_2": 0.05768261199392793, "Bleu_3": 3.9021198387520097e-07, "Bleu_4": 1.0194942480517033e-09, "METEOR": 0.13964276781458246, "ROUGE_L": 0.17192784667418262, "CIDEr": 3.817132114419436e-15, "SPICE": {"All": {"pr": 0.12121212121212122, "re": 0.14285714285714285, "f": 0.13114754098360656, "fn": 24.0, "numImages": 1.0, "fp": 29.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows two people skiing down a snowy mountain slope. One person is wearing a black and white jacket and pants, while the other person is wearing a red and white jacket and pants. They are both holding ski poles and smiling at each other. The background is a snowy mountain with trees and a blue sky."}, "284749": {"image_id": 284749, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.18594210949553755, "Bleu_3": 0.14432865208179943, "Bleu_4": 0.1075149326543758, "METEOR": 0.26844801479231045, "ROUGE_L": 0.31282051282051276, "CIDEr": 5.367405784377202e-09, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.10344827586206896, "f": 0.10526315789473684, "fn": 26.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.21428571428571427, "f": 0.21428571428571427, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "A group of people are gathered in a park, flying kites in the sky. There are children and adults alike, all enjoying the activity. The trees in the background are bare, with no leaves on them. The sky is clear and blue, with a few clouds scattered about."}, "410004": {"image_id": 410004, "Bleu_1": 0.2857142857074831, "Bleu_2": 2.6398183866786545e-09, "Bleu_3": 5.585079625938629e-12, "Bleu_4": 2.5852698128401774e-13, "METEOR": 0.13099415204678364, "ROUGE_L": 0.16874135546334715, "CIDEr": 8.975988735577875e-07, "SPICE": {"All": {"pr": 0.125, "re": 0.21052631578947367, "f": 0.1568627450980392, "fn": 15.0, "numImages": 1.0, "fp": 28.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a street market with various fruits and vegetables on display. There are several people walking around the market, some of them carrying baskets or bags of produce. The sky is clear and blue, with a few clouds scattered about."}, "561928": {"image_id": 561928, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.17869060919900012, "Bleu_3": 0.16364790162348092, "Bleu_4": 0.14468810567798146, "METEOR": 0.28257809123056854, "ROUGE_L": 0.25894481503941785, "CIDEr": 1.00322045959662e-11, "SPICE": {"All": {"pr": 0.5, "re": 0.18518518518518517, "f": 0.2702702702702703, "fn": 22.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}, "Relation": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2727272727272727, "f": 0.3529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A group of bicycles are hanging from a tree in a park. The bicycles are all different colors and styles, and they are all hanging from the branches of the tree. There are also some people walking by the tree, looking at the bicycles.\""}, "313491": {"image_id": 313491, "Bleu_1": 0.5599999999776001, "Bleu_2": 0.4041451884162355, "Bleu_3": 0.3286792832145262, "Bleu_4": 0.2637873055829728, "METEOR": 0.38335958138994203, "ROUGE_L": 0.5573604060913705, "CIDEr": 0.044172821765955814, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.23529411764705882, "f": 0.21052631578947367, "fn": 13.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is a bathroom with a toilet and sink. The walls are painted white and there is a window on the side of the room."}, "493117": {"image_id": 493117, "Bleu_1": 0.1449275362297837, "Bleu_2": 0.13057679112202067, "Bleu_3": 0.11515146751318588, "Bleu_4": 0.1037071322146391, "METEOR": 0.2621307539878522, "ROUGE_L": 0.2679355783308931, "CIDEr": 1.2061251185710562e-21, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.26666666666666666, "f": 0.23529411764705882, "fn": 11.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6, "f": 0.42857142857142855, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a motorcycle parked on the side of a dirt road in front of a large grain silo. The sun is setting in the background, casting a warm orange glow over the scene. The motorcycle's engine is visible, and the rider is wearing a helmet and leather jacket. The road is lined with tall grasses and trees, giving the impression of being in a rural area."}, "201141": {"image_id": 201141, "Bleu_1": 0.33333333332098775, "Bleu_2": 0.19611613513078086, "Bleu_3": 0.11544156732198758, "Bleu_4": 1.591178311035633e-05, "METEOR": 0.17825741277893756, "ROUGE_L": 0.41391009329940626, "CIDEr": 0.015872440493973492, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.17647058823529413, "f": 0.15, "fn": 14.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a man sitting at a small wooden table in front of a bakery with various types of bread and pastries hanging from the ceiling."}, "253810": {"image_id": 253810, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.1447907475849832, "Bleu_3": 0.07387419460030926, "Bleu_4": 9.42924728285967e-06, "METEOR": 0.19712089674329006, "ROUGE_L": 0.1821983273596177, "CIDEr": 1.0453656833240433e-12, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.21739130434782608, "f": 0.2127659574468085, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "A banana is hanging from a metal stand on a red table.\n\nThe banana is yellow and has a few brown spots on it.\n\nThe stand is made of metal and has a spiral design on it.\n\nThe table is red and has a smooth surface.\n\nThere are no other objects in the image."}, "412136": {"image_id": 412136, "Bleu_1": 0.41463414633135043, "Bleu_2": 0.287970188151824, "Bleu_3": 0.2041252900555403, "Bleu_4": 0.14545686092209525, "METEOR": 0.24722297071169116, "ROUGE_L": 0.33493479752916955, "CIDEr": 0.0005548710692569235, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.09090909090909091, "f": 0.0975609756097561, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "This is an image of a person holding a sandwich in their hand. The sandwich appears to be made of ham and cheese on a bun. There are also two glasses of orange juice on the table next to the sandwich."}, "153734": {"image_id": 153734, "Bleu_1": 0.17857142856823985, "Bleu_2": 0.08058229640108601, "Bleu_3": 4.935848712474828e-07, "Bleu_4": 1.2273047425649952e-09, "METEOR": 0.09137272590756033, "ROUGE_L": 0.14153132250580044, "CIDEr": 4.42837736118357e-15, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.10256410256410256, "f": 0.13114754098360654, "fn": 35.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a group of people standing next to a herd of cows in a field. The people are wearing hats and sunglasses, while the cows are standing in the dirt. There are several other animals in the background, including sheep and goats. The sky is clear and blue, with a few clouds scattered about."}, "391825": {"image_id": 391825, "Bleu_1": 0.714285714234694, "Bleu_2": 0.6629935440826179, "Bleu_3": 0.6034799806556997, "Bleu_4": 0.531696715290295, "METEOR": 0.43340645367844094, "ROUGE_L": 0.6692789968652038, "CIDEr": 1.951605992922796, "SPICE": {"All": {"pr": 0.5, "re": 0.23529411764705882, "f": 0.31999999999999995, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "A flock of sheep grazing in a green field with trees in the background."}, "206300": {"image_id": 206300, "Bleu_1": 0.15942028985276205, "Bleu_2": 0.10826855562008815, "Bleu_3": 0.07046713689761756, "Bleu_4": 0.04798483279886891, "METEOR": 0.147925344954253, "ROUGE_L": 0.19471044231646148, "CIDEr": 8.042844858071497e-20, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.21052631578947367, "f": 0.2, "fn": 15.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a red stop sign on the side of a building. The sign is made of metal and has the words \"stop\" written on it in white letters. The building behind the sign is made of brick and has several windows on each floor. There are also some trees and plants growing in the area. The sky is blue and there are some clouds in the background."}, "535809": {"image_id": 535809, "Bleu_1": 0.2666666666607408, "Bleu_2": 0.19069251784483274, "Bleu_3": 0.11914512632603338, "Bleu_4": 1.416592339557592e-05, "METEOR": 0.17059630786511626, "ROUGE_L": 0.25258799171842644, "CIDEr": 9.107001504647715e-09, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.07692307692307693, "f": 0.07407407407407408, "fn": 24.0, "numImages": 1.0, "fp": 26.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "This is a black and white image of a cat lying on a couch. The cat has a curious expression on its face and is looking up at the camera. The background is a beige color and there are no other objects in the image."}, "132554": {"image_id": 132554, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.1927248223279925, "Bleu_3": 0.11567016508408626, "Bleu_4": 1.347074304621809e-05, "METEOR": 0.2217410248412607, "ROUGE_L": 0.26521739130434785, "CIDEr": 1.805401922554203e-10, "SPICE": {"All": {"pr": 0.1388888888888889, "re": 0.2777777777777778, "f": 0.1851851851851852, "fn": 13.0, "numImages": 1.0, "fp": 31.0, "tp": 5.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.08333333333333333, "re": 0.25, "f": 0.125, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.42857142857142855, "f": 0.3, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a woman standing next to a brown horse in a barn. The woman is wearing a white shirt and blue jeans, and the horse is wearing a saddle and bridle. The barn has a wooden roof and walls, and there are several other horses in the background."}, "469464": {"image_id": 469464, "Bleu_1": 0.3617021276518787, "Bleu_2": 0.2660221937781222, "Bleu_3": 0.1465157820982506, "Bleu_4": 1.6351219050554547e-05, "METEOR": 0.3026636944705769, "ROUGE_L": 0.24416277518345564, "CIDEr": 5.152914371255683e-09, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.06666666666666667, "f": 0.08888888888888888, "fn": 28.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.15384615384615385, "f": 0.2, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a child holding a video game controller in their hand. The controller has a white and black design with buttons on it. The child is wearing a green shirt and blue pants. There is a table in the background with a lamp on it."}, "335844": {"image_id": 335844, "Bleu_1": 0.24324324323666918, "Bleu_2": 0.14237369935897354, "Bleu_3": 8.335477783359319e-07, "Bleu_4": 2.031552942020332e-09, "METEOR": 0.15742158634289521, "ROUGE_L": 0.24419535628502803, "CIDEr": 9.674602310161421e-06, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.16666666666666666, "f": 0.1935483870967742, "fn": 15.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.3333333333333333, "f": 0.42857142857142855, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This is an image of a toaster on a kitchen counter. The toaster has a black body and a silver dial on the front. There is a bag of bread on the counter next to the toaster."}, "493751": {"image_id": 493751, "Bleu_1": 0.14772727272559402, "Bleu_2": 0.0921415929157484, "Bleu_3": 0.05823011646854285, "Bleu_4": 6.942342130531892e-06, "METEOR": 0.14572959871506036, "ROUGE_L": 0.14500792393026943, "CIDEr": 9.388096445253484e-35, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.19047619047619047, "f": 0.16326530612244897, "fn": 17.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a group of people standing in front of a garden. They are all looking at something on the ground, possibly a bird or a small animal. The woman in the middle is holding a camera and taking a picture. The other two women are standing on either side of her, looking at the camera as well. The man in the back is standing with his arms crossed, looking at the scene. The trees in the background are lush and green, with leaves covering the ground."}, "274629": {"image_id": 274629, "Bleu_1": 0.5769230769008876, "Bleu_2": 0.4803844613964156, "Bleu_3": 0.4067756055072855, "Bleu_4": 0.36401730391849096, "METEOR": 0.365350103884007, "ROUGE_L": 0.6151260504201681, "CIDEr": 0.18745875565058806, "SPICE": {"All": {"pr": 0.5454545454545454, "re": 0.21428571428571427, "f": 0.30769230769230765, "fn": 22.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.2222222222222222, "f": 0.3636363636363636, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.6, "re": 0.3, "f": 0.4, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This is a stop sign on the side of the road. It has a pink ribbon attached to it and is surrounded by a white background."}, "264382": {"image_id": 264382, "Bleu_1": 0.2833333333286111, "Bleu_2": 0.2078950191360966, "Bleu_3": 0.13075565381529075, "Bleu_4": 0.0791364644516525, "METEOR": 0.21861025612740434, "ROUGE_L": 0.26236559139784943, "CIDEr": 1.921445094729474e-15, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.10344827586206896, "f": 0.15789473684210528, "fn": 26.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.09090909090909091, "f": 0.14285714285714288, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image shows a baseball player pitching a ball on a green field in front of a large crowd of people. The player is wearing a white jersey with the number 23 on the back, and he is holding the ball in his right hand as he prepares to throw it. The crowd is standing behind him, watching the game."}, "301376": {"image_id": 301376, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.14401064146758893, "Bleu_3": 0.07457725404314713, "Bleu_4": 9.591924934151242e-06, "METEOR": 0.15851361014478726, "ROUGE_L": 0.1920654911838791, "CIDEr": 1.8049138032812696e-11, "SPICE": {"All": {"pr": 0.25, "re": 0.09523809523809523, "f": 0.13793103448275862, "fn": 19.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.2857142857142857, "f": 0.4, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "This is an image of a street with several people walking on the sidewalk. There are several buildings on either side of the street, including a restaurant with a red awning and a convenience store with a blue awning. The sky is clear and sunny, with a few clouds in the distance."}, "125870": {"image_id": 125870, "Bleu_1": 0.3170731707239739, "Bleu_2": 0.15420923384708043, "Bleu_3": 8.479795599581164e-07, "Bleu_4": 2.0014425975611436e-09, "METEOR": 0.2119177901852021, "ROUGE_L": 0.21463757916959889, "CIDEr": 5.738676795346732e-06, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.13333333333333333, "f": 0.125, "fn": 13.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image shows a view of an airport terminal from inside a window. There are several airplanes parked on the tarmac, and a few buses are parked in front of the terminal. The sky is cloudy and there is rain falling."}, "56092": {"image_id": 56092, "Bleu_1": 0.28787878787442606, "Bleu_2": 0.14881035630575562, "Bleu_3": 0.10125174839763933, "Bleu_4": 0.075765982615335, "METEOR": 0.18221258134490237, "ROUGE_L": 0.18208955223880596, "CIDEr": 6.703669186839649e-18, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.14285714285714285, "f": 0.18604651162790697, "fn": 24.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.08333333333333333, "f": 0.14285714285714285, "fn": 11.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows two horses running in a field with a fence in the background. One horse is brown and the other is black. They are running towards each other, their manes and tails flowing in the wind. The sky is blue and cloudy, with a few white clouds scattered across it. The grass is green and lush, and there are some trees in the background."}, "312341": {"image_id": 312341, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.09891091079132044, "Bleu_3": 5.730093203419742e-07, "Bleu_4": 1.3858898705876826e-09, "METEOR": 0.1773088756533436, "ROUGE_L": 0.17468499427262313, "CIDEr": 1.526034735354993e-12, "SPICE": {"All": {"pr": 0.14705882352941177, "re": 0.22727272727272727, "f": 0.17857142857142858, "fn": 17.0, "numImages": 1.0, "fp": 29.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.18181818181818182, "re": 0.5, "f": 0.26666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.3333333333333333, "f": 0.2608695652173913, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "This is an image of a woman riding a motorcycle on the sidewalk. She is wearing a helmet and has her arms outstretched as she rides. There are other vehicles parked on the side of the road, including a bus and a car. The sky is cloudy and there are trees in the background."}, "249356": {"image_id": 249356, "Bleu_1": 0.32499999999187507, "Bleu_2": 0.2236067977443172, "Bleu_3": 0.15804080050769032, "Bleu_4": 0.10163106686574658, "METEOR": 0.2612533579590983, "ROUGE_L": 0.3588235294117647, "CIDEr": 1.4921218502700733e-05, "SPICE": {"All": {"pr": 0.037037037037037035, "re": 0.038461538461538464, "f": 0.03773584905660377, "fn": 25.0, "numImages": 1.0, "fp": 26.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.1, "f": 0.09523809523809525, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "This is a bathroom with a white toilet, sink, and shower. The walls are painted white and there is a blue rug on the floor. The shower has a glass door and there is a towel hanging on the rack."}, "330055": {"image_id": 330055, "Bleu_1": 0.1964285714250638, "Bleu_2": 0.10350983389948797, "Bleu_3": 0.05832523373020616, "Bleu_4": 7.822100624658515e-06, "METEOR": 0.16861521317701425, "ROUGE_L": 0.21229698375870068, "CIDEr": 1.1709165514814335e-12, "SPICE": {"All": {"pr": 0.25, "re": 0.15151515151515152, "f": 0.18867924528301888, "fn": 28.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 17.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a baseball player running towards home plate while another player is catching the ball. The player in the foreground is wearing a black and white uniform, while the player in the background is wearing a blue and white uniform. The field is covered in grass and there are no spectators in the stands."}, "46048": {"image_id": 46048, "Bleu_1": 0.3928571428431123, "Bleu_2": 0.269724531227751, "Bleu_3": 0.20323395413067125, "Bleu_4": 0.1609791748390107, "METEOR": 0.29266412552790183, "ROUGE_L": 0.4169921875, "CIDEr": 0.021526347118357554, "SPICE": {"All": {"pr": 0.24, "re": 0.35294117647058826, "f": 0.28571428571428564, "fn": 11.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.7142857142857143, "f": 0.588235294117647, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a young girl sitting on a bed, surrounded by toys and books. The walls are painted orange and there is a window in the background."}, "403295": {"image_id": 403295, "Bleu_1": 0.2749999999931251, "Bleu_2": 0.16794382454767393, "Bleu_3": 0.09054159909521357, "Bleu_4": 1.1901061222904039e-05, "METEOR": 0.1584781710970073, "ROUGE_L": 0.25558659217877094, "CIDEr": 9.02118610543604e-06, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.2, "f": 0.21739130434782608, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is an image of a bicycle parked next to a street sign. The bicycle is red and has a basket on the front. There are several other bicycles parked nearby, and a few people are walking down the street."}, "116361": {"image_id": 116361, "Bleu_1": 0.38461538460552275, "Bleu_2": 0.3336705446737535, "Bleu_3": 0.2623383336508901, "Bleu_4": 0.1969477416362651, "METEOR": 0.293484761031456, "ROUGE_L": 0.3287143956889915, "CIDEr": 3.725811589705745e-05, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.08695652173913043, "f": 0.1111111111111111, "fn": 21.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a group of people sitting in a room with laptops on their laps. They are all looking at their screens and typing away. The room is dimly lit and there are curtains hanging from the ceiling."}, "204100": {"image_id": 204100, "Bleu_1": 0.20689655172057078, "Bleu_2": 0.10435177140627983, "Bleu_3": 5.793449266323811e-07, "Bleu_4": 1.371236085850038e-09, "METEOR": 0.1798933905144819, "ROUGE_L": 0.17548906789413118, "CIDEr": 1.3779999704342312e-15, "SPICE": {"All": {"pr": 0.2, "re": 0.23809523809523808, "f": 0.21739130434782608, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This image shows a woman standing next to a pile of bananas on the side of the road. She is wearing a black and white striped shirt and has a basket in her hand. There are several other baskets of bananas on the ground next to her. The sky is clear and there are trees in the background."}, "508899": {"image_id": 508899, "Bleu_1": 0.5789473683905818, "Bleu_2": 0.31063037208189476, "Bleu_3": 0.17838005936563955, "Bleu_4": 2.4405051723208498e-05, "METEOR": 0.1879939038233896, "ROUGE_L": 0.29221556886227545, "CIDEr": 0.2810669550468832, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.2608695652173913, "f": 0.23076923076923075, "fn": 17.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is a living room with a couch, coffee table, and TV. There is a dog on the floor."}, "388395": {"image_id": 388395, "Bleu_1": 0.29824561402985533, "Bleu_2": 0.2307772635281109, "Bleu_3": 0.1797731658491244, "Bleu_4": 0.144032403450261, "METEOR": 0.2506980389771165, "ROUGE_L": 0.307563025210084, "CIDEr": 2.991854642730873e-12, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.1875, "f": 0.17142857142857143, "fn": 13.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.4, "f": 0.3076923076923077, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\nThe image shows several buses parked on a street. The buses are different colors and have different designs. Some of them have advertisements on the sides, while others have windows and doors. The buses are parked next to each other, creating a line of them along the street."}, "52827": {"image_id": 52827, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.1940285000252239, "Bleu_3": 0.09158935294477764, "Bleu_4": 1.124795146748506e-05, "METEOR": 0.17671316442427407, "ROUGE_L": 0.2238532110091743, "CIDEr": 7.55035659739109e-11, "SPICE": {"All": {"pr": 0.2, "re": 0.17391304347826086, "f": 0.18604651162790697, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a lighthouse on a rocky coastline with a bird flying overhead. The sky is blue and there are clouds in the distance. The lighthouse is white with red and white stripes and has a red roof. The water is calm and there are some boats in the distance."}, "505080": {"image_id": 505080, "Bleu_1": 0.15999999999680004, "Bleu_2": 0.11428571428340528, "Bleu_3": 0.06480087729347118, "Bleu_4": 8.722906144737809e-06, "METEOR": 0.18049042335070173, "ROUGE_L": 0.27128335451080055, "CIDEr": 3.735687645147932e-11, "SPICE": {"All": {"pr": 0.19444444444444445, "re": 0.5, "f": 0.28, "fn": 7.0, "numImages": 1.0, "fp": 29.0, "tp": 7.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2777777777777778, "re": 0.8333333333333334, "f": 0.4166666666666667, "fn": 1.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}}, "caption": "This image shows a group of people standing on the shore of a river, looking at a boat that is tied up to a dock. The people are wearing life jackets and helmets, and one of them is holding a flag. The background is a blue sky with some clouds."}, "66271": {"image_id": 66271, "Bleu_1": 0.5238095237845806, "Bleu_2": 0.4577377081947216, "Bleu_3": 0.35332952049108113, "Bleu_4": 0.22249323813615754, "METEOR": 0.3229834442924058, "ROUGE_L": 0.5252152521525214, "CIDEr": 0.22494384574621565, "SPICE": {"All": {"pr": 0.1951219512195122, "re": 0.3333333333333333, "f": 0.24615384615384614, "fn": 16.0, "numImages": 1.0, "fp": 33.0, "tp": 8.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.18181818181818182, "f": 0.13793103448275862, "fn": 9.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2777777777777778, "re": 0.625, "f": 0.3846153846153846, "fn": 3.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}}, "caption": "A black and white cat sitting on top of a red suitcase in a room with wooden floors and white walls."}, "6471": {"image_id": 6471, "Bleu_1": 0.2608695652136106, "Bleu_2": 0.17518714873957753, "Bleu_3": 0.09712250915805416, "Bleu_4": 0.06103851181578297, "METEOR": 0.18908180489656926, "ROUGE_L": 0.27240829346092504, "CIDEr": 7.233503250920062e-14, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.09523809523809523, "f": 0.0784313725490196, "fn": 19.0, "numImages": 1.0, "fp": 28.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a baseball player in the middle of a swing, with his bat raised and ready to hit the ball. The player is wearing a black and orange jersey with the number 10 on the back, and his pants are black with orange stripes. The umpire is standing behind him, watching the play. The background is a green field with a dirt infield and a blue sky."}, "351297": {"image_id": 351297, "Bleu_1": 0.5999999999600001, "Bleu_2": 0.462910049854313, "Bleu_3": 0.36704871426530855, "Bleu_4": 0.25336549462596675, "METEOR": 0.39377191922356436, "ROUGE_L": 0.6108726752503576, "CIDEr": 1.471672317512482, "SPICE": {"All": {"pr": 0.25, "re": 0.15384615384615385, "f": 0.1904761904761905, "fn": 22.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "A giraffe standing on the side of a dirt road, looking out into the distance."}, "146831": {"image_id": 146831, "Bleu_1": 0.1428571428545919, "Bleu_2": 0.08827348294888435, "Bleu_3": 0.05245121930500332, "Bleu_4": 7.223500778671168e-06, "METEOR": 0.15712459485936361, "ROUGE_L": 0.2426136363636364, "CIDEr": 3.3078318631201666e-14, "SPICE": {"All": {"pr": 0.12, "re": 0.1111111111111111, "f": 0.11538461538461538, "fn": 24.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3333333333333333, "f": 0.27272727272727276, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA young girl is skateboarding on a ramp in a park. She is wearing a black shirt and jeans, and her hair is tied back in a ponytail. The ramp is made of metal and has a wooden surface. There are trees and buildings in the background."}, "434417": {"image_id": 434417, "Bleu_1": 0.2340425531865098, "Bleu_2": 0.18871982178961313, "Bleu_3": 0.14683429567045103, "Bleu_4": 0.10952542776952066, "METEOR": 0.24650429235007038, "ROUGE_L": 0.31063017186505404, "CIDEr": 7.625822624006222e-09, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.15, "f": 0.14634146341463414, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "This is a hotel room with a large bed, a couch, and a bathroom. The walls are painted a light green color and there are two paintings on the wall. The floor is made of tile and there is a large window that lets in natural light."}, "188345": {"image_id": 188345, "Bleu_1": 0.47999999998080006, "Bleu_2": 0.28284271246306963, "Bleu_3": 0.19089624343986394, "Bleu_4": 0.1333497993154046, "METEOR": 0.2454611814730183, "ROUGE_L": 0.3096446700507614, "CIDEr": 0.03934701393010452, "SPICE": {"All": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 25.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.3333333333333333, "f": 0.47058823529411764, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The image is a cake with strawberries on top. There is a name written on the plate, but it is not visible in the image."}, "271772": {"image_id": 271772, "Bleu_1": 0.3913043478090738, "Bleu_2": 0.2667325346727717, "Bleu_3": 0.1501911109396443, "Bleu_4": 2.0287366423929855e-05, "METEOR": 0.2770565722861788, "ROUGE_L": 0.407119021134594, "CIDEr": 0.09672871591837562, "SPICE": {"All": {"pr": 0.3, "re": 0.1, "f": 0.15, "fn": 27.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.2727272727272727, "f": 0.37499999999999994, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows a man holding a kite in his hand while standing on a beach with the sun shining in the background."}, "10104": {"image_id": 10104, "Bleu_1": 0.11504424778659254, "Bleu_2": 0.07850531639830607, "Bleu_3": 0.0381497520143362, "Bleu_4": 4.739915704186664e-06, "METEOR": 0.10741555954844399, "ROUGE_L": 0.1325675256131636, "CIDEr": 8.02362429994763e-64, "SPICE": {"All": {"pr": 0.15, "re": 0.1, "f": 0.12, "fn": 27.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This image shows a group of people riding motorcycles on a wet road. They are wearing red and white clothing and have their arms outstretched as they ride. The sky is cloudy and there is water on the ground.\n\nThe image is taken from a low angle, looking up at the motorcyclists as they ride down the road. The lighting is dim, with shadows cast by the trees and buildings in the background. The colors are muted, with a focus on the red and white clothing of the riders.\n\nThe overall mood of the image is energetic and playful, with the motorcyclists appearing to be having fun as they ride through the rain."}, "506127": {"image_id": 506127, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.16695677422191285, "Bleu_3": 8.865761273541133e-07, "Bleu_4": 2.0559894081168643e-09, "METEOR": 0.21362867237373775, "ROUGE_L": 0.3214756258234519, "CIDEr": 2.981497182153847e-06, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 9.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a small wooden bench sitting in the middle of a green field. The bench is empty and there is no one sitting on it. The sky above is a bright green color, giving the impression of a sunny day."}, "500175": {"image_id": 500175, "Bleu_1": 0.05976095617506072, "Bleu_2": 0.02677931056054021, "Bleu_3": 1.4227649099103252e-07, "Bleu_4": 3.2827434156661747e-10, "METEOR": 0.06836112784116592, "ROUGE_L": 0.08071748878923767, "CIDEr": 0.0, "SPICE": {"All": {"pr": 0.034482758620689655, "re": 0.02631578947368421, "f": 0.029850746268656716, "fn": 37.0, "numImages": 1.0, "fp": 28.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.07142857142857142, "f": 0.08333333333333333, "fn": 13.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a bird flying in the sky with its wings spread out. The bird is surrounded by other birds flying in the sky. The sky is blue and there are clouds in the background. The image is taken from a bird's eye view.\n\nThe image is taken at sunset, as there are shadows on the ground and the sky is darkening. The bird is flying towards the left side of the image, and there are other birds flying in the sky. The image is taken from a bird's eye view, and the bird is flying towards the left side of the image. The sky is darkening, and there are shadows on the ground.\n\nThe image is taken at sunset, as there are shadows on the ground and the sky is darkening. The bird is flying towards the left side of the image, and there are other birds flying in the sky. The image is taken from a bird's eye view, and the bird is flying towards the left side of the image. The sky is darkening, and there are shadows on the ground.\n\nThe image shows a bird flying in the sky with its wings spread out. The bird is surrounded by other birds flying in the sky. The sky is blue and there are clouds in the background. The image is taken from a bird's eye view.\n\nThe image is taken at sunset, as there are shadows on the ground and the sky is"}, "209221": {"image_id": 209221, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.09712858623387621, "Bleu_3": 5.697810303144272e-07, "Bleu_4": 1.3868787330575517e-09, "METEOR": 0.18998018810082717, "ROUGE_L": 0.21908296420447745, "CIDEr": 1.2575565851554763e-11, "SPICE": {"All": {"pr": 0.18421052631578946, "re": 0.2413793103448276, "f": 0.208955223880597, "fn": 22.0, "numImages": 1.0, "fp": 31.0, "tp": 7.0}, "Relation": {"pr": 0.1, "re": 0.08333333333333333, "f": 0.0909090909090909, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.35294117647058826, "re": 0.46153846153846156, "f": 0.4000000000000001, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}}, "caption": "The image shows a green and yellow train traveling down the tracks at a high speed. The train has a large cargo car attached to the front of it, and there are people standing on the platform watching it go by. The train is moving quickly and appears to be in good condition."}, "338108": {"image_id": 338108, "Bleu_1": 0.43749999999088546, "Bleu_2": 0.28944186936439076, "Bleu_3": 0.1938540845661923, "Bleu_4": 0.13414070594775387, "METEOR": 0.21172286877296842, "ROUGE_L": 0.2675438596491228, "CIDEr": 9.819647152438694e-07, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 16.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "This is a photograph of a man standing on a snowy slope, wearing ski gear and holding ski poles. He is standing in front of a group of people who are also skiing. The image appears to be taken at a ski resort, with mountains in the background."}, "45648": {"image_id": 45648, "Bleu_1": 0.1702127659538253, "Bleu_2": 0.1490022319427778, "Bleu_3": 0.13511835401219335, "Bleu_4": 0.12237355827839205, "METEOR": 0.34123749077519816, "ROUGE_L": 0.32555036691127415, "CIDEr": 3.3472271260765947e-09, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.38095238095238093, "f": 0.3137254901960784, "fn": 13.0, "numImages": 1.0, "fp": 22.0, "tp": 8.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.1111111111111111, "f": 0.09999999999999999, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.8571428571428571, "f": 0.5454545454545455, "fn": 1.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}}, "caption": "The image shows a person walking on the beach with a surfboard. The person is walking towards the ocean and the waves are crashing against the shore. The sky is clear and blue, with some clouds in the distance. The beach is surrounded by rocks and greenery."}, "313762": {"image_id": 313762, "Bleu_1": 0.24324324323666918, "Bleu_2": 0.16439898730085242, "Bleu_3": 0.11558994996382838, "Bleu_4": 1.4598906514772132e-05, "METEOR": 0.32082290732842755, "ROUGE_L": 0.3418734987990392, "CIDEr": 1.2506097954337431e-05, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.23076923076923078, "f": 0.26666666666666666, "fn": 20.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.6, "f": 0.631578947368421, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image shows a man standing on the beach holding a surfboard. He is wearing a black wetsuit and has his hands on his hips. The sky is cloudy and there are waves crashing on the shore."}, "553935": {"image_id": 553935, "Bleu_1": 0.37142857141795926, "Bleu_2": 0.3305203435080167, "Bleu_3": 0.2708182332036774, "Bleu_4": 0.22322145190184947, "METEOR": 0.3094571880773215, "ROUGE_L": 0.4423495286439449, "CIDEr": 0.001102758015160813, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.21739130434782608, "f": 0.25, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a surveillance camera mounted on the side of a building. The camera is pointed towards the sky and there is a plane flying in the distance. The sky is clear and blue."}, "554255": {"image_id": 554255, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.20957473279408317, "Bleu_3": 0.15305490466093202, "Bleu_4": 0.09296621060191432, "METEOR": 0.3183265174321106, "ROUGE_L": 0.3433395872420263, "CIDEr": 6.760158385408165e-10, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.20833333333333334, "f": 0.2127659574468085, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of people playing tennis on a court with a net in the center. The players are wearing pink shirts and white shorts, and they are standing on the court with their rackets at the ready. The background is a green field with trees in the distance."}, "580608": {"image_id": 580608, "Bleu_1": 0.39393939392745647, "Bleu_2": 0.2717786532439402, "Bleu_3": 0.19263273100143882, "Bleu_4": 0.12424166064592143, "METEOR": 0.2525666721904284, "ROUGE_L": 0.394685153090699, "CIDEr": 0.0028019464548449083, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.3157894736842105, "f": 0.2926829268292683, "fn": 13.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a green plant growing out of a beer bottle. The plant has long, thin leaves and is sitting on a wooden table. There is a wooden chair in the background."}, "55955": {"image_id": 55955, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.1412673303879691, "Bleu_3": 0.10549005488471223, "Bleu_4": 0.08277965966610605, "METEOR": 0.1903139361533018, "ROUGE_L": 0.24707788450410828, "CIDEr": 8.90698384786596e-12, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.16, "f": 0.19047619047619052, "fn": 21.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a motorcycle parked on a dirt road. The motorcycle has a black and white paint job and is equipped with a sidecar. The rider is wearing a helmet and sunglasses, and the sidecar has a bag strapped to it. The background is a scenic mountainous area with trees and rocks."}, "356708": {"image_id": 356708, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.25425669045977695, "Bleu_3": 0.19589143276192844, "Bleu_4": 0.15222275337401533, "METEOR": 0.2943929856228683, "ROUGE_L": 0.3609467455621302, "CIDEr": 6.074888773114528e-08, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.17647058823529413, "f": 0.20000000000000004, "fn": 14.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5, "f": 0.36363636363636365, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a man and a girl on skis in the snow. The man is wearing a helmet and goggles, while the girl is wearing a helmet and a pair of skis. They are standing on a slope, with a mountain in the background."}, "420229": {"image_id": 420229, "Bleu_1": 0.22916666666189242, "Bleu_2": 0.13965509692979164, "Bleu_3": 7.512513229843848e-07, "Bleu_4": 1.7520068866272228e-09, "METEOR": 0.22272126912730053, "ROUGE_L": 0.2401574803149606, "CIDEr": 4.867919416746145e-10, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.16666666666666666, "f": 0.12121212121212123, "fn": 10.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.4, "f": 0.2857142857142857, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a person holding a white apple slicer on a cutting board. The slicer has a round blade and a handle that is shaped like a half circle. The person is holding the slicer in their hand and is about to cut an apple with it."}, "480726": {"image_id": 480726, "Bleu_1": 0.34782608694896033, "Bleu_2": 0.26375218935251743, "Bleu_3": 0.16801713501101306, "Bleu_4": 0.1024821120796751, "METEOR": 0.26491740865955443, "ROUGE_L": 0.27619663648124193, "CIDEr": 2.03621498259919e-08, "SPICE": {"All": {"pr": 0.125, "re": 0.17391304347826086, "f": 0.14545454545454545, "fn": 19.0, "numImages": 1.0, "fp": 28.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}}, "caption": "The image shows a group of people watching a tennis match on a court. There are several people in the stands, including some in the front row who are holding up their phones to take pictures. The players are standing on the court, ready to serve."}, "210607": {"image_id": 210607, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.15649215928402857, "Bleu_3": 0.10067569617030046, "Bleu_4": 0.06826042950277836, "METEOR": 0.1671755560543385, "ROUGE_L": 0.22732919254658387, "CIDEr": 7.288283889195243e-11, "SPICE": {"All": {"pr": 0.25, "re": 0.23076923076923078, "f": 0.24000000000000002, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "This is an image of a train on the tracks. The train is made of metal and has a large engine on the front. There are two cars attached to the engine, one with windows and one without. The train is traveling through a field with trees in the background."}, "238691": {"image_id": 238691, "Bleu_1": 0.3199999999872001, "Bleu_2": 3.651483716552006e-09, "Bleu_3": 8.33816145303051e-12, "Bleu_4": 4.028998028940258e-13, "METEOR": 0.1541818181818182, "ROUGE_L": 0.2571127502634352, "CIDEr": 0.01415703450770151, "SPICE": {"All": {"pr": 0.5714285714285714, "re": 0.15384615384615385, "f": 0.24242424242424246, "fn": 22.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}, "Relation": {"pr": 0.5, "re": 0.07692307692307693, "f": 0.13333333333333336, "fn": 12.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.42857142857142855, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "A group of people are standing in a line at an airport, waiting to board a plane. They are all wearing sunglasses and carrying luggage."}, "260486": {"image_id": 260486, "Bleu_1": 0.3235294117551904, "Bleu_2": 0.14002800839862017, "Bleu_3": 8.493628895835745e-07, "Bleu_4": 2.1085288028412016e-09, "METEOR": 0.277135640129268, "ROUGE_L": 0.3061224489795918, "CIDEr": 0.00011203848432929084, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.1111111111111111, "f": 0.1212121212121212, "fn": 16.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "This is a desk with a computer, keyboard, and mouse on it. There are also some papers and pens on the desk. The desk is made of wood and has a light on it."}, "400123": {"image_id": 400123, "Bleu_1": 0.5517241378929845, "Bleu_2": 0.280744962517904, "Bleu_3": 0.18006531235543413, "Bleu_4": 0.12241346948603216, "METEOR": 0.27246873641556535, "ROUGE_L": 0.4049792531120332, "CIDEr": 0.17297105115590317, "SPICE": {"All": {"pr": 0.15151515151515152, "re": 0.25, "f": 0.18867924528301888, "fn": 15.0, "numImages": 1.0, "fp": 28.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5714285714285714, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "This is a bathroom with a toilet, sink, and shower. The walls are painted blue and green, and there is a window on the left side of the room."}, "227187": {"image_id": 227187, "Bleu_1": 0.5882352940830451, "Bleu_2": 0.3321055820573897, "Bleu_3": 1.9445555935422507e-06, "Bleu_4": 4.787218652070603e-09, "METEOR": 0.2002974674221306, "ROUGE_L": 0.33701657458563533, "CIDEr": 0.37177096923034125, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.14285714285714285, "f": 0.13636363636363635, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a bird feeder with several birds perched on it, surrounded by plants and trees."}, "461275": {"image_id": 461275, "Bleu_1": 0.37499999998437505, "Bleu_2": 0.2855201203479251, "Bleu_3": 0.19496661442652874, "Bleu_4": 2.4373357803127186e-05, "METEOR": 0.22109600966872522, "ROUGE_L": 0.38705583756345174, "CIDEr": 0.031720925372941924, "SPICE": {"All": {"pr": 0.1875, "re": 0.2, "f": 0.19354838709677422, "fn": 24.0, "numImages": 1.0, "fp": 26.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.46153846153846156, "f": 0.48000000000000004, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a street with a few trees on either side. There is a street sign in the foreground that reads \"Fir Street.\""}, "121534": {"image_id": 121534, "Bleu_1": 0.2586206896507135, "Bleu_2": 0.2130071614174478, "Bleu_3": 0.17833344843241028, "Bleu_4": 0.15068722474426408, "METEOR": 0.23839277048964136, "ROUGE_L": 0.26961325966850824, "CIDEr": 4.202479031402714e-15, "SPICE": {"All": {"pr": 0.1388888888888889, "re": 0.20833333333333334, "f": 0.16666666666666669, "fn": 19.0, "numImages": 1.0, "fp": 31.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 16.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a man and a woman standing next to each other, both wearing glasses and smiling at the camera. The man is wearing a gray sweater and blue jeans, while the woman is wearing a black dress and red tights. They are both standing in front of a white wall with a large window behind them."}, "500657": {"image_id": 500657, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.19402850002522387, "Bleu_3": 0.11539535372137631, "Bleu_4": 1.337614391433853e-05, "METEOR": 0.25950196510460244, "ROUGE_L": 0.2893689114781872, "CIDEr": 8.425584883281349e-09, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.05405405405405406, "f": 0.07142857142857144, "fn": 35.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.15384615384615385, "f": 0.18181818181818185, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a young boy in a red baseball uniform, kneeling on the ground and reaching for a baseball that is on the ground. The boy is wearing a white helmet and has a determined look on his face. The background is a green field with trees in the distance."}, "162021": {"image_id": 162021, "Bleu_1": 0.3333333333247864, "Bleu_2": 0.1324532357030635, "Bleu_3": 7.797842756800693e-07, "Bleu_4": 1.905044960725107e-09, "METEOR": 0.14447067800880606, "ROUGE_L": 0.22846441947565538, "CIDEr": 1.4820675459904804e-06, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.3157894736842105, "f": 0.2608695652173913, "fn": 13.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a group of people skateboarding on the sidewalk. They are all wearing helmets and knee pads, and some of them are holding skateboards. The scene is set in a city with tall buildings in the background."}, "511844": {"image_id": 511844, "Bleu_1": 0.34782608694896033, "Bleu_2": 0.24866794885861784, "Bleu_3": 0.14112555009560282, "Bleu_4": 1.5989582418932847e-05, "METEOR": 0.3230015920046934, "ROUGE_L": 0.32099229468145085, "CIDEr": 4.814581708797105e-07, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.10714285714285714, "f": 0.11111111111111112, "fn": 25.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.23076923076923078, "f": 0.24999999999999994, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a man riding a horse down the street with an American flag on his back. The horse is wearing a saddle and bridle, and the man is wearing a cowboy hat and boots. There are people standing on the sidewalk watching the parade."}, "299001": {"image_id": 299001, "Bleu_1": 0.20481927710596604, "Bleu_2": 0.12242049000647116, "Bleu_3": 0.05698244360648645, "Bleu_4": 6.934789856572616e-06, "METEOR": 0.17319268649683867, "ROUGE_L": 0.14599122457120062, "CIDEr": 5.012287292932029e-28, "SPICE": {"All": {"pr": 0.11363636363636363, "re": 0.35714285714285715, "f": 0.17241379310344826, "fn": 9.0, "numImages": 1.0, "fp": 39.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.3333333333333333, "f": 0.15384615384615383, "fn": 4.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.42857142857142855, "f": 0.27272727272727276, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "The image shows a market stall with various fruits and vegetables on display. There are apples, oranges, and other fruits arranged in rows on the table, while vegetables such as carrots, potatoes, and onions are arranged in baskets. A man stands behind the stall, wearing a blue shirt and white pants, and another man stands in front of the stall, wearing a red shirt and black pants. The overall atmosphere is lively and bustling, with people milling about and shopping for their groceries."}, "341111": {"image_id": 341111, "Bleu_1": 0.24137931034066593, "Bleu_2": 0.17217163877715416, "Bleu_3": 0.1166681070294023, "Bleu_4": 0.08717278881588163, "METEOR": 0.24634270889278928, "ROUGE_L": 0.23591160220994478, "CIDEr": 2.0743244400373615e-14, "SPICE": {"All": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 21.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a person standing on a surfboard in the ocean, holding a paddle and wearing a life jacket. The person is standing on the board with their feet on the board and their hands on the paddle, ready to paddle out into the water. The sky is cloudy and there are waves crashing on the shore."}, "526972": {"image_id": 526972, "Bleu_1": 0.36666666665444453, "Bleu_2": 0.2514326764768464, "Bleu_3": 0.16528691241294277, "Bleu_4": 0.11372027709677378, "METEOR": 0.24924126489266085, "ROUGE_L": 0.29383429672447015, "CIDEr": 0.0036072470286497033, "SPICE": {"All": {"pr": 0.15151515151515152, "re": 0.29411764705882354, "f": 0.19999999999999998, "fn": 12.0, "numImages": 1.0, "fp": 28.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.5555555555555556, "f": 0.43478260869565216, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "This image shows a tray filled with mini pizzas and olives. The pizzas are topped with cheese, pepperoni, and other toppings. The tray is sitting on top of a refrigerator."}, "2299": {"image_id": 2299, "Bleu_1": 0.46153846152071015, "Bleu_2": 0.27174648818404223, "Bleu_3": 0.18325206540749794, "Bleu_4": 0.12789533377278686, "METEOR": 0.2518042160621238, "ROUGE_L": 0.30198019801980197, "CIDEr": 0.024940968676812683, "SPICE": {"All": {"pr": 0.1, "re": 0.06666666666666667, "f": 0.08, "fn": 28.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.07692307692307693, "f": 0.10526315789473684, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "This is a group of children sitting on the ground in front of a building. They are all wearing school uniforms and smiling at the camera."}, "527480": {"image_id": 527480, "Bleu_1": 0.28124999999121103, "Bleu_2": 0.2333141313069371, "Bleu_3": 0.15367277821608147, "Bleu_4": 1.880824215481622e-05, "METEOR": 0.17593726041337954, "ROUGE_L": 0.21708185053380782, "CIDEr": 0.00025859065006902016, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.16666666666666666, "f": 0.1935483870967742, "fn": 15.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "A person is kiteboarding on a body of water. The sun is shining down on the water and the person is holding onto the kite as they ride it across the water."}, "152618": {"image_id": 152618, "Bleu_1": 0.36666666665444453, "Bleu_2": 0.1947589137374367, "Bleu_3": 1.1064850538656952e-06, "Bleu_4": 2.6614494565584342e-09, "METEOR": 0.27333992567478316, "ROUGE_L": 0.4356031624585564, "CIDEr": 0.0022068839024511375, "SPICE": {"All": {"pr": 0.022222222222222223, "re": 0.07142857142857142, "f": 0.03389830508474576, "fn": 13.0, "numImages": 1.0, "fp": 44.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 17.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.05555555555555555, "re": 0.16666666666666666, "f": 0.08333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 17.0, "tp": 1.0}}, "caption": "This is a sign that reads \"stop report all business here\" in red letters on a white background. The sign is attached to a fence in front of a building."}, "547457": {"image_id": 547457, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.17712297710451136, "Bleu_3": 0.08618888098293648, "Bleu_4": 1.0746774156673132e-05, "METEOR": 0.1967456099212661, "ROUGE_L": 0.2238532110091743, "CIDEr": 1.5181913277848887e-09, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.12, "f": 0.13043478260869565, "fn": 22.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a young woman sitting in the driver's seat of a car, looking at her phone. She is wearing a pink shirt and shorts, and has her hair tied back in a ponytail. The car is parked in front of a house with a tree in the background."}, "210766": {"image_id": 210766, "Bleu_1": 0.46666666665629636, "Bleu_2": 0.2912876324952211, "Bleu_3": 0.1580284245644431, "Bleu_4": 1.750810269276388e-05, "METEOR": 0.29667902584409905, "ROUGE_L": 0.3233929754804506, "CIDEr": 1.3131446846148095e-07, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.23529411764705882, "f": 0.20512820512820512, "fn": 13.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a red and white sign on a street corner with the words \"like a brick fitchen\" written on it. The sign is attached to a pole and has a few scratches on it. There are buildings in the background of the image."}, "115721": {"image_id": 115721, "Bleu_1": 0.1710526315766967, "Bleu_2": 0.1510199243254196, "Bleu_3": 0.13509592666655662, "Bleu_4": 0.12400108520532568, "METEOR": 0.2929490598457019, "ROUGE_L": 0.29224738675958184, "CIDEr": 1.9630386577732086e-26, "SPICE": {"All": {"pr": 0.15, "re": 0.13043478260869565, "f": 0.13953488372093023, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "A small dog is sleeping on a couch next to a person wearing pajamas. The dog is lying on its side with its head resting on the person's lap. The person is wearing a red and white striped shirt and has their arms wrapped around the dog. The dog is wearing a red collar and has its paws tucked under its body. The background is a beige colored wall with a window in the background."}, "545730": {"image_id": 545730, "Bleu_1": 0.29999999999250004, "Bleu_2": 0.2148344622063902, "Bleu_3": 0.15387988463781624, "Bleu_4": 0.0996175732941772, "METEOR": 0.24768056549305772, "ROUGE_L": 0.3043044469783352, "CIDEr": 6.1104331981645255e-06, "SPICE": {"All": {"pr": 0.3888888888888889, "re": 0.3684210526315789, "f": 0.37837837837837834, "fn": 12.0, "numImages": 1.0, "fp": 11.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.7142857142857143, "re": 0.8333333333333334, "f": 0.7692307692307692, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "A herd of zebras are standing in the water, looking up at the camera. The river is flowing through the valley, with trees and rocks on either side. The sky is clear and blue, with a few clouds scattered about."}, "93639": {"image_id": 93639, "Bleu_1": 0.20338983050502735, "Bleu_2": 0.1776527256753781, "Bleu_3": 0.13034957774113842, "Bleu_4": 0.07930219617488021, "METEOR": 0.2599605451621783, "ROUGE_L": 0.2644576914144151, "CIDEr": 6.904099482694993e-15, "SPICE": {"All": {"pr": 0.125, "re": 0.15, "f": 0.13636363636363635, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a group of zebras standing in a field with a mountain range in the background. The zebras are standing in a line, looking out at the viewer. The grass is tall and green, and there are no other animals in the field. The sky is clear and blue, with a few white clouds scattered across it."}, "449879": {"image_id": 449879, "Bleu_1": 0.2166666666630556, "Bleu_2": 0.16033157732774106, "Bleu_3": 0.09606091316953058, "Bleu_4": 1.1167123500978704e-05, "METEOR": 0.2673119567594927, "ROUGE_L": 0.26236559139784943, "CIDEr": 3.4716542080154014e-15, "SPICE": {"All": {"pr": 0.09259259259259259, "re": 0.3125, "f": 0.14285714285714285, "fn": 11.0, "numImages": 1.0, "fp": 49.0, "tp": 5.0}, "Relation": {"pr": 0.05, "re": 0.3333333333333333, "f": 0.08695652173913045, "fn": 2.0, "numImages": 1.0, "fp": 19.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.17391304347826086, "re": 0.5, "f": 0.25806451612903225, "fn": 4.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}}, "caption": "The man is sitting on the back of a motorcycle, wearing a leather jacket and holding a cat in his arms. The cat is looking up at him with a curious expression on its face. The man is smiling and appears to be enjoying the moment. The background is a residential street with trees and houses visible in the distance."}, "378244": {"image_id": 378244, "Bleu_1": 0.2499999999958334, "Bleu_2": 0.14555562743244904, "Bleu_3": 0.10309804281481255, "Bleu_4": 0.07874565515343887, "METEOR": 0.26204064472223787, "ROUGE_L": 0.25738396624472576, "CIDEr": 1.339042245179777e-15, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.12, "f": 0.13953488372093023, "fn": 22.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This image shows a person skiing down a snowy slope. The person is wearing a black jacket and black pants, and has a black helmet on their head. They are holding a black ski pole in their hand and are making turns on the snow. The trees in the background are covered in snow and have a lot of branches."}, "9003": {"image_id": 9003, "Bleu_1": 0.30769230768441824, "Bleu_2": 0.22041550750546754, "Bleu_3": 0.1379656129587101, "Bleu_4": 0.09241713818213783, "METEOR": 0.25941957721513054, "ROUGE_L": 0.30609318996415774, "CIDEr": 1.2637669860795079e-05, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.16666666666666666, "f": 0.1702127659574468, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2727272727272727, "f": 0.2608695652173913, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a man playing tennis on a court with a net in the background. He is wearing a white shirt and black shorts, and has a racket in his hand. The image is in black and white."}, "202653": {"image_id": 202653, "Bleu_1": 0.11881188118694247, "Bleu_2": 0.07707524933003927, "Bleu_3": 0.049325885737116965, "Bleu_4": 5.915611580998953e-06, "METEOR": 0.13538701944476353, "ROUGE_L": 0.1458233727204426, "CIDEr": 9.842876943828727e-49, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.2631578947368421, "f": 0.23809523809523808, "fn": 14.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a couple sitting on a bench in front of a building with a large window on the side. The man is leaning back on the bench with his arms crossed, while the woman is sitting upright with her hands in her lap. The bench is made of wood and has a metal frame. The building behind them appears to be a government office or courthouse, with tall windows and a stone facade. The sky is clear and blue, with a few clouds scattered across it. The temperature is cold, as evidenced by the couple's hats and scarves."}, "179174": {"image_id": 179174, "Bleu_1": 0.3170731707239739, "Bleu_2": 0.17806548534627567, "Bleu_3": 0.09333222718437928, "Bleu_4": 1.2094218846986128e-05, "METEOR": 0.1785938514766138, "ROUGE_L": 0.22021660649819497, "CIDEr": 2.776584246423265e-06, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.06896551724137931, "f": 0.08695652173913043, "fn": 27.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.15384615384615385, "f": 0.17391304347826086, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This image shows a group of old suitcases stacked up on the sidewalk. The suitcases are various colors and sizes, and some of them have wheels on the bottom. There are people walking by the suitcases, and the sky is cloudy."}, "500100": {"image_id": 500100, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.19603921176003908, "Bleu_3": 0.1161912088962168, "Bleu_4": 1.3445273575061206e-05, "METEOR": 0.2471443045078394, "ROUGE_L": 0.29204069419509276, "CIDEr": 1.1466287461983868e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.13636363636363635, "f": 0.1764705882352941, "fn": 19.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "A woman is riding a skateboard down the sidewalk while her dog runs alongside her. The woman is wearing a black jacket and jeans, and the dog is wearing a red collar. There are cars parked on the side of the road, and a building can be seen in the background."}, "576052": {"image_id": 576052, "Bleu_1": 0.7333333332844446, "Bleu_2": 0.5606119105426793, "Bleu_3": 0.45900113549351607, "Bleu_4": 0.3563054844721135, "METEOR": 0.2500888282839401, "ROUGE_L": 0.6047087980173481, "CIDEr": 1.1680331972162623, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.2631578947368421, "f": 0.19999999999999998, "fn": 14.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5, "f": 0.36363636363636365, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "A woman is riding a horse through a grassy field with mountains in the background."}, "544140": {"image_id": 544140, "Bleu_1": 0.25423728813128416, "Bleu_2": 0.13241452366608922, "Bleu_3": 0.08505022398980135, "Bleu_4": 0.05757177103686273, "METEOR": 0.15933920186429137, "ROUGE_L": 0.23735408560311286, "CIDEr": 6.235154158383779e-15, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.04, "f": 0.05555555555555555, "fn": 24.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image shows a group of people playing music on the street in front of a large building with a lot of windows. There are several people standing on the sidewalk, some of them playing instruments, while others are sitting on the ground, listening to the music. The sky is cloudy and there are a few birds flying overhead."}, "349647": {"image_id": 349647, "Bleu_1": 0.24999999999609374, "Bleu_2": 0.1543033499596618, "Bleu_3": 0.07268637438786686, "Bleu_4": 8.907530052595531e-06, "METEOR": 0.2038058073121133, "ROUGE_L": 0.22858672376873657, "CIDEr": 9.012415175239525e-14, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.15789473684210525, "f": 0.13043478260869565, "fn": 16.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The woman is standing in the kitchen, holding a plate of pizza in one hand and a glass of wine in the other. She is wearing a white shirt and black pants. There are several other plates of food on the counter, including a salad and some bread. The walls are painted a light blue color and there is a window in the background."}, "240915": {"image_id": 240915, "Bleu_1": 0.30952380951644, "Bleu_2": 0.17377412013914983, "Bleu_3": 9.105491676695635e-07, "Bleu_4": 2.0975455444446706e-09, "METEOR": 0.16001301717458014, "ROUGE_L": 0.25957446808510637, "CIDEr": 5.399996183989703e-07, "SPICE": {"All": {"pr": 0.47368421052631576, "re": 0.3103448275862069, "f": 0.375, "fn": 20.0, "numImages": 1.0, "fp": 10.0, "tp": 9.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.16666666666666666, "f": 0.2857142857142857, "fn": 10.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a red umbrella with the words \"Kindergarten\" written on it. There are several people standing around the umbrella, some of them holding flowers and other items. The background is a city street with buildings and trees in the distance."}, "235964": {"image_id": 235964, "Bleu_1": 0.19999999999636367, "Bleu_2": 0.17213259316161544, "Bleu_3": 0.14969266991794247, "Bleu_4": 0.13401149931009848, "METEOR": 0.2677001042850445, "ROUGE_L": 0.3099943534726144, "CIDEr": 1.2790296132751036e-12, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 14.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a woman standing in front of a mirror in a bathroom. She is wearing a red dress and has a hat on her head. There are green tiles on the walls and a green carpet on the floor. The mirror is framed with white molding and has a gold frame around it."}, "358039": {"image_id": 358039, "Bleu_1": 0.6666666665777778, "Bleu_2": 0.43643578041275427, "Bleu_3": 0.24469914282722582, "Bleu_4": 3.324137842971454e-05, "METEOR": 0.26243365642949984, "ROUGE_L": 0.3469852104664391, "CIDEr": 0.5414055619048666, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.15, "f": 0.125, "fn": 17.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "There are two pizzas on a plate with a fork and knife next to them."}, "514292": {"image_id": 514292, "Bleu_1": 0.5882352940830451, "Bleu_2": 0.3321055820573897, "Bleu_3": 0.194455559354225, "Bleu_4": 2.6920508807813403e-05, "METEOR": 0.3019368560969552, "ROUGE_L": 0.4277699859747546, "CIDEr": 0.37737945207658485, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a stuffed animal wearing sunglasses and sitting on the floor next to a box."}, "558362": {"image_id": 558362, "Bleu_1": 0.3749999999765626, "Bleu_2": 0.22360679773553777, "Bleu_3": 1.528553543562194e-06, "Bleu_4": 4.071220775270606e-09, "METEOR": 0.17429193899782136, "ROUGE_L": 0.2527624309392265, "CIDEr": 0.22567223473656914, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.11538461538461539, "f": 0.13953488372093026, "fn": 23.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.18181818181818182, "f": 0.19999999999999998, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"Fresh produce on display at a market\""}, "436865": {"image_id": 436865, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.09671474291033856, "Bleu_3": 5.838426740772723e-07, "Bleu_4": 1.442223004001259e-09, "METEOR": 0.06862292674515566, "ROUGE_L": 0.118140735958683, "CIDEr": 1.5503750405418038e-11, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.29411764705882354, "f": 0.25316455696202533, "fn": 24.0, "numImages": 1.0, "fp": 35.0, "tp": 10.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.08333333333333333, "re": 0.08333333333333333, "f": 0.08333333333333333, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.47368421052631576, "re": 0.6428571428571429, "f": 0.5454545454545454, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 9.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA giraffe stands in front of a rocky cliff, looking out at the landscape. The giraffe's long neck and legs are visible, as well as its spots on its fur. The sky is clear and blue in the background."}, "80733": {"image_id": 80733, "Bleu_1": 0.31034482758085613, "Bleu_2": 0.23333765443696047, "Bleu_3": 0.18001593881915867, "Bleu_4": 0.1517522183850875, "METEOR": 0.29314737788739326, "ROUGE_L": 0.3304442036836403, "CIDEr": 2.087263367919391e-11, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.06666666666666667, "f": 0.08888888888888888, "fn": 28.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.16666666666666666, "f": 0.2105263157894737, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a man standing in front of a mirror, looking at his hair with a concerned expression on his face. He is wearing a striped shirt and has a pair of glasses on his face. The mirror is reflecting his image, and there are some bottles of shampoo and conditioner on the counter next to him."}, "383001": {"image_id": 383001, "Bleu_1": 0.33333333332679743, "Bleu_2": 0.21602468994265056, "Bleu_3": 0.1418983411941997, "Bleu_4": 0.08783602619536428, "METEOR": 0.2213808483376468, "ROUGE_L": 0.22889305816135083, "CIDEr": 5.468238067402008e-09, "SPICE": {"All": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 32.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.08333333333333333, "f": 0.1111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is an image of a woman holding an umbrella while walking on the sidewalk. She is wearing a black and white striped shirt and black pants. There are people in the background, some of whom are also holding umbrellas. The sky is cloudy and there are trees in the background."}, "312627": {"image_id": 312627, "Bleu_1": 0.30952380951644, "Bleu_2": 0.1504928025607928, "Bleu_3": 0.10423186007764307, "Bleu_4": 0.07340644874496201, "METEOR": 0.16608646448395192, "ROUGE_L": 0.2881241565452092, "CIDEr": 8.006216857722241e-07, "SPICE": {"All": {"pr": 0.2, "re": 0.19230769230769232, "f": 0.19607843137254902, "fn": 21.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This is an image of a parking lot with several cars parked in it. There are also some trash cans and recycling bins in the background. The lighting in the image is dim, with only a few streetlights visible in the distance."}, "482590": {"image_id": 482590, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.20195126571496114, "Bleu_3": 0.13566654900343936, "Bleu_4": 0.08492670489284881, "METEOR": 0.26383544105629175, "ROUGE_L": 0.26704190118824267, "CIDEr": 4.8997720230082486e-11, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.2631578947368421, "f": 0.19999999999999998, "fn": 14.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows two women walking down a street in a city. One of them is carrying an umbrella and the other is walking behind her. The street is lined with buildings and there are people walking in the background. The sky is cloudy and there are raindrops on the umbrella."}, "334521": {"image_id": 334521, "Bleu_1": 0.5454545454297521, "Bleu_2": 0.16116459279757608, "Bleu_3": 1.0910293277246606e-06, "Bleu_4": 2.8753380959849475e-09, "METEOR": 0.21839393559019726, "ROUGE_L": 0.3489702517162472, "CIDEr": 0.054401908717327974, "SPICE": {"All": {"pr": 0.2, "re": 0.08333333333333333, "f": 0.11764705882352941, "fn": 22.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A group of giraffes standing in a fenced enclosure, looking at each other.\""}, "418219": {"image_id": 418219, "Bleu_1": 0.4999999999750001, "Bleu_2": 0.28097574346008974, "Bleu_3": 0.16368983753038932, "Bleu_4": 2.253741272145215e-05, "METEOR": 0.18736857217857883, "ROUGE_L": 0.3519230769230769, "CIDEr": 0.1434845866955288, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.11764705882352941, "f": 0.14285714285714285, "fn": 15.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A man walks down a tree-lined sidewalk on a sunny day.\""}, "575012": {"image_id": 575012, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.18994132206127556, "Bleu_3": 0.14746720993983883, "Bleu_4": 0.10987931098352247, "METEOR": 0.22653049023253588, "ROUGE_L": 0.32265647957684396, "CIDEr": 1.7707629627238722e-06, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.16666666666666666, "f": 0.11764705882352942, "fn": 15.0, "numImages": 1.0, "fp": 30.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.2222222222222222, "f": 0.17391304347826086, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "The image shows a woman sitting on a bench, wearing a pink floral dress and white sunglasses. She is holding a cell phone in her hand and has a serious expression on her face. The background is a city street with cars and buildings in the distance."}, "182696": {"image_id": 182696, "Bleu_1": 0.472222222209105, "Bleu_2": 0.36731544333587757, "Bleu_3": 0.25131581370253364, "Bleu_4": 0.14809362972137902, "METEOR": 0.2765796969763782, "ROUGE_L": 0.38006230529595014, "CIDEr": 0.00023366045570616265, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.19047619047619047, "f": 0.16, "fn": 17.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5714285714285714, "f": 0.38095238095238093, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "A black cat is sitting on top of a laptop computer, looking at the screen. The laptop has a pink keyboard and a black screen. The cat is looking at the screen with its eyes closed."}, "343972": {"image_id": 343972, "Bleu_1": 0.11764705882179932, "Bleu_2": 0.04190377370888481, "Bleu_3": 2.9852963182164213e-07, "Bleu_4": 7.998568064870978e-10, "METEOR": 0.1783177827073096, "ROUGE_L": 0.1227364185110664, "CIDEr": 4.733419338893498e-23, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.14285714285714285, "f": 0.1, "fn": 12.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image shows a mother elephant and her baby standing on the ground. The mother elephant is looking down at her baby while the baby is looking up at her. The mother elephant has a large body and a long trunk, while the baby elephant has a smaller body and a shorter trunk. The background of the image is a dirt path with some trees in the distance."}, "7260": {"image_id": 7260, "Bleu_1": 0.20833333333043982, "Bleu_2": 0.132686223106713, "Bleu_3": 0.09103847195685184, "Bleu_4": 0.0683854873028529, "METEOR": 0.2292212484056939, "ROUGE_L": 0.19768518518518519, "CIDEr": 3.51836390676071e-24, "SPICE": {"All": {"pr": 0.1388888888888889, "re": 0.23809523809523808, "f": 0.17543859649122806, "fn": 16.0, "numImages": 1.0, "fp": 31.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.29411764705882354, "re": 0.5, "f": 0.37037037037037035, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}}, "caption": "The image shows a group of people playing tennis on a green grass court. There are four players in total, two men and two women, all wearing tennis outfits and holding rackets. They are standing on the court, ready to hit the ball back and forth. The crowd is watching from the sidelines, cheering and clapping as the players play. The sky is cloudy and there are some trees in the background."}, "64084": {"image_id": 64084, "Bleu_1": 0.33333333331746035, "Bleu_2": 0.22360679773906486, "Bleu_3": 1.3806135595143185e-06, "Bleu_4": 3.477250470403683e-09, "METEOR": 0.14790532817844224, "ROUGE_L": 0.287396937573616, "CIDEr": 0.12443954666618649, "SPICE": {"All": {"pr": 0.12, "re": 0.11538461538461539, "f": 0.11764705882352941, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "A table with a white tablecloth and several plates of bread rolls, a bottle of ketchup, and a glass of milk."}, "324527": {"image_id": 324527, "Bleu_1": 0.23529411763321803, "Bleu_2": 0.12126781251081024, "Bleu_3": 9.934208620967142e-07, "Bleu_4": 2.8927969314267103e-09, "METEOR": 0.13126385809312638, "ROUGE_L": 0.2566619915848527, "CIDEr": 0.17588886368524964, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.2222222222222222, "f": 0.24, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.1, "f": 0.09523809523809525, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.45454545454545453, "f": 0.45454545454545453, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"Surfer riding a wave at an aquatic park\""}, "91617": {"image_id": 91617, "Bleu_1": 0.34883720929421314, "Bleu_2": 0.24112141107953186, "Bleu_3": 0.16203281746698117, "Bleu_4": 0.10155170980557418, "METEOR": 0.21431351493497994, "ROUGE_L": 0.35169762972453555, "CIDEr": 8.331038566234571e-05, "SPICE": {"All": {"pr": 0.5555555555555556, "re": 0.21739130434782608, "f": 0.3125, "fn": 18.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.4444444444444444, "f": 0.6153846153846153, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 4.0}}, "caption": "This is a modern office space with a large window overlooking the ocean. There is a desk with a computer and other office supplies, as well as a comfortable chair and a couch. The walls are painted white and there are hardwood floors."}, "541593": {"image_id": 541593, "Bleu_1": 0.23333333332944448, "Bleu_2": 0.17787191480959694, "Bleu_3": 0.11784269714184226, "Bleu_4": 0.07319952982776265, "METEOR": 0.23501308194930187, "ROUGE_L": 0.2553064275037369, "CIDEr": 2.077203307410019e-15, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.18181818181818182, "f": 0.2222222222222222, "fn": 18.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is a black and white image of a clock tower in the city. The clock face is visible on the front of the tower, with the hands pointing to the time. The tower is made of brick and has a steeple on top. There are buildings in the background, with people walking on the sidewalk in front of them."}, "468354": {"image_id": 468354, "Bleu_1": 0.39999999998400004, "Bleu_2": 0.25819888973661803, "Bleu_3": 0.20563674453180714, "Bleu_4": 0.16767849550070033, "METEOR": 0.2969098212566271, "ROUGE_L": 0.40087623220153346, "CIDEr": 0.02783819759562988, "SPICE": {"All": {"pr": 0.16216216216216217, "re": 0.2857142857142857, "f": 0.20689655172413793, "fn": 15.0, "numImages": 1.0, "fp": 31.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.6666666666666666, "f": 0.4800000000000001, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}}, "caption": "The image shows a river with a bridge in the background. There are several swans swimming in the water. The sky is clear and blue."}, "276893": {"image_id": 276893, "Bleu_1": 0.34042553190765057, "Bleu_2": 0.21072097723733796, "Bleu_3": 0.09955605444507262, "Bleu_4": 1.2237355827839207e-05, "METEOR": 0.26212509939439554, "ROUGE_L": 0.31302116741500957, "CIDEr": 8.900776706691222e-08, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.15384615384615385, "f": 0.1702127659574468, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a young boy sleeping in bed with a book on his chest. The bed is covered in white sheets and there are pillows on either side of him. The room is dimly lit and there is a window on the wall opposite the bed."}, "3156": {"image_id": 3156, "Bleu_1": 0.37499999999062505, "Bleu_2": 0.21926450482120546, "Bleu_3": 0.10815610103033259, "Bleu_4": 1.3598400757144137e-05, "METEOR": 0.3028016874943426, "ROUGE_L": 0.34957020057306587, "CIDEr": 3.4133359895435673e-06, "SPICE": {"All": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 24.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}, "Relation": {"pr": 0.5, "re": 0.07692307692307693, "f": 0.13333333333333336, "fn": 12.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.3333333333333333, "f": 0.42857142857142855, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This image shows a man in a white shirt and black pants standing in front of a toilet. He is holding a plunger and appears to be fixing the toilet. The walls of the bathroom are black and white checkered."}, "340704": {"image_id": 340704, "Bleu_1": 0.21999999999560005, "Bleu_2": 0.06700593942469525, "Bleu_3": 4.5393651709319995e-07, "Bleu_4": 1.187741350296707e-09, "METEOR": 0.16231884057971013, "ROUGE_L": 0.1813317479191439, "CIDEr": 1.6531748036117929e-10, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.05128205128205128, "f": 0.08333333333333333, "fn": 37.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.14285714285714285, "f": 0.21052631578947364, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "This image shows an older woman sitting at a table with a hamburger in her hand. She is wearing a white shirt and has a smile on her face. The background is a light blue color with some other objects in the room, such as a vase and a lamp."}, "452515": {"image_id": 452515, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.18516401995076925, "Bleu_3": 0.11262478804206155, "Bleu_4": 1.3203863485033786e-05, "METEOR": 0.2551351310505003, "ROUGE_L": 0.30310559006211185, "CIDEr": 1.1379558633434229e-10, "SPICE": {"All": {"pr": 0.20512820512820512, "re": 0.2857142857142857, "f": 0.23880597014925373, "fn": 20.0, "numImages": 1.0, "fp": 31.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.4, "f": 0.2857142857142857, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Object": {"pr": 0.35294117647058826, "re": 0.5454545454545454, "f": 0.42857142857142855, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}}, "caption": "The image shows a woman in a white tennis dress playing a tennis match on a blue court. She is holding a tennis racket in her right hand and is about to hit the ball with her left hand. The crowd in the background is cheering and waving their hands."}, "553072": {"image_id": 553072, "Bleu_1": 0.35185185184533607, "Bleu_2": 0.23045544793969702, "Bleu_3": 0.145243695343206, "Bleu_4": 0.1046978883007826, "METEOR": 0.19890397874775845, "ROUGE_L": 0.2853801169590643, "CIDEr": 2.51022414063524e-12, "SPICE": {"All": {"pr": 0.28, "re": 0.25, "f": 0.2641509433962264, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a line of several small planes parked on the runway. They are all painted in red and white colors with the words \"Canadian Air Force\" written on the side. The planes are lined up in a row, facing the direction of the runway. There are no people visible in the image."}, "543215": {"image_id": 543215, "Bleu_1": 0.6315789473019391, "Bleu_2": 0.4955946277304597, "Bleu_3": 0.38662335329677483, "Bleu_4": 0.322638641567532, "METEOR": 0.2543287743448505, "ROUGE_L": 0.47368421052631576, "CIDEr": 0.9194626983859724, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2571428571428571, "f": 0.2903225806451613, "fn": 26.0, "numImages": 1.0, "fp": 18.0, "tp": 9.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.14285714285714285, "f": 0.19047619047619047, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.46153846153846156, "f": 0.4999999999999999, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "This is a street sign with the name of a town on it. The town is called greenville cemetery."}, "503808": {"image_id": 503808, "Bleu_1": 0.26829268292028563, "Bleu_2": 0.2006088294094673, "Bleu_3": 0.14574228638178904, "Bleu_4": 0.0950043048668591, "METEOR": 0.21052570487905994, "ROUGE_L": 0.2260934025203855, "CIDEr": 1.812192270988357e-06, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.02631578947368421, "f": 0.04, "fn": 37.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 17.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.07142857142857142, "f": 0.10526315789473682, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}}, "caption": "This is an image of a person skiing down a snowy slope. The person is wearing a red and white ski suit and has their skis pointed down the slope. There are trees in the background and a blue sky above."}, "424975": {"image_id": 424975, "Bleu_1": 0.3913043478175804, "Bleu_2": 0.2284160962830436, "Bleu_3": 0.10584416257170214, "Bleu_4": 1.2886443367349682e-05, "METEOR": 0.2388478342487942, "ROUGE_L": 0.26991150442477874, "CIDEr": 7.162888740220928e-08, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.45454545454545453, "f": 0.31249999999999994, "fn": 6.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 1.0, "f": 0.6153846153846153, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "This is an image of a street with a group of people standing in front of a store. The store has a colorful mural on the side of it, with graffiti and other artwork covering the walls. There are also several cars parked on the street."}, "450886": {"image_id": 450886, "Bleu_1": 0.17187499999731448, "Bleu_2": 0.13819269959596528, "Bleu_3": 0.11548249870651957, "Bleu_4": 0.10024660377689842, "METEOR": 0.1787431251530557, "ROUGE_L": 0.19385593220338984, "CIDEr": 5.4445909203275e-18, "SPICE": {"All": {"pr": 0.24, "re": 0.25, "f": 0.24489795918367346, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6666666666666666, "f": 0.5714285714285715, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "This image shows a group of stop signs in a parking lot. The signs are made of metal and have the words \"stop\" written on them in white letters. There are several other signs in the background, including one that says \"no parking\" and another that says \"no trespassing.\" The image is taken from a low angle, looking down at the signs from above."}, "170640": {"image_id": 170640, "Bleu_1": 0.48717948716699544, "Bleu_2": 0.3580574370104147, "Bleu_3": 0.2402082328127251, "Bleu_4": 0.18435104536393854, "METEOR": 0.3544260561379818, "ROUGE_L": 0.4280701754385964, "CIDEr": 8.60698461479481e-05, "SPICE": {"All": {"pr": 0.038461538461538464, "re": 0.05, "f": 0.043478260869565216, "fn": 19.0, "numImages": 1.0, "fp": 25.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.1111111111111111, "f": 0.09523809523809525, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The image shows a man sitting on a bed in a room with a red wall. He is holding a dog in his lap and looking at it. There are books and other items on the shelves behind him."}, "97857": {"image_id": 97857, "Bleu_1": 0.4047619047522676, "Bleu_2": 0.2433792297516304, "Bleu_3": 0.1643902651700362, "Bleu_4": 0.10330965714322903, "METEOR": 0.20570231800211944, "ROUGE_L": 0.3292847503373819, "CIDEr": 9.190790266189608e-07, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.16, "f": 0.14814814814814817, "fn": 21.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a yellow school bus driving down a narrow street lined with palm trees and shops. There are several cars parked on the side of the road, and people are walking on the sidewalk. The sky is clear and blue."}, "120478": {"image_id": 120478, "Bleu_1": 0.4074074073923183, "Bleu_2": 0.2168145451878124, "Bleu_3": 1.2342759676459987e-06, "Bleu_4": 2.97513306285635e-09, "METEOR": 0.16859379903936947, "ROUGE_L": 0.2533748701973001, "CIDEr": 0.006475394666256504, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.2631578947368421, "f": 0.2127659574468085, "fn": 14.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This is an image of a road with a sign on the side that reads, \"Welcome to the city.\" There are trees and buildings in the background."}, "280370": {"image_id": 280370, "Bleu_1": 0.33333333332407417, "Bleu_2": 0.21821789022984422, "Bleu_3": 0.14096477244685904, "Bleu_4": 0.09598524129527268, "METEOR": 0.20647243688428532, "ROUGE_L": 0.2839851024208566, "CIDEr": 0.00024345726472763782, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 15.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows two men riding horses in a rodeo competition. The men are wearing cowboy hats and riding on horses that are pulling a rope. The crowd is cheering and waving flags in the background."}, "396608": {"image_id": 396608, "Bleu_1": 0.8461538460236689, "Bleu_2": 0.5937710859021021, "Bleu_3": 0.40021356110815515, "Bleu_4": 0.2829559627860283, "METEOR": 0.30280999531998726, "ROUGE_L": 0.5641618497109826, "CIDEr": 2.4124313149537135, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.16, "f": 0.1818181818181818, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "A cup of coffee, a banana, and an orange on a white tablecloth."}, "416534": {"image_id": 416534, "Bleu_1": 0.22033898304711294, "Bleu_2": 0.13782140587560074, "Bleu_3": 0.0873499841408337, "Bleu_4": 0.05873542506951284, "METEOR": 0.2509639763019265, "ROUGE_L": 0.27741283476503287, "CIDEr": 1.5853096196228556e-13, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.12903225806451613, "f": 0.18181818181818182, "fn": 27.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.09090909090909091, "f": 0.14285714285714288, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "This is a living room with a wooden floor and white walls. There is a couch in the corner of the room, and a coffee table in front of it. There are two chairs in front of the coffee table, and a bookshelf on the wall behind the couch. The room has large windows that let in natural light."}, "159627": {"image_id": 159627, "Bleu_1": 0.14444444444283952, "Bleu_2": 0.09008249790765034, "Bleu_3": 4.517859521221133e-07, "Bleu_4": 1.014658105273746e-09, "METEOR": 0.1084482302153544, "ROUGE_L": 0.12017336485421591, "CIDEr": 1.49867048635421e-39, "SPICE": {"All": {"pr": 0.25, "re": 0.08, "f": 0.12121212121212122, "fn": 23.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.2222222222222222, "f": 0.3333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\nThis is a bus stop sign on a street in a city. The sign has the words \"Bus Stop\" written on it in white letters, with an arrow pointing to the right. The sign is surrounded by a blue background with white lines and a white border. The bus stop is located in front of a building with a large window and a door. There are people standing on the sidewalk in front of the building, looking at the bus stop."}, "509719": {"image_id": 509719, "Bleu_1": 0.36585365852766216, "Bleu_2": 0.25303041366748835, "Bleu_3": 0.2017206146343491, "Bleu_4": 0.1714477581871228, "METEOR": 0.3615149370476556, "ROUGE_L": 0.37166793602437165, "CIDEr": 2.8908032781487637e-06, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.1111111111111111, "f": 0.14634146341463417, "fn": 24.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "This is an image of a bird standing on the ground, looking up at the camera. The bird has a small beak and is wearing a small collar around its neck. The background is a blurred image of trees and buildings."}, "77400": {"image_id": 77400, "Bleu_1": 0.24561403508341031, "Bleu_2": 0.1480872194371519, "Bleu_3": 7.360220454770081e-07, "Bleu_4": 1.6484268393209962e-09, "METEOR": 0.21148658206002868, "ROUGE_L": 0.20926243567753, "CIDEr": 2.3684118304792772e-14, "SPICE": {"All": {"pr": 0.16, "re": 0.2, "f": 0.17777777777777778, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The man in the image is wearing a black tuxedo with a white shirt and black tie. He is standing in front of a wooden door with a window on it. The room appears to be a living room with a couch, coffee table, and chairs. The man is holding a glass of wine in his hand."}, "207431": {"image_id": 207431, "Bleu_1": 0.370370370356653, "Bleu_2": 0.11935247900206675, "Bleu_3": 8.290377243671376e-07, "Bleu_4": 2.2073840969171685e-09, "METEOR": 0.24844505366890246, "ROUGE_L": 0.2946859903381643, "CIDEr": 0.01714962893457427, "SPICE": {"All": {"pr": 0.0625, "re": 0.045454545454545456, "f": 0.052631578947368425, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "The image shows a pizza with various toppings, including mushrooms, onions, and cheese. There are also two glasses of wine on the table next to the pizza."}, "541813": {"image_id": 541813, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.1593710424504603, "Bleu_3": 0.09986796846096184, "Bleu_4": 1.1880293241977446e-05, "METEOR": 0.17059630786511623, "ROUGE_L": 0.28355607205113303, "CIDEr": 1.5394137762571697e-10, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.21428571428571427, "f": 0.23999999999999996, "fn": 22.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is a small, dimly lit room with a wooden table and chairs in the center. There is a large mirror on the wall behind the table, and a small window on the opposite wall that looks out onto a courtyard. The walls are made of concrete and have a rough, unfinished texture."}, "306582": {"image_id": 306582, "Bleu_1": 0.4814814814636489, "Bleu_2": 0.2721655269656347, "Bleu_3": 0.14362897932992935, "Bleu_4": 1.8744710838941805e-05, "METEOR": 0.2014312693021657, "ROUGE_L": 0.3306233062330623, "CIDEr": 0.01779588079957011, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.2857142857142857, "f": 0.3, "fn": 15.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "This is a small village with several houses made of wood and thatch. There are clothes hanging on a line in front of one of the houses."}, "458223": {"image_id": 458223, "Bleu_1": 0.3255813953412656, "Bleu_2": 0.23294541396842086, "Bleu_3": 0.13833056672829191, "Bleu_4": 1.6038864534634092e-05, "METEOR": 0.23796774928195336, "ROUGE_L": 0.25505226480836235, "CIDEr": 2.586589962874528e-07, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.2857142857142857, "f": 0.2727272727272727, "fn": 15.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "A man is walking along a pier with a red lighthouse in the background. The pier is made of wooden planks and there are rocks and seaweed on the ground. The sky is cloudy and there is a small boat in the water."}, "198397": {"image_id": 198397, "Bleu_1": 0.305555555547068, "Bleu_2": 0.16183471873797783, "Bleu_3": 9.166878867586852e-07, "Bleu_4": 2.1980503399202124e-09, "METEOR": 0.22859123355873434, "ROUGE_L": 0.27477477477477474, "CIDEr": 0.0003012651177225347, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.25925925925925924, "f": 0.27450980392156865, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.18181818181818182, "f": 0.2222222222222222, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5555555555555556, "f": 0.5263157894736842, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a man playing tennis on a court. He is wearing a white shirt and shorts, and has a tennis racket in his hand. There are several people in the background watching the game."}, "413551": {"image_id": 413551, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.18233123936852927, "Bleu_3": 8.974042296560842e-07, "Bleu_4": 2.0018796078270936e-09, "METEOR": 0.26373635769111786, "ROUGE_L": 0.2459677419354839, "CIDEr": 6.518875288300753e-10, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.13636363636363635, "f": 0.1395348837209302, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.2727272727272727, "f": 0.3157894736842105, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This image shows a table with various types of pastries and bread on it. There are several plates and cups on the table, as well as a few utensils such as forks and knives. The table is surrounded by chairs and there are some people sitting at it."}, "526622": {"image_id": 526622, "Bleu_1": 0.39393939392745647, "Bleu_2": 0.1921765286905374, "Bleu_3": 1.0600987725377332e-06, "Bleu_4": 2.5103220166185564e-09, "METEOR": 0.19820409763055358, "ROUGE_L": 0.25738396624472576, "CIDEr": 0.0008219370845337717, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.1875, "f": 0.16216216216216214, "fn": 13.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a bicycle parked next to a canal in a city. There are buildings on either side of the canal, with windows and balconies visible. The sky is clear and blue."}, "401850": {"image_id": 401850, "Bleu_1": 0.26027397259917434, "Bleu_2": 0.20827624788389396, "Bleu_3": 0.14509876478913097, "Bleu_4": 0.08127805017075344, "METEOR": 0.23427806765768533, "ROUGE_L": 0.21972084646555606, "CIDEr": 2.5572541050380763e-23, "SPICE": {"All": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 15.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5555555555555556, "f": 0.4761904761904762, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a horse and carriage on a city street. The carriage is white with red trim and has a black top. The horse is brown and has a black mane and tail. There are buildings on either side of the street, including a large building with a clock tower. There are people walking on the sidewalk and cars driving by. The sky is blue and there are clouds in the distance."}, "224368": {"image_id": 224368, "Bleu_1": 0.26829268292028563, "Bleu_2": 0.11582156166137168, "Bleu_3": 7.006558330325156e-07, "Bleu_4": 1.7345333611892186e-09, "METEOR": 0.153308539371207, "ROUGE_L": 0.20933424845573095, "CIDEr": 7.05045084825033e-07, "SPICE": {"All": {"pr": 0.24, "re": 0.3333333333333333, "f": 0.27906976744186046, "fn": 12.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.7142857142857143, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "This is an image of a person snowboarding down a hill. The person is wearing a helmet and gloves, and is holding onto the handlebars of the snowboard. The hill is covered in snow and there are trees in the background."}, "552235": {"image_id": 552235, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.2175844552512906, "Bleu_3": 0.1291053828237431, "Bleu_4": 1.4956884792307707e-05, "METEOR": 0.27690994899844956, "ROUGE_L": 0.24830393487109906, "CIDEr": 1.1512154160618677e-08, "SPICE": {"All": {"pr": 0.5714285714285714, "re": 0.2222222222222222, "f": 0.32, "fn": 14.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.2, "f": 0.33333333333333337, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.3, "f": 0.4, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The living room is decorated for Christmas with a large tree in the center of the room. There are presents under the tree and a fireplace in the corner. The walls are painted a warm color and there are windows on either side of the room."}, "130043": {"image_id": 130043, "Bleu_1": 0.2647058823451558, "Bleu_2": 0.08956221510130578, "Bleu_3": 6.30521487401884e-07, "Bleu_4": 1.686298660670985e-09, "METEOR": 0.11194444656217054, "ROUGE_L": 0.20783645655877342, "CIDEr": 8.37690484350393e-05, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.15384615384615385, "f": 0.11764705882352941, "fn": 11.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows two women standing in a living room, one holding a plate of food and the other holding a drink. They are both wearing casual clothing and appear to be enjoying themselves."}, "576449": {"image_id": 576449, "Bleu_1": 0.26229508196291323, "Bleu_2": 0.16195526603310612, "Bleu_3": 0.096158875776368, "Bleu_4": 1.1127177976000066e-05, "METEOR": 0.1922857484951438, "ROUGE_L": 0.22438255386232267, "CIDEr": 1.6341509678528317e-16, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.15, "f": 0.15384615384615385, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a green bus parked in front of a building with people standing around it. The bus has the words \"City Bus\" written on the side in white letters. There are several people standing around the bus, looking at their phones or talking to each other. The building behind the bus appears to be a warehouse or storage facility."}, "274678": {"image_id": 274678, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.1596564940032875, "Bleu_3": 0.10132945277550723, "Bleu_4": 1.213365000609625e-05, "METEOR": 0.18235223533680298, "ROUGE_L": 0.26505276225946617, "CIDEr": 4.180472488875338e-11, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.19047619047619047, "f": 0.2222222222222222, "fn": 17.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a giraffe standing in a grassy field surrounded by trees. The giraffe is looking down at the ground with its long neck stretched out in front of it. The trees in the background are tall and green, with leaves on their branches. The sky is clear and blue."}, "573943": {"image_id": 573943, "Bleu_1": 0.39999999998666674, "Bleu_2": 0.28767798088147595, "Bleu_3": 0.18081247989280658, "Bleu_4": 2.1631187458455554e-05, "METEOR": 0.23161134863335364, "ROUGE_L": 0.36125211505922167, "CIDEr": 0.007886977076817446, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.15384615384615385, "f": 0.21621621621621623, "fn": 22.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.23076923076923078, "f": 0.33333333333333337, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This is an image of a large parking lot with many trucks and cars parked in it. The parking lot is surrounded by buildings and there are people walking around."}, "515355": {"image_id": 515355, "Bleu_1": 0.16326530611911708, "Bleu_2": 0.08247860988253151, "Bleu_3": 5.250430761975165e-07, "Bleu_4": 1.3318543818752488e-09, "METEOR": 0.12581626793982795, "ROUGE_L": 0.20158625247851947, "CIDEr": 1.7819315051281497e-10, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.11538461538461539, "f": 0.11111111111111112, "fn": 23.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This image shows a plate with a doughnut on it. The doughnut is topped with chocolate frosting and sprinkles. There is a fork on the plate, and a white napkin is folded on top of the plate. The background is a white tablecloth with a yellow and orange pattern."}, "559440": {"image_id": 559440, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.19669894811330474, "Bleu_3": 0.11808065064918527, "Bleu_4": 0.07734719974142869, "METEOR": 0.25304101625818876, "ROUGE_L": 0.3242764323685765, "CIDEr": 1.6430192906618817e-08, "SPICE": {"All": {"pr": 0.16, "re": 0.14814814814814814, "f": 0.15384615384615383, "fn": 23.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.25, "f": 0.2727272727272727, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a bathroom with a sink, toilet, and shower. The walls are painted white and there is a green tiled floor. There is a mirror on the wall above the sink and a window with curtains on the opposite wall. The room is clean and well maintained."}, "511647": {"image_id": 511647, "Bleu_1": 0.25806451612486997, "Bleu_2": 0.13008560009537212, "Bleu_3": 0.06557964575018893, "Bleu_4": 8.31502954805806e-06, "METEOR": 0.21412932212000815, "ROUGE_L": 0.19307870858830975, "CIDEr": 7.160207751683388e-15, "SPICE": {"All": {"pr": 0.75, "re": 0.23076923076923078, "f": 0.3529411764705882, "fn": 20.0, "numImages": 1.0, "fp": 2.0, "tp": 6.0}, "Relation": {"pr": 0.5, "re": 0.1, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.2222222222222222, "f": 0.3636363636363636, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.42857142857142855, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image shows a man standing on a balcony with his hands up in the air, looking at a kite flying in the sky. The sky is clear and blue, with a few clouds scattered about. The man is wearing a white shirt and jeans, and has a look of concentration on his face as he watches the kite soar above him."}, "356280": {"image_id": 356280, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.06868028197303624, "Bleu_3": 4.522355034563233e-07, "Bleu_4": 1.1662213550197089e-09, "METEOR": 0.14593698175787725, "ROUGE_L": 0.2334609075997813, "CIDEr": 4.5263359585433096e-10, "SPICE": {"All": {"pr": 0.1935483870967742, "re": 0.24, "f": 0.21428571428571427, "fn": 19.0, "numImages": 1.0, "fp": 25.0, "tp": 6.0}, "Relation": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3125, "re": 0.4166666666666667, "f": 0.35714285714285715, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}}, "caption": "The image shows a large room with tables set up for a meeting or conference. There are people sitting at the tables, some of them talking and others listening to a speaker at the front of the room. The walls are painted white and there are windows on one side of the room."}, "78465": {"image_id": 78465, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.15291943545714587, "Bleu_3": 0.07923964199176128, "Bleu_4": 1.0198056661125237e-05, "METEOR": 0.20288120053636405, "ROUGE_L": 0.19690122659780504, "CIDEr": 4.721827973132205e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.21739130434782608, "f": 0.23255813953488372, "fn": 18.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA white bus is parked on the side of a street in a city. The bus has the words \"City Bus\" written on the side in blue letters. There are people walking on the sidewalk in front of the bus."}, "365511": {"image_id": 365511, "Bleu_1": 0.305555555547068, "Bleu_2": 0.18687063685519775, "Bleu_3": 0.10089455706733778, "Bleu_4": 1.3282270438373226e-05, "METEOR": 0.28657792290601525, "ROUGE_L": 0.2420634920634921, "CIDEr": 9.770865683643148e-05, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.14814814814814814, "f": 0.14545454545454545, "fn": 23.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.2727272727272727, "f": 0.23999999999999996, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a street sign with the words \"Oakland\" written on it. The sign is mounted on a pole next to a tree. The sky is cloudy and there are some clouds in the background."}, "322511": {"image_id": 322511, "Bleu_1": 0.3584905660309719, "Bleu_2": 0.2033821429715532, "Bleu_3": 0.09325779742018382, "Bleu_4": 1.1285514534092683e-05, "METEOR": 0.22438572792721528, "ROUGE_L": 0.226906385616863, "CIDEr": 2.7775048500190537e-11, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.30434782608695654, "f": 0.31818181818181823, "fn": 16.0, "numImages": 1.0, "fp": 14.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows two horses racing down a dirt track, with one horse in the lead and the other following closely behind. The horses are wearing jockey caps and riding on the backs of their respective jockeys. The track is lined with fences and trees, and there are people watching from the stands."}, "477924": {"image_id": 477924, "Bleu_1": 0.35483870966597303, "Bleu_2": 0.21751282250452736, "Bleu_3": 0.11772189470040113, "Bleu_4": 1.5536508417020945e-05, "METEOR": 0.1793001595944871, "ROUGE_L": 0.2775250227479527, "CIDEr": 0.000486840368019825, "SPICE": {"All": {"pr": 0.24, "re": 0.23076923076923078, "f": 0.23529411764705882, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a young girl standing on a snowy slope, wearing a blue and white jacket and holding ski poles. She is smiling and appears to be enjoying the snow."}, "469634": {"image_id": 469634, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.20597146021314577, "Bleu_3": 0.14357835226443494, "Bleu_4": 0.10895869675460172, "METEOR": 0.26261980588989065, "ROUGE_L": 0.28073635765943455, "CIDEr": 1.0682196148580732e-07, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.08333333333333333, "f": 0.1142857142857143, "fn": 22.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.18181818181818182, "f": 0.25000000000000006, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a young man riding a skateboard down a road lined with trees. He is wearing a black shirt and jeans and has his arms outstretched as he jumps off the board. The sky is blue and there are clouds in the background."}, "251343": {"image_id": 251343, "Bleu_1": 0.4210526315678671, "Bleu_2": 0.2822385621600037, "Bleu_3": 0.16417992979299406, "Bleu_4": 1.8857018976734923e-05, "METEOR": 0.29877283451826614, "ROUGE_L": 0.3320373250388802, "CIDEr": 9.955148358596982e-05, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.13636363636363635, "f": 0.1333333333333333, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is a kitchen with white cabinets and a black stove. There is a microwave on the counter and a sink in the corner. The floor is made of wood and there are no windows in the room."}, "49682": {"image_id": 49682, "Bleu_1": 0.7857142856581634, "Bleu_2": 0.6504436355397438, "Bleu_3": 0.5205143345346209, "Bleu_4": 0.4001601601599777, "METEOR": 0.3747557453386353, "ROUGE_L": 0.6240409207161125, "CIDEr": 2.0502456167402285, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.24, "f": 0.30769230769230765, "fn": 19.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.16666666666666666, "f": 0.26666666666666666, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a woman wearing an umbrella and holding a box of chicken."}, "324155": {"image_id": 324155, "Bleu_1": 0.23333333332944448, "Bleu_2": 0.14062009564344036, "Bleu_3": 0.06985898340781152, "Bleu_4": 8.794233288972274e-06, "METEOR": 0.1934758860698904, "ROUGE_L": 0.17058165548098433, "CIDEr": 1.3163703091198444e-16, "SPICE": {"All": {"pr": 0.125, "re": 0.11764705882352941, "f": 0.12121212121212122, "fn": 30.0, "numImages": 1.0, "fp": 28.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This is an image of a person doing a trick on a skateboard in the middle of a city street. The person is wearing a black shirt and pants, and has a white helmet on their head. There are other people in the background watching the skateboarder. The image is taken from a low angle, looking up at the skateboarder."}, "467096": {"image_id": 467096, "Bleu_1": 0.29999999998500004, "Bleu_2": 0.1256561724810606, "Bleu_3": 9.572639770080818e-07, "Bleu_4": 2.680165156210373e-09, "METEOR": 0.33518577267562194, "ROUGE_L": 0.3096446700507614, "CIDEr": 0.12271024213514492, "SPICE": {"All": {"pr": 0.3, "re": 0.10344827586206896, "f": 0.15384615384615385, "fn": 26.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.2727272727272727, "f": 0.37499999999999994, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This is a small dining room with a table and chairs. There is a stuffed bear sitting on the table."}, "91349": {"image_id": 91349, "Bleu_1": 0.26388888888522377, "Bleu_2": 0.2021984026941471, "Bleu_3": 0.15990123338263068, "Bleu_4": 0.12407708601028977, "METEOR": 0.25741003701270593, "ROUGE_L": 0.2770110875206417, "CIDEr": 9.230169482451841e-19, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.12903225806451613, "f": 0.13793103448275862, "fn": 27.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.23076923076923078, "f": 0.27272727272727276, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a group of people standing on a baseball field, watching a man in a wheelchair throw a baseball. The man in the wheelchair is wearing a baseball cap and has a big smile on his face. The people standing around him are all wearing baseball caps and have their arms around each other. The background is a green field with a dirt path leading to the pitcher's mound."}, "32992": {"image_id": 32992, "Bleu_1": 0.23255813952947546, "Bleu_2": 0.1288848155535838, "Bleu_3": 7.399571153427093e-07, "Bleu_4": 1.7839797285693462e-09, "METEOR": 0.19155869951902876, "ROUGE_L": 0.21254355400696864, "CIDEr": 6.636198880136387e-08, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.15, "f": 0.14285714285714282, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "This is a wooden bowl with a cross design on it. The bowl is made of wood and has a cross design on it. It is a decorative piece that can be used for serving food or as a decoration in a room."}, "310227": {"image_id": 310227, "Bleu_1": 0.2909090909038017, "Bleu_2": 0.164121987969432, "Bleu_3": 0.07980300087819454, "Bleu_4": 9.942911665844388e-06, "METEOR": 0.20404289268746145, "ROUGE_L": 0.22008418520745643, "CIDEr": 2.1156591667620492e-10, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.32, "f": 0.3404255319148936, "fn": 17.0, "numImages": 1.0, "fp": 14.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a person lying in bed with their head covered by a pillow. The bed is made of white sheets and has a black blanket on it. There are stuffed animals on the bed, including a teddy bear and a rabbit. The room is dimly lit and there are curtains on the windows."}, "573206": {"image_id": 573206, "Bleu_1": 0.47058823526643606, "Bleu_2": 0.29704426287498314, "Bleu_3": 1.8051655058649962e-06, "Bleu_4": 4.527471870659266e-09, "METEOR": 0.1388904277257737, "ROUGE_L": 0.3283100107642627, "CIDEr": 0.13498629543534452, "SPICE": {"All": {"pr": 0.06451612903225806, "re": 0.08, "f": 0.07142857142857142, "fn": 23.0, "numImages": 1.0, "fp": 29.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "This is an image of a dish of pasta with olives and cheese on a kitchen counter."}, "576939": {"image_id": 576939, "Bleu_1": 0.3947368420948754, "Bleu_2": 0.3098662125759413, "Bleu_3": 0.22014152945079551, "Bleu_4": 0.17389607800310708, "METEOR": 0.2329262488320174, "ROUGE_L": 0.3024079320113314, "CIDEr": 0.00010474414807736687, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.21212121212121213, "f": 0.23728813559322037, "fn": 26.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4666666666666667, "re": 0.4666666666666667, "f": 0.4666666666666667, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 7.0}}, "caption": "This image shows a group of scissors hanging on a wall. The scissors are made of metal and have sharp blades. They are arranged in a row on the wall, with each one labeled with a different name."}, "479213": {"image_id": 479213, "Bleu_1": 0.37142857141795926, "Bleu_2": 0.2560199571978607, "Bleu_3": 0.1583754635438043, "Bleu_4": 0.1055549075428401, "METEOR": 0.31954283670347267, "ROUGE_L": 0.3951417004048583, "CIDEr": 0.00012818557970816635, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.17391304347826086, "f": 0.1904761904761905, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows two women standing next to a cake with a photo on it. One of the women is holding a camera and the other is smiling. They are both wearing wigs and glasses."}, "45094": {"image_id": 45094, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.20957473279408317, "Bleu_3": 0.15305490466093202, "Bleu_4": 0.12235041385584791, "METEOR": 0.2454902988341397, "ROUGE_L": 0.26704190118824267, "CIDEr": 2.0523837710803104e-11, "SPICE": {"All": {"pr": 0.4, "re": 0.2, "f": 0.26666666666666666, "fn": 24.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.08333333333333333, "f": 0.11764705882352941, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.4166666666666667, "f": 0.5263157894736842, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image shows a man and a woman sitting at a table in a restaurant, both holding glasses of wine. The man is wearing a black hat and the woman is wearing a white shirt and black pants. There are other people in the background of the image, also drinking wine."}, "127517": {"image_id": 127517, "Bleu_1": 0.22916666666189242, "Bleu_2": 0.15613914506966814, "Bleu_3": 8.092609555849529e-07, "Bleu_4": 1.8525217352695958e-09, "METEOR": 0.21439060800380239, "ROUGE_L": 0.2582244799225931, "CIDEr": 1.2546788086920074e-08, "SPICE": {"All": {"pr": 0.0625, "re": 0.05, "f": 0.05555555555555556, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image shows a group of surfboards leaning against a wooden fence in a beach setting. The surfboards are all different colors and have different designs on them. Some of the surfboards have stickers or decals on them. The sky is cloudy and there is an umbrella nearby."}, "504732": {"image_id": 504732, "Bleu_1": 0.14705882352797003, "Bleu_2": 0.07631586874846043, "Bleu_3": 0.03876233241386539, "Bleu_4": 4.924913732466204e-06, "METEOR": 0.1575349103619511, "ROUGE_L": 0.14458892049302452, "CIDEr": 2.582725798667885e-47, "SPICE": {"All": {"pr": 0.3103448275862069, "re": 0.36, "f": 0.3333333333333333, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 9.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.5454545454545454, "f": 0.5217391304347826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The woman in the image is wearing a black coat and holding a phone to her ear. She is standing on the sidewalk in front of a group of people who are also wearing costumes. There are bicycles parked on the side of the road.\n\nThe woman is smiling and talking on the phone, while the people around her are laughing and taking pictures. The streetlights are on, casting a warm glow over the scene.\n\nThe image is taken at night, with the city lights reflecting off the pavement. The atmosphere is festive and lively, with people enjoying themselves in the streets."}, "86215": {"image_id": 86215, "Bleu_1": 0.32142857142283165, "Bleu_2": 0.22934123614279892, "Bleu_3": 0.14296528607741424, "Bleu_4": 0.08616958092754766, "METEOR": 0.24185805672016478, "ROUGE_L": 0.25296208530805686, "CIDEr": 8.194085568612322e-12, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.20833333333333334, "f": 0.25641025641025644, "fn": 19.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a dog lying on a bed next to a cat. The dog is looking directly at the camera with its brown eyes, while the cat is looking away from the camera with its green eyes. The background of the image is a messy room with a window open, allowing natural light to enter."}, "82180": {"image_id": 82180, "Bleu_1": 0.6999999998600002, "Bleu_2": 0.5577733509080639, "Bleu_3": 0.33879878553311354, "Bleu_4": 4.854917716006407e-05, "METEOR": 0.33750272502130596, "ROUGE_L": 0.4178082191780822, "CIDEr": 1.454049704265909, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.18181818181818182, "f": 0.15384615384615383, "fn": 18.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "A wooden chair with a stuffed animal sitting on it."}, "253835": {"image_id": 253835, "Bleu_1": 0.2077922077895092, "Bleu_2": 0.1478947733273738, "Bleu_3": 0.09564344584528334, "Bleu_4": 1.0427578811980992e-05, "METEOR": 0.19033530342004756, "ROUGE_L": 0.21134690342139456, "CIDEr": 3.512206681905367e-27, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.375, "f": 0.2857142857142857, "fn": 10.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6666666666666666, "f": 0.4444444444444444, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "A woman is standing on the platform of a train station, looking at a train that is pulling into the station. The train is red and white with black stripes and has the words \"train\" written on the side. The woman is wearing a backpack and has a child in a stroller. There are other people standing on the platform, looking at the train as well. The sky is cloudy and there are trees in the background."}, "91406": {"image_id": 91406, "Bleu_1": 0.4583333333142362, "Bleu_2": 0.3457820373893416, "Bleu_3": 0.1758169434508259, "Bleu_4": 2.2554890371657057e-05, "METEOR": 0.28790821341938594, "ROUGE_L": 0.43660531697341515, "CIDEr": 0.06349027250265277, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.26666666666666666, "f": 0.17777777777777776, "fn": 11.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.2, "f": 0.12500000000000003, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.42857142857142855, "f": 0.3, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This is a group of people standing in a classroom with pizza boxes on a table. They are smiling and looking at the camera."}, "252133": {"image_id": 252133, "Bleu_1": 0.5999999999700001, "Bleu_2": 0.5026246899242421, "Bleu_3": 0.3478928170795551, "Bleu_4": 0.22308576864951288, "METEOR": 0.25433326430473235, "ROUGE_L": 0.4765625, "CIDEr": 0.3899051992593908, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 12.0, "numImages": 1.0, "fp": 24.0, "tp": 9.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.16666666666666666, "f": 0.11764705882352942, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5714285714285714, "f": 0.38095238095238093, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "This is an image of a sign on the side of the road that reads, \"No parking for senior citizens.\""}, "533137": {"image_id": 533137, "Bleu_1": 0.31914893616342244, "Bleu_2": 0.16658955971162087, "Bleu_3": 8.511922922355496e-07, "Bleu_4": 1.9348958476953622e-09, "METEOR": 0.17608804402201098, "ROUGE_L": 0.23297262889879056, "CIDEr": 1.263529003188756e-09, "SPICE": {"All": {"pr": 0.12121212121212122, "re": 0.13793103448275862, "f": 0.12903225806451615, "fn": 25.0, "numImages": 1.0, "fp": 29.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.3076923076923077, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "This image shows a group of people standing at the base of a mountain, looking up at the snow covered peaks. There is a sign in the foreground that reads \"ski resort\". The sky is cloudy and there is a light dusting of snow on the ground."}, "580704": {"image_id": 580704, "Bleu_1": 0.39999999998400004, "Bleu_2": 0.2236067977408484, "Bleu_3": 0.12954303153373917, "Bleu_4": 1.772984226393885e-05, "METEOR": 0.20544931699884972, "ROUGE_L": 0.3715736040609137, "CIDEr": 0.0313825396344425, "SPICE": {"All": {"pr": 0.8333333333333334, "re": 0.20833333333333334, "f": 0.33333333333333337, "fn": 19.0, "numImages": 1.0, "fp": 1.0, "tp": 5.0}, "Relation": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.15384615384615385, "f": 0.2666666666666667, "fn": 11.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A group of motorcyclists ride down a winding road in a park on a sunny day.\""}, "359086": {"image_id": 359086, "Bleu_1": 0.1917808219151811, "Bleu_2": 0.14597595765228583, "Bleu_3": 0.09656250509804915, "Bleu_4": 0.07121793582045176, "METEOR": 0.1730253339450998, "ROUGE_L": 0.2209144409234948, "CIDEr": 3.0859495180769686e-21, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.21739130434782608, "f": 0.18518518518518517, "fn": 18.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5555555555555556, "f": 0.4545454545454546, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "Sure, here is a short caption for the image:\n\nA black motorcycle is parked in front of a large building with a blue and white striped awning. The building has a sign that reads \"Welcome to the Harley Davidson Museum\" in white letters. The motorcycle has a red and white striped seat and a black engine. There is a green lawn in front of the building and a blue sky in the background."}, "581205": {"image_id": 581205, "Bleu_1": 0.2931034482708086, "Bleu_2": 0.22676343971299212, "Bleu_3": 0.1542905565035873, "Bleu_4": 0.090399043801018, "METEOR": 0.20426843752094057, "ROUGE_L": 0.23908174692049275, "CIDEr": 4.5554877656557286e-14, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.22727272727272727, "f": 0.20408163265306123, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.625, "f": 0.5555555555555556, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a table with three plates of food on it. There are two plates with eggs and bacon on them, and one plate with pancakes and maple syrup on it. There is also a cup of coffee on the table. The table is set with a white tablecloth and a vase of flowers in the center."}, "171050": {"image_id": 171050, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.18233123936852927, "Bleu_3": 0.12942808646135376, "Bleu_4": 0.0833140543636033, "METEOR": 0.2373513848558139, "ROUGE_L": 0.2635802469135803, "CIDEr": 9.97165827166201e-09, "SPICE": {"All": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "This is an old fire hydrant on the side of a brick building. It has a large, rusty handle and a small spout on top. The hydrant is surrounded by a brick wall with a large window on the side. There are no other objects in the image."}, "509404": {"image_id": 509404, "Bleu_1": 0.2105263157857803, "Bleu_2": 0.18394180184223394, "Bleu_3": 0.13500589269947996, "Bleu_4": 0.08216107324774444, "METEOR": 0.2060030887427819, "ROUGE_L": 0.20098846787479405, "CIDEr": 4.665117867380897e-14, "SPICE": {"All": {"pr": 0.6153846153846154, "re": 0.25, "f": 0.35555555555555557, "fn": 24.0, "numImages": 1.0, "fp": 5.0, "tp": 8.0}, "Relation": {"pr": 0.25, "re": 0.09090909090909091, "f": 0.13333333333333333, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 9.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4444444444444444, "f": 0.5333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image shows a train traveling down the tracks on the left side of the image, while another train is parked on the right side. The train on the left has a blue and yellow livery, while the train on the right has a red and white livery. There are buildings and trees visible in the background."}, "407083": {"image_id": 407083, "Bleu_1": 0.3220338982996266, "Bleu_2": 0.19714502311481263, "Bleu_3": 0.11089422375095655, "Bleu_4": 0.07024811695227015, "METEOR": 0.26345697853808675, "ROUGE_L": 0.25115800308800823, "CIDEr": 2.0023144153566274e-12, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.21739130434782608, "f": 0.27777777777777773, "fn": 18.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image shows a man sitting in the back of a pickup truck with his dog sitting on the passenger seat. The man is wearing a baseball cap and sunglasses, while the dog is wearing a blue collar and looking up at the man. The truck is parked in front of a house with a tree in the background."}, "214447": {"image_id": 214447, "Bleu_1": 0.30645161289828304, "Bleu_2": 0.1002376868515668, "Bleu_3": 5.511928904968084e-07, "Bleu_4": 1.2979701428228035e-09, "METEOR": 0.18747999706943086, "ROUGE_L": 0.1953041622198506, "CIDEr": 9.062329609750739e-18, "SPICE": {"All": {"pr": 0.03333333333333333, "re": 0.09090909090909091, "f": 0.04878048780487805, "fn": 10.0, "numImages": 1.0, "fp": 29.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.07692307692307693, "re": 0.2, "f": 0.1111111111111111, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}}, "caption": "This is an image of a person snowboarding down a snowy hill. The person is wearing a black and white snowboarding suit and has a helmet on their head. They are holding onto the handlebars of their snowboard and are in mid-air as they jump off a small jump. The background is a snowy forest with trees and snow on the ground."}, "567390": {"image_id": 567390, "Bleu_1": 0.5599999999776001, "Bleu_2": 0.4582575694768719, "Bleu_3": 0.30144232985198327, "Bleu_4": 0.18784407806545977, "METEOR": 0.32439086076137996, "ROUGE_L": 0.5078043704474506, "CIDEr": 0.04240677673091346, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.1, "f": 0.09302325581395349, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "This image shows a plate of food with broccoli, carrots, and rice on it. The plate is on a white plate with a white background."}, "7873": {"image_id": 7873, "Bleu_1": 0.19999999999600004, "Bleu_2": 0.06388765649870325, "Bleu_3": 4.397416072405079e-07, "Bleu_4": 1.1597748989748829e-09, "METEOR": 0.1369749369532927, "ROUGE_L": 0.2108294930875576, "CIDEr": 2.596727957885562e-09, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.2916666666666667, "f": 0.27999999999999997, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "Sure, here is a short caption for the image:\n\nThe woman in the image is smiling and looking at something in her hand. She is wearing a scarf and a shawl, and has a bag slung over her shoulder. The background is a busy street with people walking and shopping."}, "576463": {"image_id": 576463, "Bleu_1": 0.5384615384408284, "Bleu_2": 0.32816506164407266, "Bleu_3": 0.20781065557855458, "Bleu_4": 2.4993029414165317e-05, "METEOR": 0.36304457009800956, "ROUGE_L": 0.5073937153419593, "CIDEr": 0.04828756937532288, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.1, "f": 0.08695652173913043, "fn": 18.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image is a magazine cover featuring a soccer player in blue and white uniform, with the words \"Chelsea FC\" written in white on the front."}, "282680": {"image_id": 282680, "Bleu_1": 0.6249999999609376, "Bleu_2": 0.5400617248324427, "Bleu_3": 0.2751606040561537, "Bleu_4": 3.557982867691925e-05, "METEOR": 0.2918120536013436, "ROUGE_L": 0.49087982832618027, "CIDEr": 0.614524291609022, "SPICE": {"All": {"pr": 0.4, "re": 0.2727272727272727, "f": 0.3243243243243243, "fn": 16.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.8333333333333334, "f": 0.7142857142857143, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "A surfer rides a wave on a lake, with the water and sky in the background."}, "488386": {"image_id": 488386, "Bleu_1": 0.7999999998400004, "Bleu_2": 0.6666666665296299, "Bleu_3": 0.4807498566671996, "Bleu_4": 0.35494810552300854, "METEOR": 0.31743352242512857, "ROUGE_L": 0.6, "CIDEr": 2.0242780589191085, "SPICE": {"All": {"pr": 0.3125, "re": 0.22727272727272727, "f": 0.2631578947368421, "fn": 17.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The cat is sleeping on top of a laptop computer."}, "293002": {"image_id": 293002, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.16968474448956103, "Bleu_3": 0.0888861127479458, "Bleu_4": 1.1510930649036865e-05, "METEOR": 0.22805765903522054, "ROUGE_L": 0.24286662242866625, "CIDEr": 7.870185233827928e-07, "SPICE": {"All": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 1.0, "f": 0.8, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a woman standing on the sidewalk holding an umbrella. The umbrella is pink and has a floral pattern on it. The woman is wearing a blue shirt and black pants. There are buildings in the background with windows and doors."}, "105974": {"image_id": 105974, "Bleu_1": 0.1666666666635803, "Bleu_2": 0.07930515857033198, "Bleu_3": 4.945382002622933e-07, "Bleu_4": 1.240958731067451e-09, "METEOR": 0.17182125119652433, "ROUGE_L": 0.1783625730994152, "CIDEr": 4.7212352561510916e-14, "SPICE": {"All": {"pr": 0.16, "re": 0.19047619047619047, "f": 0.17391304347826086, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a man playing handball in an indoor court. He is wearing a red shirt and white shorts, and has his arms outstretched as he jumps to hit the ball with his hand. The court is made of wood and has lines on the floor to mark the boundaries of the game."}, "274399": {"image_id": 274399, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.0922138891935132, "Bleu_3": 5.655855085604915e-07, "Bleu_4": 1.4082645504822834e-09, "METEOR": 0.19838468542937773, "ROUGE_L": 0.19690122659780504, "CIDEr": 1.473454244719737e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.30434782608695654, "f": 0.27450980392156865, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 7.0}, "Relation": {"pr": 0.1, "re": 0.1111111111111111, "f": 0.10526315789473685, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.5, "f": 0.48000000000000004, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image shows two elephants standing in a jungle clearing, surrounded by trees and foliage. One of the elephants is riding on the back of the other, both with their trunks raised in the air. The scene is peaceful and serene, with the sun shining down on the animals."}, "91267": {"image_id": 91267, "Bleu_1": 0.5199999999792001, "Bleu_2": 0.36055512753167634, "Bleu_3": 0.25690876632139, "Bleu_4": 0.16662053420227918, "METEOR": 0.3201946728162726, "ROUGE_L": 0.4443288241415192, "CIDEr": 0.16855916155692796, "SPICE": {"All": {"pr": 0.16, "re": 0.18181818181818182, "f": 0.1702127659574468, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "This is a living room with black couches, a coffee table, and a television. There is also a bookshelf in the corner of the room."}, "115791": {"image_id": 115791, "Bleu_1": 0.333333333325926, "Bleu_2": 0.23028309323074364, "Bleu_3": 0.15466509142805826, "Bleu_4": 0.09687950349169154, "METEOR": 0.272954092584186, "ROUGE_L": 0.32635903315181036, "CIDEr": 1.5929274376112782e-06, "SPICE": {"All": {"pr": 0.21875, "re": 0.35, "f": 0.2692307692307692, "fn": 13.0, "numImages": 1.0, "fp": 25.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3125, "re": 0.625, "f": 0.4166666666666667, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}}, "caption": "This is an image of a baseball player at the plate, holding a bat and ready to swing. The player is wearing a white jersey with black pants and white cleats. The background is a green field with a dirt infield and a blue sky."}, "135680": {"image_id": 135680, "Bleu_1": 0.6129032257866805, "Bleu_2": 0.4740582061107671, "Bleu_3": 0.3785481486533532, "Bleu_4": 0.27610969151667797, "METEOR": 0.31066726808570516, "ROUGE_L": 0.37621145374449333, "CIDEr": 0.021494910438905897, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.15384615384615385, "f": 0.21052631578947367, "fn": 22.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.375, "f": 0.42857142857142855, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a vase with a red flower in it sitting on a windowsill. The window is covered with lace curtains, and there is a view of the snow outside."}, "197528": {"image_id": 197528, "Bleu_1": 0.339622641503026, "Bleu_2": 0.24244760629354595, "Bleu_3": 0.151215262126857, "Bleu_4": 0.09119147048897473, "METEOR": 0.22904789372596288, "ROUGE_L": 0.27774615822424586, "CIDEr": 7.369244014083765e-11, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.25, "f": 0.24000000000000002, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a gray and white cat sitting on the windowsill of a house. The cat is looking out the window with its eyes closed, seemingly lost in thought. The window is open, allowing the cat to look outside. The background is a clear blue sky with some clouds in the distance."}, "292485": {"image_id": 292485, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.1458649914948234, "Bleu_3": 0.1115377437347146, "Bleu_4": 0.08861775869596061, "METEOR": 0.16526034073147255, "ROUGE_L": 0.2675438596491228, "CIDEr": 1.3261313821765812e-09, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.23809523809523808, "f": 0.2631578947368421, "fn": 16.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "This is an image of a man standing on a snowy slope, holding a ski pole and wearing a red shirt. He is standing in front of a sign that reads \"Ski Race\" in white letters. The background is a mountain range with trees and snow covered slopes."}, "45721": {"image_id": 45721, "Bleu_1": 0.32608695651465036, "Bleu_2": 0.24077170616624616, "Bleu_3": 0.18746034392462774, "Bleu_4": 0.14641826518869364, "METEOR": 0.25423169963377173, "ROUGE_L": 0.32317880794701986, "CIDEr": 1.2361904715001444e-08, "SPICE": {"All": {"pr": 0.12, "re": 0.16666666666666666, "f": 0.13953488372093023, "fn": 15.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a cat sitting on top of a computer keyboard, looking up at the camera. The cat is brown and has a white patch on its forehead. The background is a blurred image of a room with a desk and chair in the foreground."}, "157657": {"image_id": 157657, "Bleu_1": 0.20967741935145687, "Bleu_2": 0.19444969060790948, "Bleu_3": 0.16400374587380936, "Bleu_4": 0.13904962559258344, "METEOR": 0.2470888208727345, "ROUGE_L": 0.2821171634121274, "CIDEr": 2.8342201309309325e-16, "SPICE": {"All": {"pr": 0.08823529411764706, "re": 0.17647058823529413, "f": 0.11764705882352942, "fn": 14.0, "numImages": 1.0, "fp": 31.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.375, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a group of people riding on the back of an elephant through a jungle. The elephant is wearing a saddle and the people are sitting on its back, holding onto the sides. The jungle is filled with trees and plants, and there are other animals in the background, such as monkeys and birds. The sky is clear and blue."}, "494566": {"image_id": 494566, "Bleu_1": 0.1690140845046618, "Bleu_2": 0.12036162814104857, "Bleu_3": 0.08572011741029728, "Bleu_4": 0.055167695122147704, "METEOR": 0.17203516381162498, "ROUGE_L": 0.17436874702239158, "CIDEr": 1.5211622901509276e-24, "SPICE": {"All": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 28.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2, "f": 0.27272727272727276, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "This is an image of a person skiing down a snowy hill. The person is wearing a black and white suit with a red scarf around their neck. They are holding onto a pair of skis with black and yellow bindings. The skis have black and yellow stripes on them. The person is skiing down the hill with their poles in the air. There are trees and snow in the background."}, "46345": {"image_id": 46345, "Bleu_1": 0.17187499999731448, "Bleu_2": 0.1566957926295344, "Bleu_3": 0.14047757681731918, "Bleu_4": 0.12850221368766102, "METEOR": 0.28374838583768164, "ROUGE_L": 0.30561122244488975, "CIDEr": 6.631124463872501e-17, "SPICE": {"All": {"pr": 0.24242424242424243, "re": 0.42105263157894735, "f": 0.3076923076923077, "fn": 11.0, "numImages": 1.0, "fp": 25.0, "tp": 8.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.14285714285714285, "f": 0.10526315789473685, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.7, "f": 0.5833333333333334, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 7.0}}, "caption": "This is a black and white image of a dog sitting on a bench in front of some potted plants. The dog is looking up at the camera with its tongue hanging out of its mouth. The bench is made of wood and has a small table on top of it. There are some potted plants in the background, including a large pink flower."}, "403177": {"image_id": 403177, "Bleu_1": 0.6874999999570314, "Bleu_2": 0.3708099243308351, "Bleu_3": 0.21415335740369643, "Bleu_4": 2.948206012282362e-05, "METEOR": 0.27834380497358935, "ROUGE_L": 0.505524861878453, "CIDEr": 0.43375183485656443, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2413793103448276, "f": 0.28, "fn": 22.0, "numImages": 1.0, "fp": 14.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.75, "re": 0.2727272727272727, "f": 0.39999999999999997, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "This is an image of a chicken sandwich with lettuce, tomato, and cheese on a bun."}, "147721": {"image_id": 147721, "Bleu_1": 0.23333333332944448, "Bleu_2": 0.1886616557167528, "Bleu_3": 0.14531254128144008, "Bleu_4": 0.1127298484678521, "METEOR": 0.21753851667242224, "ROUGE_L": 0.22736954206602766, "CIDEr": 1.5741140743769872e-14, "SPICE": {"All": {"pr": 0.5, "re": 0.15384615384615385, "f": 0.23529411764705882, "fn": 22.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.07692307692307693, "f": 0.13333333333333336, "fn": 12.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.25, "f": 0.36363636363636365, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "The image shows a person surfing on a wave in the ocean. The person is wearing a wetsuit and standing on a surfboard, holding onto the handlebars with one hand and paddling with the other. The water is choppy and there are waves crashing against the shore. In the background, there is a mountain range with trees and houses visible."}, "229111": {"image_id": 229111, "Bleu_1": 0.49805493606340595, "Bleu_2": 0.3015872407051041, "Bleu_3": 2.097493871297004e-06, "Bleu_4": 5.696822650199491e-09, "METEOR": 0.2825207150661588, "ROUGE_L": 0.4803149606299213, "CIDEr": 0.8978163044113213, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.19230769230769232, "f": 0.2272727272727273, "fn": 21.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The boy is holding a white game controller in his hand."}, "327917": {"image_id": 327917, "Bleu_1": 0.39999999998400004, "Bleu_2": 0.1825741858276003, "Bleu_3": 1.1316626169059293e-06, "Bleu_4": 2.8489318276508903e-09, "METEOR": 0.17092823559025488, "ROUGE_L": 0.2571127502634352, "CIDEr": 0.010757527928199683, "SPICE": {"All": {"pr": 0.25, "re": 0.10714285714285714, "f": 0.15, "fn": 25.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "Sure, here is a short caption for the image:\n\n\"A group of people are kite surfing in the ocean with the sky in the background.\""}, "496264": {"image_id": 496264, "Bleu_1": 0.2972972972892623, "Bleu_2": 0.20320258681677345, "Bleu_3": 0.133129245897645, "Bleu_4": 0.09127153924244578, "METEOR": 0.2393321817359333, "ROUGE_L": 0.2627422828427854, "CIDEr": 5.489326672279407e-05, "SPICE": {"All": {"pr": 0.5454545454545454, "re": 0.20689655172413793, "f": 0.3, "fn": 23.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.09090909090909091, "f": 0.16666666666666669, "fn": 10.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.36363636363636365, "f": 0.4705882352941177, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA giraffe stands in front of a rocky outcropping, looking out into the distance. Its long neck and legs are visible as it stands on the rocky terrain."}, "492282": {"image_id": 492282, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.18314741859482844, "Bleu_3": 0.10886194393769152, "Bleu_4": 0.0709193129947971, "METEOR": 0.21497245535945175, "ROUGE_L": 0.24355464293862653, "CIDEr": 5.090965497628127e-12, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.2727272727272727, "f": 0.23529411764705882, "fn": 16.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.8571428571428571, "f": 0.6, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image shows a group of people riding horses down a dirt road. The horses are wearing saddles and bridles, and the riders are wearing cowboy hats and boots. The trees on either side of the road are tall and green, and there is a small stream running through the center of the image."}, "79545": {"image_id": 79545, "Bleu_1": 0.18644067796294173, "Bleu_2": 0.09820123900819437, "Bleu_3": 5.530779693696516e-07, "Bleu_4": 1.318386547657897e-09, "METEOR": 0.1337951714626972, "ROUGE_L": 0.17300056721497448, "CIDEr": 7.56617737420558e-16, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.16, "f": 0.16326530612244897, "fn": 21.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA herd of bison grazes in a grassy meadow next to a river. The bison are standing in a line, looking out at the viewer. The sky is clear and blue, with a few clouds scattered about. The landscape is surrounded by tall, green trees and mountains in the distance."}, "21563": {"image_id": 21563, "Bleu_1": 0.4411764705752596, "Bleu_2": 0.28322059201005423, "Bleu_3": 0.1959176861357509, "Bleu_4": 0.12480006420009673, "METEOR": 0.2605520595974007, "ROUGE_L": 0.38065522620904835, "CIDEr": 0.0006527665995173242, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.13043478260869565, "f": 0.10714285714285714, "fn": 20.0, "numImages": 1.0, "fp": 30.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1875, "re": 0.375, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}}, "caption": "This is an image of a pizza on a plate with a glass of wine on the side. The pizza has cheese and vegetables on it, and there are two forks on the plate."}, "437221": {"image_id": 437221, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.09288407280072536, "Bleu_3": 5.60482607100497e-07, "Bleu_4": 1.3839209880654026e-09, "METEOR": 0.19023006014206734, "ROUGE_L": 0.22584228063680117, "CIDEr": 9.703951218357747e-11, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.10869565217391304, "f": 0.14492753623188406, "fn": 41.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.2777777777777778, "f": 0.33333333333333337, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a person skateboarding on a ramp. The person is wearing a black shirt and pants, and has a black and white skateboard. The ramp is made of concrete and has a metal rail on the side. There are other skateboarders in the background, and the sky is blue."}, "213843": {"image_id": 213843, "Bleu_1": 0.4814814814636489, "Bleu_2": 0.33333333332075027, "Bleu_3": 0.23712622029020833, "Bleu_4": 0.1535259783805314, "METEOR": 0.2662181384736905, "ROUGE_L": 0.4274274274274274, "CIDEr": 0.013013004902851719, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.13043478260869565, "f": 0.12, "fn": 20.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2857142857142857, "f": 0.2105263157894737, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a chocolate cake with white frosting and sprinkles on top. There are also two glasses of wine on the table next to the cake."}, "351127": {"image_id": 351127, "Bleu_1": 0.46428571426913273, "Bleu_2": 0.22712838128148707, "Bleu_3": 0.12565790685020078, "Bleu_4": 1.6784459624551696e-05, "METEOR": 0.19448859509071798, "ROUGE_L": 0.28773584905660377, "CIDEr": 0.0036559989389473753, "SPICE": {"All": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a group of people flying kites on a beach with mountains in the background. The sky is cloudy and there are waves in the water."}, "439897": {"image_id": 439897, "Bleu_1": 0.32142857142283165, "Bleu_2": 0.2756338621637189, "Bleu_3": 0.24141104001529012, "Bleu_4": 0.19977295353080474, "METEOR": 0.31447576458815424, "ROUGE_L": 0.3396436525612472, "CIDEr": 6.657485987481601e-12, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.15789473684210525, "f": 0.19999999999999998, "fn": 16.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a person sitting at a table with a plate of pizza in front of them. The person is wearing a black hoodie and has a slice of pizza on their plate. There are other plates of food on the table, including a salad and some bread. The background is a dark brown color."}, "112093": {"image_id": 112093, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.24253562503152987, "Bleu_3": 0.193123630168691, "Bleu_4": 0.15652411276385142, "METEOR": 0.33181551570169293, "ROUGE_L": 0.3730886850152905, "CIDEr": 1.0198421668022648e-10, "SPICE": {"All": {"pr": 0.08, "re": 0.08, "f": 0.08, "fn": 23.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2, "f": 0.1904761904761905, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "This is an image of a white truck with a sign on the side that reads \"Good Humor Ice Cream.\" The truck is parked on the side of the road in front of a building. There are people walking by on the sidewalk and other cars driving by in the background."}, "10092": {"image_id": 10092, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.17496355305240635, "Bleu_3": 0.10844960613620269, "Bleu_4": 1.2835019116177698e-05, "METEOR": 0.24985719438888648, "ROUGE_L": 0.18944099378881987, "CIDEr": 1.6449893069443278e-09, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.11538461538461539, "f": 0.11320754716981132, "fn": 23.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.16666666666666666, "re": 0.18181818181818182, "f": 0.17391304347826086, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "This is a bedroom with a large bed and a mosquito net hanging from the ceiling. The walls are made of wood and there are windows on either side of the room. There is a table and chairs in the corner of the room and a lamp on the nightstand."}, "452695": {"image_id": 452695, "Bleu_1": 0.378378378368152, "Bleu_2": 0.17757120129627854, "Bleu_3": 9.65811429093868e-07, "Bleu_4": 2.2688173050579472e-09, "METEOR": 0.27469179251038295, "ROUGE_L": 0.39411342426417806, "CIDEr": 0.00010887593740896797, "SPICE": {"All": {"pr": 0.09375, "re": 0.23076923076923078, "f": 0.13333333333333333, "fn": 10.0, "numImages": 1.0, "fp": 29.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.4, "f": 0.21052631578947364, "fn": 3.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "This is a kitchen in a hospital. It has a white refrigerator, stove, and sink. There is also a microwave oven on the counter. The walls are painted white and there are no windows in the room."}, "392511": {"image_id": 392511, "Bleu_1": 0.19565217390879022, "Bleu_2": 0.06593804733812939, "Bleu_3": 4.6231696364506e-07, "Bleu_4": 1.2312259432484024e-09, "METEOR": 0.13707408813906338, "ROUGE_L": 0.20691994572591585, "CIDEr": 6.248389051647422e-10, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.1111111111111111, "f": 0.13043478260869565, "fn": 24.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.125, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.18181818181818182, "f": 0.18181818181818182, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a group of people standing in front of a pool with umbrellas. One person is holding a sign that says \"Green is the new black.\" The people are all wearing swimsuits and sunglasses, and they appear to be enjoying themselves in the sun."}, "577864": {"image_id": 577864, "Bleu_1": 0.7999999999200001, "Bleu_2": 0.5163977794398137, "Bleu_3": 3.2182979483248667e-06, "Bleu_4": 8.307018473418093e-09, "METEOR": 0.18952895878603665, "ROUGE_L": 0.4535315985130111, "CIDEr": 0.7187842517073042, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.25, "f": 0.22641509433962265, "fn": 18.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5, "f": 0.4347826086956522, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "A group of people playing soccer on a sandy beach."}, "259567": {"image_id": 259567, "Bleu_1": 0.20967741935145687, "Bleu_2": 0.1551171918385293, "Bleu_3": 0.10635631722528446, "Bleu_4": 0.07991291338622837, "METEOR": 0.24763331964327684, "ROUGE_L": 0.26040554962646745, "CIDEr": 3.3901000879228572e-12, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.2, "f": 0.17857142857142855, "fn": 20.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.7142857142857143, "f": 0.4761904761904762, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "A man and woman are sitting on a couch with their dogs. The man is holding a remote control and the woman is holding a book. There are several electronic devices on the coffee table in front of them, including a television, a computer, and a stereo. The walls are painted white and there are windows on either side of the room."}, "517945": {"image_id": 517945, "Bleu_1": 0.2166666666630556, "Bleu_2": 0.18179892039425347, "Bleu_3": 0.13160474029391678, "Bleu_4": 1.4141156721980737e-05, "METEOR": 0.2514050852749081, "ROUGE_L": 0.17058165548098433, "CIDEr": 9.067800040986069e-17, "SPICE": {"All": {"pr": 0.5, "re": 0.1935483870967742, "f": 0.27906976744186046, "fn": 25.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.75, "re": 0.375, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.25, "f": 0.3157894736842105, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a baseball game being played on a field with a large crowd of people watching from the stands. The players are wearing uniforms and are standing on the field, ready to hit the ball. The umpire is standing behind home plate, ready to call the next pitch. The crowd is cheering and waving their arms in excitement."}, "384596": {"image_id": 384596, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.10737969231852026, "Bleu_3": 6.052669898452478e-07, "Bleu_4": 1.4440016772249673e-09, "METEOR": 0.15681605651759525, "ROUGE_L": 0.2738496071829405, "CIDEr": 5.305373804684805e-11, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.08695652173913043, "f": 0.1111111111111111, "fn": 21.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.16666666666666666, "f": 0.2105263157894737, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a small child standing in front of a wooden crib with a white sheet on it. The child is wearing a blue shirt and pants, and has a toy in their hand. There is a window in the background with blinds open, and a wooden floor with a rug on it."}, "546674": {"image_id": 546674, "Bleu_1": 0.3255813953412656, "Bleu_2": 0.17609018126098094, "Bleu_3": 0.09110918073501856, "Bleu_4": 1.1726181398583003e-05, "METEOR": 0.246392746701786, "ROUGE_L": 0.30442919525888956, "CIDEr": 3.912375576718376e-06, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.20689655172413793, "f": 0.21818181818181817, "fn": 23.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a wooden table with a vase on it containing a bamboo plant. The table is in front of a window with blinds and a view of the outside. There is a white wall behind the table and a wooden floor."}, "330265": {"image_id": 330265, "Bleu_1": 0.2909090909038017, "Bleu_2": 0.14679516868082104, "Bleu_3": 7.408254355300373e-07, "Bleu_4": 1.6721917553985766e-09, "METEOR": 0.24417049486384146, "ROUGE_L": 0.20666290231507625, "CIDEr": 2.1977401218979462e-12, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 21.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.2222222222222222, "f": 0.3333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "This image shows a bathroom with a toilet, sink, and mirror. The toilet is white and has a seat and lid. The sink is made of marble and has a faucet. The mirror is large and has a frame around it. There are also some toilet paper rolls on the counter next to the sink."}, "296797": {"image_id": 296797, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.1630820182599269, "Bleu_3": 0.08330762903217113, "Bleu_4": 1.0646588104484678e-05, "METEOR": 0.11886025804599078, "ROUGE_L": 0.2293233082706767, "CIDEr": 8.554128291555378e-10, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is an image of a group of people standing on the sidewalk in front of a cable car. They are all wearing umbrellas and looking at the camera. The cable car is in the background, with people standing on the platform and looking out at the city."}, "53315": {"image_id": 53315, "Bleu_1": 0.28571428570918367, "Bleu_2": 0.2496751135684447, "Bleu_3": 0.21820586555137017, "Bleu_4": 0.19246659275695577, "METEOR": 0.32934856793256734, "ROUGE_L": 0.3396436525612472, "CIDEr": 1.5046518714539994e-12, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.2, "f": 0.2631578947368421, "fn": 20.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a young boy standing in front of a birthday cake with Captain America on it. He is smiling and holding a sword in one hand and a shield in the other. There are balloons and streamers hanging from the ceiling and a banner that reads \"Happy Birthday\" in red, white, and blue letters."}, "35105": {"image_id": 35105, "Bleu_1": 0.35294117646366785, "Bleu_2": 0.278652218402176, "Bleu_3": 0.23317016082633985, "Bleu_4": 0.19062810073330191, "METEOR": 0.26852781000173975, "ROUGE_L": 0.361711139347734, "CIDEr": 5.041684730407564e-10, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.16666666666666666, "f": 0.1111111111111111, "fn": 15.0, "numImages": 1.0, "fp": 33.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.07142857142857142, "re": 0.25, "f": 0.11111111111111112, "fn": 3.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.1111111111111111, "re": 0.5, "f": 0.1818181818181818, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Object": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA red fire hydrant sits on the side of the road in front of a small building with a green awning. The building has a sign that reads \"The Green House\" in white letters. The hydrant is surrounded by grass and trees."}, "324135": {"image_id": 324135, "Bleu_1": 0.45454545453168055, "Bleu_2": 0.4128614119096789, "Bleu_3": 0.3207249266409321, "Bleu_4": 0.2396621968029373, "METEOR": 0.35197198975673244, "ROUGE_L": 0.4354032833690221, "CIDEr": 0.011057809329855001, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.23809523809523808, "f": 0.23809523809523808, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a young boy wearing a baseball cap and sunglasses, holding a baseball bat and standing in front of a building. The boy is smiling and looking up at the camera."}, "40011": {"image_id": 40011, "Bleu_1": 0.5128205128073636, "Bleu_2": 0.3485075176696078, "Bleu_3": 0.14861895129487873, "Bleu_4": 1.7377208785097006e-05, "METEOR": 0.2724151893866537, "ROUGE_L": 0.3155949741315595, "CIDEr": 0.0001203298827514555, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.13043478260869565, "f": 0.10169491525423728, "fn": 20.0, "numImages": 1.0, "fp": 33.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.375, "f": 0.26086956521739135, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "A purple train is traveling down the tracks at a slow pace. There are people standing on the platform, looking at the train as it passes by. The sky is clear and blue, with a few clouds scattered about."}, "146448": {"image_id": 146448, "Bleu_1": 0.23255813952947546, "Bleu_2": 0.19687480773490648, "Bleu_3": 0.12365418261033179, "Bleu_4": 1.4744892493104462e-05, "METEOR": 0.2849655983695067, "ROUGE_L": 0.26852531181217903, "CIDEr": 9.746576456889787e-08, "SPICE": {"All": {"pr": 0.4375, "re": 0.2916666666666667, "f": 0.35000000000000003, "fn": 17.0, "numImages": 1.0, "fp": 9.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.375, "f": 0.5454545454545454, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A young boy is skateboarding on a blue skateboard in the park. He is wearing a black shirt and yellow pants, and has a serious expression on his face as he rides the board.\""}, "274593": {"image_id": 274593, "Bleu_1": 0.34146341462581803, "Bleu_2": 0.2065984676302324, "Bleu_3": 0.12983940805705807, "Bleu_4": 1.5492053781230032e-05, "METEOR": 0.27221279699263595, "ROUGE_L": 0.31373989713446, "CIDEr": 9.683060162507392e-06, "SPICE": {"All": {"pr": 0.045454545454545456, "re": 0.037037037037037035, "f": 0.04081632653061224, "fn": 26.0, "numImages": 1.0, "fp": 21.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.09090909090909091, "f": 0.08695652173913043, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "This is an image of a fire hydrant on the side of the road. It is red and has a sign on it that says \"Fire Hydrant\". There are buildings in the background and a few cars parked on the street."}, "524742": {"image_id": 524742, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.16968474448956103, "Bleu_3": 0.12819595791702068, "Bleu_4": 0.10130905165632138, "METEOR": 0.22707556089346545, "ROUGE_L": 0.2576376179079263, "CIDEr": 9.043115548635372e-08, "SPICE": {"All": {"pr": 0.3125, "re": 0.2631578947368421, "f": 0.2857142857142857, "fn": 14.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.2857142857142857, "f": 0.4444444444444445, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a graffiti mural on the side of a yellow train. The mural appears to be a colorful, abstract design with swirling shapes and patterns. The train is parked on the platform, and there are people walking by on the sidewalk."}, "22793": {"image_id": 22793, "Bleu_1": 0.4399999999824001, "Bleu_2": 0.2708012801434743, "Bleu_3": 0.1471830720269309, "Bleu_4": 1.951136832159569e-05, "METEOR": 0.1859038684627429, "ROUGE_L": 0.3096446700507614, "CIDEr": 0.0294231889888485, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.08, "f": 0.1111111111111111, "fn": 23.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.18181818181818182, "f": 0.25000000000000006, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a bathroom with several stalls and sinks. There are several posters on the walls, including one of a woman in a bikini."}, "384616": {"image_id": 384616, "Bleu_1": 0.5416666666440973, "Bleu_2": 0.4603873605140388, "Bleu_3": 0.40704339729190725, "Bleu_4": 0.3366593727525654, "METEOR": 0.4216417272277327, "ROUGE_L": 0.6282771535580524, "CIDEr": 0.29813828220635713, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.19230769230769232, "f": 0.19230769230769232, "fn": 21.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "This is an image of a red fire hydrant in the middle of a dirt road surrounded by trees and mountains in the background."}, "89405": {"image_id": 89405, "Bleu_1": 0.305555555547068, "Bleu_2": 0.18687063685519775, "Bleu_3": 0.10089455706733778, "Bleu_4": 1.3282270438373226e-05, "METEOR": 0.2398161750437787, "ROUGE_L": 0.3454692556634304, "CIDEr": 8.438798737231662e-05, "SPICE": {"All": {"pr": 0.05714285714285714, "re": 0.1, "f": 0.07272727272727272, "fn": 18.0, "numImages": 1.0, "fp": 33.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.2857142857142857, "f": 0.19047619047619047, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "A vase filled with white roses sits on a desk in an office. The desk has a computer and other office supplies on it. There are bookshelves behind the desk and a window in the background."}, "432120": {"image_id": 432120, "Bleu_1": 0.3636363636280992, "Bleu_2": 0.26010243549896195, "Bleu_3": 0.14769184446990152, "Bleu_4": 1.6742542942575295e-05, "METEOR": 0.28873221790241665, "ROUGE_L": 0.2733674775928297, "CIDEr": 6.252127686005062e-07, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.18181818181818182, "f": 0.17391304347826086, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a person sitting in the driver's seat of a car, looking out the side mirror at a dog running alongside the car on the side of the road. The sky is cloudy and the trees are swaying in the wind."}, "6673": {"image_id": 6673, "Bleu_1": 0.3090909090852893, "Bleu_2": 0.22696949467552002, "Bleu_3": 0.12480434418424341, "Bleu_4": 1.3905014336583783e-05, "METEOR": 0.24283085428349743, "ROUGE_L": 0.35260115606936415, "CIDEr": 4.2746710551868593e-10, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.1, "f": 0.08695652173913043, "fn": 18.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a vase with a sunflower in it. The vase is blue and has a white handle. The sunflower is yellow and has a long stem. There are some other flowers in the vase as well, but they are not visible in the image. The background of the image is a brick wall."}, "500492": {"image_id": 500492, "Bleu_1": 0.49999999998437505, "Bleu_2": 0.3810003809884732, "Bleu_3": 0.2684910740226452, "Bleu_4": 0.16073034971813757, "METEOR": 0.3586050064852612, "ROUGE_L": 0.38485804416403785, "CIDEr": 0.006805663346793028, "SPICE": {"All": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 16.0, "numImages": 1.0, "fp": 24.0, "tp": 8.0}, "Relation": {"pr": 0.15384615384615385, "re": 0.2222222222222222, "f": 0.18181818181818185, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.5454545454545454, "f": 0.4999999999999999, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "A glass of beer sits on a wooden table next to a bottle of wine. The walls of the room are made of stone and there is a fireplace in the background."}, "295412": {"image_id": 295412, "Bleu_1": 0.23214285713871177, "Bleu_2": 0.18375590810914594, "Bleu_3": 0.13574263794224228, "Bleu_4": 0.10908086164789181, "METEOR": 0.28326495067370416, "ROUGE_L": 0.2830626450116009, "CIDEr": 5.660704649220911e-13, "SPICE": {"All": {"pr": 0.125, "re": 0.08333333333333333, "f": 0.1, "fn": 22.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "This image shows a man standing next to a wooden boat that he is building. The boat is made of wood and has a flat bottom and a pointed bow. The man is wearing a white shirt and pants and has a tool belt around his waist. The background is a jungle with trees and foliage."}, "564352": {"image_id": 564352, "Bleu_1": 0.23529411764359862, "Bleu_2": 0.177782655281154, "Bleu_3": 0.09857231259143598, "Bleu_4": 0.06195664181750357, "METEOR": 0.2174524724179397, "ROUGE_L": 0.20302396348421453, "CIDEr": 2.815966560195545e-19, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.13793103448275862, "f": 0.13793103448275862, "fn": 25.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a man sitting at a table on the edge of a river, surrounded by tall buildings with windows and balconies. The man is wearing a white shirt and black pants, and he is looking out at the water. There are several boats moored to the riverbank, and people are walking along the sidewalk. The sky is blue and there are trees growing along the riverbank."}, "524621": {"image_id": 524621, "Bleu_1": 0.15942028985276205, "Bleu_2": 0.08386446256690658, "Bleu_3": 0.04717302333721624, "Bleu_4": 6.315159146246178e-06, "METEOR": 0.1418107536769141, "ROUGE_L": 0.1488530990727184, "CIDEr": 3.995178312855268e-22, "SPICE": {"All": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.8333333333333334, "f": 0.7692307692307692, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image shows two giraffes standing in a clearing surrounded by trees. They are both looking up at the sky, with their long necks stretched out in front of them. The sky is blue and cloudy, with a few white clouds scattered across it. The trees are tall and green, with leaves on their branches. The ground is dry and cracked, with some small rocks and twigs scattered around."}, "248793": {"image_id": 248793, "Bleu_1": 0.6249999999739584, "Bleu_2": 0.2855201203479251, "Bleu_3": 0.15474510441967504, "Bleu_4": 2.0495469204345803e-05, "METEOR": 0.18439488319360478, "ROUGE_L": 0.264069264069264, "CIDEr": 0.10655566981789852, "SPICE": {"All": {"pr": 0.2, "re": 0.05, "f": 0.08000000000000002, "fn": 19.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}}, "caption": "This is a photograph of a city street with tall buildings on either side. The sky is cloudy and there are birds flying overhead."}, "488756": {"image_id": 488756, "Bleu_1": 0.18840579709871877, "Bleu_2": 0.12893425037681305, "Bleu_3": 0.07917059898764064, "Bleu_4": 9.31187128341737e-06, "METEOR": 0.16391488986327074, "ROUGE_L": 0.17553956834532372, "CIDEr": 8.737084342153031e-21, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.13333333333333333, "f": 0.0975609756097561, "fn": 13.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a group of people playing in a swimming pool. One person is jumping off the side of the pool and another person is trying to catch the water with their hands. There are several other people in the pool, including one who is swimming and another who is sitting on the edge of the pool. The image is taken from above, looking down at the pool."}, "460783": {"image_id": 460783, "Bleu_1": 0.3584905660309719, "Bleu_2": 0.24909123653704068, "Bleu_3": 0.16946066413438396, "Bleu_4": 0.11811816077501729, "METEOR": 0.21172286877296842, "ROUGE_L": 0.24469914040114613, "CIDEr": 4.344963846756386e-10, "SPICE": {"All": {"pr": 0.1875, "re": 0.25, "f": 0.21428571428571427, "fn": 18.0, "numImages": 1.0, "fp": 26.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a white poodle standing on a kitchen counter next to a bowl of fruit. The poodle has a pink bow tied around its neck and is looking directly at the camera with its big brown eyes. The background of the image is a kitchen with a stove, sink, and cabinets."}, "367872": {"image_id": 367872, "Bleu_1": 0.3888888888780865, "Bleu_2": 0.298142396991572, "Bleu_3": 0.25032637112060246, "Bleu_4": 0.1943263893563523, "METEOR": 0.35319824649882314, "ROUGE_L": 0.39869281045751637, "CIDEr": 0.00011372413496486101, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.15384615384615385, "f": 0.125, "fn": 22.0, "numImages": 1.0, "fp": 34.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.4444444444444444, "f": 0.33333333333333337, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image shows a baseball player swinging a bat at a ball on a field. There are several people in the stands watching the game. The sky is blue and there are trees in the background."}, "398525": {"image_id": 398525, "Bleu_1": 0.4999999999833334, "Bleu_2": 0.3474041668780458, "Bleu_3": 0.20504412815077033, "Bleu_4": 2.3770841795028944e-05, "METEOR": 0.3113453190645873, "ROUGE_L": 0.42582897033158806, "CIDEr": 0.005515570810089241, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.08333333333333333, "f": 0.08888888888888889, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "This is an image of a street with a stop sign on the corner. There are palm trees on either side of the street and cars parked along the sidewalk."}, "548722": {"image_id": 548722, "Bleu_1": 0.222222222217284, "Bleu_2": 0.15891043153736062, "Bleu_3": 0.10550882455558673, "Bleu_4": 0.07272006626035298, "METEOR": 0.1754103665874609, "ROUGE_L": 0.21048999309868874, "CIDEr": 2.19818888606462e-08, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.3157894736842105, "f": 0.33333333333333337, "fn": 13.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5555555555555556, "f": 0.5263157894736842, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a zebra standing in the middle of a dry, barren landscape with no trees or vegetation in sight. The zebra is looking around and appears to be searching for something. The sky is clear and blue, with a few clouds scattered about."}, "82367": {"image_id": 82367, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.17458222992646102, "Bleu_3": 0.10612555247189982, "Bleu_4": 1.2434332373336153e-05, "METEOR": 0.23113978728983306, "ROUGE_L": 0.2507339988256019, "CIDEr": 5.0288862470588255e-12, "SPICE": {"All": {"pr": 0.1590909090909091, "re": 0.30434782608695654, "f": 0.20895522388059704, "fn": 16.0, "numImages": 1.0, "fp": 37.0, "tp": 7.0}, "Relation": {"pr": 0.058823529411764705, "re": 0.1111111111111111, "f": 0.07692307692307691, "fn": 8.0, "numImages": 1.0, "fp": 16.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.8333333333333334, "f": 0.3846153846153846, "fn": 1.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}}, "caption": "The image shows a clock hanging on the wall in a room with white walls and a wooden floor. The clock has a white face with black numbers and hands, and is surrounded by a metal frame. There are plants on the windowsill and a lamp on the table next to the clock."}, "181462": {"image_id": 181462, "Bleu_1": 0.3749999999882814, "Bleu_2": 0.19050019049423667, "Bleu_3": 0.10655075333690474, "Bleu_4": 1.4291173573605973e-05, "METEOR": 0.20505624679469, "ROUGE_L": 0.3060200668896321, "CIDEr": 0.0009305501069142232, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.10526315789473684, "f": 0.09523809523809525, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a dead seal lying on the beach with its body covered in sand. The sky is blue and there are rocks and pebbles scattered around the seal's body."}, "332377": {"image_id": 332377, "Bleu_1": 0.42857142854081637, "Bleu_2": 0.3144854509932483, "Bleu_3": 0.2019946918829379, "Bleu_4": 2.9420957078790955e-05, "METEOR": 0.2303067207651421, "ROUGE_L": 0.3620178041543027, "CIDEr": 0.29507858195606296, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.15384615384615385, "f": 0.21621621621621623, "fn": 22.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.36363636363636365, "f": 0.5000000000000001, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "There are two doughnuts on a table with white paper bags next to them."}, "205504": {"image_id": 205504, "Bleu_1": 0.16363636363338846, "Bleu_2": 0.1100963765106158, "Bleu_3": 0.061153792306271486, "Bleu_4": 8.143605172498537e-06, "METEOR": 0.18081587565426427, "ROUGE_L": 0.18340348767288037, "CIDEr": 6.873272627500107e-14, "SPICE": {"All": {"pr": 0.1875, "re": 0.2608695652173913, "f": 0.21818181818181817, "fn": 17.0, "numImages": 1.0, "fp": 26.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4444444444444444, "f": 0.34782608695652173, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a young man in a red jersey and white pants throwing a baseball on a green field. There are several people watching from the stands, including a woman in a blue shirt and a man in a black shirt. The sky is clear and sunny, with a few clouds in the distance."}, "149014": {"image_id": 149014, "Bleu_1": 0.22222222221869492, "Bleu_2": 0.11973686801593406, "Bleu_3": 0.06171280941219873, "Bleu_4": 7.911223895597908e-06, "METEOR": 0.18090728893952243, "ROUGE_L": 0.22920021470746108, "CIDEr": 8.79230670668425e-18, "SPICE": {"All": {"pr": 0.09375, "re": 0.13043478260869565, "f": 0.10909090909090909, "fn": 20.0, "numImages": 1.0, "fp": 29.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.1, "re": 0.1111111111111111, "f": 0.10526315789473685, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2222222222222222, "f": 0.18181818181818185, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "This image shows a person snowboarding down a snowy slope. The person is wearing a yellow jacket and black pants, and is holding onto the snowboard with both hands. The snowboard is covered in snow and the person is jumping off a small jump. The trees in the background are covered in snow and there are some branches hanging down from the trees."}, "136920": {"image_id": 136920, "Bleu_1": 0.3793103448145066, "Bleu_2": 0.2602575457946004, "Bleu_3": 0.1959693040269019, "Bleu_4": 0.13043606865671686, "METEOR": 0.3365141584364032, "ROUGE_L": 0.4652049571020019, "CIDEr": 0.004058777679678463, "SPICE": {"All": {"pr": 0.25, "re": 0.21739130434782608, "f": 0.23255813953488372, "fn": 18.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5555555555555556, "f": 0.5555555555555556, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "This is a bathroom with white walls, a white sink, and a white toilet. There is a window on the wall with curtains and a rug on the floor."}, "312889": {"image_id": 312889, "Bleu_1": 0.23529411764359862, "Bleu_2": 0.15678956443155245, "Bleu_3": 0.071949888276201, "Bleu_4": 8.700500849599995e-06, "METEOR": 0.22527012167961682, "ROUGE_L": 0.23112313937753717, "CIDEr": 7.156287860340587e-18, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.20833333333333334, "f": 0.2127659574468085, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.45454545454545453, "f": 0.43478260869565216, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The man in the image is standing at a podium, wearing a blue suit and tie. He is looking down at his notes, which are on a table in front of him. There are several chairs set up in front of the podium, and a whiteboard on the wall behind him. The room is dimly lit, with a few windows on the walls that let in natural light."}, "514416": {"image_id": 514416, "Bleu_1": 0.5499999999725, "Bleu_2": 0.4501461750660246, "Bleu_3": 0.3832376860180962, "Bleu_4": 0.2852636438992374, "METEOR": 0.4317237292971595, "ROUGE_L": 0.5674418604651164, "CIDEr": 0.5394398485523814, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.20833333333333334, "f": 0.2127659574468085, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "Sure, here is a short caption for the image:\n\n\"A woman takes a photo of herself in a bathroom mirror.\""}, "424270": {"image_id": 424270, "Bleu_1": 0.22727272726928377, "Bleu_2": 0.1322214713349675, "Bleu_3": 0.06488455529243513, "Bleu_4": 8.114669979563551e-06, "METEOR": 0.2101343538456815, "ROUGE_L": 0.23992133726647003, "CIDEr": 3.730548700103223e-19, "SPICE": {"All": {"pr": 0.16, "re": 0.13793103448275862, "f": 0.14814814814814817, "fn": 25.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a small girl lying on a bed in a room with white walls and a blue ceiling. The bed is covered in blue sheets and has a few pillows on it. There is a window on the wall opposite the bed with a view of the outside. The girl is wearing a blue dress and has her arms stretched out to the side."}, "254407": {"image_id": 254407, "Bleu_1": 0.2545454545408265, "Bleu_2": 0.09709587749880753, "Bleu_3": 5.623955869038741e-07, "Bleu_4": 1.359973957997801e-09, "METEOR": 0.1550301509492598, "ROUGE_L": 0.18340348767288037, "CIDEr": 2.6821680076241446e-13, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.2857142857142857, "f": 0.2105263157894737, "fn": 15.0, "numImages": 1.0, "fp": 30.0, "tp": 6.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.1111111111111111, "f": 0.09523809523809525, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.29411764705882354, "re": 0.625, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}}, "caption": "The image shows a train traveling down the tracks at high speed. The train is painted in blue and green colors and has a large engine on the front. There are people standing on the platform watching the train go by. The train is moving quickly and appears to be traveling through a busy city."}, "146601": {"image_id": 146601, "Bleu_1": 0.2207792207763535, "Bleu_2": 0.14260058986250168, "Bleu_3": 0.06472327137862159, "Bleu_4": 7.78014005752719e-06, "METEOR": 0.14468442407877888, "ROUGE_L": 0.15769065058164586, "CIDEr": 4.41098658081938e-28, "SPICE": {"All": {"pr": 0.375, "re": 0.2222222222222222, "f": 0.27906976744186046, "fn": 21.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.16666666666666666, "f": 0.2105263157894737, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "This is an image of a donut machine in a bakery. The machine has a conveyor belt that moves the donuts through it, and there are several trays on the conveyor belt that hold the donuts. The machine has a large window on the front that allows you to see inside and watch the donuts being made. There are also several buttons and levers on the front of the machine that control the operation of the machine."}, "357109": {"image_id": 357109, "Bleu_1": 0.4583333333142362, "Bleu_2": 0.3992747047353472, "Bleu_3": 0.2790920009876744, "Bleu_4": 0.17937244103128644, "METEOR": 0.3067871495520835, "ROUGE_L": 0.38125000000000003, "CIDEr": 0.046585991727488715, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.047619047619047616, "f": 0.060606060606060615, "fn": 20.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "Sure, here is a short caption for the image:\n\n\"A skateboarder performing a trick on a ramp in front of a crowd of people.\""}, "168175": {"image_id": 168175, "Bleu_1": 0.37499999998437505, "Bleu_2": 0.12768847960837637, "Bleu_3": 9.049548604494648e-07, "Bleu_4": 2.437335780312719e-09, "METEOR": 0.19783193862231085, "ROUGE_L": 0.30622489959839355, "CIDEr": 0.03753131124125162, "SPICE": {"All": {"pr": 0.25, "re": 0.19047619047619047, "f": 0.2162162162162162, "fn": 17.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.375, "f": 0.42857142857142855, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "This is a table set with food on it, including sandwiches, meat, and drinks. There are also some plates and utensils on the table."}, "214966": {"image_id": 214966, "Bleu_1": 0.49999999998684214, "Bleu_2": 0.4191368221312758, "Bleu_3": 0.33923426009259433, "Bleu_4": 0.2732752307483863, "METEOR": 0.42456974517763385, "ROUGE_L": 0.45319465081723626, "CIDEr": 0.00041196282377987194, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.1, "f": 0.12765957446808512, "fn": 27.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.08333333333333333, "f": 0.1111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.16666666666666666, "f": 0.1904761904761905, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a man standing on a tennis court at sunset. He is holding a tennis racket and looking down at the court. The sun is setting in the background, casting a warm glow over the scene."}, "261487": {"image_id": 261487, "Bleu_1": 0.31818181817458685, "Bleu_2": 0.12165177488782297, "Bleu_3": 7.063108368191116e-07, "Bleu_4": 1.712185985760624e-09, "METEOR": 0.21257856767520592, "ROUGE_L": 0.23890339425587467, "CIDEr": 1.5648811650107734e-06, "SPICE": {"All": {"pr": 0.375, "re": 0.125, "f": 0.1875, "fn": 21.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.09090909090909091, "f": 0.15384615384615385, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image shows a group of people playing tennis on a court. They are all wearing tennis shoes and holding rackets. One person is hitting a ball with their racket while the others watch. There are several people in the background watching the game."}, "246626": {"image_id": 246626, "Bleu_1": 0.34482758619500603, "Bleu_2": 0.22194838080144763, "Bleu_3": 0.1539536764846181, "Bleu_4": 0.10884267615297269, "METEOR": 0.232733712354962, "ROUGE_L": 0.34186437511675694, "CIDEr": 0.009255683615628077, "SPICE": {"All": {"pr": 0.25, "re": 0.16, "f": 0.19512195121951217, "fn": 21.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.3076923076923077, "f": 0.4, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "A person is holding a cell phone in their hand and looking at it. There are several other electronic devices on the desk, including a laptop and a printer."}, "987": {"image_id": 987, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.26967994497923586, "Bleu_3": 0.17183700724794354, "Bleu_4": 0.10483956314820705, "METEOR": 0.20730105035094942, "ROUGE_L": 0.403003003003003, "CIDEr": 1.1614630638619991e-06, "SPICE": {"All": {"pr": 0.22580645161290322, "re": 0.28, "f": 0.25, "fn": 18.0, "numImages": 1.0, "fp": 24.0, "tp": 7.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.08333333333333333, "f": 0.08, "fn": 11.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.5555555555555556, "f": 0.43478260869565216, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "This is a kitchen with a stove, refrigerator, and sink. The stove has a pot on it and the refrigerator has a carton of milk in it. The sink has a sponge and a dishrag in it. There are also some utensils on the counter."}}}