{"overall": {"Bleu_1": 0.23553162853265744, "Bleu_2": 0.1458269849954084, "Bleu_3": 0.08665424871474653, "Bleu_4": 0.05038045118645297, "METEOR": 0.19151802122907727, "ROUGE_L": 0.2204264049234902, "CIDEr": 2.1102488294998235e-10, "SPICE": 0.1847215974048156}, "imgToEval": {"448320": {"image_id": 448320, "Bleu_1": 0.2419354838670656, "Bleu_2": 0.17812704394707876, "Bleu_3": 0.10188560350196289, "Bleu_4": 0.06506862264259712, "METEOR": 0.2203730447792053, "ROUGE_L": 0.2791660613104751, "CIDEr": 1.1427644814069518e-14, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.2692307692307692, "f": 0.2641509433962264, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.6666666666666666, "f": 0.5454545454545455, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image is a bathroom with a sink, toilet, and shower. The sink is made of wood and has a large bowl for washing hands. The toilet is located on the opposite side of the room and has a seat and handle. The shower is located in the corner of the room and has a curtain for privacy. There is also a"}, "373713": {"image_id": 373713, "Bleu_1": 0.21874999999658204, "Bleu_2": 0.16666666666404187, "Bleu_3": 0.11035932143591104, "Bleu_4": 0.08147639524124843, "METEOR": 0.1857604241197933, "ROUGE_L": 0.1840305711987128, "CIDEr": 5.570113017276945e-18, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.12, "f": 0.11111111111111112, "fn": 22.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2222222222222222, "f": 0.18181818181818185, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a group of people sitting around a table in a conference room. They are all wearing casual clothing and are engaged in a discussion. One person is standing in front of the table, holding a laptop, while the others are seated and looking at him. The background of the image is a white wall with a large screen displaying a presentation."}, "117337": {"image_id": 117337, "Bleu_1": 0.17910447760926712, "Bleu_2": 0.12760182301581513, "Bleu_3": 0.09091604859111013, "Bleu_4": 0.05853766845419571, "METEOR": 0.16885220165779988, "ROUGE_L": 0.2061805890873974, "CIDEr": 1.8339508898590756e-18, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.18181818181818182, "f": 0.16326530612244897, "fn": 18.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This is a collage of images that show different shades of orange and blue. The images are arranged in a collage style, with different shapes and sizes of orange and blue objects in the foreground and background. The images are arranged in a collage style, with different shapes and sizes of orange and blue objects in the foreground and background. The images are arranged in a collage"}, "265472": {"image_id": 265472, "Bleu_1": 0.18333333333027782, "Bleu_2": 0.11148712271224703, "Bleu_3": 0.075396376103155, "Bleu_4": 0.052365365625869915, "METEOR": 0.2033767055330497, "ROUGE_L": 0.2325708061002179, "CIDEr": 4.851830140488478e-16, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.12903225806451613, "f": 0.1509433962264151, "fn": 27.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a plate with a breakfast dish made of bacon, eggs, and bananas. The bacon is cooked and crispy, while the eggs are over easy and the bananas are sliced and placed on top of the bacon. There is a side of toast on the plate as well. The overall presentation is simple and straightforward, with a focus"}, "285258": {"image_id": 285258, "Bleu_1": 0.24999999999632352, "Bleu_2": 0.14962640041392813, "Bleu_3": 0.08786869413347967, "Bleu_4": 1.0107582386846654e-05, "METEOR": 0.1841520418259455, "ROUGE_L": 0.17766990291262133, "CIDEr": 3.255608189429154e-21, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.21428571428571427, "f": 0.23999999999999996, "fn": 22.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a group of dogs playing in a fenced area. There are five dogs in the image, all of them are small to medium sized and have different colored fur. They are all standing on their hind legs and looking at each other. One of the dogs is wearing a collar and tag. The background of the image is a green grassy area with some trees"}, "96241": {"image_id": 96241, "Bleu_1": 0.28070175438104034, "Bleu_2": 0.1415984650784514, "Bleu_3": 0.07143616536435347, "Bleu_4": 9.06442292469654e-06, "METEOR": 0.21928449736302974, "ROUGE_L": 0.23448654585392636, "CIDEr": 2.0044154564439076e-13, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.2, "f": 0.12500000000000003, "fn": 12.0, "numImages": 1.0, "fp": 30.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.125, "f": 0.10526315789473685, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a group of people standing next to a train that is parked on the tracks. The train is black and has a number 8 painted on the side. There are people standing on both sides of the train, looking at it. The background is a rural area with trees and buildings in the distance."}, "527529": {"image_id": 527529, "Bleu_1": 0.2340425531865098, "Bleu_2": 0.10087498788996685, "Bleu_3": 0.06092349727774221, "Bleu_4": 8.466919880732135e-06, "METEOR": 0.17595075114998024, "ROUGE_L": 0.20847573479152426, "CIDEr": 2.4330220638748507e-09, "SPICE": {"All": {"pr": 0.3448275862068966, "re": 0.35714285714285715, "f": 0.3508771929824561, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 10.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5333333333333333, "re": 0.6153846153846154, "f": 0.5714285714285715, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 8.0}}, "caption": "The image shows a white cat sitting on top of a black bag that is hanging from the handle of a door. The cat is looking up at the camera with its eyes. There are several other bags and boxes on the floor next to the door."}, "18014": {"image_id": 18014, "Bleu_1": 0.3599999999928, "Bleu_2": 0.2099562636628876, "Bleu_3": 0.09720131594020677, "Bleu_4": 1.1823053204528565e-05, "METEOR": 0.22400411954638672, "ROUGE_L": 0.2692307692307692, "CIDEr": 9.72618572114481e-11, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.21739130434782608, "f": 0.19607843137254902, "fn": 18.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.4444444444444444, "f": 0.33333333333333337, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image is a pizza box with a slice of pizza inside. The pizza has a crust and cheese on top. There are also some vegetables such as bell peppers, onions, and tomatoes on the pizza. The box is blue and has a logo of a pizza place on it."}, "497348": {"image_id": 497348, "Bleu_1": 0.18840579709871877, "Bleu_2": 0.07444022416281564, "Bleu_3": 4.356925968476669e-07, "Bleu_4": 1.0580328490271384e-09, "METEOR": 0.1315814665542179, "ROUGE_L": 0.16968011126564672, "CIDEr": 2.297743380589918e-20, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.14285714285714285, "f": 0.14814814814814817, "fn": 24.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.08333333333333333, "f": 0.1, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a residential street with a few houses on either side. The houses are small and made of wood, with white trim and red roofs. There is a small tree in the front yard of one of the houses, and a car parked on the side of the road. The sky is clear and blue, with some clouds in the distance. The grass is green and well"}, "413404": {"image_id": 413404, "Bleu_1": 0.21212121211799817, "Bleu_2": 0.1399300524541518, "Bleu_3": 0.0848966731474613, "Bleu_4": 9.927339321042857e-06, "METEOR": 0.19069363629328312, "ROUGE_L": 0.2150050352467271, "CIDEr": 5.884649825723529e-19, "SPICE": {"All": {"pr": 0.08571428571428572, "re": 0.13043478260869565, "f": 0.10344827586206898, "fn": 20.0, "numImages": 1.0, "fp": 32.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.42857142857142855, "f": 0.27272727272727276, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "The image shows a park with several benches and trees. There are people walking on the sidewalks and some are sitting on the benches. The park has a paved path that leads to a building in the background. The building appears to be a restaurant or cafe. There are cars parked on the street in front of the building. The sky is cloudy and there is"}, "530624": {"image_id": 530624, "Bleu_1": 0.1969696969667126, "Bleu_2": 0.12309149097745338, "Bleu_3": 0.06186220039404225, "Bleu_4": 7.829497418405435e-06, "METEOR": 0.20816459438154838, "ROUGE_L": 0.21243781094527364, "CIDEr": 1.1633242785672224e-19, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.19047619047619047, "f": 0.1818181818181818, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a brown and white dog lying under a floral patterned blanket on a bed. The dog is curled up and appears to be sleeping. The bed is covered with a floral patterned quilt and there are pillows on either side of the dog. The room appears to be a bedroom with a window on the left side of the image and a door"}, "43448": {"image_id": 43448, "Bleu_1": 0.3134328358162174, "Bleu_2": 0.20673858190240743, "Bleu_3": 0.13803733525913842, "Bleu_4": 0.09521599948403056, "METEOR": 0.2192489434007332, "ROUGE_L": 0.2561829211385907, "CIDEr": 1.8023118049219743e-12, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.2857142857142857, "f": 0.18181818181818182, "fn": 10.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 1.0, "f": 0.18181818181818182, "fn": 0.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows two elephants standing on a rocky beach with trees in the background. The elephants are brown and have large ears and tusks. They are standing next to each other and appear to be looking at something in the distance. The sky is blue and there are clouds in the background. The image is taken from a low angle, giving the impression of being on"}}}