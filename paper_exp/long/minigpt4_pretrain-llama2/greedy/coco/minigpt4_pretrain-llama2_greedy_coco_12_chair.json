{"overall": {"Bleu_1": 0.23146944083194868, "Bleu_2": 0.14205968890298631, "Bleu_3": 0.08540915541296484, "Bleu_4": 0.049388613787937456, "METEOR": 0.18877004233347452, "ROUGE_L": 0.2251216009330006, "CIDEr": 6.266918243924357e-05, "SPICE": 0.16403777307434367}, "imgToEval": {"448320": {"image_id": 448320, "Bleu_1": 0.26984126983698664, "Bleu_2": 0.19791540342072636, "Bleu_3": 0.12442764186588164, "Bleu_4": 0.07527483986429064, "METEOR": 0.2306308737340538, "ROUGE_L": 0.2785388127853881, "CIDEr": 5.9199380381708975e-15, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.15384615384615385, "f": 0.186046511627907, "fn": 22.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image is a bathroom with a sink, toilet, and mirror. The sink is made of wood and has a large bowl for washing hands. The toilet is a standard white porcelain toilet with a seat and lid. The mirror is mounted on the wall above the sink and has a light fixture above it. There are no other objects in the room."}, "373713": {"image_id": 373713, "Bleu_1": 0.18987341771911553, "Bleu_2": 0.13053705260491785, "Bleu_3": 0.08723673003630932, "Bleu_4": 0.06465150431138969, "METEOR": 0.14776056032583545, "ROUGE_L": 0.15919965202261854, "CIDEr": 5.39159682030297e-29, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.16, "f": 0.13559322033898305, "fn": 21.0, "numImages": 1.0, "fp": 30.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3333333333333333, "f": 0.27272727272727276, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a group of people sitting around a table in a conference room. They are all wearing casual clothing and are engaged in a discussion. One person is standing at the front of the room, presenting something on a laptop. There is a whiteboard on the wall behind them with the words \"stability\" written on it in black marker. The room appears to be well lit and there are several windows on the walls, providing natural light."}, "117337": {"image_id": 117337, "Bleu_1": 0.19101123595290997, "Bleu_2": 0.12326425105029695, "Bleu_3": 0.08061677641355205, "Bleu_4": 0.04968147238851424, "METEOR": 0.14059363160962668, "ROUGE_L": 0.20011664358095793, "CIDEr": 6.1760422952554e-35, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.18181818181818182, "f": 0.16326530612244897, "fn": 18.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.21428571428571427, "re": 0.42857142857142855, "f": 0.2857142857142857, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "This is a collage of images that show different shades of orange and blue. The images are arranged in a circular pattern, with each one overlapping the next. There are several different objects in the collage, including a vase, a book, a lamp, and a painting. The objects are arranged in a random pattern, with some of them facing towards the center of the collage and others facing away from it. The overall effect is one of chaos and disorder, with the objects seeming to clash with each other."}, "265472": {"image_id": 265472, "Bleu_1": 0.13888888888695988, "Bleu_2": 0.088457482071142, "Bleu_3": 0.060692314637901236, "Bleu_4": 0.04242657785073324, "METEOR": 0.17852164844554144, "ROUGE_L": 0.17058165548098433, "CIDEr": 3.021140692087448e-24, "SPICE": {"All": {"pr": 0.1282051282051282, "re": 0.16129032258064516, "f": 0.14285714285714285, "fn": 26.0, "numImages": 1.0, "fp": 34.0, "tp": 5.0}, "Relation": {"pr": 0.07142857142857142, "re": 0.1111111111111111, "f": 0.08695652173913043, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.4, "f": 0.2857142857142857, "fn": 6.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}}, "caption": "The image shows a plate with a breakfast dish consisting of bacon, eggs, and bananas. The bacon is cooked and crispy, while the eggs are fried and fluffy. The bananas are sliced and placed on top of the eggs. The plate is surrounded by a white tablecloth, and there is a fork and knife on the side. The overall presentation is simple yet appetizing, making it look like a great breakfast option."}, "285258": {"image_id": 285258, "Bleu_1": 0.19148936170009054, "Bleu_2": 0.12834408111331008, "Bleu_3": 0.07101192505975379, "Bleu_4": 7.920235890307171e-06, "METEOR": 0.15018023043386342, "ROUGE_L": 0.13505535055350554, "CIDEr": 3.96188905196268e-43, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.17857142857142858, "f": 0.17241379310344826, "fn": 23.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a group of dogs playing in a grassy area. There are five dogs in the image, all different breeds and sizes. They are all standing on their hind legs and looking at each other. One dog is lying down on its side, with its front paws up in the air. Another dog is sitting on its haunches, with its back legs stretched out behind it. The other three dogs are standing upright, with their tails wagging. The background of the image is a green field with some trees in the distance."}, "96241": {"image_id": 96241, "Bleu_1": 0.23529411764359862, "Bleu_2": 0.1026428638838207, "Bleu_3": 0.05424643415537024, "Bleu_4": 7.039633631433768e-06, "METEOR": 0.18968055638430167, "ROUGE_L": 0.2037213740458015, "CIDEr": 4.0338834486780595e-20, "SPICE": {"All": {"pr": 0.06382978723404255, "re": 0.2, "f": 0.0967741935483871, "fn": 12.0, "numImages": 1.0, "fp": 44.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 22.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.13333333333333333, "re": 0.5, "f": 0.2105263157894737, "fn": 2.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}}, "caption": "The image shows a group of people standing next to a train that is parked on the tracks. The train is black and has a number 8 painted on the side. There are people standing on both sides of the train, looking at it. Some of them are wearing hats and coats, while others are dressed in casual clothing. The background is made up of trees and buildings."}, "527529": {"image_id": 527529, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.11429089766174176, "Bleu_3": 0.06350643060633274, "Bleu_4": 8.460008059351496e-06, "METEOR": 0.21920735697586347, "ROUGE_L": 0.18908865468071917, "CIDEr": 3.5549235505281403e-12, "SPICE": {"All": {"pr": 0.1891891891891892, "re": 0.25, "f": 0.2153846153846154, "fn": 21.0, "numImages": 1.0, "fp": 30.0, "tp": 7.0}, "Relation": {"pr": 0.07142857142857142, "re": 0.09090909090909091, "f": 0.08, "fn": 10.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.35294117647058826, "re": 0.46153846153846156, "f": 0.4000000000000001, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}}, "caption": "The image shows a white cat sitting on top of a black bag that is hanging from the handle of a door. The cat appears to be looking at something on the ground in front of it. There are several other bags and boxes stacked on top of each other in the background."}, "18014": {"image_id": 18014, "Bleu_1": 0.46874999998535166, "Bleu_2": 0.2749633406563063, "Bleu_3": 0.13608474551784824, "Bleu_4": 1.7169497492020694e-05, "METEOR": 0.26473459780376934, "ROUGE_L": 0.36810344827586206, "CIDEr": 0.0007038185326501091, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.21739130434782608, "f": 0.19999999999999998, "fn": 18.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image is a pizza box with a slice of pizza inside. The pizza has cheese, vegetables, and meat on it. There are also some crumbs on the bottom of the box."}, "497348": {"image_id": 497348, "Bleu_1": 0.34210526314889206, "Bleu_2": 0.16654808488508724, "Bleu_3": 0.09167669081722231, "Bleu_4": 1.2180838504699395e-05, "METEOR": 0.19895672634208866, "ROUGE_L": 0.22659732540861813, "CIDEr": 4.821146864440416e-05, "SPICE": {"All": {"pr": 0.1875, "re": 0.21428571428571427, "f": 0.19999999999999998, "fn": 22.0, "numImages": 1.0, "fp": 26.0, "tp": 6.0}, "Relation": {"pr": 0.1, "re": 0.08333333333333333, "f": 0.0909090909090909, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5, "f": 0.4347826086956522, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a road with no traffic on it. There are trees on both sides of the road and a few houses in the distance. The sky is clear and blue, with some clouds in the distance."}, "413404": {"image_id": 413404, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.1852396434051399, "Bleu_3": 0.11113289333084049, "Bleu_4": 1.2936981168128564e-05, "METEOR": 0.23483508909318063, "ROUGE_L": 0.2897862232779097, "CIDEr": 6.676947413299401e-11, "SPICE": {"All": {"pr": 0.1, "re": 0.08695652173913043, "f": 0.09302325581395349, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a park with several benches and trees. There are people walking on the sidewalk and in the background, there is a building with windows and a roof. The sky is cloudy and there are some clouds in the background. The overall mood of the image is peaceful and serene."}, "530624": {"image_id": 530624, "Bleu_1": 0.1969696969667126, "Bleu_2": 0.07784989441496369, "Bleu_3": 4.55804589653711e-07, "Bleu_4": 1.1072581435674101e-09, "METEOR": 0.18363257447658998, "ROUGE_L": 0.18208955223880596, "CIDEr": 8.689038048541177e-20, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.23809523809523808, "f": 0.23809523809523808, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a brown and white dog lying under a floral patterned bed sheet. The dog is curled up and appears to be sleeping. The bed sheet is folded over the dog, creating a cozy and comfortable space for it to rest. The background of the image is a messy room with a mix of colors and patterns, including floral wallpaper and a blue blanket."}, "43448": {"image_id": 43448, "Bleu_1": 0.3015873015825145, "Bleu_2": 0.1972675607547993, "Bleu_3": 0.1366513212357007, "Bleu_4": 0.096035115413259, "METEOR": 0.2141482918157374, "ROUGE_L": 0.298580518844836, "CIDEr": 1.1764609189075834e-10, "SPICE": {"All": {"pr": 0.08823529411764706, "re": 0.21428571428571427, "f": 0.125, "fn": 11.0, "numImages": 1.0, "fp": 31.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.07142857142857142, "re": 1.0, "f": 0.13333333333333333, "fn": 0.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows two elephants standing on a rocky beach with trees in the background. The elephants are brown and have large ears and tusks. They are standing next to each other, with one of them holding a small rock in its trunk. The image is taken from a bird's eye view, giving a clear view of the landscape and the elephants."}}}