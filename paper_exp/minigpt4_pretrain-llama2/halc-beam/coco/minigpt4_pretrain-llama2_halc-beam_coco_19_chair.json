{"overall": {"Bleu_1": 0.2442183163735021, "Bleu_2": 0.16542469354905814, "Bleu_3": 0.11231472799108677, "Bleu_4": 0.0766897894184965, "METEOR": 0.216300328454655, "ROUGE_L": 0.24639124087886832, "CIDEr": 2.3322759234016093e-06, "SPICE": 0.1893850177987549}, "imgToEval": {"281533": {"image_id": 281533, "Bleu_1": 0.23188405796765385, "Bleu_2": 0.17518714873957753, "Bleu_3": 0.12236669370684002, "Bleu_4": 0.09553043363350305, "METEOR": 0.2517724591441613, "ROUGE_L": 0.23816495851634942, "CIDEr": 1.991940966024964e-19, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.19230769230769232, "f": 0.2222222222222222, "fn": 21.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a small brown dog sitting in front of a television. The dog is looking up at the television with its ears perked up and tail wagging. The television is showing a nature documentary with a herd of wild animals running across the screen. There are plants in pots on the floor and a wooden table in the background. The walls are painted white and there are"}, "385320": {"image_id": 385320, "Bleu_1": 0.23333333332944448, "Bleu_2": 0.1886616557167528, "Bleu_3": 0.14531254128144008, "Bleu_4": 0.1127298484678521, "METEOR": 0.24672788289359304, "ROUGE_L": 0.25258799171842644, "CIDEr": 6.306130509021672e-15, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.12, "f": 0.11111111111111112, "fn": 22.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2222222222222222, "f": 0.18181818181818185, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a young girl sitting on the floor, holding a toothbrush in her mouth. She is wearing a striped shirt and white shorts. The room appears to be a living room with a couch, coffee table, and chairs. There are several toys and books scattered around the room. The girl is smiling and looking directly at the camera."}, "448320": {"image_id": 448320, "Bleu_1": 0.26984126983698664, "Bleu_2": 0.21880371112612368, "Bleu_3": 0.15773080227353056, "Bleu_4": 0.08992896013675374, "METEOR": 0.24163851866470298, "ROUGE_L": 0.3027295285359801, "CIDEr": 4.785750518609672e-15, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.18181818181818182, "f": 0.16326530612244897, "fn": 18.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image is a bathroom with a sink, toilet, and a mirror on the wall. The sink is made of white porcelain and has a large bowl shape. The toilet is a standard size and has a seat and lid. The mirror is framed in wood and has a large round frame. There is a light fixture above the sink and a window"}, "373713": {"image_id": 373713, "Bleu_1": 0.21874999999658204, "Bleu_2": 0.16666666666404187, "Bleu_3": 0.11035932143591104, "Bleu_4": 0.08147639524124843, "METEOR": 0.1857604241197933, "ROUGE_L": 0.1840305711987128, "CIDEr": 5.420563983286787e-18, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.12903225806451613, "f": 0.1509433962264151, "fn": 27.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a group of people sitting around a table in a conference room. They are all wearing casual clothing and are engaged in a discussion. One person is standing in front of the table, holding a laptop, while the others are seated and looking at him. The background of the image is a white wall with a large screen displaying a presentation."}, "117337": {"image_id": 117337, "Bleu_1": 0.17910447760926712, "Bleu_2": 0.12760182301581513, "Bleu_3": 0.09091604859111013, "Bleu_4": 0.05853766845419571, "METEOR": 0.16885220165779988, "ROUGE_L": 0.2061805890873974, "CIDEr": 1.746081552826688e-18, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.25, "f": 0.2545454545454545, "fn": 21.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.38461538461538464, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "This is a collage of images that show different shades of orange and blue. The images are arranged in a collage style, with different shapes and sizes of orange and blue objects in the foreground and background. The images are arranged in a collage style, with different shapes and sizes of orange and blue objects in the foreground and background. The images are arranged in a collage"}, "265472": {"image_id": 265472, "Bleu_1": 0.18181818181487608, "Bleu_2": 0.1297498240245396, "Bleu_3": 0.068230605987166, "Bleu_4": 8.840637545603441e-06, "METEOR": 0.2071695242646167, "ROUGE_L": 0.24956165984804207, "CIDEr": 2.965053578978717e-13, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.17857142857142858, "f": 0.21739130434782608, "fn": 23.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a plate with a breakfast dish made of bacon, bananas, and maple syrup. The bacon is cooked and crispy, while the bananas are sliced and placed on top of the bacon. The maple syrup is drizzled over the top of the dish. The plate is on a white surface, and a a"}, "285258": {"image_id": 285258, "Bleu_1": 0.24999999999632352, "Bleu_2": 0.14962640041392813, "Bleu_3": 0.08786869413347967, "Bleu_4": 1.0107582386846654e-05, "METEOR": 0.1841520418259455, "ROUGE_L": 0.17766990291262133, "CIDEr": 3.2119760978817197e-21, "SPICE": {"All": {"pr": 0.2, "re": 0.3684210526315789, "f": 0.25925925925925924, "fn": 12.0, "numImages": 1.0, "fp": 28.0, "tp": 7.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.14285714285714285, "f": 0.1, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.7142857142857143, "f": 0.4545454545454545, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}}, "caption": "The image shows a group of dogs playing in a fenced area. There are five dogs in the image, all of them are small to medium sized and have different colored fur. They are all standing on their hind legs and looking at each other. One of the dogs is wearing a collar and tag. The background of the image is a green grassy area with some trees"}, "96241": {"image_id": 96241, "Bleu_1": 0.28070175438104034, "Bleu_2": 0.1415984650784514, "Bleu_3": 0.07143616536435347, "Bleu_4": 9.06442292469654e-06, "METEOR": 0.21928449736302974, "ROUGE_L": 0.23448654585392636, "CIDEr": 2.106420232927915e-13, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.2, "f": 0.12500000000000003, "fn": 12.0, "numImages": 1.0, "fp": 30.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.125, "f": 0.10526315789473685, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a group of people standing next to a train that is parked on the tracks. The train is black and has a number 8 painted on the side. There are people standing on both sides of the train, looking at it. The background is a rural area with trees and buildings in the distance."}, "326911": {"image_id": 326911, "Bleu_1": 0.22727272726756204, "Bleu_2": 0.14540168172223333, "Bleu_3": 0.11472822500028991, "Bleu_4": 0.0926433478217715, "METEOR": 0.2562074608630539, "ROUGE_L": 0.285427807486631, "CIDEr": 1.0503749924163056e-07, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.1, "f": 0.09523809523809525, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a small black and white dog standing on the sidewalk next to a bicycle. The dog is looking at the camera with its tail wagging. The background of the image is a cobblestone street with trees and buildings in the distance."}, "527529": {"image_id": 527529, "Bleu_1": 0.2340425531865098, "Bleu_2": 0.10087498788996685, "Bleu_3": 0.06092349727774221, "Bleu_4": 8.466919880732135e-06, "METEOR": 0.17595075114998024, "ROUGE_L": 0.20847573479152426, "CIDEr": 2.165494762253116e-09, "SPICE": {"All": {"pr": 0.16, "re": 0.23529411764705882, "f": 0.19047619047619052, "fn": 13.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.6, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a white cat sitting on top of a black bag that is hanging from the handle of a door. The cat is looking up at the camera with its eyes. There are several other bags and boxes on the floor next to the door."}, "516212": {"image_id": 516212, "Bleu_1": 0.23333333332944448, "Bleu_2": 0.19886684640115515, "Bleu_3": 0.17603360743951676, "Bleu_4": 0.15479815867447325, "METEOR": 0.34735941070817583, "ROUGE_L": 0.35390295358649787, "CIDEr": 7.993990694064384e-14, "SPICE": {"All": {"pr": 0.3448275862068966, "re": 0.35714285714285715, "f": 0.3508771929824561, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 10.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5333333333333333, "re": 0.6153846153846154, "f": 0.5714285714285715, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 8.0}}, "caption": "The image shows a cat sitting on top of a microwave oven in a kitchen. The cat is looking directly at the camera with its eyes. The microwave oven has a plate of food on top of it, and there are several other kitchen appliances in the background, including a refrigerator, stove, and sink. The walls are white and there"}, "208132": {"image_id": 208132, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.17131872291347974, "Bleu_3": 0.1413162504531272, "Bleu_4": 0.12197379410072966, "METEOR": 0.2915219081315538, "ROUGE_L": 0.27949599083619703, "CIDEr": 1.598096682438059e-11, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.22727272727272727, "f": 0.19607843137254902, "fn": 17.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a table with a plate of food on it. There are several glasses of red wine on the table, as well as a bottle of ketchup and a bottle of mustard. There is also a knife and a fork on the table. The background of the image is dark and blurry."}, "289264": {"image_id": 289264, "Bleu_1": 0.19999999999555562, "Bleu_2": 0.11677484162160401, "Bleu_3": 0.0681935615181132, "Bleu_4": 9.321701825196602e-06, "METEOR": 0.15781010830518202, "ROUGE_L": 0.25258799171842644, "CIDEr": 4.009863821629396e-08, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.21739130434782608, "f": 0.19607843137254902, "fn": 18.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.4444444444444444, "f": 0.33333333333333337, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image shows a brown dog sitting on a windowsill looking out at the view. The dog is wearing a collar and appears to be looking out at the rain outside. The background is a dark green color with a few clouds in the sky."}, "18014": {"image_id": 18014, "Bleu_1": 0.3888888888780865, "Bleu_2": 0.23570226038887507, "Bleu_3": 0.11778306710176518, "Bleu_4": 1.4917074526131141e-05, "METEOR": 0.20306147868680155, "ROUGE_L": 0.25673400673400676, "CIDEr": 4.409727186141277e-05, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.17857142857142858, "f": 0.17241379310344826, "fn": 23.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.08333333333333333, "f": 0.1, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4, "f": 0.34782608695652173, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image is a pizza box with a slice of pizza inside. The pizza has a crispy crust and toppings such as vegetables, meat, and cheese. The box is open and the pizza is visible inside."}, "497348": {"image_id": 497348, "Bleu_1": 0.3617021276518787, "Bleu_2": 0.25080812955550935, "Bleu_3": 0.1612614844344404, "Bleu_4": 0.09880634191227361, "METEOR": 0.25005301235805133, "ROUGE_L": 0.30367143746110764, "CIDEr": 6.036652155512065e-08, "SPICE": {"All": {"pr": 0.15, "re": 0.13043478260869565, "f": 0.13953488372093023, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a street with a sign that reads \"no through traffic\". The road is lined with trees on both sides and there are houses on the left and right sides of the road. The sky is cloudy and there are some clouds in the background."}, "413404": {"image_id": 413404, "Bleu_1": 0.21212121211799817, "Bleu_2": 0.1399300524541518, "Bleu_3": 0.0848966731474613, "Bleu_4": 9.927339321042857e-06, "METEOR": 0.19069363629328312, "ROUGE_L": 0.2150050352467271, "CIDEr": 5.963630782131652e-19, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.38461538461538464, "f": 0.24390243902439027, "fn": 8.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5714285714285714, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a park with several benches and trees. There are people walking on the sidewalks and some are sitting on the benches. The park has a paved path that leads to a building in the background. The building appears to be a restaurant or cafe. There are cars parked on the street in front of the building. The sky is cloudy and there is"}, "530624": {"image_id": 530624, "Bleu_1": 0.1969696969667126, "Bleu_2": 0.12309149097745338, "Bleu_3": 0.06186220039404225, "Bleu_4": 7.829497418405435e-06, "METEOR": 0.20816459438154838, "ROUGE_L": 0.21243781094527364, "CIDEr": 1.1465016158633575e-19, "SPICE": {"All": {"pr": 0.125, "re": 0.17647058823529413, "f": 0.14634146341463414, "fn": 14.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.75, "f": 0.4285714285714285, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a brown and white dog lying under a floral patterned blanket on a bed. The dog is curled up and appears to be sleeping. The bed is covered with a floral patterned quilt and there are pillows on either side of the dog. The room appears to be a bedroom with a window on the left side of the image and a door"}, "43448": {"image_id": 43448, "Bleu_1": 0.3134328358162174, "Bleu_2": 0.20673858190240743, "Bleu_3": 0.13803733525913842, "Bleu_4": 0.09521599948403056, "METEOR": 0.2192489434007332, "ROUGE_L": 0.2561829211385907, "CIDEr": 1.7849434464526192e-12, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.19047619047619047, "f": 0.1818181818181818, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows two elephants standing on a rocky beach with trees in the background. The elephants are brown and have large ears and tusks. They are standing next to each other and appear to be looking at something in the distance. The sky is blue and there are clouds in the background. The image is taken from a low angle, giving the impression of being on"}, "516508": {"image_id": 516508, "Bleu_1": 0.23913043477741028, "Bleu_2": 0.12626174790809142, "Bleu_3": 0.07129027762233402, "Bleu_4": 9.580884740728586e-06, "METEOR": 0.1685714285714286, "ROUGE_L": 0.2121001390820584, "CIDEr": 8.284165344983304e-09, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.2857142857142857, "f": 0.18181818181818182, "fn": 10.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 1.0, "f": 0.18181818181818182, "fn": 0.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This image shows a large, ornate clock hanging on the wall of a church. The clock has two hands and is surrounded by intricate carvings on the walls. The room is dimly lit, with only a small amount of light coming from the stained glass windows."}}}